<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python on Phạm Duy Tùng Machine Learning Blog</title>
    <link>/tags/python/</link>
    <description>Recent content in python on Phạm Duy Tùng Machine Learning Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2016-{year} Phạm Duy Tùng. All Rights Reserved.</copyright>
    <lastBuildDate>Sun, 11 Apr 2021 00:19:00 +0300</lastBuildDate><atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tinh chỉnh thuật toán XGBoost  với Learning Curves</title>
      <link>/blog/2021-04-11-xgboost_learning_curves/</link>
      <pubDate>Sun, 11 Apr 2021 00:19:00 +0300</pubDate>
      
      <guid>/blog/2021-04-11-xgboost_learning_curves/</guid>
      <description>Giới thiệu Trong quá trình giải các bài toán có sử dụng machine learning, vì để làm nhanh nên đôi khi mình sẽ sử dụng các tham số mặc định của mô hình để train. Một phần vì lý do chúng ta không biết cách chỉnh các tham só như thế nào, so với cái gì để có mô hình huấn luyện là tốt nhất. Ở bài viết này, mình sẽ sử dụng Learning Curves để tối ưu hóa các tham số của XGBoost.</description>
    </item>
    
    <item>
      <title>Tìm hiểu thuật toán tối ưu hóa Adabelief Optimizer</title>
      <link>/blog/2021-01-15-adabelief-optimizer/</link>
      <pubDate>Fri, 15 Jan 2021 00:19:00 +0300</pubDate>
      
      <guid>/blog/2021-01-15-adabelief-optimizer/</guid>
      <description>Giới thiệu Hi các bạn, lại là mình đây, hôm nay mình sẽ cùng các bạn tìm hiểu thuật toán tối ưu hóa AdaBelief. Thuật toán này được sử dụng để thay cho thuật toán Adam optimizer mà các bạn hiện đang xài để huấn luyện mô hình Deep learning. Nào, chúng ta cùng bắt đầu tìm hiểu nhé.
Ẩn sâu bên trong các thuật toán sử dụng Neural Network và một vài thuật toán machine learning đều sử dụng các hàm tối ưu hóa.</description>
    </item>
    
    <item>
      <title>Reinforcement Learning và tictactoe</title>
      <link>/blog/2020-12-26-tic-tac-toe/</link>
      <pubDate>Sun, 27 Dec 2020 00:19:00 +0300</pubDate>
      
      <guid>/blog/2020-12-26-tic-tac-toe/</guid>
      <description>Advantages of Reinforcement Learning Trong khi trong các phương pháp lý thuyết trò chơi nói chung, ví dụ thuật toán min-max, thuật toán luôn giả định chúng ta có một đối thủ hoàn hảo, công việc phải thực hiện là tối đa hóa phần thưởng của mình và giảm thiểu phần thưởng của đối thủ ( tối đa hóa điểm của mình và tối thiểu hóa điểm của đối thủ), trong học củng cố, chúng ta không cần giả định đối thủ của chúng ta là 1 thiên tài xuất chúng, nhưng chung ta vẫn thu được mô hình với kết quả rất tốt.</description>
    </item>
    
    <item>
      <title>Xây dựng game xếp gạch bằng opencv và python</title>
      <link>/blog/2020-12-25-tetric/</link>
      <pubDate>Sat, 26 Dec 2020 00:19:00 +0300</pubDate>
      
      <guid>/blog/2020-12-25-tetric/</guid>
      <description>Mã nguồn 1 2import cv2 3import numpy as np 4from random import choice 5 6def getColor(): 7	lstColor = [[255,64,64],[255,165,0],[255,244,79],[102,255,0],[172,229,238],[148,87,235],[148,87,235],[241,156,187]] 8	return choice(lstColor) 9 10def getInfo(piece): 11	if piece == &amp;#34;&amp;#34;: 12	coords = np.array([[0, 0]]) 13	elif piece == &amp;#34;I&amp;#34;: 14	coords = np.array([[0, 3], [0, 4], [0, 5], [0, 6]]) 15	elif piece == &amp;#34;T&amp;#34;: 16	coords = np.array([[1, 3], [1, 4], [1, 5], [0, 4]]) 17	elif piece == &amp;#34;L&amp;#34;: 18	coords = np.</description>
    </item>
    
    <item>
      <title>Ngưỡng (thresholding) trong opencv</title>
      <link>/blog/2020-12-24-thresholding/</link>
      <pubDate>Fri, 25 Dec 2020 00:19:00 +0300</pubDate>
      
      <guid>/blog/2020-12-24-thresholding/</guid>
      <description>Giá trị ngưỡng: Nói theo kiểu lúa hóa, trong opencv, ngưỡng là một số nằm trong đoạn từ 0 đến 255. Giá trị ngưỡng sẽ chia tách giá trị độ xám của ảnh thành 2 miền riêng biệt. Miền thứ nhất là tập hợp các điểm ảnh có giá trị nhỏ hơn giá trị ngưỡng. Miền thứ hai là tập hợp các các điểm ảnh có giá trị lớn hơn hoặc bằng giá trị ngưỡng.</description>
    </item>
    
    <item>
      <title>Simhash</title>
      <link>/blog/2020-01-26-simhash/</link>
      <pubDate>Sun, 26 Jan 2020 00:19:00 +0300</pubDate>
      
      <guid>/blog/2020-01-26-simhash/</guid>
      <description>Đặt vấn đề Giả sử bạn và tôi đều thích nghe nhạc trên trang mp3.zing.vn. Mỗi người đều nghe khoảng 100 bài nhạc khác nhau. Để đo sự giống nhau giữa danh sách bài hát bạn nghe và danh sách bài hát tôi nghe, thông thường chúng ta sẽ dùng độ đo Jaccard Similarity, được đo bằng cách lấy phần giao (intersection ) chia cho phần hợp (union). Nghĩa là đếm số lượng bài hát cả hai cùng nghe (phần giao) chia cho tổng số bài hát không lặp của cả hai.</description>
    </item>
    
    <item>
      <title>Các hàm hash có sẵn trong python</title>
      <link>/blog/2020-01-13-hash-in-python/</link>
      <pubDate>Sat, 25 Jan 2020 00:19:00 +0300</pubDate>
      
      <guid>/blog/2020-01-13-hash-in-python/</guid>
      <description>Built-In Hashing Python có xây dựng sẵn cho chúng ta một hàm hash, chúng ta cứ việc gọi ra và sử dụng.
1hash(&amp;#34;pham duy tung&amp;#34;) 2-7141560399917772220 Một lưu ý nhỏ là giá trị của hàm hash sẽ khác nhau giữa các phiên bản python. Ví dụ ở trên mình xài python 3.8, với bản 3.6 sẽ là
1hash(&amp;#34;pham duy tung&amp;#34;) 21568935795476364190 Checksums Chúng ta có thể sử dụng checksums để hash dữ liệu.</description>
    </item>
    
    <item>
      <title>Lựa chọn siêu tham số cho mô hình LSTM đơn giản sử dụng Keras</title>
      <link>/blog/2019-02-06-choosing-the-right-hyperparameters-for-a-simple-lstm-using-keras/</link>
      <pubDate>Wed, 06 Feb 2019 00:20:00 +0300</pubDate>
      
      <guid>/blog/2019-02-06-choosing-the-right-hyperparameters-for-a-simple-lstm-using-keras/</guid>
      <description>Mở đầu Việc xây dựng một mô hình machine learning chưa bao giờ thật sự dễ dàng. Rất nhiều bài báo chỉ &amp;ldquo;show hàng&amp;rdquo; những thứ cao siêu, những thứ chỉ nằm trong sự tưởng tượng của chính các nhà báo. Còn khi đọc các bài báo khoa học về machine learning, tác giả công bố cho chúng ta những mô hình rất tốt, giải quyết một domain nhỏ vấn đề của họ.</description>
    </item>
    
    <item>
      <title>Giảm bộ nhớ sử dụng trong python</title>
      <link>/blog/2019-02-06-how-to-reduce-memory-consumption-by-half-by-adding-just-one-line-of-code/</link>
      <pubDate>Wed, 06 Feb 2019 00:19:00 +0300</pubDate>
      
      <guid>/blog/2019-02-06-how-to-reduce-memory-consumption-by-half-by-adding-just-one-line-of-code/</guid>
      <description>Mở đầu Bắt đầu bằng một class đơn giản như sau:
1class DataItem(object): 2 def __init__(self, name, age, address): 3 self.name = name 4 self.age = age 5 self.address = address Bạn nghĩ một đối tượng của class trên sẽ chiếm bao nhiêu bộ nhớ. Chúng ta cùng tiến hành một vài thí nghiệm nho nhỏ bên dưới.
1dx = DataItem(&amp;#34;Alex Black&amp;#34;, 42, &amp;#34;-&amp;#34;) 2print (&amp;#34;sys.getsizeof(dx):&amp;#34;, sys.getsizeof(dx)) 3&amp;gt;&amp;gt; sys.getsizeof(dx): 56 Kết quả ra là 56 bytes, khá hợp lý phải không các bạn.</description>
    </item>
    
    <item>
      <title>5 mẹo hay sử dụng python</title>
      <link>/blog/2019-02-05-5-python-tricks-you-need-to-know-today/</link>
      <pubDate>Tue, 05 Feb 2019 00:19:00 +0300</pubDate>
      
      <guid>/blog/2019-02-05-5-python-tricks-you-need-to-know-today/</guid>
      <description>Mở đầu Hiện nay, có rất nhiều thư viện do cộng đồng đóng góp và xây dựng. Ví dụ như biopython trong tin sinh học, pandas (data science), keras/tensorflow (machine learning), astropy ( cho thiên văn học - astronomy). Trước khi bắt đầu đọc bài viết này, bạn đên đọc &amp;ldquo;Python Tricks Book&amp;rdquo; của Dan Bader trước (https://dbader.org/products/python-tricks-book/). Trong sách, anh ấy đã chia sẻ một số lời khuyên và mẹo về các code python hiệu quả hơn.</description>
    </item>
    
  </channel>
</rss>
