<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine learning on Phạm Duy Tùng Machine Learning Blog</title>
    <link>/tags/machine-learning/</link>
    <description>Recent content in machine learning on Phạm Duy Tùng Machine Learning Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>alexblack2202@gmail.com (Phạm Duy Tùng)</managingEditor>
    <webMaster>alexblack2202@gmail.com (Phạm Duy Tùng)</webMaster>
    <copyright>&amp;copy; 2018 Phạm Duy Tùng. Website chia sẻ kiến thức của Phạm Duy Tùng và Đặng Thị Hằng. Vui lòng liên hệ email alexblack2202@gmail.com nếu bạn có thông tin cần trao đổi.</copyright>
    <lastBuildDate>Thu, 12 Aug 2021 00:19:00 +0300</lastBuildDate>
    <atom:link href="/tags/machine-learning/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Xây dựng chương trình AI đơn giản cho game cờ tướng</title>
      <link>/blog/2021-08-12-china_chess_alpha_beta_ai/</link>
      <pubDate>Thu, 12 Aug 2021 00:19:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2021-08-12-china_chess_alpha_beta_ai/</guid>
      <description>

&lt;h1 id=&#34;giới-thiệu&#34;&gt;Giới thiệu&lt;/h1&gt;

&lt;p&gt;Cờ tướng là một môn thể thao khá phổ biến ở Việt Nam. Các bạn có thể bắt gặp các bàn cờ ở các con hẻm của mỗi góc phố. Hoặc là khi các bộ bàn ghế đá thì người mua cũng thường nhờ thợ khắc lên bàn cờ tướng để hàng xóm láng giềng giải trí ngày cuối tuần. Trong bài viết này, mình sẽ hướng dẫn step by step ứng dụng chơi game cờ tướng đơn giản với một chút AI. Hi vọng sẽ giúp được các bạn trên con đường thực hành máy học.&lt;/p&gt;

&lt;p&gt;Các việc cần làm:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Tạo bàn cờ và sinh nước đi&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Lượng giá bàn cờ&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Áp dụng minimax&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Áp dụng cắt tỉa alpha, beta&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Bạn có thể chơi thử game cờ tướng mình có post ở đây:  &lt;a href=&#34;https://www.phamduytung.com/games/china_chess/&#34;&gt;https://www.phamduytung.com/games/china_chess/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;bước-1-tạo-bàn-cờ-và-sinh-nước-đi&#34;&gt;Bước 1: Tạo bàn cờ và sinh nước đi&lt;/h1&gt;

&lt;p&gt;Mình không có gỏi lắm trong việc thiết kế mấy icon cho mấy con tướng, sĩ, tượng. Ngoài ra, công việc chính của chúng ta là phần làm sao cho máy tự đánh được, nên phần này mình sẽ xài các open source có sẵn, lượn lờ một chút trên mạng thì mình đã lụm được cái bàn cờ ở link &lt;a href=&#34;https://github.com/lengyanyu258/xiangqiboardjs&#34;&gt;https://github.com/lengyanyu258/xiangqiboardjs&lt;/a&gt; và thư viện sinh nước đi xiangqi.js. Thư viện xiangqi.js đã có sẵn các hàm kiểm tra tính hợp lệ của nước đi, nên mình chỉ việc lấy ra rồi dùng thôi, khỏi mất công phải viết lại.&lt;/p&gt;

&lt;p&gt;Bàn cờ được chia làm 2 đội, là đội đen (black, ký hiệu b) và đội đỏ (red , ký hiệu r), mỗi đội gồm 16 quân, bao gồm 1 con tướng (General  hoặc king , ký hiệu k), 2 con sỹ (Advisor hoặc guards,  ministers, ký hiệu là a), 2 con tượng (Elephants hoặc bishops - ký hiệu là b), 2 con mã (Horses hoặc knights - ký hiệu là n, do chữ k trùng với king là con tướng, nên người ta xài chữ n), 2 con xe (Chariot hoặc rooks - ký hiệu là r), 2 con pháo (canons, ký hiệu là c ), 5 con chốt (Soldiers , ký hiệu là p ( do con chốt ở cờ đen và cờ đỏ có phiên âm tiếng trung khác nhau, chốt cờ đen đọc gần giống chữ &amp;ldquo;zú&amp;rdquo; (&amp;ldquo;pawn&amp;rdquo; hoặc &amp;ldquo;private&amp;rdquo; - tiếng anh), còn chốt cờ đỏ đọc là bing (&amp;ldquo;soldier&amp;rdquo; - tiếng anh) )).&lt;/p&gt;

&lt;p&gt;Tổng cộng, ta có tướng, sỹ, tượng, mã, xe, pháo, chốt, 7 loại quân, tương đương với 7 ký hiệu, tổ hợp với 2 đội là đỏ và đen, tổ hợp với nhau, ta xác định được&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/china_chess_base_board.png&#34; alt=&#34;AI Cờ tướng - Bàn cờ gốc&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Để bắt đầu, chúng ta sẽ code một hàm random bước đi đơn giản. Hàm có nhiệm vụ lấy ngẫu nhiên một bước đi trong danh sách các bước có thể đi, sau đó máy sẽ đánh bước đi đó.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;

function makeRandomMove () {
  let possibleMoves = game.moves();

  // game over
  if (possibleMoves.length === 0) return; // Không còn nước nào có thể đi, end game

  let randomIdx = Math.floor(Math.random() * possibleMoves.length); // bốc đại 1 nước đi trong danh sách các bước có thể đi
  game.move(possibleMoves[randomIdx]);
  board.position(game.fen());
}


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/china_chess_simple_move.gif&#34; alt=&#34;AI Cờ tướng - đi ngẫu nhiên&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Do thuật toán chúng ta cho máy chạy khá là ngốc, nên nó đánh cũng hơi ngốc. :)&lt;/p&gt;

&lt;h1 id=&#34;bước-2-hàm-lượng-giá&#34;&gt;Bước 2: Hàm lượng giá&lt;/h1&gt;

&lt;p&gt;Dựa vào mức độ cơ động, tầm quang trọng của mỗi quân lính trên bàn cờ, chúng ta sẽ gán cho mỗi quân cờ một trọng số khác nhau thể hiện điều đó.&lt;/p&gt;

&lt;p&gt;Ví dụ, chúng ta set các trọng số như sau:&lt;/p&gt;

&lt;p&gt;tướng của ta là 900 điểm, tướng của đối thủ là -900 điểm&lt;/p&gt;

&lt;p&gt;sỹ của ta là 20 điểm, sỹ của đối thủ là -20 điểm&lt;/p&gt;

&lt;p&gt;tượng của ta là 20 điểm, tượng của đối thủ là -20 điểm&lt;/p&gt;

&lt;p&gt;mã của ta là 40 điểm, mã của đối thủ là -40 điểm&lt;/p&gt;

&lt;p&gt;xe của ta là 90 điểm, xe của đối thủ là -90 điểm&lt;/p&gt;

&lt;p&gt;pháo của ta là 45 điểm, pháo của đối thủ là -45 điểm&lt;/p&gt;

&lt;p&gt;chốt của ta là 15 điểm, chốt của đối thủ là -15 điểm&lt;/p&gt;

&lt;p&gt;Hàm lượng giá ở trên khá ngây thơ, mọi quân cờ đều có điểm ngang nhau, không quan tâm vị trí đứng của nó.&lt;/p&gt;

&lt;p&gt;Trên thực tế, chúng ta thấy rằng, con tướng ở vị trí trung tâm thường là an toàn nhất, một khi  tướng leo lên lầu 1 hoặc leo lầu 2, nghĩa là con tướng có khả năng bị đột tử cao hơn, nên chúng ta phải tinh chỉnh lại điểm của con tướng trong trường hợp này.&lt;/p&gt;

&lt;p&gt;Một ví dụ nữa là vị trí con mã, mã gần với thành của tướng địch hơn thì khả năng con xe chiếu bí tướng địch sẽ cao hơn con mã chưa qua sông.&lt;/p&gt;

&lt;p&gt;Giá trị lượng giá cho cờ tướng, các bạn có thể tham khảo ở link &lt;a href=&#34;https://github.com/markdirish/xiangqi/blob/master/evaluate.js&#34;&gt;https://github.com/markdirish/xiangqi/blob/master/evaluate.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Chúng ta sẽ duyệt lần lượt từ trái qua phải, từ trên xuống dưới, tính điểm của bàn cờ hiện tại.&lt;/p&gt;

&lt;p&gt;Hàm lượng giá của bàn cờ xét như sau:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;


function evaluateBoard(board) {
  var totalEvaluation = 0;
  for (var i = 0; i &amp;lt; 10; i++) {
    for (var j = 0; j &amp;lt; 9; j++) {
      totalEvaluation = totalEvaluation + getPieceValue(board[i][j], i ,j);
    }
  }
  return totalEvaluation;
}



function getPieceValue(piece, x, y) {
  if (piece === null) {
    return 0;
  }
  var getAbsoluteValue = function (piece, isRed, x ,y) {
    if (piece.type === &#39;p&#39;) { //chốt
      return 15 + ( isRed ? pEvalRed[x][y] : pEvalBlack[x][y] );
    } else if (piece.type === &#39;r&#39;) { //Xe
      return 90 +( isRed ? rEvalRed[x][y] : rEvalBlack[x][y] );
    } else if (piece.type === &#39;c&#39;) { //pháo
      return 45 +( isRed ? cEvalRed[x][y] : cEvalBlack[x][y] );
    } else if (piece.type === &#39;n&#39;) { // mã
      return 40 +( isRed ? nEvalRed[x][y] : nEvalBlack[x][y] );
    } else if (piece.type === &#39;b&#39;) { // tượng
      return 20 +( isRed ? bEvalRed[x][y] : bEvalBlack[x][y] );
    } else if (piece.type === &#39;a&#39;) { // sỹ
      return 20 +( isRed ? aEvalRed[x][y] : aEvalBlack[x][y] );
    } else if (piece.type === &#39;k&#39;) { // tướng
      return 900 +( isRed ? kEvalRed[x][y] : kEvalBlack[x][y] );
    }
    throw &amp;quot;Unknown piece type: &amp;quot; + piece.type;
  };

  var absoluteValue = getAbsoluteValue(piece, piece.color === &#39;r&#39;, x ,y);
  return piece.color === &#39;r&#39; ? absoluteValue : -absoluteValue;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bây giờ, chúng ta chỉ cần duyệt qua toàn bộ các nước có thể đi, tính xem nước đi nào có điểm số là lớn nhất, thì máy sẽ đi theo nước đi đó.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;

function getBestMove(game) {

var newGameMoves = game.moves();
var bestMove = null;
// set đại một số âm vô hạn
var bestValue = -9999;

for (var i = 0; i &amp;lt; newGameMoves.length; i++) {
    var newGameMove = newGameMoves[i];
    game.move(newGameMove);

    var boardValue = -evaluateBoard(game.board())
    game.undo();
    if (boardValue &amp;gt; bestValue) {
        bestValue = boardValue;
        bestMove = newGameMove
    }
}

return bestMove;

};

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Vì vậy, ngoài việc xét điểm cho các loại quân, chúng ta sẽ có một bảng xét điểm cho các con&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/china_chess_evaluation.gif&#34; alt=&#34;AI Cờ tướng - Chọn nước đi tốt nhất&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Kết quả có vẻ tốt hơn so với việc random bước đi trước đó, nhưng thuật toán vẫn còn hơi dốt dốt xíu,  do máy chỉ tính 1 nước đi và chọn ra nước đi tốt nhất. Nên máy chưa có cái nhìn dài hơn. Có nhiều cách để cho máy có thể có góc nhìn xa hơn về thế cục của bàn cờ, một trong các cách được giới thiệu ở đây là sử dụng minimax&lt;/p&gt;

&lt;h1 id=&#34;bước-3-tìm-kiếm-cây-sử-dụng-minimax&#34;&gt;Bước 3. Tìm kiếm cây sử dụng minimax&lt;/h1&gt;

&lt;p&gt;Thuật toán minimax thuộc nhóm duyệt theo chiều sâu (depth first search). Hai người chơi, một người được gọi là MAX, người còn lại gọi là MIN. Thuật toán được thiết kế để tìm nước đi tối ưu cho người MAX. Người MAX sẽ giữ node gốc, lần lượt duyệt đệ quy qua tất cả các node con theo chiều sâu nhất định đến khi duyệt qua tất cả các node hoặc là tìm được một đường đi mà đạt MAX.&lt;/p&gt;

&lt;p&gt;Chi tiết hơn, người MAX sẽ đi đầu tiên. Nhiệm vụ của MAX là tìm nước đi sao cho điểm số của mình là cao nhất, nhiệm vụ của MIN là tìm nước đi để cực tiểu hoá điểm số của MAX.&lt;/p&gt;

&lt;p&gt;Các bạn có thể đọc thêm ở link &lt;a href=&#34;https://en.wikipedia.org/wiki/Minimax&#34;&gt;https://en.wikipedia.org/wiki/Minimax&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Để triển khai minimax, đầu tiên, chúng ta sẽ sửa lại hàm getBestMove ở trên, thay vì gọi lượng giá bàn cờ evaluateBoard, chúng ta sẽ gọi hàm minimax&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;

function minimaxRoot(depth, game, isMaximisingPlayer) {
  var newGameMoves = game.moves();
  var bestMove = -9999;
  var bestMoveFound;

  for(var i = 0; i &amp;lt; newGameMoves.length; i++) {
    var newGameMove = newGameMoves[i]
    game.move(newGameMove);
    var value = minimax(depth - 1, game, !isMaximisingPlayer);
    game.undo();
    if(value &amp;gt;= bestMove) {
      bestMove = value;
      bestMoveFound = newGameMove;
    }
  }
  return bestMoveFound;
}


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;với hàm minimax cũng cùng ý tưởng với hàm getBestMove ở trên, nhưng ta sẽ gọi đệ quy, luân phiên tính điểm máy, sau đó tính điểm người &amp;hellip; theo độ sâu ta đã thiết lập, để tìm ra đường đi có số điểm là lớn nhất.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;
function minimax (depth, game, isMaximisingPlayer) {
    if (depth === 0) {
        return -evaluateBoard(game.board());
    }
    var newGameMoves = game.moves();
    if (isMaximisingPlayer) {
        var bestMove = -9999;
        for (var i = 0; i &amp;lt; newGameMoves.length; i++) {
            game.move(newGameMoves[i]);
            bestMove = Math.max(bestMove, minimax(depth - 1, game, !isMaximisingPlayer));
            game.undo();
        }
        return bestMove;
    } else {
        var bestMove = 9999;
        for (var i = 0; i &amp;lt; newGameMoves.length; i++) {
            game.move(newGameMoves[i]);
            bestMove = Math.min(bestMove, minimax(depth - 1, game, !isMaximisingPlayer));
            game.undo();
        }
        return bestMove;
    }
};

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thuật toán này hoạt động khá hiệu quả, nhưng có một điểm yếu là nó sẽ vét cạn toàn bộ các trường hợp để tìm ra đường đi tối ưu nhất. Vì vậy, với giá trị độ sâu càng lớn thì thuật toán chạy càng chậm.&lt;/p&gt;

&lt;h1 id=&#34;bước-4-cắt-tỉa-alpha-beta&#34;&gt;Bước 4: Cắt tỉa Alpha - Beta&lt;/h1&gt;

&lt;p&gt;Cắt tỉa Alpha - Beta là một phương pháp tối ưu hoá của thuật toán minimax, phương pháp này giúp chúng ta bỏ qua một vài nhánh trong quá trình tìm kiếm, làm giới hạn phạm vi tìm kiếm, giúp mô hình hoạt động nhanh hơn.&lt;/p&gt;

&lt;p&gt;Thuật toán sẽ hoạt động hiệu quả hơn nếu những bước tìm kiếm đầu tiên là những nước đi tốt nhất :)&lt;/p&gt;

&lt;p&gt;Hàm minimax với alpla, beta được viết lại như sau&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;


function minimax(depth, game, alpha, beta, isMaximisingPlayer) {
  positionCount++;
  if (depth === 0) {
    return -evaluateBoard(game.board());
  }

  var newGameMoves = game.moves();

  if (isMaximisingPlayer) {
    var bestMove = -9999;
    for (var i = 0; i &amp;lt; newGameMoves.length; i++) {
      game.moves(newGameMoves[i]);
      bestMove = Math.max(bestMove, minimax(depth - 1, game, alpha, beta, !isMaximisingPlayer));
      game.undo();
      alpha = Math.max(alpha, bestMove);
      if (beta &amp;lt;= alpha) {
        return bestMove;
      }
    }
    return bestMove;
  } else {
    var bestMove = 9999;
    for (var i = 0; i &amp;lt; newGameMoves.length; i++) {
      game.moves(newGameMoves[i]);
      bestMove = Math.min(bestMove, minimax(depth - 1, game, alpha, beta, !isMaximisingPlayer));
      game.undo();
      beta = Math.min(beta, bestMove);
      if (beta &amp;lt;= alpha) {
        return bestMove;
      }
    }
    return bestMove;
  }
}


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/china_chess_maxmin.gif&#34; alt=&#34;AI Cờ tướng với cắt tỉa alpha-beta Minimax&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi bài viết. Xin chào và hẹn gặp lại các bạn ở bài viết kế tiếp.&lt;/p&gt;

&lt;p&gt;Các bạn có thể chơi game ở đây nha , link &lt;a href=&#34;https://www.phamduytung.com/games/china_chess/&#34;&gt;https://www.phamduytung.com/games/china_chess/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Mình sẽ update dần giao diện để cho game trở nên đẹp đẹp hơn.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hai khái niệm quan trọng giúp tăng độ chính xác của các mô hình trong machine learning</title>
      <link>/blog/2020-04-16-two-important-machine-learning-concepts-to-improve-every-model/</link>
      <pubDate>Sun, 26 Jan 2020 00:19:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2020-04-16-two-important-machine-learning-concepts-to-improve-every-model/</guid>
      <description>

&lt;p&gt;Việc huấn luyên mô hình máy học có thể sẽ gây ra cho bạn một chút khó khăn nếu bạn không hiểu những thứ bạn dang làm là đúng hay sai. Trong hầu hết các trường hợp, các mô hình học máy là các &amp;ldquo;hộp đen&amp;rdquo;, chúng ta chỉ có thể &amp;ldquo;nhìn thấy&amp;rdquo; dữ liệu đầu vào và độ chính xác mà mô hình trả ra. Chúng ta không biết bên trong nó đang làm cái gì. Việc hiểu lý do tại sao mô hình cho ra kết quả tệ hại là chìa khóa cho cái &amp;ldquo;cách&amp;rdquo; mà bạn cải tiến nó.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Tìm hiểu lý do &amp;ldquo;tại sao&amp;rdquo; mô hình cho ra kết quả tệ hại bằng cách &amp;ldquo;xác định bias và variance&amp;rdquo;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Tìm hiểu &amp;ldquo;cách&amp;rdquo; cải tiến mô hình bằng việc thực hiện &amp;ldquo;giảm bias và variance&amp;rdquo;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;xác-định-bias-và-variance&#34;&gt;Xác định bias và variance&lt;/h1&gt;

&lt;p&gt;Trước hết, chúng ta hãy bắt đầu nói về lỗi. Lỗi là phần không chính xác của mô hình trên tập test.&lt;/p&gt;

&lt;p&gt;$$ error = 1 - testing accuracy $$&lt;/p&gt;

&lt;p&gt;Nếu mô hình đạt độ chính xác  là 86% trên tập test, điều đó đồng nghĩa với độ lỗi là 14%. Trong 14% đó bao gồm bias và variance.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/bias_variance.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Biểu đồ bias - variance. Nguồn towardsdatascience.com&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Hai ý chính của hình trên cần làm rõ ở đây:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Bias là lỗi trên tập huấn luyện.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Variance  là gap giữa độ chính xác trên tập train và độ chính xác trên tập test.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Bạn hãy hình thật kỹ vào hình ở trên, nhìn đi nhìn lại 2, 3 lần. Nhắm mắt lại và nghiền ngẫm thật kỹ hai ý chính mình vừa đề cập ở trên.&lt;/p&gt;

&lt;h2 id=&#34;bias&#34;&gt;Bias&lt;/h2&gt;

&lt;p&gt;Bias mô tả khả năng học của mô hình. Giá trị bias lớn đồng nghĩa với việc mô hình cần phải học nhiều hơn nữa từ tập huấn luyện.&lt;/p&gt;

&lt;p&gt;Nếu mô hình có độ chính xác 90% trên tập train, điều đó đồng nghĩa với việc bạn có 10% bias. Bias cũng được chia làm 2 nhóm, nhóm bias có thể tránh được (avoidable bias) và nhóm bias không thể tránh được (unavoidable bias).&lt;/p&gt;

&lt;p&gt;$$ bias = 1 - trainning accuracy $$&lt;/p&gt;

&lt;h3 id=&#34;unavoidable-bias&#34;&gt;Unavoidable bias&lt;/h3&gt;

&lt;p&gt;Unavoidable bias hay còn được sử dụng dưới tên là optimal error rate. Đây là giới hạn trên của mô hình. Trong một số bài toán, ví dụ như là bài toán dự đoán giá chứng khoán, chúng ta - con người -  không thể dự đoán chính xác 100%. Do đó, trong điều kiện lý tưởng nhất, tại một thời điểm nào đó, mô hình của chúng ta vẫn cứ trả ra kết quả sai.&lt;/p&gt;

&lt;p&gt;Nếu bạn quyết định rằng mô hình có độ sai ít nhất là 4%. Nghĩa là chúng ta có 4% unavoidable bias.&lt;/p&gt;

&lt;h3 id=&#34;avoidable-bias&#34;&gt;Avoidable bias&lt;/h3&gt;

&lt;p&gt;Khác với optimal error rate và trainning error. Độ lỗi này xảy ra khi mô hình chúng ta chưa đủ độ tới. Chúng ta hoàn toàn có thể cái tiến mô hình này để giảm độ lỗi này về mức 0, v&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/bias-variance-avoidable_bias.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Biểu đồ bias - variance. Nguồn towardsdatascience.com&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Bạn hãy để ý kỹ phần bias ở hình trên. Bias được chia làm 2 phần. Ở trên phần nét đứt là Unavoidable bias. Nó là điểm tới hạn của mô hình. Việc cần làm của chúng ta là huấn luyện, cải tiến mô hình, để cho đường trainning accuracy  màu đỏ tiến sát với đường nét đứt.&lt;/p&gt;

&lt;h2 id=&#34;variance&#34;&gt;Variance&lt;/h2&gt;

&lt;p&gt;Variance ý nghĩa của nó là mô tả mức độ tổng quát hóa của mô hình của bạn đối với dữ liệu mà nó chưa được huấn luyện. Và định nghĩa của nó là phần sai lệch giữa độ chính xác trên tập huấn luyện và độ chính xác tên tập test.&lt;/p&gt;

&lt;p&gt;$$ Variance = trainning accuracy - testing accuracy $$&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/variance.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Biểu đồ variance. Nguồn towardsdatascience.com&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;tradeoff-giữa-bias-và-variance&#34;&gt;Tradeoff giữa bias và variance&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/bias_variance_tradeoff.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Sự đánh đổi giữa bias và variace. Nguồn towardsdatascience.com&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Mình nghĩ hình trên đủ nói lên tất cả ý mình muốn nói. Khi mô hình cảng trở nên phức tạp, thì bias sẽ giảm, nhưng  mức độ tổng quát hóa cũng giảm theo (đồng nghĩa với việc variace sẽ tăng).&lt;/p&gt;

&lt;h2 id=&#34;cách-giảm-bias-và-variance&#34;&gt;Cách giảm bias và variance&lt;/h2&gt;

&lt;h3 id=&#34;cách-giảm-bias&#34;&gt;Cách giảm bias&lt;/h3&gt;

&lt;p&gt;Như đã nói ở phần trên, bias được chia thành 2 nhóm là Avoidable bias và unavoidable bias. Chúng ta không thể nào giảm Avoidable bias, nhưng chúng ta có thể giảm unavoidable bias bằng một trong các cách sau.&lt;/p&gt;

&lt;h4 id=&#34;tăng-kích-thước-mô-hình&#34;&gt;Tăng kích thước mô hình&lt;/h4&gt;

&lt;p&gt;Việc tăng kích thước mô hình là một trong những cách làm giảm avoidable bias. Mô hình càng lớn thì có càng nhiều tham số phải điều chỉnh. Có nhiều tham sos đồng nghĩa với việc mô hình sẽ học được nhiều mối quan hệ phức tạp hơn. Chúng ta có thể tăng kích thước mô hình bằng cách thêm nhiều layer hơn nữa, hoặc thêm nhiều node hơn nữa cho mỗi layer.&lt;/p&gt;

&lt;h4 id=&#34;giảm-regulation&#34;&gt;Giảm Regulation&lt;/h4&gt;

&lt;p&gt;Việc giảm regulation cũng giúp mô hình tăng độ chính xác trên tập huấn luyên. Tuy nhiên, nếu chúng ta giảm regularization  quá đà, mô hình sẽ không đạt được mức độ tổng quát hóa, và làm tăng variance. Đây là ví dụ dễ thấy nhất nhất về sự đánh đổi giữa bias và variance.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/reduce_bias_reducing_regulation.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Giảm Regulation . Nguồn towardsdatascience.com&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;thay-đổi-kiến-trúc-mô-hình&#34;&gt;Thay đổi kiến trúc mô hình&lt;/h4&gt;

&lt;p&gt;Việc thay đổi kiến trúc mô hình cũng có thể giúp chúng ta đạt được độ chính xác cao hơn.&lt;/p&gt;

&lt;p&gt;Một số mục có thể thay đổi:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Thay đổi activation function ( ví dụ tanh, ReLU, sigmoid, LeakyReLU)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Thay đổi loại mô hình (ANN, CNN, RNN, KNNKNN, &amp;hellip;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Thay đổi các tham số (learning rate, image size, &amp;hellip;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Thay đổi thuật toán tối ưu (Adam, SGD, RMSprop, …)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;thêm-đặc-trưng-mới&#34;&gt;Thêm đặc trưng mới&lt;/h4&gt;

&lt;p&gt;Việc thêm đặc trưng mới giúp chúng ta cung cấp cho mô hình nhiều thông tin hơn. Chúng ta có thể thực hiện điều này thông qua kỹ thuật feature engineering.&lt;/p&gt;

&lt;h3 id=&#34;giảm-variance&#34;&gt;Giảm variance&lt;/h3&gt;

&lt;h4 id=&#34;thêm-nhiều-dữ-liệu&#34;&gt;Thêm nhiều dữ liệu&lt;/h4&gt;

&lt;p&gt;Thêm dữ liệu là cách đơn giản nhất, thường gặp nhất để tăng độ chính xác của mô hình trong trường hợp mô hình huấn luyện của chúng ta bị hight variance. Hiệu quả của việc thêm nhiều dữ liệu vào mô hình đã được đề cập ở bài báo có tựa đề là  &lt;em&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/em&gt; của Andrej Karpathy (link: &lt;a href=&#34;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&#34;&gt;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&lt;/a&gt;). Việc thêm dữ liệu thường không ảnh hưởng đến độ lỗi bias, giúp làm giảm variance, nên đây là cách thường được sử dụng nhất.&lt;/p&gt;

&lt;h4 id=&#34;tăng-regularization&#34;&gt;Tăng Regularization&lt;/h4&gt;

&lt;p&gt;Việc tăng Regularization giúp mô hình chống overfitting. Qua đó giúp giảm variance, và tăng bias :(. Một só cách Regularization hot ở thời điểm hiện lại là dropout ( với biến thể là Monte Carlo Dropout), BatchNorm&amp;hellip;&lt;/p&gt;

&lt;h4 id=&#34;giảm-kích-thước-mô-hình&#34;&gt;Giảm kích thước mô hình&lt;/h4&gt;

&lt;p&gt;Việc giảm kích thước mô hình giúp cho chúng ta giảm overfitting trên tập train. Mục tiêu của Việc này làm giảm khả năng liên kết những pattern của dữ liệu. Bởi vậy, mục tiêu của nó hoàn toàn tương tự như tăng Regularization. Trong thực tế, chúng ta thường sử dụng tăng thêm Regularization hơn là giảm kích thước mô hình để chống variace.&lt;/p&gt;

&lt;h4 id=&#34;lựa-chọn-đặc-trưng-feature-selection&#34;&gt;Lựa chọn đặc trưng (feature selection)&lt;/h4&gt;

&lt;p&gt;Giảm chiều dữ liệu, bằng cách bỏ đi các đặc trưng thừa, giúp giảm nhiễu, là cách thường được sử dụng để giảm variace. Chúng ta có thể sử dụng PCA (Principal Component Analysis) để lọc ra các đặc trưng tốt hoặc kết hợp chúng với nhau để tạo các đặc trưng tốt hơn.&lt;/p&gt;

&lt;h2 id=&#34;bức-tranh-tổng-quát&#34;&gt;Bức tranh tổng quát&lt;/h2&gt;

&lt;p&gt;Sau tất cả, chúng ta sẽ xây dựng được một bức tranh tổng quan về lỗi chúng ta đang mắc phải là gì và chúng ta nên làm gì để giảm độ lỗi đó.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/bias_variance_overview.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Tổng quan . Nguồn towardsdatascience.com&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;tổng-kết&#34;&gt;Tổng kết&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Reducing Bias&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Increase model size&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reduce regularization&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Change model architecture&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Add features&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reducing Variance&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Add More data&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Decrease model size&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Add regularization&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Feature selection&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cảm ơn các bạn đã quan tâm và theo dõi bài viết, hẹn gặp bạn ở các bài viết tiếp theo.&lt;/p&gt;

&lt;p&gt;Bài viết được lược dịch từ link &lt;a href=&#34;https://towardsdatascience.com/two-important-machine-learning-concepts-to-improve-every-model-62fd058916b&#34;&gt;https://towardsdatascience.com/two-important-machine-learning-concepts-to-improve-every-model-62fd058916b&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Nguồn tự liệu từ bài viết được sử dụng trong cuốn sách Machine Learning Yearning của Andrew Ng. Các bạn có thể search theo từ khóa trên hoặc đăng ký trên site &lt;a href=&#34;http://deeplearning.net/&#34;&gt;http://deeplearning.net/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tìm hiểu mạng AlexNet, mô hình giành chiến thắng tại cuộc thi ILSVRC 2012</title>
      <link>/blog/2019-05-27-alexnet/</link>
      <pubDate>Mon, 27 May 2019 00:12:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-05-27-alexnet/</guid>
      <description>

&lt;p&gt;Trong bài viết này, chúng ta sẽ tìm hiểu mô hình AlexNet từ nhóm của giáo sư Hinton. Tới thời điểm hiện tại (2019-05-27), bài viết của giáo sư đã có hơn 40316 lượt trích dẫn. Bài báo này có bước đóng góp cực kỳ quan trọng, là một đột phá lớn trong lĩnh vực deep learning, mở đầu cho sự quay lại của mạng neural network và đóng góp trực tiếp vào thành công của những chương trình trí tuệ nhân tạo tại thời điểm hiện tại.&lt;/p&gt;

&lt;p&gt;Về bài báo gốc của tác giả, mình có để ở phần trích dẫn bên dưới. Các bạn có nhu cầu tìm hiểu có thể tìm và đọc. Theo ý kiến riêng của mình, đây là một bài báo &lt;em&gt;rất nên đọc và phải đọc&lt;/em&gt;. Trước đây mình đã có viết 1 bài về tập AlexNet nhưng chưa đầy đủ, bài đó mình chỉ giới thiệu phớt phớt qua mạng AlexNet. Trong bài viết này, mình sẽ trình bày kỹ hơn.&lt;/p&gt;

&lt;p&gt;Sơ lược một chút, tập dữ liệu ImageNet là tập dataset có khoảng 15 triệu hình ảnh có độ phân giải cao đã được gán nhãn (có khoảng 22000 nhãn). Cuộc thi ILSVRC  sử dụng một phần nhỏ của tập ImageNet với khoảng 1.2 triệu ảnh của 1000 nhãn (trung bình mỗi nhãn có khoảng 1.2 ngàn hình ảnh) làm tập train, 50000 ảnh làm tập validation và 150000 ảnh làm tập test (tập validation và tập test đều có 1000 nhãn thuộc tập train).&lt;/p&gt;

&lt;h1 id=&#34;kiến-trúc-mạng-alexnet&#34;&gt;Kiến trúc mạng AlexNet&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/alexnet_architecture.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Kiến trúc mô hình AlexNet&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Mạng AlexNet bao gồm 8 lớp (tính luôn lớp input là 9), bao gồm:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Input&lt;/em&gt;: có kích thước 224x224x3 (Scale ảnh đầu vào về dạng 224x224x3, thực chất ảnh của tập ImageNet có size tùy ý)&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Lớp thứ nhất&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Convolution Layer có kích thước 11x11x3 với stride size = 4 và pad = 0. Kết quả sau bước này ta được tập feature map có kích thước 55x55x96 (mình nghĩ là các bạn sẽ biết cách tính sao cho ra số 55, mình cũng đã đề cập vấn đề cách tính này ở 1 bài viết trước đây).

Tiếp theo là một Overlapping Max Pooling 3x3 có stride =2 =&amp;gt; feature maps = 27x27x96.

Tiếp theo là Local Response Normalization =&amp;gt; feature maps = 27x27x96.

Xong lớp thứ nhất
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Lớp thứ hai&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Convolutional Layer: 256 kernels có kích thước 5x5x48 (stride size = 1, pad = 2) =&amp;gt; 27x27x256 feature maps.

Overlapping Max Pooling 3x3 có stride =2 =&amp;gt; feature maps = 13x13x256.

Tiếp theo là Local Response Normalization =&amp;gt; feature maps = 13x13x256.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Lớp thứ ba&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Convolutional Layer: 384 kernels có kích thước 3x3x256 (stride size = 1, pad = 1) =&amp;gt; 13x13x384 feature maps.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Lớp thứ bốn&lt;/em&gt;: 384 kernels có kích thước 3x3x192 (stride size = 1, pad = 1) =&amp;gt; 13x13x384 feature maps.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Lớp thứ năm&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Convolutional Layer: 256 kernels có kích thước 3x3x192 (stride size = 1, pad = 1) =&amp;gt; 13x13x256 feature maps.

Overlapping Max Pooling 3x3 có stride =2 =&amp;gt; feature maps = 6x6x256.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Lớp thứ sáu&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Full connected (hay còn gọi là Dense layer) với 4096 neurals
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Lớp thứ bảy&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Full connected  với 4096 neurals
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Lớp thứ tám&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Full connected ra output 1000 neural (do có 1000 lớp)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hàm độ lỗi được sử dụng là Softmax.&lt;/p&gt;

&lt;p&gt;Tổng cộng, chúng ta có 60 triệu tham số được sử dụng để huấn luyện.&lt;/p&gt;

&lt;h1 id=&#34;cải-tiến-của-mô-hình-để-giảm-error-rate&#34;&gt;Cải tiến của mô hình để giảm error rate&lt;/h1&gt;

&lt;h2 id=&#34;sử-dụng-relu-thay-cho-tanh&#34;&gt;Sử dụng ReLU thay cho TanH&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/relu_activation_function.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hàm kích hoạt ReLU và TanH&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Các mô hình neural network trước khi bài báo ra đời thường sử dụng hàm Tanh làm hàm kích hoạt. Mô hình AlexNet không sử dụng hàm TanH mà giới thiệu một hàm kích hoạt mới là ReLU. ReLU giúp cho quá trình huấn luyện chạy nhanh hơn gấp 6 lần so với kiến trúc tương tự sử dụng TanH, góp một phần vào việc độ lỗi trên tập huấn luyện là 25%.&lt;/p&gt;

&lt;h2 id=&#34;local-response-normalization&#34;&gt;Local Response Normalization&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/local_response_norm_vs_batch_norm.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Local Response Normalization và Batch Normalization&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Trong mạng AlexNet, nhóm tác giả sử dụng hàm chuẩn hóa là Local Response Normalization. Hàm này không phải là Batch Normalization mà các bạn hay sử dụng ở thời điểm hiện tại (xem hình ở trên, hai hàm có công thức tính toán hoàn toàn khác nhau). Việc sử dụng chuẩn hóa (Normalization) giúp tăng tốc độ hội tụ. Ngày nay, chúng ta không còn sử dụng Local Response Normalization nữa. Thay vào đó, chúng ta sử  dụng Batch Normalization làm hàm chuẩn hóa.&lt;/p&gt;

&lt;p&gt;Với việc sử dụng hàm chuẩn hóa Local Response Normalization, độ lỗi top-1 error rate giảm 1.4%, top-5 giảm 1.2%.&lt;/p&gt;

&lt;h2 id=&#34;overlapping-pooling&#34;&gt;Overlapping Pooling&lt;/h2&gt;

&lt;p&gt;Overlapping Pooling là pooling với stride nhỏ hơn kernel size. Một khái niệm ngược với Overlapping Pooling là Non-Overlapping Pooling với stride lớn hoăn hoặc bằng kernel.&lt;/p&gt;

&lt;p&gt;Mạng AlexNet sử dụng Overlapping Pooling ở hidden layer thứ 1, 2 và 5 (Kernel size = 3x3, stride =2).&lt;/p&gt;

&lt;p&gt;Với việc sử dụng overlapping pooling, top-1 error rates giảm 0.4%, top-5 error rate giảm 0.3%.&lt;/p&gt;

&lt;h2 id=&#34;sử-dụng-data-augmentation&#34;&gt;Sử dụng Data Augmentation&lt;/h2&gt;

&lt;p&gt;Dữ liệu của tập huấn luyện khá nhiều, 1.2 triệu mẫu. Nhưng chia ra cho 1000 lớp thì mỗi lớp có khoảng 1200, khá khiêm tốn phải không. Cho nên, tác giả đã nghĩ ra một cách khá hay để tăng số lượng hình ảnh mà vẫn giữ được tính IID của dữ liệu, đó là sử dụng các phép biến đổi affine trên dữ liệu ảnh gốc để thu thêm nhiều ảnh hơn.&lt;/p&gt;

&lt;p&gt;Có hai dạng Data Augentation được tác giả sử dụng&lt;/p&gt;

&lt;p&gt;Dạng thứ nhất: Image translation và horizontal reflection (mirroring)&lt;/p&gt;

&lt;p&gt;Image translation được hiểu như sau: ảnh ImageNet gốc có kích thước 256x256 pixel, tác giả rút ra một ảnh con có kích thước 224x224 pixel, sau đó dịch qua trái 1 pixel và lấy 1 ảnh con tiếp theo có kích thước 224x224. Làm như vậy theo hàng, hết hàng làm theo cột. Cuối cùng tác giả có thể từ một bức hình 256x256 ban đầu rút trích thành 1024 hình có kích thước 224x224&lt;/p&gt;

&lt;p&gt;horizontal reflection (mirroring) được hiểu là lấy ảnh phản chiếu của ánh gốc qua đường chéo chính. Ví dụ con báo dang có hướng tai của nó từ trái qua phải, ta lấy horizontal reflection của ảnh đó thì sẽ được con báo hướng tai từ phải qua trái.&lt;/p&gt;

&lt;p&gt;Với việc kết hợp Image translation và horizontal reflection (mirroring), tác giả có thể rút tối đa 2048 bức ảnh khác nhau chỉ từ 1 bức ảnh gốc =&amp;gt; với hơn 1000 bức ảnh của 1 nhãn có thể sinh ra tối đa là 2048000 bức ảnh, một con số khá lớn phải không các bạn.&lt;/p&gt;

&lt;p&gt;Ở tập test, tác giả sử dụng 4 hình 224x224 ở bốn góc cộng với 1 hình 224x224 ở trung tâm =&amp;gt; được 5 hình, đem 5 hình đó sử dụng horizontal reflection thì thu được 10 hình cho mỗi file test.&lt;/p&gt;

&lt;p&gt;Dạng thứ hai: Thay đổi độ sáng&lt;/p&gt;

&lt;p&gt;Thực hiện tính PCA trên tập train. Với mỗi hình trên tập train, thay đổi giá trị độ sáng&lt;/p&gt;

&lt;p&gt;$$[p_1, p_2, p_3][\alpha_1 \gamma_1, \alpha_2 \gamma_2, \alpha_3 \gamma_3]^T$$&lt;/p&gt;

&lt;p&gt;với pi và gammai là giá trị trị riêng và vector riêng thứ i của ma trận hiệp phương sai 3x3 của ảnh, và alpha i là một giá trị ngẫu nhiên thuộc đoạn 1 và độ lệch chuẩn 0.1..&lt;/p&gt;

&lt;p&gt;Với việc sử dụng data augmentation, top-1 error rate giảm 1% độ lỗi.&lt;/p&gt;

&lt;h2 id=&#34;dropout&#34;&gt;Dropout&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/drop_out.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Dropout&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Với mỗi layer sử dụng dropout, mỗi neural sẽ có cơ hội không đóng góp vào feed forward và backpropagation. Do đó, mỗi neural đều có cơ hội  rất lớn đóng góp vào thuật toán, và chúng ta sẽ giảm thiểu tình trạng phụ thuộc vào một vài neural.&lt;/p&gt;

&lt;p&gt;Không sử dụng dropout trong tập quá trình test.&lt;/p&gt;

&lt;p&gt;Mạng AlexNet sử dụng giá trị xác xuất của dropout là 0.5  ở hai fully-connected layer. &lt;em&gt;Dopout được xem như là một kỹ thuật chuẩn hóa nhằm mục đích giảm overfitting.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;sử-dụng-nhiều-gpu&#34;&gt;Sử dụng nhiều GPU&lt;/h2&gt;

&lt;p&gt;Tại năm 2012, nhóm tác giả sử dụng card đồ họa NIVIDIA GTX 580 có 3GB bộ nhớ RAM. Cho nên, để có thể huấn luyện được mô hình AlexNet trên GPU, mô hình cần sử dụng  2 GPU.&lt;/p&gt;

&lt;p&gt;vì vậy &lt;em&gt;việc sử dụng 2 hoặc nhiều GPU là do vấn đề thiếu bộ nhớ, chứ không phải là vấn đề tăng tốc quá trình train hơn so với 1 GPU&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Ngoài ra, do giới hạn của GPU, nên mô hình AlexNet được tách ra làm 2 phần, mỗi phần được huấn luyện trên 1 GPU. Phiên bản 1 GPU của mô hình có tên là CaffeNet, và đòi hỏi chúng ta phải sử dụng GPU có bộ nhớ RAM lớn hơn hoặc bằng 6GB.&lt;/p&gt;

&lt;h1 id=&#34;một-số-chi-tiết-khác-về-các-learning-param&#34;&gt;Một số chi tiết khác về các learning param&lt;/h1&gt;

&lt;p&gt;Batch size: 128&lt;/p&gt;

&lt;p&gt;Momemtum: 0.9&lt;/p&gt;

&lt;p&gt;Weight Decay: 0.0005&lt;/p&gt;

&lt;p&gt;Learning rate: 0.01, giá trị learning rate sẽ giảm đi 10 lần nếu validation error rate không thay đổi trong 1 khoảng thời gian. Số lần giảm là 3.&lt;/p&gt;

&lt;p&gt;Epoch: 90&lt;/p&gt;

&lt;p&gt;Nhóm tác giả đã sử dụng 2 GPU 580 có  3GB GPU RAM và tốn 6 ngày để huấn luyện.&lt;/p&gt;

&lt;h1 id=&#34;kết-quả&#34;&gt;Kết quả&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/alexnet_result_1.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Độ lỗi của AlexNet trên ILSVRC 2010&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Trong cuộc thi ILSVRC 2010, AlexNet đạt độ chính xác top-1 error 37.5% và top-5 error là 17.0%, kết quả này tốt hơn vượt trội so với các cách tiếp cận khác.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/alexnet_result_2.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Độ lỗi của AlexNet trên ILSVRC 2012&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Đến cuộc thi ILSVRC 2012, độ lỗi của AlexNet trên tập validation giảm còn 18.2%.&lt;/p&gt;

&lt;p&gt;Nếu lấy trung bình của dự đoán trên 5 mạng AlexNet được huấn luyện khác nhau, độ lỗi giảm còn 16.4%. Các lấy trung bình trên nhiều hơn 1 mạng CNN là một kỹ thuật &lt;em&gt;boosting&lt;/em&gt; và được sử dụng trước đó ở bài toán phân loại số của mạng LeNet.&lt;/p&gt;

&lt;p&gt;Ở dòng số 3 là mạng AlexNet nhưng được thêm 1 convolution layer nữa (nên được ký hiệu là 1CNN*), độ lỗi trên tập validation giảm còn 16.4%.&lt;/p&gt;

&lt;p&gt;Nếu lấy kết quả trung bình của 2 mạng neural net được chỉnh sửa (thêm 1 convolution layer) và 5 mạng AlexNet gốc (=&amp;gt; chúng ta có 7CNN*), độ lỗi trên tập validation giảm xuống 15.4%&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/alexnet_result_3.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Demo kết quả top-5 của mạng AlexNet&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;mạng-caffenet&#34;&gt;Mạng CaffeNet&lt;/h1&gt;

&lt;p&gt;Mạng này là phiên bản kiến trúc 1-GPU của AlexNet. Kiến trúc của mạng caffeNet như hình bên dưới:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/caffenet.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Mạng caffeNet&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Bạn thấy đó, thay vì có 2 phần trên và dưới như mô ình AlexNet ở trên, mô hình CaffeNet chỉ có 1 phần. Ví dụ lớp hidden layer thứ 7 mạng AlexNet gồm 2 phần, mỗi phần có kích thước 2048, còn ở phiên bản CaffeNet thì đã gộp lại thành 1 phần.&lt;/p&gt;

&lt;p&gt;Tài liệu tham khảo&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&#34;&gt;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.image-net.org/challenges/LSVRC/&#34;&gt;http://www.image-net.org/challenges/LSVRC/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi bài viết, có chỗ nào bạn chưa rõ hoặc mình viết bị sai, các bạn vui lòng để lại comment để mình sửa lại cho đúng.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tìm hiểu mạng MobileNetV1</title>
      <link>/blog/2019-05-26-mobilenetv1/</link>
      <pubDate>Sat, 25 May 2019 00:12:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-05-26-mobilenetv1/</guid>
      <description>

&lt;p&gt;Trong bài viết này, chúng ta sẽ tìm hiểu mô hình MobileNetV1 từ nhóm tác giả đến từ Google. Điểm cải tiến (chắc là cải tiến :) của mô hình là sử dụng một cách tính tích chập có tên là &lt;em&gt;Depthwise Separable Convolution&lt;/em&gt; để giảm kích thước mô hình và giảm độ phức tạp tính toán. Do đó, mô hình sẽ hữu ích khi chạy các ứng dụng trên di động và các thiết bị nhúng.&lt;/p&gt;

&lt;p&gt;Lý do:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Mô hình có ít tham số hơn -&amp;gt; kích thước model sẽ nhỏ hơn.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Mô hình có ít phép tính cộng trừ nhân chia hơn -&amp;gt; độ phức tạp sẽ nhỏ hơn.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hiện tại (2019-05-26), tại thời điểm viết bài, bài viết gốc của tác giả đã được 1594 lượt trích dẫn. Các bạn có thể tìm đọc bài báo gốc của tác giả tại trang &lt;a href=&#34;https://arxiv.org/abs/1704.04861&#34;&gt;https://arxiv.org/abs/1704.04861&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/cimobilenetv1_citations.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Số lượt trích dẫn bài báo MobileNets Efficient Convolutional Neural Networks for Mobile Vision Applications&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;chi-tiết-về-mạng-mobilenet&#34;&gt;Chi tiết về mạng MobileNet&lt;/h1&gt;

&lt;h2 id=&#34;mô-hình-kiến-trúc&#34;&gt;Mô hình kiến trúc&lt;/h2&gt;

&lt;p&gt;Kiến trúc mạng MobileNet được trình bày bên dưới. Hình bên dưới được trích từ bài báo gốc của tác giả&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/mobilenetv1_architecture.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Mô hình kiến trúc mạng MobileNet&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Diễn dịch ra ngôn ngữ tự nhiên, chúng ta thấy rằng mô hình có 30 lớp với các đặc điểm sau:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Lớp 1:  Convolution layer với stride bằng 2&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Lớp 2: Depthwise layer&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Lớp 3: Pointwise layer&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Lớp 4: Depthwise layer với stride bằng 2 (khác với bước 2, dw lớp 2 có stride size bằng 1)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Lớp 5: Pointwise layer&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Lớp 30: Softmax, dùng để phân lớp.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;depthwise-separable-convolution&#34;&gt;Depthwise Separable Convolution&lt;/h2&gt;

&lt;p&gt;Depthwise separable convolution  là một &lt;em&gt;depthwise convolution theo sau bởi một pointwise convolution&lt;/em&gt; như hình bên dưới:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/depthwise_separable_convolution.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Cấu trúc của một Depthwise Separable Convolution&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Depthwise convolution: là một &lt;em&gt;channel-wise DK×DK spatial convolution&lt;/em&gt;. Ví dụ ở hình trên, ta có 5 channels (các bạn để ý cục đầu tiên có 5 khối hộp, cục thứ 2 là phân tách 5 khối hộp ra thành ma trận mxn, cục thứ 3 là spatial convolution có kích thước kxk, cục thứ 4 là kết quả sau khi convolution, cục thứ 5 là ráp 5 cái kết quả của convolution lại ), do đó chúng ta sẽ có 5 DK×DK spatial convolution tương ứng với 5 channel trên.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pointwise convolution: đơn giản là một convolution có kích thước 1x1 (như hình ở trên).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Với M là số lượng input channel, N là số lượng output channel, Dk là kernel size, Df là feature map size (với dataset ImageNet thì input có kích thước là 224, do đó feature map ban đầu có Df = 224), chúng ta có thể tính được:&lt;/p&gt;

&lt;p&gt;Chi phí tính toán của Depthwise convolution là :&lt;/p&gt;

&lt;p&gt;$$D_k \cdot D_k \cdot M \cdot D_f \cdot D_f$$&lt;/p&gt;

&lt;p&gt;Chi phí tính toán của Pointwise convolution là :&lt;/p&gt;

&lt;p&gt;$$M \cdot N \cdot D_f \cdot D_f$$&lt;/p&gt;

&lt;p&gt;Tổng chi phí tính toán của Depthwise Separable Convolution là:&lt;/p&gt;

&lt;p&gt;$$D_k \cdot D_k \cdot M \cdot D_f \cdot D_f + M \cdot N \cdot D_f \cdot D_f$$&lt;/p&gt;

&lt;p&gt;Nếu chúng ta không sử dụng Depthwise Separable Convolution mà sử dụng phép convolution như bình thường, chi phí tính toán là&lt;/p&gt;

&lt;p&gt;$$ D_k \cdot D_k \cdot M \cdot N \cdot D_f \cdot D_f$$&lt;/p&gt;

&lt;p&gt;Do đó, chi phí tính toán sẽ giảm:&lt;/p&gt;

&lt;p&gt;$$\frac{D_k \cdot D_k \cdot M \cdot D_f \cdot D_f + M \cdot N \dot D_f \cdot D_f}{D_k \cdot D_k \cdot M \cdot N \cdot D_f \cdot D_f} =  \frac{1}{N} + \frac{1}{D^2_k}$$&lt;/p&gt;

&lt;p&gt;Giả sử, chúng ta chọn kernel size Dk = 3, chúng ta sẽ giảm từ 8 đến 9 lần phép tính nhân =&amp;gt; giảm chi phí tính toán đi rất nhiều.&lt;/p&gt;

&lt;p&gt;Một chú ý nhỏ về kiến trúc ở đây, là sau mỗi convolution MobileNet sẽ sử dụng Batch Normalization (BN) và ReLU như hình bên dưới:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/standard_convolution_vs_depthwise_seperable_convolution.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Standard Convolution bên trái, Depthwise separable convolution với BN và ReLU bên phải&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So sánh kết quả của việc sử dụng mạng 30 layer sử dụng thuần Convolution và mạng 30 layer sử dụng  Depthwise Separable Convolution (MobileNet) trên tập dữ liệu ImageNet, chúng ta có bảng kết quả bên dưới&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/standard_convolution_vs_depthwise_seperable_convolution_imagenetds.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Standard Convolution bên trái, Depthwise separable convolution với BN và ReLU bên phải&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;MobileNet giảm 1% độ chính xác, nhưng số lượng tham số của mô hình và số lượng phép tính toán giảm đi rất rất nhiều, gần xấp xỉ 90%. Một con số đáng kinh ngạc.&lt;/p&gt;

&lt;h2 id=&#34;làm-mô-hình-gọn-nhẹ-hơn-nữa&#34;&gt;Làm mô hình gọn nhẹ hơn nữa&lt;/h2&gt;

&lt;p&gt;Với mong muốn làm mô hình gọn nhẹ hơn nữa, nhóm tác giả đã thêm vào hai tham số alpha và rho.&lt;/p&gt;

&lt;p&gt;Tham số alpha: Điều khiển số lượng channel (M và N).&lt;/p&gt;

&lt;p&gt;Chi phí tính toán của depthwise separable convolution khi sử dụng thêm tham số alpha.&lt;/p&gt;

&lt;p&gt;$$D_k \cdot D_k \cdot \alpha M \cdot D_f \cdot D_f + \alpha M \cdot \alpha N \cdot D_f \cdot D_f$$&lt;/p&gt;

&lt;p&gt;Giá trị alpha nằm trong đoạn [0,1], nhóm tác giả set giá trị alpha có bước nhảy là 0.25, các giá trị cần xét là 0.25, 0.5, 0.75, 1. Trường hợp alpha = 1 chính là mạng MobileNet baseline của mình. Trong trường hợp thay đổi alpha, số phép tính toán, số tham số, cũng giảm đi rất nhiều, và tất nhiên, độ chính xác cũng giảm đi tương ứng.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/mobilenet_alpha_changes.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Mạng MobileNet với alpha thay đổi&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Phân tích kỹ hình ở trên, ta thấy rằng với alpha bằng  0.75 và 0.5 giá trị độ chính xác còn nằm ở mức miễn cưỡng có thể chấp nhận được. Nhưng với alpha bằng 0.25 thì khó mà có thể chấp nhận được kết quả đó. Việc giảm phép tính toán và số lượng tham số dẫn đến kết quả tệ như trên quả là một điều không nên. Mình nghĩ ở đây nhóm tác giả để con số để có ý nghĩa so sánh.&lt;/p&gt;

&lt;p&gt;Tham số rho: Tham số này được sử dụng để điều khiển độ phân giải của ảnh input.&lt;/p&gt;

&lt;p&gt;Chi phí tính toán của depthwise separable convolution khi sử dụng thêm tham số rho.&lt;/p&gt;

&lt;p&gt;$$D_k \cdot D_k \cdot \alpha M \cdot \rho D_f \cdot \rho D_f + \alpha M \cdot \alpha N \cdot \rho D_f \cdot \rho D_f$$&lt;/p&gt;

&lt;p&gt;Giá trị rho cũng nằm trong đoạn [0,1]. Nhóm tác giả sử dụng các giá trị độ phân giải là 224 (độ phân giải gốc, tương ứng với rho =1), 192, 160, 128.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/mobilenet_beta_changes.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Mạng MobileNet với rho thay đổi&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Giá trị độ chính xác thay đổi theo hướng giảm khá mượt. Việc thay đổi rho chỉ làm giảm số lượng phép tính toán, không làm giảm số lượng tham số. Việc giảm độ chính xác có thể lý giải lý do là có một số hình có kích thước nhỏ nên khi giảm kích thước sẽ làm mất những đặc trưng cần thiết của đối tượng cần xét.&lt;/p&gt;

&lt;h1 id=&#34;so-sánh-mobilenet-với-các-state-of-the-art-đương-thời&#34;&gt;So sánh MobileNet với các State-of-the-art đương thời&lt;/h1&gt;

&lt;p&gt;Khi so sánh 1.0 MobileNet-224 với GoogleNet và VGG 16 (hình bên dưới), chúng ta thấy rằng độ chính xác của cả 3 thuật toán là hầu như tương đương nhau. Nhưng 1.0 MobileNet-224 có số lượng tham số ít (75% so với GoogleNet) và số lượng phép toán nhỏ hơn rất nhiều =&amp;gt; chạy nhanh hơn.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/mobilenet_compare_1.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;So sánh 1.0 MobileNet-224 với GoogleNet và VGG 16 trên tập ImageNet&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Với mô hình 0.50 MobileNet-160, chúng ta có thể so sánh với mô hình Squeezenet và AlexNet (mô hình thắng giải nhất cuộc thi ILSVRC 2012). Một lần nữa, mô hình 0.50 MobileNet-160 cho kết quả tốt hơn, nhưng có số lượng phép tính toán ít hơn rất nhiều (hơi đáng buồn là số lượng tham số của mô hình 0.50 MobileNet-160 khá cao, số lượng tham số gấp đôi so với AlexNet và gần bằng Squeezenet) =&amp;gt; 0.50 MobileNet-160 train nhanh hơn, predict cũng nhanh hơn so với Squeezenet và AlexNet, nhưng tốn bộ nhớ RAM hơn.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/mobilenet_compare_2.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;So sánh 0.50 MobileNet-160 với Squeezenet và AlexNet trên tập ImageNet&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So với mô hình Inception-v3 (mô hình thắng giải nhất cuộc thi ILSVRC 2015), MobileNet cho kết quả khá tốt, nhưng số tham số và số lượng phép tính toán nhỏ hơn rất nhiều&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/mobilenet_compare_3.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;So sánh Mobile net và Inception-v3 trên tập Stanford Dog&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Các thí nghiệm ở dưới trên các tập dataset khác nhau chứng minh mức độ hiệu quả của MobileNet
&lt;img src=&#34;/post_image/mobilenet_compare_4.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;GPS Localization Via Photos&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/mobilenet_compare_5.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Face Attribute Classification&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/mobilenet_compare_6.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;MMicrosoft COCO Object Detection Dataset&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/mobilenet_compare_7.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Face Recognition&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;kết-luận&#34;&gt;Kết luận&lt;/h1&gt;

&lt;p&gt;MobileNet cho kết quả tốt ngang ngữa các state-of-the-art thắng giải nhất ở quá khứ, nhưng với mô hình có số lượng tham số nhỏ hơn và số phép tính toán ít hơn. Điều này đạt được là nhờ vào việc sử dụng Depthwise Separable Convolution.&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi bài viết, có chỗ nào bạn chưa rõ hoặc mình viết bị sai, các bạn vui lòng để lại comment để mình sửa lại cho đúng.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contour</title>
      <link>/blog/2019-05-26-contours/</link>
      <pubDate>Fri, 24 May 2019 00:12:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-05-26-contours/</guid>
      <description>

&lt;h1 id=&#34;contour-là-gì&#34;&gt;Contour là gì&lt;/h1&gt;

&lt;p&gt;Các bạn có thể hiểu contour là &amp;ldquo;tập các điểm-liên-tục tạo thành một đường cong (curve) (boundary), và không có khoảng hở trong đường cong đó, đặc điểm chung trong một contour là các các điểm có cùng /gần xấu xỉ một giá trị màu, hoặc cùng mật độ. Contour là một công cụ hữu ích được dùng để phân tích hình dạng đối tượng, phát hiện đối tượng và nhận dạng đối tượng&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Để tìm contour chính xác, chúng ta cần phải &lt;em&gt;nhị phân hóa bức ảnh&lt;/em&gt; (nhớ là ảnh nhị phân nha các bạn, không phải ảnh grayscale đâu). Các kỹ thuật nhị phân hóa ảnh ở xử lý ảnh cơ bản có thể liệt kê đến là đặt ngưỡng, hoặc candy edge detection. Chúng ta sẽ không bàn kỹ về các cách đặt ngưỡng ( mặc dù có khá nhiều cách đặt ngưỡng, và trong opencv cũng có implement một vài phương pháp, nhưng nó không phải là mục tiêu của bài này, nên mình không đề cập ở đây) hoặc edge detection ở bài viết này, mà chúng ta sẽ đi vào các tìm contours bằng các sử dụng opencv luôn.&lt;/p&gt;

&lt;p&gt;Trong opencv, việc tìm một contour là việc &lt;em&gt;tìm một đối tượng có màu trắng trên nền đen&lt;/em&gt;. Cho nên, các bạn hãy nhớ rằng hãy set đối tượng thành màu trắng và để nền là màu đen, đừng làm ngược lại nha.&lt;/p&gt;

&lt;p&gt;Một lưu ý nhỏ là tại thời điểm mình viết bài viết này, mình sử dụng phiên bản opencv3.6. Các bạn có thể sử dụng phiên bản opencv mới hơn, nhưng có thể những sample code mình để bên dưới sẽ không work, do không tương thích.&lt;/p&gt;

&lt;h1 id=&#34;sử-dụng-contour-trong-opencv&#34;&gt;Sử dụng contour trong opencv&lt;/h1&gt;

&lt;p&gt;Opencv hỗ trợ cho chúng ta hàm để tìm contour của một bức ảnh&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;modifiedImage, contours, hierarchy = cv2.findContours(binaryImage, typeofContour, methodofContour)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Trong đó:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;contours: Danh sách các contour có trong bức ảnh nhị phân. Mỗi một contour được lưu trữ dưới dạng vector các điểm&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;hierarchy: Danh sách các vector, chứa mối quan hệ giữa các contour.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;modifiedImage: Ảnh sau khi sử dụng contour, thường chúng ta không xài đối số này&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;binaryImage: Ảnh nhị phân gốc. Một chú ý quan trọng ở đây là sau khi sử dụng hàm findContours thì giá trị của binaryImage cũng thay đổi theo, nên khi sử dụng bạn có thể áp dụng binaryImage.copy() để không làm thay đổi giá trị của binaryImage&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;typeofContour: có các dạng sau: RETR_EXTERNAL, RETR_LIST, RETR_CCOMP, RETR_TREE, RETR_FLOODFILL.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;methodofContour: Có các phương thức sau: CHAIN_APPROX_NONE, CHAIN_APPROX_SIMPLE, CHAIN_APPROX_TC89_L1, CHAIN_APPROX_TC89_KCOS.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ví dụ về các sử dụng hàm&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
import numpy as np
import cv2

im = cv2.imread(&#39;test.jpg&#39;) # đọc ảnh màu
imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)  # chuyển ảnh màu sang dạng grayscale
ret,thresh = cv2.threshold(imgray,127,255,0) # nhị phân hóa bức ảnh bằng cách đặt ngưỡng, với giá trị của ngưỡng là 127
im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) # tìm contour

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Opencv hỗ trợ chúng ta hàm để vẽ contor lên bức ảnh, giúp chúng ta nhìn rõ ràng hơn&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cv2.drawContours(image, contours, contourIndex, colorCode, thickness)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Với:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;imgage: ảnh, có thể là ảnh grayscale hoặc ảnh màu.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;contours: danh sách các contour, là vector, nếu bạn muốn vẽ một contour, thì bạn phải cho nó vào trong một list.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;contourIndex Vị trí của contor, thông thường chúng ta để -1&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;colorCode: Giá trị màu của contour chúng ta muốn vẽ, ở dạng BGR, nếu bạn muốn vẽ contour màu xanh lá cây thì set là (0,255,0).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;thickness : độ dày của đường contour cần vẽ, giá trị thickness càng lớn thì đường contor vẽ càng bự&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;ví-dụ-đếm-số-lượng-quả-bóng-bay-trong-hình&#34;&gt;Ví dụ: Đếm số lượng quả bóng bay trong hình&lt;/h1&gt;

&lt;p&gt;Giả sử chúng ta có bức ảnh
&lt;img src=&#34;/post_image/colorfull_ballon.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Bong bóng bay&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Chúng ta thực hiện tìm contour của ảnh trên bằng cách&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
import numpy as np
import cv2

im = cv2.imread(&#39;colorfull_ballon.jpg&#39;)
imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) # chuyển ảnh xám thành ảnh grayscale
thresh = cv2.Canny(imgray, 127, 255) # nhị phân hóa ảnh
_, contours, _ = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)

cv2.drawContours(im, contours, -1, (0, 255, 0), 2) # vẽ lại ảnh contour vào ảnh gốc

# show ảnh lên
cv2.imshow(&amp;quot;ballons&amp;quot;, im)
cv2.waitKey(0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/vietnam_coins_set_contours.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Contour màu xanh là đường curve bao quanh dữ liệu được rút trích được&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tìm hiểu về dropout trong deep learning, machine learning</title>
      <link>/blog/2019-05-05-deep-learning-dropout/</link>
      <pubDate>Sun, 05 May 2019 00:12:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-05-05-deep-learning-dropout/</guid>
      <description>

&lt;h1 id=&#34;1-dropout-là-gì-nó-có-ý-nghĩa-gì-trong-mạng-neural-network&#34;&gt;1. Dropout là gì, nó có ý nghĩa gì trong mạng neural network&lt;/h1&gt;

&lt;p&gt;Theo Wikipedia, thuật ngữ &amp;ldquo;dropout&amp;rdquo; đề cập đến việc bỏ qua các đơn vị (unit) (cả hai hidden unit và visible unit) trong mạng neural network.&lt;/p&gt;

&lt;p&gt;Hiểu đơn giản là, trong mạng neural network, kỹ thuật dropout là việc chúng ta sẽ bỏ qua một vài unit trong suốt quá trình train trong mô hình, những unit bị bỏ qua được lựa chọn ngẫu nhiên. Ở đây, chúng ta hiểu &amp;ldquo;bỏ qua - ignoring&amp;rdquo; là unit đó sẽ không tham gia và đóng góp vào quá trình huấn luyện (lan truyền tiến và lan truyền ngược).&lt;/p&gt;

&lt;p&gt;Về mặt kỹ thuật, tại mỗi giai đoạn huấn luyện, mỗi node có xác suất bị bỏ qua là 1-p và xác suất được chọn là p&lt;/p&gt;

&lt;h1 id=&#34;2-tạo-sao-chúng-ta-cần-dropout&#34;&gt;2. Tạo sao chúng ta cần dropout&lt;/h1&gt;

&lt;p&gt;Giả sử rằng bạn hiểu hoàn toàn những gì đã nói ở phần 1, câu hỏi đặt ra là tại sao chúng ta cần đến dropout, tại sao chúng ta cần phải loại bỏ một vài các unit nào đó trong mạng neural network?&lt;/p&gt;

&lt;p&gt;Câu trả lời cho câu hỏi này là &lt;strong&gt;để chống over-fitting&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Khi chúng ta sử dụng full connected layer, các neural sẽ phụ thuộc &amp;ldquo;mạnh&amp;rdquo; lẫn nhau trong suốt quá trình huấn luyện, điều này làm giảm sức mạng cho mỗi neural và dẫn đến bị over-fitting tập train.&lt;/p&gt;

&lt;h1 id=&#34;3-dropout&#34;&gt;3. Dropout&lt;/h1&gt;

&lt;p&gt;Đọc đến đây, bạn đã có một khái niệm cơ bản về dropout và động lực - động cơ để chúng ta sử dụng nó. Nếu bạn chỉ muốn có cái nhìn tổng quan về dropout trong neural network, hai sections trên đã cung cấp đầy đủ thông tin cho bạn, bạn có thể dừng tại đây. Phần tiếp theo, chúng ta sẽ nói kỹ hơn về mặt kỹ thuật của dropout.&lt;/p&gt;

&lt;p&gt;Trước đây, trong machine learning, người ta thường sử dụng regularization để ngăng chặn over-fititng. Regularization làm giảm over-fitting bằng cách thêm yếu tố &amp;ldquo;phạt&amp;rdquo; vào hàm độ lỗi (loss function).  Bằng việc thêm vào điểm phạt này, mô hình được huấn luyện sẽ giúp các features weights giảm đi sự phụ thuộc lẫn nhau. Đối với những ai đã sử dụng Logistic Regression rồi thì sẽ không xa lạ với thuật ngữ phạt L1(Laplacian) và L2 (Gaussian).&lt;/p&gt;

&lt;p&gt;Dropout là một kỹ thuật khác, một cách tiếp cận khác để regularization  trong mạng neural netwoks.&lt;/p&gt;

&lt;p&gt;Kỹ thuật dropout được thực hiện như sau:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Trong pha train&lt;/strong&gt;: với mỗi hidden layer, với mỗi trainning sample, với mỗi lần lặp, chọn ngẫu nhiên p phần trăm số node và bỏ qua nó (bỏ qua luôn hàm kích hoạt cho các node bị bỏ qua).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Trong pha test&lt;/strong&gt;: Sử dụng toàn bộ activations, nhưng giảm chúng với tỷ lệ p (do chúng ta bị miss p% hàm activation trong quá trình train).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/drop_out.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Mô tả về kiến trúc mạng có và không có dropout&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;4-một-số-đặc-điểm-rút-ra-được-khi-huấn-luyện-nhiều-mô-hình-khác-nhau-sử-dụng-dropout&#34;&gt;4. Một số đặc điểm rút ra được khi huấn luyện nhiều mô hình khác nhau sử dụng dropout&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Dropout ép mạng neural phải tìm ra nhiều robust features hơn, với đặc điểm là chúng phải hữu ích hơn, tốt hơn, ngon hơn khi kết hợp với nhiều neuron khác.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Dropout đòi hỏi phải gấp đôi quá trình huấn luyện để đạt được sự hội tụ. Tuy nhiên, thời gian huấn luyện cho mỗi epoch sẽ ít hơn.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Với H unit trong mô hình, mỗi unit đều có xác xuất bị bỏ qua hoặc được chọn, chúng ta sẽ có 2^H mô hình có thể có. Trong pha test, toàn bộ network được sử dụng và mỗi hàm activation được giảm đi với hệ số p.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Một số nghiên cứu chỉ ra rằng, khi sử dụng Dropout và Batch Normalization (BN) cùng nhau thì kết quả rất tệ, trong cả lý thuyết và thực nghiệm, ví dụ nghiên cứu ở papper &amp;ldquo;Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift&amp;rdquo;, nguồn &lt;a href=&#34;https://arxiv.org/abs/1801.05134&#34;&gt;https://arxiv.org/abs/1801.05134&lt;/a&gt;, nhóm tác giả giải thích về mặt lý thuyết rằng: &amp;ldquo;đối với một neural, Dropout sẽ thay đổi phương sai của nó khi chúng ta chuyển trạng thái từ trian sang test. Còn BN thì không, BN vẫn tích luỹ đầy đủ thông tin trong quá trình huấn luyện. Do Dropout làm thay đổi phương sai nên sẽ xảy ra hiện tượng không đồng nhất về phương sai, dẫn đến hành vi suy luận không chắc chắn dẫn đến suy luận bị sai nhiều. Đặc biệt là khi kết hợp dropout và BN thì khiến cho suy luận càng sai lầm trầm trọng. &amp;ldquo;. Cho nên, trong một số trường hợp/bài toán chúng ta có thể dùng Dropout, trong một số trường hợp/ bài toán, người ta sử dụng BN và không sử dụng dropout.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Người ta thường dùng hệ số dropout là 0.5. Lý giải cho việc này, bạn có thể đọc bài báo &lt;a href=&#34;http://papers.nips.cc/paper/4878-understanding-dropout.pdf&#34;&gt;http://papers.nips.cc/paper/4878-understanding-dropout.pdf&lt;/a&gt;. Nói nôm là việc sử dụng giảm 50% của dropout giúp kết quả đạt được là tốt nhất so với các phương pháp chuẩn hoá khác.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;5-thực-nghiệm-trong-keras&#34;&gt;5. Thực nghiệm trong keras&lt;/h1&gt;

&lt;p&gt;Những vấn đề nói ở trên chỉ là lý thuyết. Bây giờ chúng ta sẽ bắt tay vào làm thực tế. Để xem thử dropout hoạt động như thế nào, chúng ta sẽ xây dựng mô hình deep net sử dụng keras và sử dụng tập dữ liệu cifar-10. Mô hình chúng ta xây dựng có 3 hidden layer với kích thước lần lượt là 64, 128, 256 và 1 full connected layer có kích thước 512 và output layer có kích thước 10 (do mình có 10 lớp).&lt;/p&gt;

&lt;p&gt;Chúng ta sử dụng hàm kích hoạt là ReLU trên các hidden layer và sử dụng hàm sigmoid trên output layer. Sử dụng hàm lỗi categorical cross-entropy.&lt;/p&gt;

&lt;p&gt;Trong trường hợp mô hình có sử dụng dropout, chúng ta sẽ set dropout ở tất cả các layer và thay đổi tỷ lệ dropout nằm trong khoảng từ 0.0 đến 0.9 với bước nhảy là 0.1.&lt;/p&gt;

&lt;p&gt;Mô hình setup với số epochs là 20. Bắt đầu xem nào.&lt;/p&gt;

&lt;p&gt;Đầu tiên, chúng ta sẽ load một vài thư viện cần thiết&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import os

import keras

from keras.datasets import cifar10
from keras.models  import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.optimizers import SGD
from keras.utils import np_utils
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

from pylab import rcParams
rcParams[&#39;figure.figsize&#39;] = 20, 20

from keras.datasets import cifar10

(X_train, y_train), (X_test, y_test) = cifar10.load_data()


print(&amp;quot;Training data:&amp;quot;)
print(&amp;quot;Number of examples: &amp;quot;, X_train.shape[0])
print(&amp;quot;Number of channels:&amp;quot;,X_train.shape[3]) 
print(&amp;quot;Image size:&amp;quot;,X_train.shape[1], X_train.shape[2], X_train.shape[3])

print(&amp;quot;Test data:&amp;quot;)
print(&amp;quot;Number of examples:&amp;quot;, X_test.shape[0])
print(&amp;quot;Number of channels:&amp;quot;, X_test.shape[3])
print(&amp;quot;Image size:&amp;quot;,X_test.shape[1], X_test.shape[2], X_test.shape[3])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Training data:
Number of examples:  50000
Number of channels: 3
Image size: 32 32 3
Test data:
Number of examples: 10000
Number of channels: 3
Image size: 32 32 3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Chúng ta có 50000 hình train, và 10000 hình test. Mỗi hình là một ảnh RGB có kích thước 33x32x3 pixel.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/cifar-10-overview.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;dataset cifar 10&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Tiếp theo, chúng ta sẽ chuẩn hoá dữ liệu. Đây là 1 bước quan trọng trước khi huấn luyện mô hình&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print( &amp;quot;mean before normalization:&amp;quot;, np.mean(X_train)) 
print( &amp;quot;std before normalization:&amp;quot;, np.std(X_train))

mean=[0,0,0]
std=[0,0,0]
newX_train = np.ones(X_train.shape)
newX_test = np.ones(X_test.shape)
for i in range(3):
    mean[i] = np.mean(X_train[:,i,:,:])
    std[i] = np.std(X_train[:,i,:,:])
    
for i in range(3):
    newX_train[:,i,:,:] = X_train[:,i,:,:] - mean[i]
    newX_train[:,i,:,:] = newX_train[:,i,:,:] / std[i]
    newX_test[:,i,:,:] = X_test[:,i,:,:] - mean[i]
    newX_test[:,i,:,:] = newX_test[:,i,:,:] / std[i]
        
    
X_train = newX_train
X_test = newX_test

print(&amp;quot;mean after normalization:&amp;quot;, np.mean(X_train))
print(&amp;quot;std after normalization:&amp;quot;, np.std(X_train))


&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;mean before normalization: 120.70756512369792
std before normalization: 64.1500758911213
mean after normalization: 0.9062499999999979
std after normalization: 0.4227421643271468

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Full code đoạn huấn luyện&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;

# In[3]:Specify Training Parameters

batchSize = 512                   #-- Training Batch Size
num_classes = 10                  #-- Number of classes in CIFAR-10 dataset
num_epochs = 100                   #-- Number of epochs for training   
learningRate= 0.001               #-- Learning rate for the network
lr_weight_decay = 0.95            #-- Learning weight decay. Reduce the learn rate by 0.95 after epoch


img_rows, img_cols = 32, 32       #-- input image dimensions

Y_train = np_utils.to_categorical(y_train, num_classes)
Y_test = np_utils.to_categorical(y_test, num_classes)



batchSize = 512                   #-- Training Batch Size
num_classes = 10                  #-- Number of classes in CIFAR-10 dataset
num_epochs = 100                   #-- Number of epochs for training   
learningRate= 0.001               #-- Learning rate for the network
lr_weight_decay = 0.95            #-- Learning weight decay. Reduce the learn rate by 0.95 after epoch


img_rows, img_cols = 32, 32       #-- input image dimensions

Y_train = np_utils.to_categorical(y_train, num_classes)
Y_test = np_utils.to_categorical(y_test, num_classes)


# In[4]:VGGnet-10


from keras.layers import Conv2D
import copy
result = {}
y = {}
loss = []
acc = []
dropouts = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
for dropout in dropouts:
    print(&amp;quot;Dropout: &amp;quot;, (dropout))
    model = Sequential()                                               

    #-- layer 1
    model.add(Conv2D(64, (3, 3),                                    
                            border_mode=&#39;valid&#39;,
                            input_shape=( img_rows, img_cols,3))) 
    model.add(Dropout(dropout))  
    model.add(Conv2D(64, (3, 3)))
    model.add(Dropout(dropout))
    model.add(Activation(&#39;relu&#39;))                                       
    model.add(MaxPooling2D(pool_size=(2, 2)))

    ##--layer 2                        
    model.add(Conv2D(128, (3, 3)))
    model.add(Dropout(dropout)) 
    model.add(Activation(&#39;relu&#39;))                                       
    model.add(MaxPooling2D(pool_size=(2, 2)))

    ##--layer 3                         
    model.add(Conv2D(256, (3, 3)))
    model.add(Dropout(dropout)) 
    model.add(Activation(&#39;relu&#39;))                                       
    model.add(MaxPooling2D(pool_size=(2, 2)))

    ##-- layer 4
    model.add(Flatten())                                                
    model.add(Dense(512))                                               
    model.add(Activation(&#39;relu&#39;))                                                                           

    #-- layer 5
    model.add(Dense(num_classes))                                       

    #-- loss
    model.add(Activation(&#39;softmax&#39;))
    
    sgd = SGD(lr=learningRate, decay = lr_weight_decay)
    model.compile(loss=&#39;categorical_crossentropy&#39;,
                  optimizer=&#39;sgd&#39;,
                  metrics=[&#39;accuracy&#39;])
    
    model_cce = model.fit(X_train, Y_train, batch_size=batchSize, epochs=20, verbose=1, shuffle=True, validation_data=(X_test, Y_test))
    score = model.evaluate(X_test, Y_test, verbose=0)
    y[dropout] = model.predict(X_test)
    print(&#39;Test score:&#39;, score[0])
    print(&#39;Test accuracy:&#39;, score[1])
    result[dropout] = copy.deepcopy(model_cce.history)   
    loss.append(score[0])
    acc.append(score[1])



# In[5]: plot dropout 
import numpy as np                                                               
import matplotlib.pyplot as plt

width = 0.1

plt.bar(dropouts, acc, width, align=&#39;center&#39;)

plt.tick_params(axis=&#39;both&#39;, which=&#39;major&#39;, labelsize=35)
plt.tick_params(axis=&#39;both&#39;, which=&#39;minor&#39;, labelsize=35)

plt.ylabel(&#39;Accuracy&#39;,size = 30)
plt.xlabel(&#39;Dropout&#39;, size = 30)
plt.show()


# In[6]: plot non drop out

import numpy as np                                                               
import matplotlib.pyplot as plt

width = 0.1

plt.bar(dropouts, loss, width, align=&#39;center&#39;,color = &#39;green&#39;)

plt.tick_params(axis=&#39;both&#39;, which=&#39;major&#39;, labelsize=35)
plt.tick_params(axis=&#39;both&#39;, which=&#39;minor&#39;, labelsize=35)

plt.ylabel(&#39;Loss&#39;,size = 30)
plt.xlabel(&#39;Dropout&#39;, size = 30)
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/drop_out_result.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Kết quả&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Nhìn hình kết quả ở trên, chúng ta có một số kết luận nhỏ như sau:&lt;/p&gt;

&lt;p&gt;Giá trị dropout tốt nhất là 0.2, khoảng dropout cho giá trị chấp nhận được là nằm trong đoạn từ 0 đến 0.5. Nếu dropout lớn hơn 0.5 thì kết quả hàm huấn luyện trả về khá tệ.&lt;/p&gt;

&lt;p&gt;Giá trị độ chính xác còn khá thấp =&amp;gt; 20 epochs là chưa đủ, cần huấn luyện nhiều hơn nữa.&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Các kỹ thuật lấy mẫu</title>
      <link>/blog/2019-05-04-sampling-method/</link>
      <pubDate>Sat, 04 May 2019 00:12:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-05-04-sampling-method/</guid>
      <description>

&lt;p&gt;Lấy mẫu dữ liệu là một kỹ thuật rất quang trọng trong thống kê, là yếu tố quan trọng góp phần xác định độ chính xác của research/ survey. Nếu có bất kỳ sai sót gì trong quá trình lấy mẫu, nó sẽ ảnh hưởng trực tiếp đến kết quả cuối cùng. Có rất nhiều kỹ thuật giúp chúng ta thu thập mẫu dựa trên nhu cầu và tình huống chúng ta cần. Bài viết này sẽ giải thích một số kỹ thuật phổ biến nhất.&lt;/p&gt;

&lt;p&gt;Để bắt đầu bài viết, chúng ta sẽ làm rõ mốt số khái niệm cơ bản là &lt;strong&gt;Quần thể - Population&lt;/strong&gt;,&lt;strong&gt;mẫu - Sample&lt;/strong&gt; và &lt;strong&gt;lấy mẫu - sampling&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Quần thể - population là tập hợp của các cá thể có một hoặc một số đặc điểm chung. Kích thước của một quần thể là số lượng cá thể trong quần thể đó.&lt;/p&gt;

&lt;p&gt;Mẫu - sample là một tập con của quần thể. Quá trình chọn một mẫu được gọi là lấy mẫu -sampling. Kích thước mẫu là số lượng cá thể trong tập mẫu.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/target-population.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 1: Ví dụ về lấy mẫu dữ liệu&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Có rất nhiều kỹ thuật lấy mẫu dữ liệu khác nhau, nhưng chúng ta có thể gom chúng vào 2 nhóm chính:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Lấy mẫu ngẫu nhiên - Probability Sampling&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Lấy mẫu phi ngẫu nhiên - non-probability sampling&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/probability-vs-non-probability-sampling.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 2: Ví dụ so về lấy mẫu ngẫu nhiên và lấy mẫu phi ngẫu nhiên&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Sự khác biệt của hai nhóm trên là phương pháp lấy mẫu có sử dụng &amp;ldquo;hàm ngẫu nhiên&amp;rdquo; hay không. Với việc sử dụng hàm ngẫu nhiên, mỗi cá thể đều có cơ hội được lựa chọn ngang nhau và đều có cơ hội là một cá thể trong tập mẫu.&lt;/p&gt;

&lt;h2 id=&#34;lấy-mẫu-ngẫu-nhiên&#34;&gt;Lấy mẫu ngẫu nhiên&lt;/h2&gt;

&lt;p&gt;Những thuật toán trong nhóm này sử dụng hàm &amp;ldquo;ngẫu nhiên&amp;rdquo; để đảm bảo rằng mọi phần tử đều có cơ hội lựa chọn ngang nhau. Một tên khác của phương pháp này là random sampling.&lt;/p&gt;

&lt;p&gt;Một số phương pháp thuộc nhóm này&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Simple Random Sampling&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Stratified sampling&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Systematic sampling&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Cluster Sampling&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Multi stage Sampling&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;simple-random-sampling&#34;&gt;Simple Random Sampling&lt;/h4&gt;

&lt;p&gt;Mỗi cá thể đều có cơ hội lựa chọn ngang nhau vào tập mẫu. Phương pháp này được sử dụng khi chúng ta không có bất kỳ thông tin gì về tập population.&lt;/p&gt;

&lt;p&gt;Ví dụ: Chọn ngẫu nhiên 20 sinh viên trong lớp học 50 sinh viên. Mỗi sinh viên đều có cơ hội được chọn ngang nhau là &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;50&lt;/sub&gt;.&lt;/p&gt;

&lt;h4 id=&#34;stratified-sampling&#34;&gt;Stratified sampling&lt;/h4&gt;

&lt;p&gt;Kỹ thuật này phân chia mỗi cá thể trong quần thể thành từng nhóm nhỏ dựa trên sự tương đồng (similarity), nghĩa là các cá thể trong cùng 1 nhóm sẽ đồng nhất với nhau về một khía cạnh nào đó, và sẽ không giống với các nhóm khác về khía cạnh đó. Và chúng ta sẽ chọn ngẫu nhiên các các thể trong mỗi nhóm. Ở phương pháp này, chúng ta cần thông tin cho trước về tập quần thể để tạo các nhóm con.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/stratified_sampling.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 2: lấy mẫu Stratified sampling&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Ở ví dụ trên, chúng ta sẽ chia tập quần thể thành các nhóm con mặc áo đỏ, mặc áo xanh, mặc áo vàng (phải biết trước được trong quần thể thằng nào mặc áo màu gì). Sau đó sẽ lựa chọn ngẫu nhiên 2 các thể trong mỗi nhóm.&lt;/p&gt;

&lt;h4 id=&#34;cluster-sampling&#34;&gt;Cluster Sampling&lt;/h4&gt;

&lt;p&gt;Toàn bộ tập quần thể sẽ được chia thành từ cụm hoặc thành từng phần. Sau đó chúng ta sẽ chọn ngẫu nhiên từng cụm. Tất cả các cá thể trong cụm đó sẽ được sử dụng làm tập mẫu. Các cụm được định danh dựa trên các yếu tố xác định trước. Ví dụ ở trong hình ở trên, các cụm được định danh dựa vào màu sắc của áo mà người đó mặc. Điểm khác biệt ở phương pháp này so với phương pháp ở trên là phương pháp ở trên lựa chọn ngẫu nhiên một số các cá thể trong mỗi cụm. Còn phương pháp này sẽ lựa chọn ngẫu nhiên các cụm, và chọn hết tất cả các các thể trong cụm đó.&lt;/p&gt;

&lt;p&gt;Một số chiến lược để lựa chọn cụm:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Single Stage Cluster Sampling&lt;/strong&gt;: Các cụm được lựa chọn ngẫu nhiên&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/single-state-cluster-sampling.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 3: Single Stage Cluster Sampling&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Two Stage Cluster Sampling&lt;/strong&gt;: Ở phương pháp này, chúng ta sẽ lựa chọn ngẫu nhiên các cụm, sau đó, trong mỗi cụm, chúng ta sẽ lựa chọn ngẫu nhiên các cá thể trong mỗi cụm&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/two-stage-cluster-sampling.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 4: Two Stage Cluster Sampling&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;systematic-clustering&#34;&gt;Systematic Clustering&lt;/h4&gt;

&lt;p&gt;Ở phương pháp này, việc lựa chọn cá thể là có quy luật và không ngẫu nhiên, từ cá thể đầu tiên. Các cá thể của tập mẫu được chọn ra từ tập quần thể dựa vào một quy luật nào đó. Đầu tiên, tất cả các cá thể trong tập quần thể phải được xắp xếp có thứ tự. Sau đó chúng ta sẽ lựa chọn ngẫu nhiên cá thể đầu tiên (mỗi cá thể đều có xác suất ngang nhau ở đây), và sử dụng quy luật nào đó để rút ra các cá thể tiếp theo.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/systematic-clustering.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 5: Systematic Clustering&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Như ví dụ ở trên, chúng ta xắp xếp các nhân vật áo vàng, xanh, đỏ ngẫu nhiên tuỳ ý theo sự lựa chọn của người ta. Quy luật là cứ 4 người sẽ lấy người cuối. Ấn nút ngẫu nhiên &amp;hellip; ta được số 3. Vậy là cá thể đầu tiên là nhân vật ở vị trí số 3, tiếp theo sẽ là nhân vật ở vị trí 7, 11, 15,19, 5, &amp;hellip;&lt;/p&gt;

&lt;h4 id=&#34;multi-stage-sampling&#34;&gt;Multi-Stage Sampling&lt;/h4&gt;

&lt;p&gt;Phương pháp này là sự kết hợp của một hoặc nhiều phương pháp được mô tả ở trên.&lt;/p&gt;

&lt;p&gt;Quần thể được chia thành nhiều cụm (cluster) và mỗi cụm được chia vào từng nhóm con (subgrop - strata) dựa trên sự tương đồng =&amp;gt; chúng ta được một tập các cụm con được gọi là stratum. Chúng ta sẽ lựa nhọn một hoặc một vài strata trong stratum. Quá trình này sẽ được lặp đi lặp lại đến khi không còn cụm nào có thể phân chia được nữa.&lt;/p&gt;

&lt;p&gt;Ví dụ, các quốc gia có thể được phân chia thành từng bang, thành phố, thành thị, nông thôn. Và tất cả các khu vực có cùng ký tự đầu có thể được gom lại thành với nhau tạo thành một strata.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/multi-stage-sampling.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 6: Multi-Stage Sampling&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;lấy-mẫu-phi-ngẫu-nhiên&#34;&gt;Lấy mẫu phi ngẫu nhiên&lt;/h2&gt;

&lt;p&gt;Những kỹ thuật nằm trong nhóm này không sử dụng hàm ngẫu nhiên. Kỹ thuật này phụ thuộc vào khả năng hiểu biết của các nhà nghiên cứu (researcher) trên tập quần thể họ đang có để chọn lựa cá thể cho tập mẫu. Kết quả của việc lấy mẫu có thể bị lệch.&lt;/p&gt;

&lt;p&gt;Một số phương pháp thuộc nhóm này là:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Convenience Sampling&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Purposive Sampling&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Quota Sampling&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Referral /Snowball Sampling&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;convenience-sampling&#34;&gt;Convenience Sampling&lt;/h4&gt;

&lt;p&gt;Các cá thể được chọn dựa trên tính khả dụng của dữ liệu. Phương pháp này được sử dụng khi tính khả dụng của dữ liệu là hiếm và tốn kém. Do vậy, chúng ta sẽ lựa chọn mẫu dựa trên sự tiện lợi.&lt;/p&gt;

&lt;p&gt;Ví dụ, Các nhà nghiên cứu thường hay sử dụng phương pháp này trong các giai đoạn đầu của các nghiên cứu khảo sát, vì nó dễ dàng, nhanh chóng và cho ra kết quả nhanh.&lt;/p&gt;

&lt;h4 id=&#34;purposive-sampling&#34;&gt;Purposive Sampling&lt;/h4&gt;

&lt;p&gt;Phương pháp lấy mẫu này dựa trên mục đích của nghiên cứu. Chỉ chọn ra những cá thể trong quần thể phù hợp nhất với mục đích nghiên cứu .&lt;/p&gt;

&lt;p&gt;Ví dụ: Nếu chúng ta muốn hiểu được &amp;ldquo;suy nghĩ của những người quan tâm đến bằng thạc sỹ&amp;rdquo; thì tiêu chí lựa chọn cá thể là những người say yes trong câu hỏi &amp;ldquo;bạn có hứng thú với bậc thạc sỹ trong lĩnh vực &amp;hellip; không?&amp;rdquo;. Những người say &amp;ldquo;No&amp;rdquo; sẽ bị loại khỏi tập mẫu của chúng ta.&lt;/p&gt;

&lt;h4 id=&#34;quota-sampling&#34;&gt;Quota Sampling&lt;/h4&gt;

&lt;p&gt;Phương pháp lấy mẫu này phụ thuộc vào một số tiêu chuẩn thiết lập từ trước. Tỷ lệ của các nhóm cá thể trong tập mẫu phải giống hết trong tập quần thể. Các cá thể được chọn cho đến khi chúng đạt đúng tỷ lệ của một loại dữ liệu.&lt;/p&gt;

&lt;p&gt;Ví dụ: Giả sử chúng ta biết rằng trên trái đất này có 6 tỷ người, và 45% trong số đó là nam giới và 55% là nữ giới. Vậy thì chúng ta sẽ lấy mẫu làm sao cho tập mẫu chúng ta cũng phản ánh số đó, nghĩa là trong tập mẫu có 1000 người thì 45% trong số 1000 người đó phải là nam và 55% trong số 1000 người đó là nữ.&lt;/p&gt;

&lt;h4 id=&#34;referral-snowball-sampling&#34;&gt;Referral /Snowball Sampling&lt;/h4&gt;

&lt;p&gt;Kỹ thuật này được sử dụng khi chúng ta không biết gì về tập quần thể hoặc tập quần thể hiếm. Lúc đó chúng ta sẽ tìm ra cá thể đầu tiên trong quần thể, rồi nhờ cá thể đầu tiên đó gợi ý các cá thể tiếp theo với điều kiện thoả nhu cẫu lấy mẫu của nghiên cứu. Cứ tiếp tục như vậy thì kích thước của tập mẫu sẽ tăng lên theo cấp nhân như kích thước quả quả cầu tuyết, nên kỹ thuật này còn có tên gọi khác là Snowball Sampling.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/snowball-sampling.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 7: Ví dụ về Snowball Sampling&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Ví dụ: Trong tình huống, ngữ cảnh là bạn muốn làm 1 bài khảo sát về những người bị nhiễm HIV, những người này thường có khuynh hướng không cởi mở ở mức độ công cộng và khó cho chúng ta tiếp cận để thu thập thông tin trực tiếp từ họ.&lt;/p&gt;

&lt;p&gt;Nhóm khảo sát sẽ tiến hành liên hệ 1 người nào đó mà họ biết hoặc người nào đó xung phong làm cầu nối với các người bị nhiễm và thu thập thông tin từ họ (những người bị nhiễn tin tưởng người được xung phong hơn nhóm khảo sát. Vì nhóm khảo sát là người lạ).&lt;/p&gt;

&lt;p&gt;Hi vọng sau bài viết này, các bạn có thêm nhiều ý tưởng hơn nữa về việc lấy mẫu và các cách để lấy mẫu trong ứng dụng thực tế.&lt;/p&gt;

&lt;p&gt;Bài viết được lược dịch và một số hình ảnh được lấy từ nguồn &lt;a href=&#34;https://towardsdatascience.com/sampling-techniques-a4e34111d808&#34;&gt;https://towardsdatascience.com/sampling-techniques-a4e34111d808&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PredictionIO Phần 1 - Hướng dẫn cài đặt</title>
      <link>/blog/2019-05-04-setup-predictio/</link>
      <pubDate>Fri, 03 May 2019 00:12:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-05-04-setup-predictio/</guid>
      <description>

&lt;h1 id=&#34;1-giới-thiệu-về-predictionio&#34;&gt;1. Giới thiệu về PredictionIO&lt;/h1&gt;

&lt;p&gt;PredictionIO là một &amp;ldquo;open source Machine Learning Server built on top of a state-of-the-art open source stack&amp;rdquo; giúp cho các developers và các data scientists tạo ra các engine dự đoán trong học máy. PredictionIO giúp chúng ta&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Xây dựng và triển khai các ứng dụng, dịch vụ một cách nhanh chóng bằng cách tuỳ chỉnh lại các template đã sẵn có.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Trả lời các câu truy vấn động trong thời gian thực.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;huấn luyện và so sánh/đánh giá nhiều mô hình khác nhau dễ dàng.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hợp nhất hoá dữ liệu từ nhiều nền tảng khác nhau hoặc trong thời gian thực để thực hiện phân tích dự đoán.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hỗ trợ các thư viện máy học và xử lý dữ liệu như Spark MLLib và OpenNLP&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Tự xây dựng, triển khai, customize một mô hình machine learning&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;2-cơ-chế-hoạt-động-của-predictionio&#34;&gt;2. Cơ chế hoạt động của PredictionIO&lt;/h1&gt;

&lt;p&gt;PredictionIO bao gồm các thành phần sau:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;PredictionIO platform: là nền tảng open source được apache xây dựng sẵn giúp chúng ta triển khai, xây dựng, đánh giá các mô hình máy học.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Event Server: là nơi giúp chúng ta chuẩn hoá các sự kiện từ nhiều nguồn khác nhau&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Template Gallery: là nơi chúng ta download các engine template máy học về. PredictionIO hỗ trợ cho chúng ta rất nhiều template mẫu khác nhau. Chúng ta sẽ lần lượt tìm hiểu và implement ở các bài viết tiếp theo.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;event-server&#34;&gt;Event Server&lt;/h3&gt;

&lt;p&gt;PredictionIO Event Server chịu trách nhiệu thu thập dữ liệu từ các ứng dụng của bạn. Bạn có thể nhìn kỹ hơn ở hình bên dưới, các ứng dụng web, mobile app &amp;hellip; khi người dùng tương tác sẽ phát sinh các sự kiện (Event Data), ví dụ sự kiện người dùng thêm 1 đơn hàng vào giỏ hàng, người dùng xem sản phẩn A, người dùng xem sản phẩm C sau khi xem sản phẩm A&amp;hellip; Event Server sẽ ghi nhận lại đống dữ liệu này, chuẩn hoá lại. PredictionIO engine sau đó sẽ xây dựng mô hình dự đoán dựa trên các dữ liệu chúng ta thu thập được. Sau khi bạn có được mô hình tối ưu, chúng ta sẽ deploy các predict webservice, lắng nghe các truy vấn từ các ứng dụng và trả về kết quả trong thời gian thực.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/predictionio-event.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 1: Event server trong predictionio&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Event Server sẽ thu thập dữ liệu của bạn trong thời gian thực hoặc theo chu kỳ. Sau đó, nó sẽ chuẩn hoá dữ liệu hỗn độn của bạn từ nhiều nguồn khác nhau thành một dạng chuẩn chung. Event Server chủ yếu phục vụ hai mục đính chính:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Cung cấp dữ liệu cho các engine để huấn luyện và đánh giá&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Cung cấp dữ liệu dạng chuẩn để data analysis&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cũng giống như một database server, Event Server có thể được sử dụng để phục vụ cho nhiều ứng dụng khác nhau. Dữ liệu được phân tách cho các ứng dụng bằng &amp;ldquo;app_name&amp;rdquo; duy nhất. Cái này sẽ nói lại lúc xây dựng ứng dụng ở bên dưới.&lt;/p&gt;

&lt;p&gt;Khi một Event Server được triển khai, bạn có thể gửi dữ liệu cho một &amp;lsquo;app_name&amp;rsquo; cụ thể nào đó, app-name được định danh bằng access key. Dữ liệu được gửi đến Event Server sử dụng &lt;strong&gt;EventAPI&lt;/strong&gt; sử dụng giao thức http (tham khảo thêm ở &lt;a href=&#34;https://predictionio.apache.org/datacollection/eventapi/&#34;&gt;https://predictionio.apache.org/datacollection/eventapi/&lt;/a&gt;) hoặc sử dụng các PredictionIO SDK. Tham khảo thêm các SDK ở &lt;a href=&#34;https://predictionio.apache.org/sdk/&#34;&gt;https://predictionio.apache.org/sdk/&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Trong một số trường hợp, bạn muốn engine đọc dữ liệu từ một datastore nào đó thay vì Event Server. Bạn có thể thực hiện thông qua hướng dẫn ở &lt;a href=&#34;https://predictionio.apache.org/start/customize/&#34;&gt;https://predictionio.apache.org/start/customize/&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;engine&#34;&gt;Engine&lt;/h3&gt;

&lt;p&gt;Engine là nơi chịu trách nhiệu đưa ra các quyết định. Nó gồm một hoặc nhiều thuật toán học máy học khác nhau. Các Engine sẽ huấn luyện dữ liệu và xây dựng các mô hình dự đoán. Sau đó sẽ phát triển thành các webservice. Các webservice sẽ nhận các truy vấn từ ứng dụng, dự đoán và trả về kết quả cho ứng dụng.&lt;/p&gt;

&lt;p&gt;PredictionIO&amp;rsquo;s  cung cấp cho chúng ta rất nhiều các template khác nhau đáp ứng gần như là đẩy đủ các mô hình máy học mà chúng ta cần. Bạn có thể dễ dàng tạo một mô hình máy học từ các template. Các thành phần của một template dược đặt tên là &lt;strong&gt;Data Source, Data Preparator, Algorithm(s), Serving&lt;/strong&gt;, các bạn có thể dễ dàng customize lại tuỳ thuộc nhu cầu của bạn.&lt;/p&gt;

&lt;h1 id=&#34;3-cài-đặt-predictionio-trên-môi-trường-ubuntu&#34;&gt;3. Cài đặt PredictionIO trên môi trường Ubuntu&lt;/h1&gt;

&lt;p&gt;Trong thời đại docker, các bạn có thể cài đặt PredictionIO dựa vào các docker được xây dựng sẵn đầy rẫy trên mạng, chúng giúp bạn đỡ tốn công sức hơn. Tuy nhiên, trong bài viết này, mình sẽ cài đặt từng thành phần PredictiIO trên ubuntu, không sử dụng docker.&lt;/p&gt;

&lt;h3 id=&#34;download-và-build-apache-prediction-io&#34;&gt;Download và build Apache Prediction IO&lt;/h3&gt;

&lt;p&gt;Chúng ta sẽ download Prediction IO từ trang github chính chủ. Phiên bản hiện tại là 0.14.0. Các bạn có thể lưu dữ liệu ở đâu tuỳ ý các bạn. Mình lưu ở thư mục &lt;strong&gt;/data/pio&lt;/strong&gt;. Và trong suốt bài viết này, mình sẽ lưu các thứ liên quan trong thư mục /data/pio. Các bạn có cài đặt theo hướng dẫn của mình thì nhớ sửa lại cho đúng đường dẫn của các bạn. Chúng ta sẽ clone nguồn từ trang github predictionio. và sẽ switch qua branch release. Đây là branch chính thành phẩm, các branch khác đang trong giai đoạn phát triển nên có thể build không được. Lúc các bạn làm có thể nó đã phát triển lên bản 15, 16 hoặc 1.0 gì đó rồi. Các bạn cứ tự tin sử dụng phiên bản mới nhất.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;git clone https://github.com/apache/predictionio.git
git checkout release/0.14.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;biên-dịch-prediction-io&#34;&gt;Biên dịch Prediction IO&lt;/h3&gt;

&lt;p&gt;Sau khi tải về bộ nguồn của Prediction IO, chúng ta sẽ tiền hành biên dịch. Quá trình biên dịch sẽ xảy ra khá lâu, các bạn kiên nhẫn chờ đợi&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cd predictionio
./make-distribution.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết thúc quá trình biên dịch, các bạn sẽ thấy dòng chữ&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;PredictionIO binary distribution created at PredictionIO-0.14.0.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Vậy là chúng ta đã thành công. Việc tiếp theo là giải nén file PredictionIO-0.14.0.tar.gz để sử dụng&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tar xvzf PredictionIO-0.14.0.tar.gz -C /data/pio
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nhắc lại 1 lần nữa là do thời điểm hiện tại mình viết bài viết này, PredictionIO mới release bản 0.14.0 nên file tập tin sẽ là PredictionIO-0.14.0.tar.gz. Các bạn nhớ giải nén đúng với tên file ứng với phiên bản PredictionIO tương ứng nhé.&lt;/p&gt;

&lt;h3 id=&#34;download-và-giải-nén-các-dependencies&#34;&gt;Download và giải nén các Dependencies&lt;/h3&gt;

&lt;p&gt;Mình sẽ sử dụng Spark, ElasticSearch, Hbase và zookeeper, nên mình download hết về. Mình có thói quen sử dụng phiên bản mới nhất. Nên mình lên trang chủ và lấy link download mới nhất của chúng thôi. Tất cả các Dependencies mình dùng đều được bỏ vào trong thư mục vendors&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
cd PredictionIO-0.14.0
mkdir vendors
cd vendors
wget https://archive.apache.org/dist/spark/spark-2.4.2/spark-2.4.2-bin-hadoop2.7.tgz

wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.9.tar.gz

wget https://www.apache.org/dyn/closer.lua/hbase/2.1.4/hbase-2.1.4-bin.tar.gz

wget https://www-us.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz

tar xvzf spark-2.4.2-bin-hadoop2.7.tgz

tar xvzf elasticsearch-5.6.9.tar.gz

tar xvzf hbase-2.1.4-bin.tar.gz

tar xvzf zookeeper-3.4.14/zookeeper-3.4.14.tar.gz

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;cấu-hình-chương-trình&#34;&gt;Cấu hình chương trình&lt;/h3&gt;

&lt;h5 id=&#34;cấu-hình-dependency&#34;&gt;Cấu hình dependency&lt;/h5&gt;

&lt;p&gt;Chúng ta sẽ cấu hình một chút để PredictionIO nhận ra các dependency của mình và cấu hình các dependency&lt;/p&gt;

&lt;p&gt;Đầu tiên, chúng ta sẽ chỉnh sửa file &lt;strong&gt;hbase-site.xml&lt;/strong&gt; của HBase&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;nano /data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4/conf/hbase-site.xml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thay đoạn&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;lt;configuration&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bằng đoạn&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;lt;configuration&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;file:///data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.zookeeper.property.dataDir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/data/pio/PredictionIO-0.14.0/vendors/zookeeper-3.4.14&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tiếp theo, chúng ta sẽ add đường dẫn java cho hbase&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;nano /data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4/conf/hbase-env.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thêm đoạn&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt; export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;các bạn hãy thay đường dẫn java tương ứng với đường dẫn trong máy bạn. Nếu chưa có java thì các bạn hãy cài vào, nếu các bạn đã cài java mà không biết nó nằm ở đâu, các bạn có thể gọi lệnh bên dưới để xem đường dẫn&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;update-alternatives --config java
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Để chắc chắn rằng trong máy của bạn có cài java bạn hãy gọi lện &lt;strong&gt;java -version&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Ví dụ trong máy mình&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;$java -version
openjdk version &amp;quot;1.8.0_191&amp;quot;
OpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-2ubuntu0.16.04.1-b12)
OpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode)


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Các bạn cố gắng sử dụng phiên bản java mới nhất. Nó sẽ tương thích tốt hơn với phiên bản mới nhất của HBase, hoặc đọc phiên bản java đề nghị trong trang chủ HBase. Tránh trường hợp sử dụng phiên bản java quá cũ HBase không hỗ trợ.&lt;/p&gt;

&lt;h5 id=&#34;cấu-hình-prediction-io&#34;&gt;Cấu hình Prediction IO&lt;/h5&gt;

&lt;p&gt;Chỉnh sửa file &lt;strong&gt;pio-env.sh&lt;/strong&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
nano /data/pio/PredictionIO-0.14.0/conf/pio-env.sh

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Mặc định PredictionIO sử dụng PosgresSQl làm event server. Mình không dùng nó mà thay thế bằng HBASE và ELASTICSEARCH.&lt;/p&gt;

&lt;p&gt;Một số thay đổi mình sẽ liệt kê bên dưới&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;SPARK_HOME=$PIO_HOME/vendors/spark-2.3.2-bin-hadoop2.7

HBASE_CONF_DIR=$PIO_HOME/vendors/hbase-2.1.4/conf

PIO_STORAGE_REPOSITORIES_METADATA_NAME=pio_meta
PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH

PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=pio_event
PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE

PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_model
PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS

#Comment các dòng này lại, do không dùng postgres
# PIO_STORAGE_SOURCES_PGSQL_PASSWORD accordingly
# PIO_STORAGE_SOURCES_PGSQL_TYPE=jdbc
# PIO_STORAGE_SOURCES_PGSQL_URL=jdbc:postgresql://localhost/pio
# PIO_STORAGE_SOURCES_PGSQL_USERNAME=pio
# PIO_STORAGE_SOURCES_PGSQL_PASSWORD=pio

PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=$PIO_HOME/vendors/elasticsearch-5.6.9
PIO_STORAGE_SOURCES_HBASE_HOME=$PIO_HOME/vendors/hbase-2.1.4
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;4-khởi-chạy-hệ-thống&#34;&gt;4.Khởi chạy hệ thống&lt;/h1&gt;

&lt;p&gt;Chúng ta sẽ add path của PredictIO vào biến môi trường để sử dụng cho các lần sau&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
nano ~/.bashrc
erport PATH=/data/pio/PredictionIO-0.14.0/bin:$PATH

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hoặc có thể add path trong mỗi session&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;PATH=$PATH:/data/pio/PredictionIO-0.14.0/bin; export PATH
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tiếp theo, chúng ta sẽ cấp quyền cho thư mục PredictionIO&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sudo chmod -R 775 /data/pio
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nếu không cấp quyền write cho thư mục thì PredictionIO không thể write log file được.&lt;/p&gt;

&lt;p&gt;Chạy PredictionIO Server bằng cách gọi câu lệnh&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pio-start-all
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Stopping PredictionIO Event Server...
Stopping HBase...
stopping hbase.............
Stopping Elasticsearch...
tgdd@U1604:/data/pio/PredictionIO-0.14.0/bin$ pio-start-all
Starting Elasticsearch...
Starting HBase...
running master, logging to /data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4/bin/../logs/hbase-tgdd-master-U1604.out
Waiting 10 seconds for Storage Repositories to fully initialize...
Starting PredictionIO Event Server...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Để kiểm tra hệ thống khi start có lỗi lầm gì không, chúng ta sử dụng lệnh&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pio status
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[INFO] [Management$] Inspecting PredictionIO...
[INFO] [Management$] PredictionIO 0.14.0 is installed at /data/pio/PredictionIO-0.14.0
[INFO] [Management$] Inspecting Apache Spark...
[INFO] [Management$] Apache Spark is installed at /data/spark-2.3.2-bin-hadoop2.7
[INFO] [Management$] Apache Spark 2.3.2 detected (meets minimum requirement of 2.0.2)
[INFO] [Management$] Inspecting storage backend connections...
[INFO] [Storage$] Verifying Meta Data Backend (Source: ELASTICSEARCH)...
[INFO] [Storage$] Verifying Model Data Backend (Source: LOCALFS)...
[INFO] [Storage$] Verifying Event Data Backend (Source: HBASE)...
[INFO] [Storage$] Test writing to Event Store (App Id 0)...
[INFO] [HBLEvents] The table pio_event:events_0 doesn&#39;t exist yet. Creating now...
[INFO] [HBLEvents] Removing table pio_event:events_0...
[INFO] [Management$] Your system is all ready to go.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bạn thấy dòng chữ &lt;strong&gt;[INFO] [Management$] Your system is all ready to go.&lt;/strong&gt; thì yên tâm, hệ thống đã chạy thành công.&lt;/p&gt;

&lt;p&gt;Để stop hệ thống, các bạn gọi lệnh&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pio-stop-all
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả khi stop&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Stopping PredictionIO Event Server...
Stopping HBase...
stopping hbase.............
Stopping Elasticsearch...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Vậy là chúng ta đã tiến hành cài đặt thành công PredictionIO Server rồi. Hẹn gặp bạn ở bài thứ hai, cài đặt các template cho PredictionIO và tiến hành dự đoán.&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PredictionIO Phần 2 - Cài đặt chương trình demo</title>
      <link>/blog/2019-05-07-predictio-mini-demo1/</link>
      <pubDate>Fri, 03 May 2019 00:12:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-05-07-predictio-mini-demo1/</guid>
      <description>

&lt;h1 id=&#34;1-tạo-chương-trình-đầu-tiên-bằng-predictionio&#34;&gt;1. Tạo chương trình đầu tiên bằng PredictionIO&lt;/h1&gt;

&lt;p&gt;Đầu tiên, các bạn hãy tạo thư mục template ở đâu đó. Mình sẽ tạo ở trong thư mục /data/pio. Đường dẫn của mình sẽ là /data/pio/template&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;mdkir /data/pio/template
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tiếp theo, chúng ta sẽ clone templte trên github về, các bạn thực hiện lệnh sau&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;git clone https://github.com/apache/predictionio-template-recommender.git
cd predictionio-template-recommender
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tiếp theo, chúng ta sẽ tạo một app đầu tiên, mình đặt tên là ourrecommendation, các bạn thích đặt tên gì thì đặt nha.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pio app new ourrecommendation

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Để liệt kê danh sách app đang có trong hệ thống, các bạn dùng lệnh&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pio app list
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả trong máy mình tại thời điểm viết bài là&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[INFO] [Pio$]                 Name |   ID |                                                       Access Key | Allowed Event(s)
[INFO] [Pio$]    ourrecommendation |    1 | Z93rJZ7Xq2pXiQwVC6B5nRK6jRykcfyMI5huOijKbdDJeUeKEnVT-ph5nabptIX1 | (all)
[INFO] [Pio$] Finished listing 1 app(s).

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Mình mới tạo app đầu tiên tên là ourrecommendation nên chỉ có 1 app trong hệ thống. Sau này sẽ có nhiều hơn. À, sau khi tạo app, thì hệ thống sẽ generate tự động cho app với một Access Key, ví dụ access key của app ourrecommendateion của mình là Z93rJZ7Xq2pXiQwVC6B5nRK6jRykcfyMI5huOijKbdDJeUeKEnVT-ph5nabptIX1. Các bạn sẽ có access key khác với access key của mình, nên đừng copy của mình về làm gì hết :).&lt;/p&gt;

&lt;p&gt;Sau khi khởi tạo app xong, chúng ta sẽ import data vào hệ thống. Ở đây, mình sẽ download dữ liệu mẫu từ nguồn &lt;a href=&#34;https://gist.githubusercontent.com/vaghawan/0a5fb8ddb85e03631dd500d7c8f0677d/raw/17487437dd8269588d9dd1ac859b129a43842ba5/data-sample.json&#34;&gt;https://gist.githubusercontent.com/vaghawan/0a5fb8ddb85e03631dd500d7c8f0677d/raw/17487437dd8269588d9dd1ac859b129a43842ba5/data-sample.json&lt;/a&gt;. Sau khi download về các bạn import dữ liệu vào hệ thống bằng lệnh&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pio import — appid 1 — input data-sample.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Với appod 1 là id của ourrecommendation chúng ta vừa mới tạo. Nếu quên appid, các bạn có thể xem lại bằng lệnh &lt;strong&gt;pio app list&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Sau khi import thành công, chúng ta sẽ thay đổi giá trị của trường appname trong file engine.json thành tên của app mình, là ourrecommendation&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;nano engine.json

{
  &amp;quot;id&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;Default settings&amp;quot;,
  &amp;quot;engineFactory&amp;quot;: &amp;quot;org.example.recommendation.RecommendationEngine&amp;quot;,
  &amp;quot;datasource&amp;quot;: {
    &amp;quot;params&amp;quot; : {
      &amp;quot;appName&amp;quot;: &amp;quot;ourrecommendation&amp;quot;
    }
  },
  &amp;quot;algorithms&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;als&amp;quot;,
      &amp;quot;params&amp;quot;: {
        &amp;quot;rank&amp;quot;: 10,
        &amp;quot;numIterations&amp;quot;: 20,
        &amp;quot;lambda&amp;quot;: 0.01,
        &amp;quot;seed&amp;quot;: 3
      }
    }
  ]
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Một lưu ý quang trọng là giá trị &amp;ldquo;org.example.recommendation.RecommendationEngine&amp;rdquo; trong &amp;ldquo;engineFactory&amp;rdquo; là của hệ thống. Và bạn đừng sửa, thay đổi chúng. Nói chung là ngoài giá trị của &amp;ldquo;appName&amp;rdquo; ra, bạn không nên thay đổi bất kỳ thức gì khác trong file  engine.json.&lt;/p&gt;

&lt;p&gt;Sau khi import file thành công. Chúng ta sẽ build app. Lệnh build có tác dụng kiểm tra lại hệ thống đã được cấu hình đúng và đủ chưa.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pio build

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nếu build thành công, chúng ta sẽ thấy dòng chữ này.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
[INFO] [Engine$] Build finished successfully.
[INFO] [Pio$] Your engine is ready for training.

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sau khi build thành công, chúng ta sẽ tiến hành huấn luyện mô hình&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pio build

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Và chờ đợi dòng này xuất hiện&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
[INFO] [CoreWorkflow$] Training completed successfully.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Phân nhóm các thuật toán học máy</title>
      <link>/blog/2019-04-19-deep-learning-view/</link>
      <pubDate>Fri, 19 Apr 2019 00:12:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-04-19-deep-learning-view/</guid>
      <description>

&lt;p&gt;Ở bài trước mình đã trình bày định nghĩa và một số ứng dụng của Máy học (Machine Learning – ML), phân biệt ML với Trí tuệ nhân tạo (Artificial Intelligence – AI) cũng như mối quan hệ giữa AI, ML và Big Data. Từ bài viết này trở đi mình sẽ tập trung viết về ML, các thuật toán, cách sử dụng công cụ kèm theo một vài demo nhỏ giúp bạn đọc dễ hình dung và áp dụng. Để mở đầu cho chuỗi bài viết sắp tới, hôm nay mình sẽ trình bày cách phân nhóm các thuật toán ML.&lt;/p&gt;

&lt;p&gt;Với đa số mọi người, trước khi bắt đầu giải quyết một vấn đề nào đó, việc đầu tiên là chúng ta sẽ tìm hiểu xem liệu có ai đã gặp vấn đề này hoặc vấn đề tương tự như vậy hay không và cách họ giải quyết thế nào. Sau khi nắm được thông tin khái quát, công việc kế tiếp là chọn lựa và điều chỉnh giải pháp sao cho phù hợp với vấn đề của bản thân. Trong trường hợp vấn đề còn quá mới mẻ thì chúng ta mới phải bắt tay làm từ đầu, điều này hầu như rất hiếm, đặc biệt là trong thời đại công nghệ này, khi mà chỉ bằng một cú nhấp chuột, hàng ngàn thông tin, tư liệu về đề tài chúng ta quan tâm sẽ xuất hiện. Cũng giống như thế, ML hiện đã được nghiên cứu rộng khắp, rất nhiều công trình khoa học, thuật toán được cho ra đời. Với người mới bắt đầu mà nói thì chúng ta chưa cần phải làm gì cả ngoài việc nắm được các thuật toán cơ bản, đặc điểm của chúng để khi đối diện với một bài toán cụ thể trong thực tế chúng ta có thể biết được mình nên lựa chọn thuật toán nào cho phù hợp đã là điều rất tốt rồi.&lt;/p&gt;

&lt;p&gt;Mặc dù có rất nhiều thuật toán học nhưng dựa vào phương thức học (learning style) hoặc sự tương đồng (similarity) về hình thức hay chức năng mà chúng có thể được gom thành từng nhóm. Sau đây mình sẽ trình bày tổng quan cả hai cách phân nhóm thuật toán học này.&lt;/p&gt;

&lt;h1 id=&#34;1-phân-nhóm-dựa-trên-phương-thức-học&#34;&gt;1.    Phân nhóm dựa trên phương thức học&lt;/h1&gt;

&lt;p&gt;Xét theo phương thức học, các thuật toán ML được chia làm bốn nhóm, bao gồm “Học có giám sát” (Supervised Learning), “Học không giám sát” (Unsupervised Learning), “Học bán giám sát” (hay học kết hợp - Semi-supervised Learning) và “Học tăng cường” (Reinforcement Learning).&lt;/p&gt;

&lt;h2 id=&#34;a-học-có-giám-sát&#34;&gt;a.   Học có giám sát&lt;/h2&gt;

&lt;p&gt;Học có giám sát hay còn gọi là học có thầy là thuật toán dự đoán nhãn (label)/đầu ra (output) của một dữ liệu mới dựa trên tập dữ liệu huấn luyện mà trong đó mỗi mẫu dữ liệu đều đã được gán nhãn như minh hoạ ở Hình 1. Khi đó, thông qua một quá trình huấn luyện, một mô hình sẽ được xây dựng để cho ra các dự đoán và khi các dự đoán bị sai thì mô hình này sẽ được tinh chỉnh lại. Việc huấn luyện sẽ tiếp tục cho đến khi mô hình đạt được mức độ chính xác mong muốn trên dữ liệu huấn luyện. Điều này cũng giống như khi chúng ta đi học trên lớp, ta biết câu trả lời chính xác từ giáo viên (tập dữ liệu có nhãn) và từ đó ta sẽ sửa chữa nếu làm sai. Học có giám sát là nhóm phổ biến nhất trong các thuật toán ML.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/supervised-learning.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 1: Supervised Learning Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Một cách toán học, học có giám sát là khi chúng ra có một tập hợp biến đầu vào &lt;code&gt;$ X={x_1,x_2,…,x_N} $&lt;/code&gt; và một tập hợp nhãn tương ứng &lt;code&gt;$ Y={y_1,y_2,…,y_N} $&lt;/code&gt;, trong đó &lt;code&gt;$ x_i$&lt;/code&gt;, &lt;code&gt;$y_i $&lt;/code&gt; là các vector. Các cặp dữ liệu biết trước &lt;code&gt;$( x_i, y_i ) \in X \times Y $&lt;/code&gt; được gọi là tập dữ liệu huấn luyện (training data). Từ tập dữ liệu huấn luyện này, chúng ta cần tạo ra một hàm số ánh xạ mỗi phần tử từ tập X sang một phần tử (xấp xỉ) tương ứng của tập Y:&lt;/p&gt;

&lt;p&gt;$$ y_i \approx f(x_i), \forall i=1, 2, …, N $$&lt;/p&gt;

&lt;p&gt;Mục đích là xấp xỉ hàm số &lt;code&gt;$f$&lt;/code&gt; thật tốt để khi có một dữ liệu x mới, chúng ta có thể tính được nhãn tương ứng của nó &lt;code&gt;$y=f(x)$&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Ví dụ: Trong nhận dạng chữ số viết tay, ta có ảnh của hàng nghìn trường hợp ứng với mỗi chữ số được viết bởi nhiều người khác nhau. Ta đưa các bức ảnh này vào một thuật toán học và chỉ cho nó biết “mỗi bức ảnh tương ứng với chữ số nào”. Sau khi thuật toán tạo ra một mô hình, tức là một hàm số nhận đầu vào là một bức ảnh và cho ra kết quả là một chữ số. Khi nhận được một bức ảnh mới mà mô hình “chưa từng gặp qua” và nó sẽ dự đoán xem bức ảnh đó tương ứng với chữ số nào.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/mnist-900x506.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 2: Ảnh minh hoạ cho tập dữ liệu chữ số viết tay - MNIST&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Đối với những ai sử dụng mạng xã hội Facebook thì khá quen thuộc với tính năng phát hiện khuôn mặt trong một bức ảnh, bản chất của thuật toán dò tìm các khuôn mặt này là một thuật toán học có giám sát với tập huấn luyện là vô số ảnh đã được gán nhãn là mặt người hay không phải mặt người.&lt;/p&gt;

&lt;p&gt;Các thuật toán học có giám sát còn được phân ra thành hai loại chính là phân lớp (Classification) và hồi quy (Regression).&lt;/p&gt;

&lt;h3 id=&#34;phân-lớp&#34;&gt;Phân lớp&lt;/h3&gt;

&lt;p&gt;Một bài toán được gọi là phân lớp nếu các nhãn của dữ liệu đầu vào được chia thành một số hữu hạn lớp (miền giá trị là rời rạc). Chẳng hạn như tính năng xác định xem một email có phải là spam hay không của Gmail; xác định xem hình ảnh của con vật là chó hay mèo. Hoặc ví dụ nhận dạng ký số viết tay ở trên cũng thuộc bài toán phân lớp, bao gồm mười lớp ứng với các số từ 0 đến 9. Tương tự cho ví dụ nhận dạng khuôn mặt với hai lớp là phải và không phải khuôn mặt, …&lt;/p&gt;

&lt;h3 id=&#34;hồi-quy&#34;&gt;Hồi quy&lt;/h3&gt;

&lt;p&gt;Một bài toán được xem là hồi quy nếu nhãn không được chia thành các nhóm mà là một giá trị thực cụ thể (miền giá trị là liên tục). Hầu hết các bài toán dự báo (giá cổ phiếu, giá nhà, …) thường được xếp vào bài toán hồi quy. Ví như, nếu một căn nhà rộng 150 m^2, có 7 phòng và cách trung tâm thành phố 10 km sẽ có giá là bao nhiêu? Lúc này kết quả dự đoán sẽ là một số thực.&lt;/p&gt;

&lt;p&gt;Nếu như phát hiện khuôn mặt là bài toán phân lớp thì dự đoán tuổi là bài toán hồi quy. Tuy nhiên dự đoán tuổi cũng có thể coi là phân lớp nếu ta cho tuổi là một số nguyên dương N và khi đó ta sẽ có N lớp khác nhau tính từ 1.
Một số thuật toán nổi tiếng thuộc về nhóm học có giám sát như:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Phân lớp: k-Nearest Neighbors, mạng nơron nhân tạo, SVM, …&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hồi quy: Linear Regression, Logistic Regression, …&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;b-học-không-giám-sát&#34;&gt;b. Học không giám sát&lt;/h2&gt;

&lt;p&gt;Trái với Supervised learning, học không giám sát hay học không thầy là thuật toán dự đoán nhãn của một dữ liệu mới dựa trên tập dữ liệu huấn luyện mà trong đó tất cả các mẫu dữ liệu đều chưa được gán nhãn hay nói cách khác là ta không biết câu trả lời chính xác cho mỗi dữ liệu đầu vào như minh hoạ ở Hình 3. Điều này cũng giống như khi ta học mà không có thầy cô, sẽ không ai cho ta biết đáp án đúng là gì.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/unsupervisedlearning.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 3: Unsupervised Learning Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Khi đó, mục tiêu của thuật toán unsupervised learning không phải là tìm đầu ra chính xác mà sẽ hướng tới việc tìm ra cấu trúc hoặc sự liên hệ trong dữ liệu để thực hiện một công việc nào đó, ví như gom cụm (clustering) hoặc giảm số chiều của dữ liệu (dimension reduction) để thuận tiện trong việc lưu trữ và tính toán.&lt;/p&gt;

&lt;p&gt;Các bài toán Unsupervised learning tiếp tục được chia nhỏ thành hai loại là phân cụm (Clustering) và luật kết hợp (Association Rule).&lt;/p&gt;

&lt;h3 id=&#34;phân-cụm&#34;&gt;Phân cụm&lt;/h3&gt;

&lt;p&gt;Một bài toán phân cụm / phân nhóm toàn bộ dữ liệu X thành các nhóm/cụm nhỏ dựa trên sự liên quan giữa các dữ liệu trong mỗi nhóm. Chẳng hạn như phân nhóm khách hàng dựa vào độ tuổi, giới tính. Điều này cũng giống như việc ta đưa cho một đứa trẻ rất nhiều mảnh ghép với các hình dạng và màu sắc khác nhau, có thể là tam giác, vuông, tròn với màu xanh, đỏ, tím, vàng, sau đó yêu cầu trẻ phân chúng thành từng nhóm. Mặc dù ta không dạy trẻ mảnh nào tương ứng với hình nào hoặc màu nào, nhưng nhiều khả năng trẻ vẫn có thể phân loại các mảnh ghép theo màu sắc hoặc hình dạng.&lt;/p&gt;

&lt;h3 id=&#34;luật-kết-hợp&#34;&gt;Luật kết hợp&lt;/h3&gt;

&lt;p&gt;Là bài toán mà khi chúng ta muốn khám phá ra một quy luật dựa trên nhiều dữ liệu cho trước. Ví như những khách hàng mua mặt hàng này sẽ mua thêm mặt hàng kia; hoặc khan giả xem phim này sẽ có xu hướng thích xem phim kia, dựa vào đó ta có thể xây dựng những hệ thống gợi ý khách hàng (Recommendation System) nhằm thúc đẩy nhu cầu mua sắm hoặc xem phim&amp;hellip;.&lt;/p&gt;

&lt;p&gt;Một số thuật toán thuộc nhóm học không giám sát như Apriori (Association Rule), k-Means (Clustering), …&lt;/p&gt;

&lt;h2 id=&#34;c-học-bán-giám-sát&#34;&gt;c.   Học bán giám sát&lt;/h2&gt;

&lt;p&gt;Là bài toán mà khi tập dữ liệu đầu vào X là hỗn hợp các mẫu có nhãn và không có nhãn, trong đó số lượng có nhãn chỉ chiếm một phần nhỏ như minh hoạ ở Hình 4.&lt;/p&gt;

&lt;p&gt;Phần lớn các bài toán thực tế của ML thuộc nhóm này vì việc thu thập dữ liệu có nhãn tốn rất nhiều thời gian và có chi phí cao. Rất nhiều loại dữ liệu thậm chí cần phải có chuyên gia mới gán nhãn được, chẳng hạn như ảnh y học hoặc các cặp câu song ngữ. Ngược lại, dữ liệu chưa có nhãn có thể được thu thập với chi phí thấp từ internet.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/semi-supervisedlearning.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 4: Semi-supervised Learning Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Với bài toán này, mô hình phải tìm hiểu các cấu trúc để tổ chức dữ liệu cũng như đưa ra dự đoán. Vì đặc điểm trung gian nên ta có thể sử dụng unsupervised learning để khám phá và tìm hiểu cấu trúc trong dữ liệu đầu vào, đồng thời sử dụng supervised learning để dự đoán cho dữ liệu không được gán nhãn. Sau đó đưa dữ liệu vừa dự đoán trở lại làm dữ liệu huấn luyện cho supervised learning và sử dụng mô hình sau khi huấn luyện để đưa ra dự đoán về dữ liệu mới.&lt;/p&gt;

&lt;p&gt;Một số thuật toán học tăng cường như: Self Training, Generative models, S3VMs, Graph-Based Algorithms, Multiview Algorithms, …&lt;/p&gt;

&lt;h2 id=&#34;d-học-tăng-cường&#34;&gt;d.   Học tăng cường&lt;/h2&gt;

&lt;p&gt;Học tăng tường hay học củng cố là bài toán giúp cho một hệ thống tự động xác định hành vi dựa trên hoàn cảnh để đạt được lợi ích cao nhất. Hiện tại, reinforcement learning chủ yếu được áp dụng vào Lý Thuyết Trò Chơi (Game Theory), các thuật toán cần xác định nước đi tiếp theo để đạt được điểm số cao nhất. Hình 5 là một ví dụ đơn giản sử dụng học tăng cường.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/reinforcementlearning.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 5: Minh hoạ cho học tăng cường được áp dụng trong lý thuyết trò chơi.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;AlphaGo - một phần mềm chơi cờ vây trên máy tính được xây dựng bởi Google DeepMind hay chương trình dạy máy tính chơi game Mario là những ứng dụng sử dụng học tăng cường.&lt;/p&gt;

&lt;p&gt;Cờ vậy được xem là trò chơi có độ phức tạp cực kỳ cao với tổng số nước đi là xấp xỉ 1076110761, so với cờ vua là 1012010120, vì vậy thuật toán phải chọn ra một nước đi tối ưu trong số hàng tỉ tỉ lựa chọn. Về cơ bản, AlphaGo bao gồm các thuật toán thuộc cả Supervised learning và Reinforcement learning. Trong phần Supervised learning, dữ liệu từ các ván cờ do con người chơi với nhau được đưa vào để huấn luyện. Tuy nhiên, mục tiêu cuối cùng của AlphaGo không phải là chơi như con người mà phải thắng được con người. Vì vậy, sau khi học xong các ván cờ của con người, AlphaGo tự chơi với chính nó thông qua hàng triệu ván cờ để tìm ra các nước đi mới tối ưu hơn. Thuật toán trong phần tự chơi này được xếp vào loại Reinforcement learning.&lt;/p&gt;

&lt;p&gt;Đơn giản hơn cờ vây, tại một thời điểm cụ thể, người chơi game Mario chỉ cần bấm một số lượng nhỏ các nút (di chuyển, nhảy, bắn đạn) hoặc không cần bấm nút nào ứng với một chướng ngại vật cố định ở một vị trí cố định. Khi đó thuật toán trong ứng dụng dạy máy tính chơi game Mario sẽ nhận đầu vào là sơ đồ của màn hình tại thời điểm hiện hành, nhiệm vụ của thuật toán là tìm ra tổ hợp phím nên được bấm ứng với đầu vào đó. Việc huấn luyện này được dựa trên điểm số cho việc di chuyển được bao xa với thời gian bao lâu trong game, càng xa và càng nhanh thì điểm thưởng đạt được càng cao, tất nhiên điểm thưởng này không phải là điểm của trò chơi mà là điểm do chính người lập trình tạo ra. Thông qua huấn luyện, thuật toán sẽ tìm ra một cách tối ưu để tối đa số điểm trên, qua đó đạt được mục đích cuối cùng là cứu công chúa.&lt;/p&gt;

&lt;p&gt;Có nhiều cách khác nhau để thuật toán có thể mô hình hóa một vấn đề dựa trên sự tương tác của nó với dữ liệu đầu vào. Phân loại hoặc cách tổ chức thuật toán học máy này rất hữu ích vì nó buộc chúng ta phải suy nghĩ về vai trò của dữ liệu đầu vào và quy trình chuẩn bị mô hình và chọn một thuật toán phù hợp nhất cho vấn đề của chúng ta để có kết quả tốt nhất.&lt;/p&gt;

&lt;h1 id=&#34;2-phân-nhóm-dựa-trên-sự-tương-đồng&#34;&gt;2.    Phân nhóm dựa trên sự tương đồng&lt;/h1&gt;

&lt;p&gt;Dựa vào sự tương đồng về chức năng hay cách thức hoạt động mà các thuật toán sẽ được gom nhóm với nhau. Sau đây là danh sách các nhóm và các thuật toán theo từng nhóm.&lt;/p&gt;

&lt;h2 id=&#34;a-các-thuật-toán-hồi-quy-regression-algorithms&#34;&gt;a.   Các thuật toán hồi quy (Regression Algorithms)&lt;/h2&gt;

&lt;p&gt;Hồi quy là quá trình tìm mối quan hệ phụ thuộc của một biến (được gọi là biến phụ thuộc hay biến được giải thích, biến được dự báo, biến được hồi quy, biến phản ứng, biến nội sinh) vào một hoặc nhiều biến khác (được gọi là biến độc lập, biến giải thích, biến dự báo, biến hồi quy, biến tác nhân hay biến kiểm soát, biến ngoại sinh) nhằm mục đích ước lượng hoặc tiên đoán giá trị kỳ vọng của biến phụ thuộc khi biết trước giá trị của biến độc lập. Hình 6 tượng trưng cho ý tưởng của các thuật toán hồi quy.&lt;/p&gt;

&lt;p&gt;Ví dụ như, dự đoán rằng nếu tăng lãi suất tiền gửi thì sẽ huy động được lượng tiền gửi nhiều hơn, khi đó ngân hàng A cần biết mối quan hệ giữa lượng tiền gửi và lãi suất tiền gửi, cụ thể hơn họ muốn biết khi tăng lãi suất thêm 0.1% thì lượng tiền gửi sẽ tăng trung bình là bao nhiêu.&lt;/p&gt;

&lt;p&gt;Các thuật toán hồi quy phổ biến nhất là:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear Regression&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Logistic Regression&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Locally Estimated Scatterplot Smoothing (LOESS)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Multivariate Adaptive Regression Splines (MARS)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ordinary Least Squares Regression (OLSR)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Stepwise Regression&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/regression-algorithn.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 6: Regression Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;b-thuật-toán-dựa-trên-mẫu-instance-based-algorithms&#34;&gt;b.   Thuật toán dựa trên mẫu (Instance-based Algorithms)&lt;/h2&gt;

&lt;p&gt;Mô hình học tập dựa trên mẫu hay thực thể là bài toán ra quyết định dựa vào các trường hợp hoặc các mẫu dữ liệu huấn luyện được coi là quan trọng hay bắt buộc đối với mô hình.&lt;/p&gt;

&lt;p&gt;Nhóm thuật toán này thường xây dựng cơ sở dữ liệu về dữ liệu mẫu và so sánh dữ liệu mới với cơ sở dữ liệu bằng cách sử dụng thước đo tương tự để tìm kết quả phù hợp nhất và đưa ra dự đoán. Khi đó trọng tâm được đặt vào đại diện của các thể hiện được lưu trữ như minh hoạ ở Hình 7.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/instance-based-algorithms.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 7: Instance-based Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Các thuật toán dựa trên thực thể phổ biến nhất là:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;k-Nearest Neighbor (kNN – k láng giềng gần nhất)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Learning Vector Quantization (LVQ)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Locally Weighted Learning (LWL)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Self-Organizing Map (SOM)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;c-thuật-toán-chuẩn-hoá-regularization-algorithms&#34;&gt;c.   Thuật toán chuẩn hoá (Regularization Algorithms)&lt;/h2&gt;

&lt;p&gt;Các thuật toán chuẩn hoá ra đời từ sự mở rộng các phương pháp đã có (điển hình là các phương pháp hồi quy) bằng cách xử phạt các mô hình dựa trên mức độ phức tạp của chúng. Việc ưu tiên các mô hình đơn giản hơn cũng tốt hơn trong việc khái quát hóa. Hình 8 tượng trưng cho ý tưởng của thuật toán chuẩn hoá.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/regularization-algorithms.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 8: Regularization Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Các thuật toán chính quy phổ biến nhất là:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Elastic Net&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Least Absolute Shrinkage and Selection Operator (LASSO)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Least-Angle Regression (LARS)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ridge Regression&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;d-thuật-toán-cây-quyết-định-decision-tree-algorithms&#34;&gt;d.   Thuật toán cây quyết định (Decision Tree Algorithms)&lt;/h2&gt;

&lt;p&gt;Đây là phương pháp xây dựng mô hình ra quyết định dựa trên các giá trị thực của những thuộc tính trong dữ liệu. Sự quyết định được rẽ nhánh trong cấu trúc cây cho đến khi quyết định dự đoán được đưa ra cho một mẫu nhất định như minh hoạ ở Hình 9. Phương pháp này được sử dụng trong việc huấn luyện dữ liệu cho bài toán phân lớp và hồi quy. Vì sự nhanh chóng, chính xác nên phương pháp này rất được ưa chuộng trong ML.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/decision-tree-algorithm.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 9: Decision Tree Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Các thuật toán cây quyết định phổ biến nhất bao gồm:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Chi-squared Automatic Interaction Detection (CHAID)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Classification và Regression Tree – CART&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Conditional Decision Trees&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;C4.5 và C5.0&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Decision Stump&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Iterative Dichotomiser 3 (ID3)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;M5&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;e-thuật-toán-bayes-bayesian-algorithms&#34;&gt;e.   Thuật toán Bayes (Bayesian Algorithms)&lt;/h2&gt;

&lt;p&gt;Đây là nhóm các thuật toán áp dụng Định lý Bayes cho bài toán phân loại và hồi quy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/bayessian-algorith.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 10: Bayesian Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Các thuật toán phổ biến nhất là:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Averaged One-Dependence Estimators (AODE)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bayesian Belief Network (BBN)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bayesian Network (BN)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gaussian Naive Bayes&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Multinomial Naive Bayes&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Naive Bayes&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;f-thuật-toán-phân-cụm-clustering-algorithms&#34;&gt;f.   Thuật toán phân cụm (Clustering Algorithms)&lt;/h2&gt;

&lt;p&gt;Tất cả các phương pháp đều sử dụng các cấu trúc vốn có trong dữ liệu để tổ chức tốt nhất dữ liệu thành các nhóm có mức độ phổ biến tối đa dựa vào trọng tâm (centroid) và thứ bậc (hierarchal) như thể hiện ở Hình 11.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/clustering-algorithm.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 11: Clustering Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Các thuật toán phân cụm phổ biến nhất là:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Expectation Maximisation (EM – cực đại hoá kỳ vọng)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hierarchical Clustering&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;k-Means&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;k-Medians&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;g-các-thuật-toán-luật-kết-hợp-association-rule-learning-algorithms&#34;&gt;g.   Các thuật toán luật kết hợp (Association Rule Learning Algorithms)&lt;/h2&gt;

&lt;p&gt;Đây là những thuật toán sẽ rút trích ra các quy tắc giải thích tốt nhất mối quan hệ giữa các biến trong dữ liệu. Các quy tắc này có thể giúp khám phá ra các tính chất quan trọng và hữu ích trong các tập dữ liệu lớn và cao chiều trong thương mại cùng các lĩnh vực khác. Hình 12 minh hoạ cho ý tưởng của thuật toán luật kết hợp.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/association-rule.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 12: Association Rule Learning Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Các thuật toán luật kết hợp phổ biến nhất là:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Apriori algorithm&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Eclat algorithm&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;FP-Growth algorithm&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;h-thuật-toán-mạng-nơron-nhân-tạo-artificial-neural-network-algorithms&#34;&gt;h.   Thuật toán mạng nơron nhân tạo (Artificial Neural Network Algorithms)&lt;/h2&gt;

&lt;p&gt;Mạng nơron nhân tạo là các mô hình được lấy cảm hứng từ cấu trúc và chức năng của mạng lưới thần kinh sinh học. Hình 13 minh hoạ cho một mạng truyền thẳng.
Nhóm thuật toán này có thể được sử dụng cho bài toán phân lớp và hồi quy với rất nhiều biến thể khác nhau cho hầu hết các vấn đề. Tuy nhiên, trong bài viết này mình chỉ trình bày các thuật toán cổ điển và phổ biến nhất:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Back-Propagation (mạng lan truyền ngược)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Perceptron (Mạng lan truyền thẳng)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Multi-layer perceptron (Mạng truyền thẳng đa lớp)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hopfield Network&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Radial Basis Function Network (RBFN)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/neural-network-alg.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 13: Artificial Neural Network Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;i-thuật-toán-học-sâu-deep-learning-algorithms&#34;&gt;i.   Thuật toán học sâu (Deep Learning Algorithms)&lt;/h2&gt;

&lt;p&gt;Thực chất Deep Learning là một bản cập nhật hiện đại cho Artificial Neural Networks nhằm khai thác khả năng tính toán của máy tính, tuy nhiên vì sự phát triển lớn mạnh của chúng nên mình tách ra thành một nhóm riêng.&lt;/p&gt;

&lt;p&gt;Deep Learning quan tâm đến việc xây dựng các mạng thần kinh lớn hơn, phức tạp hơn nhiều, và làm sao để khai thác hiệu quả các bộ dữ liệu lớn chứa rất ít dữ liệu đã được gán nhãn. Hình 14 minh hoạ cho ý tưởng của Deep learning.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/deep-learning-alg.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 14: Deep Learning Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Các thuật toán học sâu phổ biến nhất là:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Convolutional Neural Network (CNN)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Deep Belief Networks (DBN)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Deep Boltzmann Machine (DBM)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Stacked Auto-Encoders&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;j-nhóm-thuật-toán-giảm-chiều-dữ-liệu-dimensionality-reduction-algorithms&#34;&gt;j.   Nhóm thuật toán Giảm chiều dữ liệu (Dimensionality Reduction Algorithms)&lt;/h2&gt;

&lt;p&gt;Giống như các phương pháp phân cụm, giảm không gian tìm kiếm và khai thác cấu trúc vốn có trong dữ liệu nhưng theo cách không giám sát hoặc để tóm tắt hay mô tả dữ liệu sử dụng ít thông tin hơn là mục tiêu của nhóm phương pháp này. Hình 15 minh hoạ cho việc giảm chiều dữ liệu.&lt;/p&gt;

&lt;p&gt;Điều này có thể hữu ích để trực quan hóa dữ liệu hoặc đơn giản hóa dữ liệu mà sau đó có thể được sử dụng trong phương pháp học có giám sát. Nhiều trong số các phương pháp này có thể được điều chỉnh để sử dụng trong phân lớp và hồi quy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/demension-reducion.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 15: Dimensional Reduction Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Các thuật toán Giảm chiều dữ liệu phổ biến như:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Flexible Discriminant Analysis (FDA)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Linear Discriminant Analysis (LDA)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Mixture Discriminant Analysis (MDA)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Multidimensional Scaling (MDS)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Partial Least Squares Regression (PLSR)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Principal Component Analysis (PCA)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Principal Component Regression (PCR)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Projection Pursuit&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Quadratic Discriminant Analysis (QDA)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Sammon Mapping&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;k-thuật-toán-tập-hợp-ensemble-algorithms&#34;&gt;k.   Thuật toán tập hợp (Ensemble Algorithms)&lt;/h2&gt;

&lt;p&gt;Ensemble methods là những phương pháp kết hợp các mô hình yếu hơn được huấn luyện độc lập và phần dự đoán của chúng sẽ được kết hợp theo một cách nào đó để đưa ra dự đoán tổng thể như minh họa ở Hình 16.&lt;/p&gt;

&lt;p&gt;Nhóm thuật toán này khá mạnh và được nghiên cứu nhiều, đặc biệt là về cách để kết hợp các mô hình với nhau.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/ensemble-alg.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 16: Ensemble Algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Một số thuật toán phổ biến như:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;AdaBoost&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Boosting&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bootstrapped Aggregation (Bagging)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gradient Boosting Machines (GBM)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gradient Boosted Regression Trees (GBRT)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Random Forest&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Stacked Generalization (blending)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;l-các-thuật-toán-khác&#34;&gt;l.   Các thuật toán khác&lt;/h2&gt;

&lt;p&gt;Còn rất nhiều các thuật toán khác không được liệt kê ở đây, chẳng hạn như Support Vector Machines (SVM), mình đang phân vân rằng liệu thuật toán này nên được đưa vào nhóm nào đó hay đứng một mình. Nếu dựa vào danh sách các biến thể và mức độ phát triển thì SVM có thể được tách thành một nhóm riêng – nhóm thuật toán sử dụng véctơ hỗ trợ.&lt;/p&gt;

&lt;p&gt;Thêm vào đó, các thuật toán được hình thành từ các nhiệm vụ đặc biệt, hoăc các thuật toán từ những nhánh con đặc biệt của ML cũng không được liệt kê vào các nhóm, chẳng hạn như:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Feature selection algorithms&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Algorithm accuracy evaluation&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Performance measures&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Có dịp mình sẽ bổ sung hoặc đề cập đến những thuật toán này ở một bài viết khác.&lt;/p&gt;

&lt;p&gt;Mặc dù rất hữu ích (dựa vào nhóm, người dùng sẽ dễ dàng nhớ được bản chất của thuật toán) nhưng phương pháp phân nhóm này chưa hoàn hảo ở điểm có những thuật toán có thể phù hợp với nhiều danh mục như Learning Vector Quantization, vừa là phương pháp lấy cảm hứng từ mạng thần kinh (neural network), vừa là phương pháp dựa trên cá thể (instance-based). Hoặc là thuật toán có cùng tên mô tả bài toán và nhóm thuật toán như Hồi quy (Regression) và Phân cụm (Clustering). Đối với những trường hợp này ta có thể giải quyết bằng cách liệt kê các thuật toán hai lần hoặc bằng cách chọn nhóm một cách chủ quan. Để tránh trùng lặp các thuật toán và giữ cho mọi thứ đơn giản thì có lẽ chọn nhóm theo cách chủ quan sẽ phù hợp hơn.&lt;/p&gt;

&lt;p&gt;Để giúp các bạn dễ nhớ cũng như tổng kết cho phần này mình đã vẽ một sơ đồ các thuật toán phân theo nhóm và sắp xếp theo alphabet, các bạn có thể xem thểm ở Hình 17 bên dưới.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/machine-learning-branch.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;strong&gt;Hình 17: Sơ đồ phân nhóm thuật toán theo sự tương đồng&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Hy vọng bài viết này sẽ mang lại hữu ích cho bạn đọc, nhất là giúp bạn có dược cái nhìn tổng quan về những gì hiện có và một số ý tưởng về cách liên kết các thuật toán với nhau.&lt;/p&gt;

&lt;p&gt;Danh sách các nhóm và thuật toán được liệt kê trong bài viết chỉ đảm bảo được yếu tố phổ biến tuy nhiên sẽ không đầy đủ. Vậy nên nếu bạn biết thêm thuật toán hoặc nhóm nào chưa được liệt kê ở đây hoặc kể cả cách phân nhóm thuật toán khác, cũng như sau khi đọc mà các bạn có bất kỳ góp ý, câu hỏi giúp cải thiện bài viết tốt hơn, các bạn có thể để lại bình luận nhằm chia sẻ cùng mình và những bạn đọc khác nhé.&lt;/p&gt;

&lt;p&gt;Tài liệu tham khảo:
A Tour of Machine Learning Algorithms by Jason Brownlee  in Understand Machine Learning Algorithms&lt;/p&gt;

&lt;p&gt;Semi-Supervised Learning Tutorial by Xiaojin Zhu&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Outline_of_machine_learning#Machine_learning_algorithms&#34;&gt;https://en.wikipedia.org/wiki/Outline_of_machine_learning#Machine_learning_algorithms&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Top 10 algorithms in data mining by Xindong Wu · Vipin Kumar · J. Ross Quinlan · Joydeep Ghosh · Qiang Yang · Hiroshi Motoda · Geoffrey J. McLachlan · Angus Ng · Bing Liu · Philip S. Yu · Zhi-Hua Zhou · Michael Steinbach · David J. Hand · Dan Steinberg.&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Thử làm ứng dụng tô màu ảnh xám thành ảnh màu sử dụng tensorflow</title>
      <link>/blog/2019-04-16-colorfull-grayscale-to-color/</link>
      <pubDate>Sun, 14 Apr 2019 00:13:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-04-16-colorfull-grayscale-to-color/</guid>
      <description>

&lt;h2 id=&#34;thực-hiện&#34;&gt;Thực hiện&lt;/h2&gt;

&lt;p&gt;Đây là một bài toán tiếp cận bằng Deep Learning, nên việc thu thập nhiều dữ liệu có ý nghĩa rất quang trọng trong việc đóng góp vào độ chính xác của mô hình. Ở đây, chúng ta sẽ download tập dữ liệu ảnh của &lt;a href=&#34;http://places2.csail.mit.edu/download.html&#34;&gt;http://places2.csail.mit.edu/download.html&lt;/a&gt; và sử dụng mạng UNet để huấn luyện mô hình.&lt;/p&gt;

&lt;h2 id=&#34;thu-thập-hình-ảnh-và-tiền-xử-lý&#34;&gt;Thu thập hình ảnh và tiền xử lý&lt;/h2&gt;

&lt;p&gt;Dữ liệu sẽ được download tại địa chỉ &lt;a href=&#34;http://data.csail.mit.edu/places/places365/train_256_places365challenge.tar&#34;&gt;http://data.csail.mit.edu/places/places365/train_256_places365challenge.tar&lt;/a&gt;. Tập trên có kích thước 108 GB. Đây là tập ảnh thuộc hệ màu RGB. Chúng ta sẽ chuyển tập ảnh trên về hệ màu grayscale làm ảnh gốc cho quá trình huấn luyện. Có một mẹo nhỏ cho chúng ta rút ngắn quá trình huấn luyện nhưng vẫn đảm bảo được độ chính xác của mô hình là ngoài kênh màu RGB mà chúng ta hay xài, trên thế giới còn có kênh màu HSV, trong đó nếu chúng ta chuyển một ảnh ở kênh màu RGB về hệ màu HSV, và bỏ đi các giá trị H, S, chỉ giữ lại giá trị V, thì chất lượng ảnh xám của nó gần như là tương đương với ảnh grayscale sử dụng công thức &amp;ldquo;thần thánh&amp;rdquo; mà chúng ta được học ở môn xử lý ảnh grayscale =0.30*R + 0.59*G + 0.11*B&lt;/p&gt;

&lt;p&gt;Vì vậy, thay vì việc input là giá trị xám của ảnh, output là giá trị của các kênh màu RGB, chúng ta sẽ chuyển đổi bài toán lại là input là giá trị xám, output là giá trị H và S.&lt;/p&gt;

&lt;p&gt;Mô hình mạng Unet&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/unet.PNG&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Mạng UNet là một mạng neural network được dùng khá phổ biến trong các cuộc thi phân đoạn ảnh, độ chính xác của nó so với các thuật toán khác là vượt trội hoàn toàn. Ở đây, chúng ta có 2 hướng tiếp cận, một là build một mạng Unet và random init weight rồi huấn luyện nó, cách thứ hai là build mạng unet sử dụng pretrain model rồi huấn luyện. Bởi vì đặc trưng của các pretrain model hoạt động khá tốt và được huấn luyện trên tập dataset lớn, nên mình sẻ sử dụng nó ở bài viết này. Song song đó, mình sẽ cung cấp một giải pháp kèm theo sử để sử dụng mạng mà không dùng pretrain model.&lt;/p&gt;

&lt;p&gt;Ú tưởng chính của mạng UNet tựa tựa như auto-encoder, từ ảnh gốc ban đầu, chúng sẽ được nén thông tin lại qua các phép biến đổi Conv2D (như các chú thích màu sắc của mũi tên trong hình trên), sau đó sẽ được &amp;ldquo;giải nén&amp;rdquo; về lại ảnh gốc ban đầu. Việc huấn luyện coi như là hoàn tất 100% nếu ảnh gốc với ảnh giải nén là là giống nhau hoàn toàn.&lt;/p&gt;

&lt;p&gt;Bài viết sẽ được cập nhật&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dự đoán giá cổ phiếu bằng mô hình mạng Echo State Networks</title>
      <link>/blog/2019-04-04-predicting-stock-prices-with-echo-state-networks---copy/</link>
      <pubDate>Thu, 04 Apr 2019 00:13:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-04-04-predicting-stock-prices-with-echo-state-networks---copy/</guid>
      <description>

&lt;p&gt;Trong cuốn The West Wing Script Book của Aaron Sorkin, ông ấy đã có một câu như thế này &amp;ldquo;There (is) order and even great beauty in what looks like total chaos. If we look closely enough at the randomness around us, patterns will start to emerge.&amp;rdquo;. Mình xin phép không dịch câu nói trên ra, bởi vì mình dịch khá tệ, và câu nói này khá nổi tiếng (đã được trích dẫn khá nhiều trên các bài viết của các bloger khác). Nhưng câu nói đó khá phù hợp với môi trường chứng khoán, nơi mà mọi thứ đều không rõ ràng và khá &amp;ldquo;hỗn loạn&amp;rdquo;.&lt;/p&gt;

&lt;h2 id=&#34;dự-đoán-chuỗi-thời-gian&#34;&gt;Dự đoán chuỗi thời gian&lt;/h2&gt;

&lt;p&gt;Giá cổ phiếu trên thị trường chứng khoán thường được quy vào bài toán là time series. Các công ty đầu tư hoặc các nhà nghiên cứu, các nhà đầu tư hiện nay thường sử dụng phương pháp stochastic hoặc các cải tiến của phương pháp stochastic (ví dụ mô hình ARIMA, RegARIMA,&amp;hellip;) để đưa ra các dự đoán hợp lý phù hợp với các giá trị quá khứ. Mục tiêu cuối cùng là tìm ra một mô hình khả dĩ nhất để phản ánh quy luật của thị trường và sử dụng nó để sinh ra lợi nhuận (trở nên giàu có hơn :)).&lt;/p&gt;

&lt;h2 id=&#34;các-thuộc-tính-của-time-series&#34;&gt;Các thuộc tính của time series&lt;/h2&gt;

&lt;p&gt;Một trong các thuộc tính của chuỗi thời gian là tính dừng (stationary). Một chuỗi time series được gọi là có tính dừng nếu các thuộc tính có ý nghĩa thống kê của nó (ví dụ như là trung bình, độ lệch chuẩn) không đổi theo thời gian. Ở đây, chúng ta luận bàn nho nhỏ một chút vì sao tính dừng rất quang trọng trong chuỗi thời gian.&lt;/p&gt;

&lt;p&gt;Trước hết, hầu hết các mô hình về time series hiện tại được xây dựng trên một giả định tính dừng của chuỗi thời gian. Có nghĩa là nếu chuỗi thời gian ở trong quá khứ có một hành vi nào đó, thì khả năng cao là nó sẽ lặp lại trong tương lai. Ngoài ra, các lý thuyết liên quan đến tính dừng của chuỗi time series đã được các nhà nghiên cứu khai thác một cách triệt để và dễ ràng implement hơn là các lý thuyết về non-stationary trong time series.&lt;/p&gt;

&lt;p&gt;Tính dừng được định nghĩa bằng các tiêu chí rõ ràng và nghiêm ngặt. Tuy nhiên, trong bài toán thực tế, chúng ta có thể giả định rằng một chuỗi time series được coi là có tính dừng nếu các thuộc tính thống kê không đổi theo thời gian, nghĩa là:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Giá trị trung bình không thay đổi. Nếu giá trị trung bình thay đổi, chuỗi thời gian sẽ có khuynh hướng đi lên hoặc đi xuống. Hình ảnh bên dưới, mô tả trực quan một chuỗi thời gian có tính dừng (trung bình không thay đổi), và một chuỗi thời gian không có tính dừng (trung bình thay đổi).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/const_mean_stationary_series.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Giá trị phương sai không thay đổi. Thuộc tính này còn được gọi là đồng đẳng (homoscedasticity). Hình bên dưới mô tả một chuỗi có phương sai thay đổi (không có tính dừng) và một chuỗi có phương sai bất biến (có tính dừng).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/const_variance_stationary_series.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Tính tự tương tự không phụ thuộc vào thời gian&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/autocorrelation_stationary_series.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;vì-sao-chúng-ta-lại-quan-tâm-đến-tính-dừng-của-dữ-liệu&#34;&gt;Vì sao chúng ta lại quan tâm đến tính dừng của dữ liệu&lt;/h2&gt;

&lt;p&gt;Chúng ta quan tâm đến tính dừng của dữ liệu, đơn giản là bởi vì nếu dữ liệu không có tính dừng, chúng ta không thể xây dựng mô hình chuỗi thời gian (như đã nói ở trên, các nghiên cứu hiện nay đều dựa trên một cơ sở là dữ liệu có tính dừng). Trong trường hợp bạn có trong tay dữ liệu thuộc dạng time series, và một tiêu chí nào đó trong 3 tiêu chí mình đã liệu kê ở trên bị vi phạm, suy ra là dữ liệu của bạn không có tính dừng. Bạn phải chuyển đổi dữ liệu bạn đang có để cho nó có tính dừng. May mắn rằng cũng có nhiều nghiên cứu thực hiện việc này, ví dụ như &amp;ldquo;khử xu hướng (detrending)&amp;rdquo;, khử sai biệt (differencing)&amp;hellip;&lt;/p&gt;

&lt;p&gt;Nếu bạn mới chỉ bắt đầu phân tích chuỗi thời gian, bạn sẽ thấy việc làm trên khá là stupid. Lý thuyết tốt nhất hiện nay cho chuỗi thời gian là chia nhỏ nó ra thành các thành phần như là xu hướng (linear trend), mùa vụ (seasonal), chu kỳ, và yếu tố ngẫu nhiên. Dự đoán cho từng phần một, sau đó lấy tổng chúng lại.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/arima.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Đối với những ai đã quen thuộc với biến đổi Fourier, thì sẽ dễ dàng &amp;ldquo;cảm&amp;rdquo; hơn cái mình vừa nói ở trên.&lt;/p&gt;

&lt;h2 id=&#34;cách-xác-định-tính-dừng-của-dữ-liệu&#34;&gt;Cách xác định tính dừng của dữ liệu&lt;/h2&gt;

&lt;p&gt;Khá khó để xác định một biểu đồ chuỗi time series có tính dừng hay không (quan sát biểu đồ bằng mắt). Cho nên chúng ta sẽ sử dụng kiểm định Dickey-Fuller. Đây là một kiểm định thống kê để kiểm tra xem chuỗi dữ liệu có tính dừng hay không. Với giả thuyết null là chuỗi time series là một chuỗi không có tính dừng. Nếu giá trị  nhỏ hơn một ngưỡng p-value nào đó (thường là 0.05), chúng ta có quyền bác bỏ giả định null, và nói rằng chuỗi thời gian đang có là có tính dừng. Ở bài viết này, mình không đề cập đến mô hình kiểm định - vốn được học trong môn xác xuất thống kê. Các bạn có nhu cầu tìm hiểu thì có thể search trên google hoặc là xem lại sách xác suất thống kê.&lt;/p&gt;

&lt;h2 id=&#34;phương-pháp-dự-đoán-chuỗi-thời-gian-cơ-bản&#34;&gt;Phương pháp dự đoán chuỗi thời gian cơ bản&lt;/h2&gt;

&lt;p&gt;Phương pháp cơ bản nhất, đơn giản nhất, và để áp dụng nhất dược sử dụng để dự đoán chuỗi thời gian là moving average. Mô hình này thực hiện tính trung bình của t giá trị cuối cùng làm giá trị dự đoán của điểm tiếp theo. Ví dụ như để dự đoán giá chứng khoán của ngày thứ 2 của tuần tiếp theo, chúng ta sẽ lấy trung bình giá đóng của của 5 ngày trước đó (giá từ thứ hai đến thứ sáu tuần này).&lt;/p&gt;

&lt;p&gt;Đến đây, các bạn đã có một số hiểu biết về time series. Một mô hình khá nổi tiếng là ARIMA đã được sử dụng nhiều để phân tích và dự báo. Cách thực hiện của mô hình trên được trình bày tóm gọn trong hình mô tả bên dưới.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/arima1.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;phương-pháp-dự-đoán-dựa-vào-mạng-neural-network&#34;&gt;Phương pháp dự đoán dựa vào mạng neural network&lt;/h2&gt;

&lt;p&gt;Thực tế, có rất nhiều mạng neural network đã được áp dụng để dự đoán mô hình chứng khoán. Các bạn có thể tìm đọc lại các bài viết trước đây của mình về sử dụng LSTM trong dự báo chứng khoán. Mô hình chứng khoán bằng mạng neural network nói chung phải đối mặt với một vấn đề khá &amp;ldquo;xương xẩu&amp;rdquo; là xử lý nhiễu và vanishing gradients. Trong đó, việc xử lý vanishing gradients là quan trọng nhất. Bản chất của mạng neural network là tối ưu hoá hàm lan truyền ngược bằng cách sử dụng đạo hàm giữa các lớp layer để chúng &amp;lsquo;học&amp;rsquo;. Trải qua nhiều layer, giá trị của đạo hàm sẽ càng ngày nhỏ dần vào xấp xỉ bằng 0. Giả sử chúng ta có một mô hình có 100 lớp hidden layer, chúng ta nhân 100 lần số 0.1 với nhau và boom, giá trị cuối cùng chung ta nhận được là 0, nghĩa là chúng ta chẳng học được cái gì cả.&lt;/p&gt;

&lt;p&gt;May mắn thay, tới thời điểm hiện tại, chúng ta có 3 cách để xử lý vấn đề trên:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Clipping gradients&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;LSTM (Long Short Term Memory) hoặc GRU (Gate Recurrent Units)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Echo states RNNs&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Kỹ thuật clipping gradients sử dụng một mẹo là khi giá trị đạo hàm quá lớn hoặc quá nhỏ, chúng ta sẽ không lấy đạo hàm nữa. Kỹ thuật này thoạt nhìn có vẻ hay, nhưng nó không thể ngăn chúng ta mất mát thông tin và đây là một ý tưởng khá tệ.&lt;/p&gt;

&lt;p&gt;RNN (LSTM hoặc GRU) là một kỹ thuật khác là điều chỉnh các kết nối theo một vài quy luật nhất định, ví dụ output của layer tầng 1 có thể là input của layer tầng 10, chứ không nhất thiết là input của layer tầng 2 như cách thông thường. Kỹ thuật này khá tốt về mặt lý thuyết. Tuy nhiên, có một vấn đề khá lớn khi sử dụng là chúng ta phải tính toán kỹ các kết nối để đảm bảo hệ thống hoạt động ổn đinh. Mô hình được xây dựng trên kỹ thuật này khá bự, làm cho thuật toán chạy chậm. Ngoài ra, tính hội tụ của thuật toán không được đảm bảo. Mô hình LSTM đơn giản mình có để ở hình bên dưới.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/lstm.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Mạng echo states network, là một mô hình mới được nghiên cứu gần đây, bản chất nó là một mảng recurrent neural network với các hidden layer liên kết &amp;ldquo;lỏng lẻo&amp;rdquo; với nhau. Lớp này được gọi là &amp;lsquo;reservoir&amp;rsquo; (như hình mô tả bên dưới).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/echo_state_network.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Trong mô hình mạng  echo state network, chúng ta chỉ cần huấn luyện lại trọng số của lớp output, việc này giúp chúng ta rút ngắn thời gian huấn luyện mô hình, và tăng tốc qusa trình training.&lt;/p&gt;

&lt;h2 id=&#34;sử-dụng-mạng-echo-state-networks&#34;&gt;Sử dụng mạng Echo State Networks&lt;/h2&gt;

&lt;p&gt;Về nguyên lý hoạt động của mô hình này, mình sẽ không đề cập ở đây. Chủ đề về mạng Echo State Networks mình sẽ nghiên cứu kỹ lưỡng và đề cập ở trong bài viết sắp tới. Mục tiêu của bài viết này là sử dụng mô hình Echo State Networks trong bài toán time series.&lt;/p&gt;

&lt;h4 id=&#34;dự-doán-chuỗi-time-series&#34;&gt;Dự doán chuỗi time series&lt;/h4&gt;

&lt;p&gt;Trước tiên, chúng ta sẽ import một số thư viện cần thiết, thư viện ESN đã có sẵn tại đường dẫn pyESN, các bạn download về rồi dùng&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;

import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt
import warnings
warnings.filterwarnings(&#39;ignore&#39;)

# This is the library for the Reservoir Computing got it by: https://github.com/cknd/pyESN
from pyESN import ESN 

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tiếp theo chúng ta sẽ đọc file&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
data = open(&amp;quot;amazon.txt&amp;quot;).read().split()
data = np.array(data).astype(&#39;float64&#39;)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Chúng ta sẽ xây dựng một mô hình ESN đơn giản&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
n_reservoir= 500
sparsity=0.2
rand_seed=23
spectral_radius = 1.2
noise = .0005


esn = ESN(n_inputs = 1,
      n_outputs = 1, 
      n_reservoir = n_reservoir,
      sparsity=sparsity,
      random_state=rand_seed,
      spectral_radius = spectral_radius,
      noise=noise)
      
      ```
      
Để đơn giản, mình sẽ tạo mô hình với dữ liệu tào lao như sau:input là một vector toàn số 1, output là các điểm dữ liệu của mình. Cho mô hình ESN học với số lượng phần tử là 1500, sau đó sẽ dự đoán 10 điểm dữ liệu tiếp theo. Với bước nhảy là 10, lặp 10 lần. Sau quá trình lặp, mình thu được 100 điểm dự đoán


```python
trainlen = 1500
future = 10
futureTotal=100
pred_tot=np.zeros(futureTotal)

for i in range(0,futureTotal,future):
    pred_training = esn.fit(np.ones(trainlen),data[i:trainlen+i])  # dữ liệu từ ngày i đến ngày i + trainlen
    prediction = esn.predict(np.ones(future))
    pred_tot[i:i+future] = prediction[:,0] # dự đoán cho ngày i+ trainlen + 1 đến ngày i + trainlen + future
    
    
    ```
    
Vẽ mô hình cùi mía của mình mới làm lên để xem dữ liệu dự đoán và dữ liệu thực tế chênh lệch như thế nào

```python
plt.figure(figsize=(16,8))
plt.plot(range(1000,trainlen+futureTotal),data[1000:trainlen+futureTotal],&#39;b&#39;,label=&amp;quot;Data&amp;quot;, alpha=0.3)
#plt.plot(range(0,trainlen),pred_training,&#39;.g&#39;,  alpha=0.3)
plt.plot(range(trainlen,trainlen+futureTotal),pred_tot,&#39;k&#39;,  alpha=0.8, label=&#39;Free Running ESN&#39;)

lo,hi = plt.ylim()
plt.plot([trainlen,trainlen],[lo+np.spacing(1),hi-np.spacing(1)],&#39;k:&#39;, linewidth=4)

plt.title(r&#39;Ground Truth and Echo State Network Output&#39;, fontsize=25)
plt.xlabel(r&#39;Time (Days)&#39;, fontsize=20,labelpad=10)
plt.ylabel(r&#39;Price ($)&#39;, fontsize=20,labelpad=10)
plt.legend(fontsize=&#39;xx-large&#39;, loc=&#39;best&#39;)
sns.despine()
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/echo_state_network_p1.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Độ phức tạp của mô hình là khá nhỏ khi so với mô hình RNN. Lý do là về bản chất, chúng ta chỉ huấn luyện trên trọng số của output layer, nó là một hàm tuyến tính. Do vậy, độ phức tạp tính toán chỉ giống như là việc tính một hàm hồi quy tuyến tính. Trong thực tế, độ phức tạp tính toán sẽ là O(N) với N là ố lượng hidden unit trong reservoir.&lt;/p&gt;

&lt;h4 id=&#34;tối-ưu-hoá-các-tham-số-hyper-parameters&#34;&gt;Tối ưu hoá các tham số Hyper parameters&lt;/h4&gt;

&lt;p&gt;Ở phần trước, chúng ta set đại các tham số spectral_radius = 1.2 và noise = .0005. Trong thực tế, chúng ta phải tìm các siêu tham số này bằng cách tìm ra mô hình trả về MSE là nhỏ nhất.&lt;/p&gt;

&lt;p&gt;Sử dụng kỹ thuật Grid Search với ngưỡng spectrum_radius nằm trong đoạn [0.5, 1.5] và noise nằm trong đoạn  noise [0.0001, 0.01], chú ý là các bạn có thể search ở đoạn lớn hơn. Kết quả thu được:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def MSE(yhat, y):
    return np.sqrt(np.mean((yhat.flatten() - y)**2))
    
    n_reservoir= 500
sparsity   = 0.2
rand_seed  = 23
radius_set = [0.9,  1,  1.1]
noise_set = [ 0.001, 0.004, 0.006]

radius_set = [0.5, 0.7, 0.9,  1,  1.1,1.3,1.5]
noise_set = [ 0.0001, 0.0003,0.0007, 0.001, 0.003, 0.005, 0.007,0.01]



radius_set_size  = len(radius_set)
noise_set_size = len(noise_set)

trainlen = 1500
future = 2
futureTotal= 100

loss = np.zeros([radius_set_size, noise_set_size])

for l in range(radius_set_size):
    rho = radius_set[l]
    for j in range(noise_set_size):
        noise = noise_set[j]

        pred_tot=np.zeros(futureTotal)

        esn = ESN(n_inputs = 1,
          n_outputs = 1, 
          n_reservoir = n_reservoir,
          sparsity=sparsity,
          random_state=rand_seed,
          spectral_radius = rho,
          noise=noise)

        for i in range(0,futureTotal,future):
            pred_training = esn.fit(np.ones(trainlen),data[i:trainlen+i])
            prediction = esn.predict(np.ones(future))
            pred_tot[i:i+future] = prediction[:,0]
        
        loss[l, j] = MSE(pred_tot, data[trainlen:trainlen+futureTotal])        
        print(&#39;rho = &#39;, radius_set[l], &#39;, noise = &#39;, noise_set[j], &#39;, MSE = &#39;, loss[l][j] )
        
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
(&#39;rho = &#39;, 0.5, &#39;, noise = &#39;, 0.0001, &#39;, MSE = &#39;, 20.367056799629353)
(&#39;rho = &#39;, 0.5, &#39;, noise = &#39;, 0.0003, &#39;, MSE = &#39;, 22.44956008062169)
(&#39;rho = &#39;, 0.5, &#39;, noise = &#39;, 0.0007, &#39;, MSE = &#39;, 24.574909979223666)
(&#39;rho = &#39;, 0.5, &#39;, noise = &#39;, 0.001, &#39;, MSE = &#39;, 25.862558649155638)
(&#39;rho = &#39;, 0.5, &#39;, noise = &#39;, 0.003, &#39;, MSE = &#39;, 29.882933676750657)
(&#39;rho = &#39;, 0.5, &#39;, noise = &#39;, 0.005, &#39;, MSE = &#39;, 32.63942614291128)
(&#39;rho = &#39;, 0.5, &#39;, noise = &#39;, 0.007, &#39;, MSE = &#39;, 36.441245548726)
(&#39;rho = &#39;, 0.5, &#39;, noise = &#39;, 0.01, &#39;, MSE = &#39;, 44.77637915282457)
(&#39;rho = &#39;, 0.7, &#39;, noise = &#39;, 0.0001, &#39;, MSE = &#39;, 19.560517902720054)
(&#39;rho = &#39;, 0.7, &#39;, noise = &#39;, 0.0003, &#39;, MSE = &#39;, 20.12742795009036)
(&#39;rho = &#39;, 0.7, &#39;, noise = &#39;, 0.0007, &#39;, MSE = &#39;, 20.81801427735713)
(&#39;rho = &#39;, 0.7, &#39;, noise = &#39;, 0.001, &#39;, MSE = &#39;, 21.26142619965559)
(&#39;rho = &#39;, 0.7, &#39;, noise = &#39;, 0.003, &#39;, MSE = &#39;, 23.270880660885513)
(&#39;rho = &#39;, 0.7, &#39;, noise = &#39;, 0.005, &#39;, MSE = &#39;, 26.061347331527354)
(&#39;rho = &#39;, 0.7, &#39;, noise = &#39;, 0.007, &#39;, MSE = &#39;, 30.298361979419834)
(&#39;rho = &#39;, 0.7, &#39;, noise = &#39;, 0.01, &#39;, MSE = &#39;, 39.17074955771047)
(&#39;rho = &#39;, 0.9, &#39;, noise = &#39;, 0.0001, &#39;, MSE = &#39;, 18.612970860501118)
(&#39;rho = &#39;, 0.9, &#39;, noise = &#39;, 0.0003, &#39;, MSE = &#39;, 18.681815816990774)
(&#39;rho = &#39;, 0.9, &#39;, noise = &#39;, 0.0007, &#39;, MSE = &#39;, 18.835785386862582)
(&#39;rho = &#39;, 0.9, &#39;, noise = &#39;, 0.001, &#39;, MSE = &#39;, 18.982346096338105)
(&#39;rho = &#39;, 0.9, &#39;, noise = &#39;, 0.003, &#39;, MSE = &#39;, 20.81632098844061)
(&#39;rho = &#39;, 0.9, &#39;, noise = &#39;, 0.005, &#39;, MSE = &#39;, 24.60968377490799)
(&#39;rho = &#39;, 0.9, &#39;, noise = &#39;, 0.007, &#39;, MSE = &#39;, 30.231007189936882)
(&#39;rho = &#39;, 0.9, &#39;, noise = &#39;, 0.01, &#39;, MSE = &#39;, 41.28587340583505)
(&#39;rho = &#39;, 1, &#39;, noise = &#39;, 0.0001, &#39;, MSE = &#39;, 18.23852181110818)
(&#39;rho = &#39;, 1, &#39;, noise = &#39;, 0.0003, &#39;, MSE = &#39;, 18.27010615150326)
(&#39;rho = &#39;, 1, &#39;, noise = &#39;, 0.0007, &#39;, MSE = &#39;, 18.36078059388596)
(&#39;rho = &#39;, 1, &#39;, noise = &#39;, 0.001, &#39;, MSE = &#39;, 18.47920006882226)
(&#39;rho = &#39;, 1, &#39;, noise = &#39;, 0.003, &#39;, MSE = &#39;, 20.613227951906246)
(&#39;rho = &#39;, 1, &#39;, noise = &#39;, 0.005, &#39;, MSE = &#39;, 25.153712109142973)
(&#39;rho = &#39;, 1, &#39;, noise = &#39;, 0.007, &#39;, MSE = &#39;, 31.700838835741898)
(&#39;rho = &#39;, 1, &#39;, noise = &#39;, 0.01, &#39;, MSE = &#39;, 44.23736750779224)
(&#39;rho = &#39;, 1.1, &#39;, noise = &#39;, 0.0001, &#39;, MSE = &#39;, 17.981571756431556)
(&#39;rho = &#39;, 1.1, &#39;, noise = &#39;, 0.0003, &#39;, MSE = &#39;, 18.009398312163942)
(&#39;rho = &#39;, 1.1, &#39;, noise = &#39;, 0.0007, &#39;, MSE = &#39;, 18.09054736889828)
(&#39;rho = &#39;, 1.1, &#39;, noise = &#39;, 0.001, &#39;, MSE = &#39;, 18.218795249276663)
(&#39;rho = &#39;, 1.1, &#39;, noise = &#39;, 0.003, &#39;, MSE = &#39;, 20.82610561349463)
(&#39;rho = &#39;, 1.1, &#39;, noise = &#39;, 0.005, &#39;, MSE = &#39;, 26.272452530336505)
(&#39;rho = &#39;, 1.1, &#39;, noise = &#39;, 0.007, &#39;, MSE = &#39;, 33.91532767431614)
(&#39;rho = &#39;, 1.1, &#39;, noise = &#39;, 0.01, &#39;, MSE = &#39;, 48.22002405965967)
(&#39;rho = &#39;, 1.3, &#39;, noise = &#39;, 0.0001, &#39;, MSE = &#39;, 17.72839068197909)
(&#39;rho = &#39;, 1.3, &#39;, noise = &#39;, 0.0003, &#39;, MSE = &#39;, 17.799908079894703)
(&#39;rho = &#39;, 1.3, &#39;, noise = &#39;, 0.0007, &#39;, MSE = &#39;, 17.92917208443474)
(&#39;rho = &#39;, 1.3, &#39;, noise = &#39;, 0.001, &#39;, MSE = &#39;, 18.143905288756557)
(&#39;rho = &#39;, 1.3, &#39;, noise = &#39;, 0.003, &#39;, MSE = &#39;, 22.20343747458126)
(&#39;rho = &#39;, 1.3, &#39;, noise = &#39;, 0.005, &#39;, MSE = &#39;, 30.05977704513729)
(&#39;rho = &#39;, 1.3, &#39;, noise = &#39;, 0.007, &#39;, MSE = &#39;, 40.56654468067572)
(&#39;rho = &#39;, 1.3, &#39;, noise = &#39;, 0.01, &#39;, MSE = &#39;, 59.43231026660687)
(&#39;rho = &#39;, 1.5, &#39;, noise = &#39;, 0.0001, &#39;, MSE = &#39;, 17.627409489404897)
(&#39;rho = &#39;, 1.5, &#39;, noise = &#39;, 0.0003, &#39;, MSE = &#39;, 17.835052829116567)
(&#39;rho = &#39;, 1.5, &#39;, noise = &#39;, 0.0007, &#39;, MSE = &#39;, 18.100099619981393)
(&#39;rho = &#39;, 1.5, &#39;, noise = &#39;, 0.001, &#39;, MSE = &#39;, 18.481406587483956)
(&#39;rho = &#39;, 1.5, &#39;, noise = &#39;, 0.003, &#39;, MSE = &#39;, 24.887601182697498)
(&#39;rho = &#39;, 1.5, &#39;, noise = &#39;, 0.005, &#39;, MSE = &#39;, 36.34166374510305)
(&#39;rho = &#39;, 1.5, &#39;, noise = &#39;, 0.007, &#39;, MSE = &#39;, 50.99612645577753)
(&#39;rho = &#39;, 1.5, &#39;, noise = &#39;, 0.01, &#39;, MSE = &#39;, 75.94229622771246)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả thu được là giá trị MSE tốt nhất là spectrum radius =  1.5 và nnoise  = 0.0001&lt;/p&gt;

&lt;p&gt;Thử dự đoán giá cổ phiếu của tập đoàn thế giới di động (Mã cổ phiếu MWG) xem sao&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/echo_state_network_mwg.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Ở hình trên, mình không tiến hành grid search mà lấy lại các hyper parameters cũ để huấn luyện mô hình. Kết quả như hình trên  mình thấy cũng khá tốt rồi, nên mình không tiến hành grid search lại để tìm kết quả tốt hơn.&lt;/p&gt;

&lt;p&gt;Dựa vào kết quả chúng ta thu được, có thể nói rằng mô hình ESN dự đoán khá tốt dữ liệu thuộc dạng time series với độ hỗn loạn cao. Đây là một kết luận nhỏ của mình dựa vào bằng chứng trên việc mình test trên tập dữ liệu ngẫu nhiên mà mình có.&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Các lý do mạng neural network không hoạt động không chính xác</title>
      <link>/blog/2019-04-02-37-reason-neural-network-not-working/</link>
      <pubDate>Tue, 02 Apr 2019 00:13:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-04-02-37-reason-neural-network-not-working/</guid>
      <description>

&lt;p&gt;Bạn huấn luyện một hình mất hơn 12 tiếng đồng hồ. Mọi thứ khá ổn: loss function giảm. Nhưng khi bạn mang mô hình ra predict thì điều tồi tệ nhất xảy ra: Tất cả trả về đều là 0, không có cái nào nhận dạng chính xác cả. &amp;ldquo;Điều gì đã xảy ra, bạn đã làm gì sai?&amp;rdquo;. Bạn hỏi máy tính, nó không trả lời bạn. Bạn đập bàn, đập ghế trong cơn tức giận và chẳng giải quyết được điều gì cả.&lt;/p&gt;

&lt;p&gt;Có rất nhiều nguyên nhân gây ra vấn đề này. Việc cần làm của các bạn là phải tìm ra chính xác nguyên nhân và &amp;ldquo;sửa&amp;rdquo; nó, sau đó tốn hơn 12 tiếng đồng hồ để huấn luyện lại :), rồi lại sửa &amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;hướng-dẫn-ban-đầu&#34;&gt;Hướng dẫn ban đầu&lt;/h2&gt;

&lt;p&gt;Nếu bạn gặp tình trạng như phần mô tả ở trên, bạn hãy thực hiện các bước mình mô tả bên dưới thử xem vấn đề của bạn là gì?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Bắt đầu huấn luyện mô hình bằng một mô hình đơn giản mà bạn biết chắc rằng nó hoạt động tốt với tập dữ liệu bạn đang có. Ví dụ, trong bài toán object detection, hãy sử dụng mô hình VGG. Và bạn hãy cố gắng sửa dụng standard loss nếu có thể.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bỏ qua những thứ râu ria như là regularization hoặc data augmentation. Hãy tập trung vào xây dựng một mô hình cho một kết quả khả quan cái đã, sau đó mới cải tiến bằng các thứ râu ria trên sau.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Nếu bạn finetuning một mô hình, bạn hãy kiểm tra thật kỹ quá trình tiền xử lý dữ liệu. Chắc chắn rằng quá trình tiền xử lý của bạn giống y chang quá trình tiền xử lý của mô hình gốc.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Chắc chắn 100% rằng giá trị đầu vào là đúng.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bắt đầu bằng một tập sample nhỏ (từ 2 đến 20 mẫu). Huấn luyện nó đến khi bị overfit và bổ sung thêm mẫu huấn luyện sau khi mô hình của bạn bị overfit.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bổ sung thên các yếu tố râu ria như augmentation/regularization,  custom loss functions, thử với một mô hình phức tạp hơn.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nếu những cách trên vẫn không thành công. Mô hình vẫn trả về giá trị zero. Bạn có thể mắc phải một số lỗi được liệt kê bên dưới.&lt;/p&gt;

&lt;p&gt;Kiểm tra rằng dữ liệu của bạn đưa vào mạng neural netwok thật sự có ý nghĩa và đúng. Ví dụ, hãy đảm bảo rằng bạn không nhầm lẫn / swap giá trị giữa width và height của hình ảnh, hoặc một lý do nào đó bạn đưa vào một zero image, hoặc bạn chỉ huấn luyện duy nhất một batch (ví dụ dữ liệu bạn lớn, chia làm 10 batch, và code nhầm sao đó chỉ đưa input là batch số 1 vào).&lt;/p&gt;

&lt;p&gt;Một trường hợp nữa là khi input và output của bạn chẳng có mối liên hệ gì với nhau, và không cách nào nhận biết rằng nó phụ thuộc nhau bởi vì bản chất của dữ liệu là như vậy, hoặc input của bạn đang có chưa đủ chứng cứ để suy ra output. Một ví dụ của trường hợp này là giá chứng khoáng.&lt;/p&gt;

&lt;p&gt;Kiểm tra kỹ dữ liệu train để đảm bảo không có đánh nhãn sai&lt;/p&gt;

&lt;p&gt;Kiểm tra xem dữ liệu có bị mất cân bằng không. Hãy sử dụng các kỹ thuật để cân bằng lại dữ liệu.&lt;/p&gt;

&lt;p&gt;Đảm bảo rằng trong 1 batch chứa dữ liệu của nhiều hơn 1 nhãn. Hãy xáo trộn ngẫu nhiên dữ liệu để tránh lỗi này.&lt;/p&gt;

&lt;p&gt;Bài báo &lt;a href=&#34;https://arxiv.org/abs/1609.04836&#34;&gt;https://arxiv.org/abs/1609.04836&lt;/a&gt; chỉ ra rằng khi bạn huấn luyện mô hình với batch size lớn có thể làm giảm tính tổng quát của mô hình.&lt;/p&gt;

&lt;p&gt;Khoá học CS231 đã chỉ ra một lỗi khá phổ biến: &amp;ldquo;Bất kỳ một quá trình tiền xử lý nào cũng phải thực hiện trên tập train, và sau đó áp dụng vào tập validation,test&amp;rdquo;. Ví dụ, chúng ta tính trung bình trên toàn bộ dữ liệu, rồi sau đó chia tập dữ liệu thành train, test, predict là không đúng. Hành động đúng là chia tập dữ liệu thành train, test, vali trước, sau đó tính giá trị trung bình trên từng kênh màu trên tập train, rồi mới lấy giá trị trung bình đó áp cho tập test và tập validate.&lt;/p&gt;

&lt;p&gt;Một vấn đề khác có thể là &amp;ldquo;Look for correct loss at chance performance&amp;rdquo;:&lt;/p&gt;

&lt;p&gt;Ví dụ, với tập dữ liệu CIFAR-10 sử dụng softmax classifier, ở lần đầu tiên, giá trị loss mong đợi của chúng ta là 2.303, bởi vì có 1 thằng đúng, 10 thằng sai, xác suất là &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;10&lt;/sub&gt; = 0.1. softmax loss là -ln(0.1) = 2.302.&lt;/p&gt;

&lt;p&gt;Với dữ liệu CIFAR-10 dùng SVM, ở lần lặp đầu tiên, giá trị loss chúng ta kỳ vọng là 9 (với mỗi lớp sai, giá trị margin sẽ là 1).&lt;/p&gt;

&lt;p&gt;Nếu các giá trị trả ra không giống như mong đợi, vấn đề xảy ra là do giá trị init không đúng.&lt;/p&gt;

&lt;p&gt;Một vấn đề nữa là khi tăng giá trị regularization thì cũng đồng thời tăng giá trị loss. =&amp;gt; Nếu loss không tăng =&amp;gt; có vấn đề.&lt;/p&gt;

&lt;p&gt;Bài viết được lược dịch từ &lt;a href=&#34;https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607?fbclid=IwAR1Qj6jJW87oKi_LR7xWMDOMZDTx8xwLZEhCCMuvOw63ztwdD1MknZVjm_Q&#34;&gt;https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607?fbclid=IwAR1Qj6jJW87oKi_LR7xWMDOMZDTx8xwLZEhCCMuvOw63ztwdD1MknZVjm_Q&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Trí tuệ nhân tạo, Máy học, Dữ liệu lớn</title>
      <link>/blog/2019-04-02-deep-learning-view/</link>
      <pubDate>Tue, 02 Apr 2019 00:12:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-04-02-deep-learning-view/</guid>
      <description>

&lt;p&gt;Trong vài năm trở lại đây (khoảng từ 2013) truyền thông trong và ngoài nước có khá nhiều bài viết giật tít về “Cách mạng công nghiệp lần thứ tư” hay “Thời đại công nghiệp 4.0”. Cùng với các cụm từ này, “Trí tuệ nhân tạo”, “Máy học”, “Dữ liệu lớn” lại được nhắc đến với tần suất cao hơn. Vậy thì những thuật ngữ này có ý nghĩa gì và giữa chúng có mối liên hệ nào với nhau hay không? Trong bài viết này, chúng ta sẽ cùng tìm hiểu.&lt;/p&gt;

&lt;h2 id=&#34;trí-tuệ-nhân-tạo&#34;&gt;Trí tuệ nhân tạo&lt;/h2&gt;

&lt;p&gt;Năm 2016, trong “Trận thách đấu của Google DeepMind” được tổ chức tại Hàn Quốc, AlphaGo  (một phần mềm chơi cờ vây trên máy tính được xây dựng bởi Google DeepMind) đã dành chiến thắng &lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;5&lt;/sub&gt; ván trước Lee Sedol (người từng 18 lần vô địch giải cờ vây thế giới) là sự kiện quan trọng khiến con người có thể tin tưởng vào tương lai và sức mạnh của &lt;em&gt;trí tuệ nhân tạo&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Sau khi trận đấu kết thúc, chính phủ Hàn Quốc công bố rằng họ sẽ đầu từ 863 triệu USD (khoảng 1 nghìn tỷ won) vào nghiên cứu trí tuệ nhân tạo trong vòng vài năm tiếp theo.&lt;/p&gt;

&lt;p&gt;Tính tới nay, lượng dữ liệu các trận đấu cờ vây được nhận vào giúp AlphaGO có kinh nghiệm tương đương với 80 năm chơi cờ vây liên tục. Một con số đáng ngạc nhiên và ngưỡng mộ.&lt;/p&gt;

&lt;p&gt;Như vậy trí tuệ nhân tạo là gì?&lt;/p&gt;

&lt;p&gt;Trí tuệ nhân tạo (AI - Artificial Intelligence) là một nhánh nghiên cứu trong lĩnh vực khoa học máy tính và từ lâu đã được rất nhiều các nhà nghiên cứu quan tâm. Thuật ngữ AI được đặt bởi nhà khoa học máy tính người Mỹ - John McCarthy vào năm 1956 tại Hội nghị Dartmouth. Cho đến thời điểm hiện tại thì có khá nhiều những phát biểu khác nhau về AI bởi các chuyên gia, chẳng hạn như:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;AI là khoa học nghiên cứu giúp tạo ra máy tính có khả năng suy nghĩ, đầy trí tuệ như tên của chính nó (Haugeland, 1985).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AI là khoa học nghiên cứu các hoạt động trí não thông qua các mô hình tính toán (Chaniaka và McDemott, 1985).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AI là khoa học nghiên cứu cách để máy tính có thể thực hiện được những công việc mà con người làm tốt hơn máy (Rich và Knight, 1991).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AI là khoa học nghiên cứu các mô hình máy tính có thể nhận thức, lập luận và hành động (Winston, 1992).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AI là khoa học nghiên cứu các hành vi thông minh mô phỏng các vật thể nhân tạo (Nilsson, 1998)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;AI là khoa học nghiên cứu các hành vi thông minh nhằm giải quyết các vấn đề được đặt ra đối với các chương trình máy tính (Học viện Kỹ thuật Quân sự).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Như vậy, từ những định nghĩa trên chúng ta có thể rút ra định nghĩa tổng quát rằng &lt;em&gt;trí tuệ nhân tạo hay trí thông minh nhân tạo là trí tuệ được biểu diễn bởi bất kỳ một hệ thống nhân tạo nào. Hệ thống đó sẽ mô phỏng các quá trình hoạt động trí tuệ của con người, bao gồm quá trình học tập, lập luận và tự sửa lỗi&lt;/em&gt;. Do đó, trí thông minh nhân tạo liên quan đến cách hành xử, sự học hỏi và khả năng thích ứng thông minh của máy móc nói chung và máy tính nói riêng.&lt;/p&gt;

&lt;p&gt;Cách đây vài năm, đối với phần đông chúng ta – những người không nghiên cứu chuyên sâu về AI sẽ cho rằng AI là một phương thức để nhân bản con người bằng máy móc và được ứng dụng trong chế tạo robot. Tuy nhiên AI hiện tại không phải chỉ là những con robot mà nó có thể biểu hiện dưới bất cứ hình dạng nào, thậm chí vô hình vô dạng, nhằm cung cấp lời giải cho các vấn đề của cuộc sống thực tế trên hầu hết các lĩnh vực, chẳng hạn như:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Trong lĩnh vực chăm sóc sức khỏe&lt;/strong&gt;: AI góp phần cải thiện tình trạng sức khỏe bệnh nhân, và giúp giảm chi phí điều trị. Một trong những hệ thống công nghệ chăm sóc sức khỏe tốt nhất phải kể đến là IBM Watson, được mệnh danh là “Bác sĩ biết tuốt” khi mà hệ thống này có khả năng hiểu được các ngôn ngữ tự nhiên và có khả năng phản hồi các câu hỏi được yêu cầu hoặc cho phép bệnh nhân tra cứu thông tin về tinh hình sức khoẻ của mình. IBM Watson có thể lướt duyệt cùng lúc hàng triệu hồ sơ bệnh án để cung cấp cho các bác sĩ những lựa chọn điều trị dựa trên bằng chứng chỉ trong vòng vài giây nhờ khả năng tổng hợp dữ liệu khổng lồ và tốc độ xử lý mạnh mẽ. “Bác sĩ biết tuốt” khai thác dữ liệu bệnh nhân và các nguồn dữ liệu sẵn có khác nhằm tạo ra giả thuyết và từ đó xậy dựng một lược đồ điểm tin cậy giúp “Bác sĩ thật” đưa ra quyết định điều trị cuối cùng. Ngoài ra, ứng dụng AI nổi bậc khác trong lĩnh vực này cần phải kể đến là chatbot - chương trình máy tính trực tuyến để trả lời các câu hỏi và hỗ trợ khách hàng, sắp xếp các cuộc hẹn hoặc trợ giúp bệnh nhân thông qua quá trình thanh toán và các trợ lý y tế ảo cung cấp phản hồi y tế cơ bản.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Trong lĩnh vực kinh doanh&lt;/strong&gt;: Các tác vụ mà con người thực hiện lặp đi lặp lại giờ đây đã được tự động hoá quy trình bằng robot. Các thuật toán Machine Learning được tích hợp trên các nền tảng phân tích và CRM (Customer Relationship Management - quản lý quan hệ khách hàng) để khám phá các thông tin về cách phục vụ khách hàng tốt hơn. Chatbots được tích hợp trên các trang web nhằm cung cấp dịch vụ ngay lập tức cho khách hàng. Một số hệ thống trợ lý ảo nổi tiếng giúp sắp xếp, nhắc cuộc họp, tìm kiếm thông tin như Google Assistant, Alexa, Siri. Hiện nay các hệ thống này đã bắt đầu được tích hợp vào trong các thiết bị gia dụng như máy giặt, tủ lạnh, lò vi sóng, … giúp người sử dụng có thể điều khiển thiết bị bằng câu lệnh thoại.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Trong lĩnh vực giáo dục&lt;/strong&gt;: Công nghệ thực tế ảo làm thay đổi cách dạy và học. Sinh viên có thể đeo kính VR và có cảm giác như đang ngồi trong lớp nghe giảng bài hay nhập vai để chứng kiến những trận đánh giả lập, ngắm nhìn di tích, điều này giúp mang lại cảm xúc và ghi nhớ sâu sắc nội dung học. Hoặc khi đào tạo nghề phi công, học viên đeo kính sẽ thấy phía trước là cabin và học lái máy bay như thật để thực hành giúp giảm thiểu rủi ro trong quá trình bay thật.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Trong lĩnh vực tài chính&lt;/strong&gt;: AI áp dụng cho các ứng dụng tài chính cá nhân như Mint hay Turbo Tax giúp tăng cường các định chế tài chính.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Trong lĩnh vực pháp luật&lt;/strong&gt;: Quá trình khám phá, chọn lọc thông qua các tài liệu trong luật pháp thường áp đảo đối với con người. Tự động hóa quá trình này giúp tiết kiệm thời gian và quá trình làm việc hiệu quả hơn. Các trợ lý ảo giúp trả lời các câu hỏi đã được lập trình sẵn.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Trong lĩnh vực sản xuất&lt;/strong&gt;: Đây là lĩnh vực đi đầu trong việc kết hợp robot vào luồng công việc. Robot công nghiệp được sử dụng để thực hiện các nhiệm vụ đơn lẻ và đã được tách ra khỏi con người. Xe tự động lái Tesla là một ứng dụng điển hình trong lĩnh vực này.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Trong lĩnh vực bảo mật thông tin&lt;/strong&gt;: rất nhiều hệ thống nhận diện và bảo mật thông minh được xây dựng, phải kể đến như FaceID - bảo mật thông qua nhận diện khuôn mặt của Apple, Facebook với khả nhận diện khuôn mặt để gợi ý tag. Bên cạnh các nước phương Tây thì Trung Quốc hiện đang là quốc gia đi đầu trong việc sử dụng AI để nhận diện và quản lý công dân.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Từ những ứng dụng trên ta có thể thấy rằng nói đến AI là nói về não bộ chứ không phải là nói về một cơ thể, là phần mềm chứ không phải là phần cứng.&lt;/p&gt;

&lt;h2 id=&#34;dữ-liệu-lớn&#34;&gt;Dữ liệu lớn&lt;/h2&gt;

&lt;p&gt;Một cách tổng quát thì dữ liệu là thông tin dưới dạng ký hiệu, chữ viết, chữ số, hình ảnh, âm thanh hoặc dạng tương tự.
Từ thế kỷ thứ 3 trước CN, Thư viện Alexandria được coi là nơi chứa đựng toàn bộ kiến thức của loài người. Ngày nay, tổng lượng dữ liệu trên toàn thế giới đủ để chia đều cho mỗi đầu người một lượng nhiều gấp 320 lần lượng dữ liệu mà các sử gia tin rằng Thư viện Alexandria từng lưu trữ – ước tính vào khoảng 120 exabyte. Các nhà thống kê cho rằng, nếu tất cả những dữ liệu này được ghi vào đĩa CD và xếp chồng chúng lên nhau thì sẽ có tới 5 chồng đĩa mà mỗi chồng đều có độ cao bằng khoảng cách từ Trái Đất đến Mặt Trăng.&lt;/p&gt;

&lt;p&gt;Sự bùng nổ dữ liệu này chỉ mới xuất hiện gần đây. Cách đây không lâu, vào năm 2000, chỉ một phần tư lượng dữ liệu lưu trữ trên toàn thế giới ở dạng kỹ thuật số, ba phần tư còn lại được người ta lưu trên giấy tờ, phim, và các phương tiện analog khác. Nhưng do lượng dữ liệu kỹ thuật số bùng nổ quá nhanh – cứ 3 năm lại tăng gấp đôi, làm cho tỉ lệ này nhanh chóng đảo ngược. Hiện nay, chỉ dưới 2% tổng lượng dữ liệu chưa được chuyển sang lưu trữ ở dạng kỹ thuật số.&lt;/p&gt;

&lt;p&gt;Dưới đây là một vài ví dụ nhỏ minh hoạ cho sự dùng nổ của dữ liệu hiện nay:&lt;/p&gt;

&lt;p&gt;Theo Forbes, lượng dữ liệu mà người dùng tạo ra mỗi ngày là 2.5 tỷ tỷ bytes, một con số rất đáng kinh ngạc và dự đoán con số này sẽ tiếp tục bùng nổ nữa cùng với sự phát triển của Internet vạn vật (IoT – Internet of thing), khi mà hệ thống các thiết bị thông minh được kết nối và tương tác với nhau cũng như tương tác với người dùng, đồng thời thu thập dữ liệu. Dự báo có khoảng 200 tỷ thiết bị như thế vào năm 2020. Giả sử chỉ xét đến thiết bị tìm kiếm bằng giọng nói, hiện tại:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Có 33 triệu thiết bị qua giọng nói đang lưu thông.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;8 triệu người dùng điều khiển giọng nói mỗi tháng.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Các câu lệnh tìm kiếm bằng giọng nói trên Google trong năm 2016 tăng 35 lần so với năm 2008.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Theo thống kê, hiện nay có hơn 7 tỷ người sử dụng internet. Trung bình Google xử lý hơn 40.000 tìm kiếm mỗi giây (tức khoảng 3.5 tỷ tìm kiếm mỗi ngày, nếu tính cả những cổ máy tìm kiếm khác ngoại trừ Google thì con số này lên tới 5 tỷ lượt/ngày, 100 tỷ lượt/tháng) và những con số này sẽ tiếp tục tăng lên theo từng giây.&lt;/p&gt;

&lt;p&gt;Rất đông người yêu thích các phương tiện truyền thông xã hội và dĩ nhiên việc sử dụng chúng cũng sẽ tạo ra dữ liệu. Theo báo cáo Data Never Sleép 5.0 của Domo, trên các phương tiện truyền thông cứ mỗi một phút sẽ có (nguồn &lt;a href=&#34;http://www.internetlivestats.com/google-search-statistics/):&#34;&gt;http://www.internetlivestats.com/google-search-statistics/):&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;527.760 bức ảnh được chia sẻ bởi người sử dụng Snapchat .&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;456.000 tweet được gửi lên Twitter.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;46.740 bức ảnh được đăng bởi người dùng Instagram.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hơn 120 người có công việc ổn định tham gia LinkedIn.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Với khoảng 2 tỷ người dùng, Facebook vẫn là mạng xã hội lớn nhất hành tinh và dưới đây là các số liệu liên quan đến Facebook (nguồn  &lt;a href=&#34;http://newsroom.fb.com/company-info/):&#34;&gt;http://newsroom.fb.com/company-info/):&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Hơn 900 triệu người thật sự sử dụng Facebook mỗi ngày, 82.8% trong số đó ở ngoài Mỹ và Canada.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;307 triệu / 2 tỷ là người Châu Âu.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Cứ mỗi giây lại có 5 tài khoản mới được tạo ra.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;510.000 bình luận được đăng tải và 293.000 trạng thái được cập nhật mỗi phút.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Hơn 300 triệu bức ảnh được tải lên mỗi ngày.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;15.000 ảnh GIF được gửi thông qua Facebook Messenger.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cũng thuộc sở hữu của Facebook, Instagram cũng có những con số ấn tượng:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;600 triệu người dùng.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;400 triệu người hoạt động mỗi ngày.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;100 triệu người sử dụng tính năng Stories mỗi ngày.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Liên quan đến số lượng người dùng và dữ liệu chúng ta không thể không nhắc đến Youtube khi mà cứ mỗi một phút sẽ có khoảng 300 giờ  video được đăng tải trên Youtube (nguồn &lt;a href=&#34;https://www.youtube.com/yt/about/press/&#34;&gt;https://www.youtube.com/yt/about/press/&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Trong thời đại công nghệ, việc thông qua các trang web hẹn hò để tìm nửa còn lại không còn là điều xa lạ. Với hơn 20 tỷ lượt kết đôi, Tinder xứng đáng là nhịp cầu công nghệ thành công bậc nhất hiện tại. Cứ mỗi phút trôi qua Tinder có khoảng 990.000 lượt vuốt và hơn 26 triệu lượt hẹn hò mỗi ngày.&lt;/p&gt;

&lt;p&gt;Ngoài việc liên kết, trao đổi với nhau qua mạng xã hội, trong công việc mọi người thường sử dụng email, skype để thư từ, liên lạc. Tính đến năm 2019 có khoảng 9 tỷ người sử dụng email và dưới đây là một vài con số thống kê các sự kiện xảy ra trong một phút:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Người dùng gửi đi 16 triệu văn bản.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;156 triệu email được gửi đi với khoảng 16 triệu văn bản.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;103.447.520 thư rác được gửi đi.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;154.200 cuộc gọi Skype.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Không còn quá khó khăn trong việc lưu giữ các khoảnh khắc, ngày nay khi mà bất cứ ai cũng có thể sở hữu một chiếc điện thoại thông minh (smartphone) và ai cũng là nhiếp ảnh gia, cứ như thế có hàng nghìn tỷ bức ảnh được cho ra đời và lưu trữ trên điện thoại.&lt;/p&gt;

&lt;p&gt;Thông qua những ví dụ vừa nêu có thể chúng ta sẽ nghĩ rằng dữ liệu lớn thuần tuý chỉ là vấn đề về kích cỡ, và nếu điều này là đúng thì dữ liệu bao nhiêu được cho là “lớn”?&lt;/p&gt;

&lt;p&gt;Để trả lời câu hỏi này ta quay lại một chút về lịch sử của thuật ngữ “Big Data”. Không giống với AI và ML, Big Data không phải là một ngành khoa học chính thống mà chỉ là một thuật ngữ truyền thông mới xuất hiện trong vài năm trở lại đây. Nó không khác gì thuật ngữ “kỷ nguyên phần mềm” hay “cách mạng công nghiệp”. Mặc dù thuật ngữ này mới xuất hiện nhưng khối lượng dữ liệu tích tụ kể từ khi mạng Internet xuất hiện vào cuối thế kỷ trước cũng không phải là nhỏ từ ví dụ về thư viện Alexandria. Vậy thì câu hỏi đặt ra là tại sao với khối lượng khổng lồ như thế mà thời đó vẫn không gọi là Big Data? Câu trả lời là mặc dù được bao quanh bởi dữ liệu khổng lồ nhưng ở thời điểm đó con người không biết làm gì với chúng ngoài lưu trữ và sao chép. Cho đến khi các nhà khoa học nhận ra rằng trong đống dữ liệu này đang ẩn chứa một khối lượng tri thức khổng lồ. Những tri thức ấy có thể giúp ta hiểu thêm về con người và xã hội. Chẳng hạn như từ danh sách các bộ phim yêu thích của một cá nhân, chúng ta có thể rút ra được sở thích xem phem của người đó và gợi ý những bộ phim cùng thể loại. Hoặc từ danh sách tìm kiếm của cộng đồng mạng chúng ta sẽ biết được vấn đề nóng hổi nhất đang được quan tâm và sẽ tập trung đăng tải nhiều tin tức hơn về vấn đề đó, …&lt;/p&gt;

&lt;p&gt;Như vậy, &lt;em&gt;bùng nổ thông tin không phải là lý do duy nhất dẫn đến sự ra đời của cụm từ Big Data mà Big Data chỉ thực sự bắt đầu khi chúng ta hiểu được giá trị của thông tin ẩn chứa trong dữ liệu và có đủ tài nguyên cũng như công nghệ để có thể khai tác chúng trên quy mô lớn&lt;/em&gt;. Và không có gì ngạc nhiên khi Máy học chính là thành phần mấu chốt của công nghệ đó.&lt;/p&gt;

&lt;h2 id=&#34;máy-học-và-mối-quan-hệ-với-trí-tuệ-nhân-tạo-cùng-dữ-liệu-lớn&#34;&gt;Máy học và mối quan hệ với Trí tuệ nhân tạo cùng Dữ liệu lớn&lt;/h2&gt;

&lt;p&gt;Để máy tính có khả năng suy nghĩ và trí tuệ như con người thì đòi hỏi máy tính phải có khả năng “học” mà không cần phải lập trình để thực hiện các tác vụ cụ thể đó. Về phía các nhà nghiên cứu AI, họ muốn xem thử liệu máy tính có thể học dữ liệu như thế nào? Từ đó thuật ngữ Máy học hay Học máy (ML – Machine Learning) được hình thành. Mặc dù không có nhiều định nghĩa như AI nhưng ML lại có 2 định nghĩa khá tường minh như sau:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Máy học là ngành học cung cấp cho máy tính khả năng học hỏi mà không cần được lập trình một cách rõ ràng (Arthur Samuel, 1959).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Theo Giáo sư Tom Mitchell – Carnegie Mellon University: Máy học là 1 chương trình máy tính được nói là học hỏi từ kinh nghiệm E từ các tác vụ T và với độ đo hiệu suất P nếu hiệu suất của nó áp dụng trên tác vụ T và được đo lường bởi độ đo P tăng từ kinh nghiệm E.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Một vài ví dụ minh hoạ cho định nghĩa của Tom Mitchell:&lt;/p&gt;

&lt;p&gt;•   Ví dụ 1: Giả sử như ta muốn máy tính xác định một tin nhắn có phải là SPAM hay không thì:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Tác vụ T: Xác định 1 tin nhắn có phải SPAM hay không?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kinh nghiệm E: Xem lại những tin nhắn được đánh dấu là SPAM xem có những đặc tính gì để có thể xác định nó là SPAM.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Độ đo P: Là phần trăm số tin nhắn SPAM được phân loại đúng.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;•   Ví dụ 2: Chương trình nhận dạng chữ số viết tay (bao gồm các chữ số từ 0 đến 9)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Tác vụ T: nhận dạng được ảnh chứa ký tự số.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kinh nghiệm E: Đặc trưng để phân loại ký tự số từ tập dữ liệu số cho trước.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Độ đo P: Độ chính xác của quá trình nhận dạng.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;mối-quan-hệ-giữa-ml-với-ai-và-big-data&#34;&gt;Mối quan hệ giữa ML với AI và Big Data&lt;/h2&gt;

&lt;p&gt;Trong phần 1 và phần 2 chúng ta luôn thấy sự xuất hiện của ML, đây là lý do vì sao mình không tách riêng mối quan hệ giữa các khái niệm này ra một phần riêng mà để chung trong nội dung của ML. Vậy thì mối liên hệ đó là gì?&lt;/p&gt;

&lt;p&gt;Một cách hàn lâm thì AI là ngành khoa học được sinh ra với mục tiêu là làm cho máy tính có được trí thông minh như con người. Mục tiêu này vẫn khá mơ hồ vì không phải ai cũng đồng ý với một định nghĩa thống nhất về trí thông minh. Các nhà khoa học phải định nghĩa một số mục tiêu cụ thể hơn, một trong số đó là việc làm cho máy tính lừa được Turing Test. Turing Test được tạo ra bởi Alan Turing (1912 – 1954), người được xem là cha để của ngành khoa học máy tính hiện đại, nhằm phân biệt xem người đối diện có phả là người hay không.&lt;/p&gt;

&lt;p&gt;Như vậy, AI thể hiện một của mục tiêu con người, trong khi ML là một phương tiện được kỳ vọng sẽ giúp con người đạt được mục tiêu đó. Và trên thực tế thì ML đã mang nhân loại đi rất xa trên quãng đường chinh phục AI. Dù có mối quan hệ chặc chẽ với nhau nhưng chúng không hẳn là trùng khớp vì môt bên là mục tiêu (AI), một bên là phương tiện (ML). Chinh phục AI mặc dù vẫn là mục đích tối thượng của ML, nhưng hiện tại ML tập trung vào những mục tiêu ngắn hạn hơn như làm cho máy tính có khả năng nhận thức cơ bản của con người như nghe, nhìn, hiểu được ngôn ngữ, giải toán, lập trình, …, các khả năng này ứng với các lĩnh vực cụ thể trong AI như:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Thị giác máy tính (computer vision): mục tiêu của lĩnh vực này là làm cho máy tính có thể nhìn như con người. Những ứng dụng quan trọng có thể kể đến trong lĩnh vực này như là nhận dạng chữ/ chứ số viết tay, nhận dạng khuôn mặt, dáng đi, cử chỉ, phân loại loài hoa, nhãn hiệu, phát hiện đồ vât, …. Từ tập hình ảnh ban đầu, các thuật toán ML sẽ tiến hành xử lý, phân tích để rút ra các đặc trưng chính giúp nhận dạng đối tượng hoặc phân biệt các đối tượng với nhau.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Xử lý Ngôn ngữ tự nhiên (Natural Language Processing – NLP): Mục tiêu là giúp cho máy tính có thể hiểu như con người. Dịch máy là một trong những ứng dụng điển hình của NLP, dịch nội dung của một đoạn văn bản từ ngôn ngữ này sang ngôn ngữ khác (Google Translate). Xuất phát từ “Từ điển” hoặc tập các cặp câu song ngữ, tập luật ngữ pháp của mỗi ngôn ngữ được tạo bởi người có chuyên môn về những ngôn ngữ đó, các thuật toán máy học sẽ tiến hành phân tích để tách câu, tách từ, xác định từ loại, phân tích cú pháp để từ đó lấy ra ngữ nghĩa phù hợp rồi ghép lại với nhau và cho ra nội dung ở ngôn ngữ tương ứng. Ngoài ra, tóm tắt văn bản dựa vào các từ khoá của từng lĩnh vực cũng là một bài toán ML rất được quan tâm trong vài năm trở lại đây, khi mà mỗi ngày lượng tin tức cần phải đọc là quá nhiều.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Xử lý tiếng nói (Speech Language Processing): nhằm làm cho máy tính có thể nghe được như người. Tổng hộp tiếng nói (text to speech) để đọc sách cho người khiếm thị, tạo sub cho các video (speech to text) để hỗ trợ cho người khiếm thính hoặc hỗ trợ cho việc học ngôn ngữ; nhận dạng giọng nói (speech recognition) giúp phát hiện tội phạm là một số ứng dụng điển hình trong lĩnh vực này.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thay vì cố gắng “dạy” máy tính cách làm một việc gì đó, chẳng hạn như lái xe hơi, điều mà các chuyên gia AI cần làm là cung cấp “đủ” dữ liệu cho một máy tính để nó có thể tính ra xác suất của tất cả mọi thứ mà người ta muốn tính toán, ví như xác suất người đi đường gặp đèn giao thông màu xanh, màu đỏ, màu vàng, … thì chuẩn xác hơn.&lt;/p&gt;

&lt;p&gt;Do đó, nhiệm vụ thực sự của ML trong AI là “học” mà thực chất của việc học này là rút trích thông tin hữu ích cho từng bài toán trong “tập dữ liệu” cho trước. Lúc này mối quan hệ giữa ML và Big Data sẽ được bộc lộ, đó là nếu khối lượng dữ liệu của Big Data càng gia tăng thì ML sẽ phát triển hơn, có khả năng rút trích được nhiều thông tin giá trị hơn hay dự đoán chính xác hơn, ngược lại thì giá trị của Big Data phụ thuộc vào khả năng khai thác tri thức từ dữ liệu của ML, vì nó sẽ thực sự là Big Data khi khối lượng dữ liệu đó mang lại thông tin hữu ích.&lt;/p&gt;

&lt;p&gt;Việc sử dụng những khối lượng thông tin theo cách này đòi hỏi chúng ta phải có sự thay đổi trong cách tiếp cận dữ liệu. Một là thu thập và sử dụng thật nhiều dữ liệu thay vì chấp nhận lấy những mẫu thống kê với số lượng nhỏ như các nhà thống kê vẫn làm từ hơn một thế kỷ nay. Hai là không nhất thiết phải kén chọn sàng lọc ra dữ liệu sạch, vì kinh nghiệm thực tiễn cho thấy rằng một chút sai lệch trong thông tin vẫn có thể chấp nhận được, và việc sử dụng một lượng khổng lồ những dữ liệu ô hợp đem lại nhiều ích lợi hơn là dữ liệu tuy chính xác nhưng dung lượng quá ít. Ba là trong nhiều trường hợp, chúng ta không nhất thiết phải cố tìm ra nguyên nhân đằng sau các hiện tượng.Ví dụ, không cần phải cố tìm hiểu chính xác vì sao một cỗ máy bị hỏng, thay vào đó các nhà nghiên cứu có thể thu thập và phân tích thật nhiều dữ liệu về chúng cùng tất cả mọi thứ liên quan, từ đó rút ra quy luật làm cơ sở dự đoán các sự vật, sự việc trong tương lai.&lt;/p&gt;

&lt;p&gt;Dưới đây là một số tài liệu mình đã sử dụng để tham khảo trong qua trình viết bài:&lt;/p&gt;

&lt;p&gt;Introduction to Machine Learning of Alex Smola and S.V.N. Vishwanathan.&lt;/p&gt;

&lt;p&gt;Artificial Intelligence (third edition) of The McGraw-Hill Companies, write by Elaine Rich, Kevin Knight and Shivashankar B Nair.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://i4iam.files.wordpress.com/2013/08/artificial-intelligence-by-rich-and-knight.pdf&#34;&gt;https://i4iam.files.wordpress.com/2013/08/artificial-intelligence-by-rich-and-knight.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Artificial_intelligence&#34;&gt;https://en.wikipedia.org/wiki/Artificial_intelligence&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://searchenterpriseai.techtarget.com/definition/AI-Artificial-Intelligence&#34;&gt;https://searchenterpriseai.techtarget.com/definition/AI-Artificial-Intelligence&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://vienthongke.vn/tin-tuc/43-tin-tuc/2176-thoi-dai-cua-du-lieu-lon-big-data&#34;&gt;http://vienthongke.vn/tin-tuc/43-tin-tuc/2176-thoi-dai-cua-du-lieu-lon-big-data&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tìm hiểu Mask R-CNN và ví dụ phân vùng quả bóng bay sử dụng deep learning</title>
      <link>/blog/2019-03-25-mask-rcnn-balloon/</link>
      <pubDate>Mon, 25 Mar 2019 00:12:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-03-25-mask-rcnn-balloon/</guid>
      <description>

&lt;h2 id=&#34;bắt-đầu&#34;&gt;Bắt đầu&lt;/h2&gt;

&lt;p&gt;Đầu tiên, chúng ta sẽ download tập dataset balloon tại &lt;a href=&#34;https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip&#34;&gt;https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip&lt;/a&gt;, giải nén và bỏ trong thư mục datasets. Tiếp đó, các bạn donwload file balloon.py và visualize.py về. File đầu tiên hỗ trợ chúng ta đọc dữ liệu của dataset balloon và file thứ hai hỗ trợ visualize hình ảnh một cách trực quan. Cả hai file mình đều lấy mã nguồn của Matterport trên &lt;a href=&#34;https://github.com/matterport/Mask_RCNN/&#34;&gt;https://github.com/matterport/Mask_RCNN/&lt;/a&gt; Tiến hành import các thư viện cần thiết về.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
import sys
import itertools
import math
import logging
import json
import re
import random
from collections import OrderedDict
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib.lines as lines
from matplotlib.patches import Polygon


import balloon
import utils
import visualize

config = balloon.BalloonConfig()
BALLOON_DIR = &amp;quot;datasets/balloon&amp;quot;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thông tin của tập train bao gồm&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dataset = balloon.BalloonDataset()
dataset.load_balloon(BALLOON_DIR, &amp;quot;train&amp;quot;)

# Must call before using the dataset
dataset.prepare()

print(&amp;quot;Image Count: {}&amp;quot;.format(len(dataset.image_ids)))
print(&amp;quot;Class Count: {}&amp;quot;.format(dataset.num_classes))
for i, info in enumerate(dataset.class_info):
    print(&amp;quot;{:3}. {:50}&amp;quot;.format(i, info[&#39;name&#39;]))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Image Count: 61
Class Count: 2
  0. BG
  1. balloon
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Vậy là có tổng cộng 61 hình train. Dữ liệu được đánh làm 2 nhãn, một nhãn là background, một nhãn là balloon.&lt;/p&gt;

&lt;h2 id=&#34;visualize-dữ-liệu&#34;&gt;Visualize dữ liệu&lt;/h2&gt;

&lt;p&gt;Chúng ta sẽ load một vài hình lên xem người ta đã mask dữ liệu như thế nào. Ở đây, với mỗi hình ảnh, mình sẽ load 1 hình gốc và 4 hình của 4 quả bóng tương ứng trong hình, nếu trong hình có nhiều hơn 4 quả bóng thì chỉ vẽ 4 quả bóng đầu tiên&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;

n_col = 5

# Load and display random samples
fig, axs = plt.subplots(nrows=4, ncols=n_col, figsize=(9.3, 6),subplot_kw={&#39;xticks&#39;: [], &#39;yticks&#39;: []})
fig.subplots_adjust(left=0.03, right=0.97, hspace=0.3, wspace=0.05)
image_ids = np.random.choice(dataset.image_ids, 4)
# for image_id in image_ids:
# for ax, image_id in zip(axs.flat, image_ids):

for index in range(0,4):
    image_id = image_ids[index]

    image = dataset.load_image(image_id)
    mask, class_ids = dataset.load_mask(image_id)
    print(mask.shape)
    print(len(class_ids))

    axs.flat[index*n_col].imshow(image)
    axs.flat[index*n_col].set_title(&#39;img&#39;)

    for sub_index in range(0,len(class_ids)):
        if sub_index &amp;gt;= n_col:
            break
        axs.flat[index*n_col +1 + sub_index].imshow(mask[:,:,sub_index])
        axs.flat[index*n_col + 1+sub_index].set_title(str(dataset.class_names[class_ids[sub_index]]))


plt.tight_layout()
plt.show()


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/mask-rnn-1.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Các bạn có thể sử dụng hàm display_top_masks của tác giả Mask R-CNN để xem thử, hàm của họ hơi khác của mình một chút.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
image_ids = np.random.choice(dataset.image_ids, 4)
for image_id in image_ids:
    image = dataset.load_image(image_id)
    mask, class_ids = dataset.load_mask(image_id)
    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/f-rcnn-image2.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;bounding-boxes&#34;&gt;Bounding Boxes&lt;/h2&gt;

&lt;p&gt;Chúng ta có 2 cách để lấy Bounding Boxes của các hình. Một là lấy trực tiếp từ tập dataset (đối với những dataset có lưu bounding box), hai là rút trích bounding box từ các toạ độ mask. Chúng ta nên thực hiện cách hai, lý do là chúng ta sẽ dùng các kỹ thuật Data Generator để sinh nhiều ảnh hơn cung cấp cho thuật toán train. Lúc này, việc tính lại bounding box sẽ dễ dàng hơn.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
# Load random image and mask.
image_id = random.choice(dataset.image_ids)
image = dataset.load_image(image_id)
mask, class_ids = dataset.load_mask(image_id)

# Compute Bounding box
bbox = utils.extract_bboxes(mask)

# Display image and additional stats
print(&amp;quot;image_id &amp;quot;, image_id, dataset.image_reference(image_id))

# Display image and instances
visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/mask-rcnn-3.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;resize-images&#34;&gt;Resize Images&lt;/h2&gt;

&lt;p&gt;Các ảnh trong tập train có các kích thước khác nhau. Các bạn có thể xem các hình ở trên, có ảnh có kích thước này, có ảnh có kích thước kia. Chúng ta sẽ resize chúng về cùng một kích thước (ví dụ 1024x1024) để làm đầu vào cho tập huấn luyện. Và chúng ta sẽ sử dụng zero padding để lấp đầy những khoảng trống của những ảnh không đủ kích thước.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;


# Load random image and mask.
image_id = np.random.choice(dataset.image_ids, 1)[0]
image = dataset.load_image(image_id)
mask, class_ids = dataset.load_mask(image_id)
original_shape = image.shape
# Resize
image, window, scale, padding, _ = utils.resize_image(
    image, 
    min_dim=config.IMAGE_MIN_DIM, 
    max_dim=config.IMAGE_MAX_DIM,
    mode=config.IMAGE_RESIZE_MODE)
mask = utils.resize_mask(mask, scale, padding)
# Compute Bounding box
bbox = utils.extract_bboxes(mask)

# Display image and additional stats
print(&amp;quot;image_id: &amp;quot;, image_id, dataset.image_reference(image_id))
print(&amp;quot;Original shape: &amp;quot;, original_shape)
print(&amp;quot;Resize shape: &amp;quot;, image.shape)
# Display image and instances
visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;image_id:  9 datasets/balloon\train\15290896925_884ab33fd3_k.jpg
Original shape:  (1356, 2048, 3)
Resize shape:  (1024, 1024, 3)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/f-rcnn-image4.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Lưu ý một điều là ở đây, mình sử dụng random image, nên nếu các bạn chạy lại câu lệnh như mình thì kết quả ra phần nhiều sẽ khác mình. Tuy nhiên, Resize shape luôn là (1024, 1024, 3).&lt;/p&gt;

&lt;h2 id=&#34;mini-masks&#34;&gt;Mini Masks&lt;/h2&gt;

&lt;p&gt;Một vấn đề khá nghiêm trọng ở đây là chúng ta cần khá nhiều bộ nhớ để lưu các masks. Numpy sử dụng 1 byte để lưu 1 giá trị bit. Do đó, với kích thước ảnh là 1024x1024, chúng ta cần 1MB bộ nhớ ram để lưu trữ. Nếu chúng ta có tập dataset tầm 1000 bức ảnh thì cần đến 1GB bộ nhớ, khá là lớn. Ngoài việc tốn bộ nhớ lữu trữ, chúng còn làm chậm tốc độ huấn luyện mô hình nữa.&lt;/p&gt;

&lt;p&gt;Để cải tiến, chúng ta có thể sử dụng một trong hai cách sau:
- Cách thứ nhất: Thay vì lưu toàn bộ mask của toàn bức ảnh, chúng ta chỉ lưu những pixel của mask trong bounding box. Với việc sử dụng cách này, chúng ta sẽ tiết kiệm kha khá bộ nhớ chính.
- Cách thứ hai: Chúng ta có thể resize mask về một kích thước chuẩn nào đó, ví dụ 48x48 pixel. Với những mask có kích thước lớn hơn 48x48, chúng sẽ bị mất thông tin.&lt;/p&gt;

&lt;p&gt;Mình không thích cách thứ hai cho lắm. Tuy nhiên, theo lý giải của nhóm tác giả Mask R-CNN, thì hầu hết việc gán các đường biên (object annotations) thường không chính xác cho lắm (thừa hoặc thiếu một vài chỗ), cho nên, việc mất mát thông tin với lượng nhỏ này hầu như là không đáng kể.&lt;/p&gt;

&lt;p&gt;Để đánh giá hiệu quả của hàm mask resizing, chúng ta sẽ chạy đoạn code bên dưới và xem ảnh kết quả. Đoạn code trên mình sử dụng 2 hàm compose_image_meta và load_image_gt của tác giả ở đường dẫn &lt;a href=&#34;https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/model.py&#34;&gt;https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/model.py&lt;/a&gt;. Mình có modify lại hàm load_image_gt một chút để hợp với ý mình hơn.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;############################################################
#  Data Formatting
############################################################

def compose_image_meta(image_id, original_image_shape, image_shape,
                       window, scale, active_class_ids):
    &amp;quot;&amp;quot;&amp;quot;Takes attributes of an image and puts them in one 1D array.
    image_id: An int ID of the image. Useful for debugging.
    original_image_shape: [H, W, C] before resizing or padding.
    image_shape: [H, W, C] after resizing and padding
    window: (y1, x1, y2, x2) in pixels. The area of the image where the real
            image is (excluding the padding)
    scale: The scaling factor applied to the original image (float32)
    active_class_ids: List of class_ids available in the dataset from which
        the image came. Useful if training on images from multiple datasets
        where not all classes are present in all datasets.
    &amp;quot;&amp;quot;&amp;quot;
    meta = np.array(
        [image_id] +                  # size=1
        list(original_image_shape) +  # size=3
        list(image_shape) +           # size=3
        list(window) +                # size=4 (y1, x1, y2, x2) in image cooredinates
        [scale] +                     # size=1
        list(active_class_ids)        # size=num_classes
    )
    return meta


def load_image_gt(dataset, config, image_id, augment=False, augmentation=None,
                  use_mini_mask=False):
    &amp;quot;&amp;quot;&amp;quot;Load and return ground truth data for an image (image, mask, bounding boxes).
    augment: (deprecated. Use augmentation instead). If true, apply random
        image augmentation. Currently, only horizontal flipping is offered.
    augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.
        For example, passing imgaug.augmenters.Fliplr(0.5) flips images
        right/left 50% of the time.
    use_mini_mask: If False, returns full-size masks that are the same height
        and width as the original image. These can be big, for example
        1024x1024x100 (for 100 instances). Mini masks are smaller, typically,
        224x224 and are generated by extracting the bounding box of the
        object and resizing it to MINI_MASK_SHAPE.
    Returns:
    image: [height, width, 3]
    shape: the original shape of the image before resizing and cropping.
    class_ids: [instance_count] Integer class IDs
    bbox: [instance_count, (y1, x1, y2, x2)]
    mask: [height, width, instance_count]. The height and width are those
        of the image unless use_mini_mask is True, in which case they are
        defined in MINI_MASK_SHAPE.
    &amp;quot;&amp;quot;&amp;quot;
    # Load image and mask
    image = dataset.load_image(image_id)
    mask, class_ids = dataset.load_mask(image_id)
    original_shape = image.shape
    image, window, scale, padding, crop = utils.resize_image(
        image,
        min_dim=config.IMAGE_MIN_DIM,
        min_scale=config.IMAGE_MIN_SCALE,
        max_dim=config.IMAGE_MAX_DIM,
        mode=config.IMAGE_RESIZE_MODE)
    mask = utils.resize_mask(mask, scale, padding, crop)

    # Random horizontal flips.
    # TODO: will be removed in a future update in favor of augmentation
    if augment:
        logging.warning(&amp;quot;&#39;augment&#39; is deprecated. Use &#39;augmentation&#39; instead.&amp;quot;)
        if random.randint(0, 1):
            image = np.fliplr(image)
            mask = np.fliplr(mask)

    # Augmentation
    # This requires the imgaug lib (https://github.com/aleju/imgaug)
    if augmentation:
        import imgaug

        # Augmenters that are safe to apply to masks
        # Some, such as Affine, have settings that make them unsafe, so always
        # test your augmentation on masks
        MASK_AUGMENTERS = [&amp;quot;Sequential&amp;quot;, &amp;quot;SomeOf&amp;quot;, &amp;quot;OneOf&amp;quot;, &amp;quot;Sometimes&amp;quot;,
                           &amp;quot;Fliplr&amp;quot;, &amp;quot;Flipud&amp;quot;, &amp;quot;CropAndPad&amp;quot;,
                           &amp;quot;Affine&amp;quot;, &amp;quot;PiecewiseAffine&amp;quot;]

        def hook(images, augmenter, parents, default):
            &amp;quot;&amp;quot;&amp;quot;Determines which augmenters to apply to masks.&amp;quot;&amp;quot;&amp;quot;
            return augmenter.__class__.__name__ in MASK_AUGMENTERS

        # Store shapes before augmentation to compare
        image_shape = image.shape
        mask_shape = mask.shape
        # Make augmenters deterministic to apply similarly to images and masks
        det = augmentation.to_deterministic()
        image = det.augment_image(image)
        # Change mask to np.uint8 because imgaug doesn&#39;t support np.bool
        mask = det.augment_image(mask.astype(np.uint8),
                                 hooks=imgaug.HooksImages(activator=hook))
        # Verify that shapes didn&#39;t change
        assert image.shape == image_shape, &amp;quot;Augmentation shouldn&#39;t change image size&amp;quot;
        assert mask.shape == mask_shape, &amp;quot;Augmentation shouldn&#39;t change mask size&amp;quot;
        # Change mask back to bool
        mask = mask.astype(np.bool)

    # Note that some boxes might be all zeros if the corresponding mask got cropped out.
    # and here is to filter them out
    _idx = np.sum(mask, axis=(0, 1)) &amp;gt; 0
    mask = mask[:, :, _idx]
    class_ids = class_ids[_idx]
    # Bounding boxes. Note that some boxes might be all zeros
    # if the corresponding mask got cropped out.
    # bbox: [num_instances, (y1, x1, y2, x2)]
    bbox = utils.extract_bboxes(mask)

    # Active classes
    # Different datasets have different classes, so track the
    # classes supported in the dataset of this image.
    active_class_ids = np.zeros([dataset.num_classes], dtype=np.int32)
    source_class_ids = dataset.source_class_ids[dataset.image_info[image_id][&amp;quot;source&amp;quot;]]
    active_class_ids[source_class_ids] = 1

    # Resize masks to smaller size to reduce memory usage
    if use_mini_mask:
        if USE_MINI_MASK_SHAPE:
            mask = utils.minimize_mask(bbox, mask, MINI_MASK_SHAPE)
        else:
            mask = utils.minimize_mask(bbox, mask, mask.shape[:2])

    # Image meta data
    image_meta = compose_image_meta(image_id, original_shape, image.shape,
                                    window, scale, active_class_ids)

    return image, image_meta, class_ids, bbox, mask


image_id = np.random.choice(dataset.image_ids, 1)[0]
image, image_meta, class_ids, bbox, mask = load_image_gt(
    dataset, config, image_id, use_mini_mask=False)


visualize.display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 5))])

image, image_meta, class_ids, bbox, mask = load_image_gt(
    dataset, config, image_id, use_mini_mask=True)


visualize.display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 5))])

USE_MINI_MASK_SHAPE = True

image, image_meta, class_ids, bbox, mask = load_image_gt(
    dataset, config, image_id, use_mini_mask=True)


visualize.display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 5))])

mask = utils.expand_mask(bbox, mask, image.shape)
visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/f-rcnn-image6.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Với ảnh ở line 1 là ảnh gốc ban đầu và các full mask của bức ảnh, ảnh ở line 2 là chỉ lấy mask của bounding box, ảnh ở line 3 là lấy mask ở bounding box và scale ảnh (do scale ảnh nên ở line 3 các bạn sẽ thấy mask có hình răng cưa, khác với các mask line 2). Line 4 là ảnh ở line 3 được revert back lại hình gốc ban đầu. Các bạn có để ý thấy rằng nó sẽ bị răng cưa ở biên cạnh chứ không được smooth như ảnh gốc. Nếu chúng ta không làm object annotations kỹ, thì object cũng sẽ bị răng cưa như trên.&lt;/p&gt;

&lt;h2 id=&#34;anchors&#34;&gt;Anchors&lt;/h2&gt;

&lt;p&gt;Thứ tự của các anchor thật sự rất quan trọng. Trong quá trình train, thứ tự của các anchor như thế nào thì trong quá trình test, validation, prediction phải dùng y hệt vậy.&lt;/p&gt;

&lt;p&gt;Trong mạng FPN, các anchor phải được xắp xếp theo cách mà chúng ta có thể dễ dàng liên kết với giá trị output&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Xắp xếp các anchor theo thứ tự các lớp của pyramid. Tất cả các anchor của level đầu tiên, tiếp theo là các anchor của các lớp thứ hai, lớp thư ba&amp;hellip; Việc xắp xếp theo cách này sẽ giúp chúng ta dễ dàng phân tách các lớp anchor và dễ hiểu theo lẽ tự nhiên.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Trong mỗi level, xắp xếp các anchor trong mỗi level bằng thứ tự xử lý của các feature map. Thông thường, một convolution layer sẽ dịch chuyển trên feature map bắt đầu từ vị trí trái - trên (top - left) đi xuống phải dưới (từ trái qua phải, xuống hàng rồi lại từ trái qua phải).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Trên mỗi cell của feature map, chúng ta sẽ xắp xếp các anchor theo các ratios.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Anchor Stride:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
backbone_shapes = modellib.compute_backbone_shapes(config, config.IMAGE_SHAPE)
anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES, 
                                          config.RPN_ANCHOR_RATIOS,
                                          backbone_shapes,
                                          config.BACKBONE_STRIDES, 
                                          config.RPN_ANCHOR_STRIDE)

# Print summary of anchors
num_levels = len(backbone_shapes)
anchors_per_cell = len(config.RPN_ANCHOR_RATIOS)
print(&amp;quot;Total anchors: &amp;quot;, anchors.shape[0])
print(&amp;quot;ANCHOR Scales: &amp;quot;, config.RPN_ANCHOR_SCALES)
print(&amp;quot;BACKBONE STRIDE: &amp;quot;, config.BACKBONE_STRIDES)
print(&amp;quot;ratios: &amp;quot;, config.RPN_ANCHOR_RATIOS)
print(&amp;quot;Anchors per Cell: &amp;quot;, anchors_per_cell)
# print(&amp;quot;Anchors stride: &amp;quot;, config.RPN_ANCHOR_STRIDE)
print(&amp;quot;Levels: &amp;quot;, num_levels)
anchors_per_level = []
for l in range(num_levels):
    num_cells = backbone_shapes[l][0] * backbone_shapes[l][1]
    print(&amp;quot;backbone_shapes in level &amp;quot;,l,&#39; &#39;,backbone_shapes[l][0],&#39;x&#39;,backbone_shapes[l][1])
    print(&amp;quot;num_cells in level &amp;quot;,l,&#39; &#39;,num_cells)
    anchors_per_level.append(anchors_per_cell * num_cells // config.RPN_ANCHOR_STRIDE**2)
    print(&amp;quot;Anchors in Level {}: {}&amp;quot;.format(l, anchors_per_level[l]))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Total anchors:  261888
ANCHOR Scales:  (32, 64, 128, 256, 512)
BACKBONE STRIDE:  [4, 8, 16, 32, 64]
ratios:  [0.5, 1, 2]
Anchors per Cell:  3
Levels:  5
backbone_shapes in level  0   256 x 256
num_cells in level  0   65536
Anchors in Level 0: 196608
backbone_shapes in level  1   128 x 128
num_cells in level  1   16384
Anchors in Level 1: 49152
backbone_shapes in level  2   64 x 64
num_cells in level  2   4096
Anchors in Level 2: 12288
backbone_shapes in level  3   32 x 32
num_cells in level  3   1024
Anchors in Level 3: 3072
backbone_shapes in level  4   16 x 16
num_cells in level  4   256
Anchors in Level 4: 768
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Trong kiến trức FPN, feature map tại một số layer đầu tiên là những feature map có độ phân giải lớn. Ví dụ, nếu bức ảnh đầu vào có kích thước là 1024x1024 pixel, và kích thước của mỗi anchor lớp đầu tiên là 32x32 pixel (giá trị đầu tiên của RPN_ANCHOR_SCALES (32, 64, 128, 256, 512)) và bước nhảy (STRIDE) của lớp đầu tiên là 4 (giá trị đầu tiên của BACKBONE_STRIDES ([4, 8, 16, 32, 64])). Từ những dữ kiện này, ta có thể suy ra được là sẽ sinh ra backbone cell có kích thước 256x256 pixel =&amp;gt; 256x256 = 65536 anchor. Với mỗi backbone cell, chúng ta thực hiện phép scale với 3 tỷ lệ khác nhau là [0.5, 1, 2], vậy chúng ta có tổng cộng là 65536x3 = 196608 anchor (xấp xỉ 200k anchor). Để ý một điều là kích thước của một anchor là 32x32 pixel, và bước nhảy là 4, cho nên chúng ta sẽ bị chống lấn (overlap) 28 pixel của anchor 1 và anchor 2 ngay sau nó.&lt;/p&gt;

&lt;p&gt;Một điều thú vị là, nếu ta tăng bước nhảy lên gấp 2 lần, ví dụ từ 4 pixel lấy một anchor lên 8 pixel lấy một anchor, thì số lượng anchor giảm đi đến 4 lần (196608 anchor ở level 0 so với 49152 anchor ở level 1).&lt;/p&gt;

&lt;p&gt;Thử vẽ tất cả các anchor của tất cả các level ở điểm giữa một bức ảnh bức kỳ lên, mỗi một level sẽ dùng một màu khác nhau, chúng ta được một hình như bên dưới.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;## Visualize anchors of one cell at the center of the feature map of a specific level

# Load and draw random image
image_id = np.random.choice(dataset.image_ids, 1)[0]
image, image_meta, _, _, _ = modellib.load_image_gt(dataset, config, image_id)
fig, ax = plt.subplots(1, figsize=(10, 10))
ax.imshow(image)
levels = len(backbone_shapes)

kn_color =np.array( [(255,0,0),(0,255,0),(0,0,255),(128,0,0),(0,128,0),(0,0,128)])/255.

for level in range(levels):
    # colors = visualize.random_colors(levels)
    colors = kn_color
    # Compute the index of the anchors at the center of the image
    level_start = sum(anchors_per_level[:level]) # sum of anchors of previous levels
    level_anchors = anchors[level_start:level_start+anchors_per_level[level]]
    print(&amp;quot;Level {}. Anchors: {:6}  Feature map Shape: {} &amp;quot;.format(level, level_anchors.shape[0], 
                                                                  backbone_shapes[level]))
    center_cell = backbone_shapes[level] // 2
    center_cell_index = (center_cell[0] * backbone_shapes[level][1] + center_cell[1])
    level_center = center_cell_index * anchors_per_cell 
    center_anchor = anchors_per_cell * (
        (center_cell[0] * backbone_shapes[level][1] / config.RPN_ANCHOR_STRIDE**2) \
        + center_cell[1] / config.RPN_ANCHOR_STRIDE)
    level_center = int(center_anchor)

    # Draw anchors. Brightness show the order in the array, dark to bright.
    for i, rect in enumerate(level_anchors[level_center:level_center+anchors_per_cell]):
        y1, x1, y2, x2 = rect
        p = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, facecolor=&#39;none&#39;,
                              edgecolor=np.array(colors[level]) / anchors_per_cell)
        print(i)
        ax.add_patch(p)


plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/f-rcnn-image7.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Nhìn ảnh trên,các bạn phần nào đó mường tượng ra các anchor sẽ như thế nào rồi phải không.&lt;/p&gt;

&lt;h2 id=&#34;prediction&#34;&gt;Prediction&lt;/h2&gt;

&lt;p&gt;Để tiến hành detect vị trí quả bóng và mask của quả bóng, chúng ta download một ảnh small party nhỏ trên internet về và kiểm chứng.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
import os

import tensorflow as tf

import cv2

DEVICE = &amp;quot;/cpu:0&amp;quot; 
ROOT_DIR = os.path.abspath(&amp;quot;../../&amp;quot;)
MODEL_DIR = os.path.join(ROOT_DIR, &amp;quot;logs&amp;quot;)
# Create model in inference mode

class InferenceConfig(config.__class__):
    # Run detection on one image at a time
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1

config = InferenceConfig()
config.display()

with tf.device(DEVICE):
    model = modellib.MaskRCNN(mode=&amp;quot;inference&amp;quot;, model_dir=MODEL_DIR,
                              config=config)


weights_path = &amp;quot;mask_rcnn_balloon.h5&amp;quot;

# Load weights
print(&amp;quot;Loading weights &amp;quot;, weights_path)
# model.load_weights(weights_path, by_name=True)

imgpath = &amp;quot;datasets\\balloon\\test\\t1.png&amp;quot;
# imgpath = &amp;quot;datasets/balloon/val/14898532020_ba6199dd22_k.jpg&amp;quot;

image = cv2.imread(imgpath)

image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)



ds_name = [&#39;BG&#39;, &#39;balloon&#39;]


results = model.detect([image], verbose=1)

def get_ax(rows=1, cols=1, size=16):
    &amp;quot;&amp;quot;&amp;quot;Return a Matplotlib Axes array to be used in
    all visualizations in the notebook. Provide a
    central point to control graph sizes.
    
    Adjust the size attribute to control how big to render images
    &amp;quot;&amp;quot;&amp;quot;
    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))
    return ax
# Display results
ax = get_ax(1)
r = results[0]
visualize.display_instances(image, r[&#39;rois&#39;], r[&#39;masks&#39;], r[&#39;class_ids&#39;], 
                            dataset.class_names, r[&#39;scores&#39;], ax=ax,
                            title=&amp;quot;Predictions&amp;quot;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/f-rcnn-image8.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Kết quả nhận dạng khá chính xác phải không các bạn.&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Thêm dấu tiếng việt cho câu không dấu</title>
      <link>/blog/2019-03-16-vietnamese-accent/</link>
      <pubDate>Sat, 16 Mar 2019 00:12:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2019-03-16-vietnamese-accent/</guid>
      <description>&lt;p&gt;Thêm dấu tiếng việt là một trong những bài toán khá hay trong xử lý  ngôn ngữ tự nhiên. Ở đây, mình đã tiến hành thu thập dữ liệu bài báo của nhiều nguồn khác nhau như zing.vn, vnexpress, kenh14.vn &amp;hellip; làm kho ngữ liệu và xây dựng mô hình.&lt;/p&gt;

&lt;p&gt;Để tiến hành thực nghiệm, mình sẽ lấy một số đoạn văn mẫu ở trang tin tức của thế giới di động (https.www.thegioididong.com) (mình không crawl nội dung tin tức ở trang này làm dữ liệu học).&lt;/p&gt;

&lt;p&gt;Ở bài viết link &lt;a href=&#34;https://www.thegioididong.com/tin-tuc/3-ngay-cuoi-tuan-mua-laptop-online-tang-them-pmh-den-400k-tra-gop-0--1151334&#34;&gt;https://www.thegioididong.com/tin-tuc/3-ngay-cuoi-tuan-mua-laptop-online-tang-them-pmh-den-400k-tra-gop-0--1151334&lt;/a&gt;, mình lấy đoạn mở đầu &amp;ldquo;Từ ngày &lt;sup&gt;15&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; đến &lt;sup&gt;17&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;, nhiều mẫu laptop tại Thế Giới Di Động sẽ được ưu đãi mạnh, tặng phiếu mua hàng đến 400 ngàn đồng, trả góp 0% và nhiều quà tặng hấp dẫn khác khi mua theo hình thức ONLINE. Nếu đang có nhu cầu mua laptop, bạn hãy nhanh chóng xem qua danh sách sản phẩm dưới đây nhé.&amp;rdquo;, bỏ dấu của câu đi, thì mình được câu&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Tu ngay &lt;sup&gt;15&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; den &lt;sup&gt;17&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;, nhieu mau laptop tai The Gioi Di Dong se duoc uu dai manh, tang phieu mua hang den 400 ngan dong, tra gop 0% va nhieu qua tang hap dan khac khi mua theo hinh thuc ONLINE. Neu dang co nhu cau mua laptop, ban hay nhanh chong xem qua danh sach san pham duoi day nhe.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Sử dụng mô hình mình đã huấn luyện, thu được kết quả như sau:&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Từ ngày &lt;sup&gt;15&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; đến &lt;sup&gt;17&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; m t m, nhiều mẫu laptoP tạI thế giỚi di động sẽ được ưu đãi mạnh, tang phiếu mua hàng đến 400 ngàn đồng, trả góp 0 r% và nhiều quà tặng hấp dẫn khác khi mua theo hìNH THỨc Onfine. nếu đang có nhu cầu mua laptop, bạn hãy nhanh chóng xem qua danh sách sản phẩm dưới&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Kết quả khá khả quan phải không các bạn, còn một số lỗi nhỏ ở phần nhận dạng ký tự hoa nữa. Mình sẽ fix lại ở các bài viết sau.&lt;/p&gt;

&lt;p&gt;Mình thí nghiệm tiếp với phần đầu bài viết &lt;a href=&#34;https://www.thegioididong.com/tin-tuc/apple-ban-ra-thi-truong-35-trieu-cap-tai-nghe-airpods-nam-2018-1155181&#34;&gt;https://www.thegioididong.com/tin-tuc/apple-ban-ra-thi-truong-35-trieu-cap-tai-nghe-airpods-nam-2018-1155181&lt;/a&gt;.
Đoạn &amp;ldquo;Hôm nay, báo cáo của Counterpoint Research cho thấy, trong năm 2018 Apple đã bán được khoảng 35 triệu cặp tai nghe không dây AirPods. Theo hãng phân tích này, AirPods hiện là tai nghe không dây phổ biến nhất.&amp;rdquo;, bỏ dấu tiếng việt là thu được &amp;ldquo;Hom nay, bao cao cua Counterpoint Research cho thay, trong nam 2018 Apple da ban duoc khoang 35 trieu cap tai nghe khong day AirPods. Theo hang phan tich nay, AirPods hien la tai nghe khong day pho bien nhat.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Kết quả của mô hình: &amp;ldquo;Hôm nay, bạo cáo của Coorteenria eEeeroa c ttt, trong năm 2018 apple đã bán được khoảng 35 triệu cặp tại nghe không đầy aitcoDs. theo Hàng phân tích này, airxoDs Hiện là tai nghe không dạy phổ biến nhất.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Mô hình của mình cho lặp 50 lần. Mình tiến hành thí nghiệm và publish mô hình ở lần lặp thứ 10.&lt;/p&gt;

&lt;p&gt;Mã nguồn file predict&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from keras.models import load_model
model = load_model(&#39;a_best_weight.h5&#39;)

from collections import Counter

import numpy as np

import utils
import string
import re

alphabet = set(&#39;\x00 _&#39; + string.ascii_lowercase + string.digits + &#39;&#39;.join(utils.ACCENTED_TO_BASE_CHAR_MAP.keys()))

print(&amp;quot;alphabet&amp;quot;,alphabet)
codec = utils.CharacterCodec(alphabet, utils.MAXLEN)

def guess(ngram):
    text = &#39; &#39;.join(ngram)
    text += &#39;\x00&#39; * (utils.MAXLEN - len(text))
    if utils.INVERT:
        text = text[::-1]
    preds = model.predict_classes(np.array([codec.encode(text)]), verbose=0)
    rtext = codec.decode(preds[0], calc_argmax=False).strip(&#39;\x00&#39;)
    if len(rtext)&amp;gt;0:
        index = rtext.find(&#39;\x00&#39;)
        if index&amp;gt;-1:
            rtext = rtext[:index]
    return rtext


def add_accent(text):
    # lowercase the input text as we train the model on lowercase text only
    # but we keep the map of uppercase characters to restore cases in output
    is_uppercase_map = [c.isupper() for c in text]
    text = utils.remove_accent(text.lower())

    outputs = []
    words_or_symbols_list = re.findall(&#39;\w[\w ]*|\W+&#39;, text)

    # print(words_or_symbols_list)

    for words_or_symbols in words_or_symbols_list:
        if utils.is_words(words_or_symbols):
            outputs.append(_add_accent(words_or_symbols))
        else:
            outputs.append(words_or_symbols)
        # print(outputs)
    output_text = &#39;&#39;.join(outputs)

    # restore uppercase characters
    output_text = &#39;&#39;.join(c.upper() if is_upper else c
                            for c, is_upper in zip(output_text, is_uppercase_map))
    return output_text

def _add_accent(phrase):
    grams = list(utils.gen_ngram(phrase.lower(), n=utils.NGRAM, pad_words=utils.PAD_WORDS_INPUT))
    
    guessed_grams = list(guess(gram) for gram in grams)
    # print(&amp;quot;phrase&amp;quot;,phrase,&#39;grams&#39;,grams,&#39;guessed_grams&#39;,guessed_grams)
    candidates = [Counter() for _ in range(len(guessed_grams) + utils.NGRAM - 1)]
    for idx, gram in enumerate(guessed_grams):
        for wid, word in enumerate(re.split(&#39; +&#39;, gram)):
            candidates[idx + wid].update([word])
    output = &#39; &#39;.join(c.most_common(1)[0][0] for c in candidates if c)
    return output.strip(&#39;\x00 &#39;)



# print(add_accent(&#39;do,&#39;))
# print(add_accent(&#39;7.3 inch,&#39;))
# print(add_accent(&#39;Truoc do, tren san khau su kien SDC 2018, giam doc cao cap mang marketing san pham di dong cua Samsung, ong Justin Denison da cam tren tay nguyen mau cua thiet bi nay. Ve co ban, no chang khac gi mot chiec may tinh bang 7.3 inch, duoc cau thanh tu nhieu lop phu khac nhau nhu polyme, lop man chong soc, lop phan cuc voi do mong gan mot nua so voi the he truoc, lop kinh linh hoat va mot tam lung da nang co the bien thanh man hinh. Tat ca se duoc ket dinh bang mot loai keo cuc ben, cho phep chiec may nay co the gap lai hang tram ngan lan ma khong bi hu hong.&#39;))
# print(add_accent(&#39;man hinh. Tat ca se duoc ket dinh bang mot loai keo cuc ben, cho phep chiec may nay co the gap lai hang tram ngan lan ma khong bi hu hong.&#39;))
print(add_accent(&#39;Hom nay, bao cao cua Counterpoint Research cho thay, trong nam 2018 Apple da ban duoc khoang 35 trieu cap tai nghe khong day AirPods. Theo hang phan tich nay, AirPods hien la tai nghe khong day pho bien nhat.&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Mã nguồn file utils&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import re
import string
import time
from contextlib import contextmanager
import numpy as np



# maximum string length to train and predict
# this is set based on our ngram length break down below
MAXLEN = 32

# minimum string length to consider
MINLEN = 3

# how many words per ngram to consider in our model
NGRAM = 5

# inverting the input generally help with accuracy
INVERT = True

# mini batch size
BATCH_SIZE = 128

# number of phrases set apart from training set to validate our model
VALIDATION_SIZE = 100000

# using g2.2xl GPU is ~5x faster than a Macbook Pro Core i5 CPU
HAS_GPU = True

PAD_WORDS_INPUT  = True

### Ánh xạ từ không dấu sang có dấu

ACCENTED_CHARS = {
    &#39;a&#39;: u&#39;a á à ả ã ạ â ấ ầ ẩ ẫ ậ ă ắ ằ ẳ ẵ ặ&#39;,
    &#39;o&#39;: u&#39;o ó ò ỏ õ ọ ô ố ồ ổ ỗ ộ ơ ớ ờ ở ỡ ợ&#39;,
    &#39;e&#39;: u&#39;e é è ẻ ẽ ẹ ê ế ề ể ễ ệ&#39;,
    &#39;u&#39;: u&#39;u ú ù ủ ũ ụ ư ứ ừ ử ữ ự&#39;,
    &#39;i&#39;: u&#39;i í ì ỉ ĩ ị&#39;,
    &#39;y&#39;: u&#39;y ý ỳ ỷ ỹ ỵ&#39;,
    &#39;d&#39;: u&#39;d đ&#39;,
}

### Ánh xạ từ có dấu sang không dấu
ACCENTED_TO_BASE_CHAR_MAP = {}
for c, variants in ACCENTED_CHARS.items():
    for v in variants.split(&#39; &#39;):
        ACCENTED_TO_BASE_CHAR_MAP[v] = c

# \x00 ký tự padding

### Những ký tự cơ bản, bao gồm ký tự padding, các chữ cái và các chữ số
BASE_ALPHABET = set(&#39;\x00 _&#39; + string.ascii_lowercase + string.digits)

### Bộ ký tự bao gồm những ký tự cơ bản và những ký tự có dấu
ALPHABET = BASE_ALPHABET.union(set(&#39;&#39;.join(ACCENTED_TO_BASE_CHAR_MAP.keys())))


def is_words(text):
    return re.fullmatch(&#39;\w[\w ]*&#39;, text)

# Hàm bỏ dấu khỏi một câu
def remove_accent(text):
    &amp;quot;&amp;quot;&amp;quot; remove accent from text &amp;quot;&amp;quot;&amp;quot;
    return u&#39;&#39;.join(ACCENTED_TO_BASE_CHAR_MAP.get(char, char) for char in text)

#hàm thêm padding vào một câu
def pad(phrase, maxlen):
    &amp;quot;&amp;quot;&amp;quot; right pad given string with \x00 to exact &amp;quot;maxlen&amp;quot; length &amp;quot;&amp;quot;&amp;quot;
    return phrase + u&#39;\x00&#39; * (maxlen - len(phrase))


def gen_ngram(words, n=3, pad_words=True):
    &amp;quot;&amp;quot;&amp;quot; gen n-grams from given phrase or list of words &amp;quot;&amp;quot;&amp;quot;
    if isinstance(words, str):
        words = re.split(&#39;\s+&#39;, words.strip())

    if len(words) &amp;lt; n:
        if pad_words:
            words += [&#39;\x00&#39;] * (n - len(words))
        yield tuple(words)
    else:
        for i in range(len(words) - n + 1):
            yield tuple(words[i: i + n])

def extract_phrases(text):
    &amp;quot;&amp;quot;&amp;quot; extract phrases, i.e. group of continuous words, from text &amp;quot;&amp;quot;&amp;quot;
    return re.findall(r&#39;\w[\w ]+&#39;, text, re.UNICODE)


@contextmanager
def timing(label):
    begin = time.monotonic()
    print(label, end=&#39;&#39;, flush=True)
    try:
        yield
    finally:
        duration = time.monotonic() - begin
    print(&#39;: took {:.2f}s&#39;.format(duration))

class CharacterCodec(object):
    def __init__(self, alphabet, maxlen):
        self.alphabet = list(sorted(set(alphabet)))
        self.index_alphabet = dict((c, i) for i, c in enumerate(self.alphabet))
        self.maxlen = maxlen

    def encode(self, C, maxlen=None):
        maxlen = maxlen if maxlen else self.maxlen
        X = np.zeros((maxlen, len(self.alphabet)))
        for i, c in enumerate(C[:maxlen]):
            X[i, self.index_alphabet[c]] = 1
        return X

    def try_encode(self, C, maxlen=None):
        try:
            return self.encode(C, maxlen)
        except KeyError:
            return None

    def decode(self, X, calc_argmax=True):
        if calc_argmax:
            X = X.argmax(axis=-1)
        return &#39;&#39;.join(self.alphabet[x] for x in X)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;link donwnload mô hình ở lần lặp thứ 10 ở &lt;a href=&#34;https://github.com/AlexBlack2202/alexmodel/blob/master/a_best_weight.h5?raw=true&#34;&gt;https://github.com/AlexBlack2202/alexmodel/blob/master/a_best_weight.h5?raw=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;À, kết quả của câu nói phần mở đầu là &amp;ldquo;mẹ nói rằng em rất đậm đang&amp;rdquo;. Hi hi, may quá.&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>