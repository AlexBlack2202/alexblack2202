<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tetris on Phạm Duy Tùng Machine Learning Blog</title>
    <link>/tags/tetris/</link>
    <description>Recent content in tetris on Phạm Duy Tùng Machine Learning Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>alexblack2202@gmail.com (Phạm Duy Tùng)</managingEditor>
    <webMaster>alexblack2202@gmail.com (Phạm Duy Tùng)</webMaster>
    <copyright>This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</copyright>
    <lastBuildDate>Sun, 27 Dec 2020 00:19:00 +0300</lastBuildDate>
    
	<atom:link href="/tags/tetris/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Reinforcement Learning và tictactoe</title>
      <link>/blog/2020-12-26---tic-tac-toe/</link>
      <pubDate>Sun, 27 Dec 2020 00:19:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2020-12-26---tic-tac-toe/</guid>
      <description>Advantages of Reinforcement Learning Trong khi trong các phương pháp lý thuyết trò chơi nói chung, ví dụ thuật toán min-max, thuật toán luôn giả định chúng ta có một đối thủ hoàn hảo, công việc phải thực hiện là tối đa hóa phần thưởng của mình và giảm thiểu phần thưởng của đối thủ ( tối đa hóa điểm của mình và tối thiểu hóa điểm của đối thủ), trong học củng cố, chúng ta không cần giả định đối thủ của chúng ta là 1 thiên tài xuất chúng, nhưng chung ta vẫn thu được mô hình với kết quả rất tốt.</description>
    </item>
    
    <item>
      <title>Xây dựng game xếp gạch bằng opencv và python</title>
      <link>/blog/2020-12-25---tetric/</link>
      <pubDate>Sat, 26 Dec 2020 00:19:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2020-12-25---tetric/</guid>
      <description>Mã nguồn import cv2 import numpy as np from random import choice def getColor(): lstColor = [[255,64,64],[255,165,0],[255,244,79],[102,255,0],[172,229,238],[148,87,235],[148,87,235],[241,156,187]] return choice(lstColor) def getInfo(piece): if piece == &amp;quot;&amp;quot;: coords = np.array([[0, 0]]) elif piece == &amp;quot;I&amp;quot;: coords = np.array([[0, 3], [0, 4], [0, 5], [0, 6]]) elif piece == &amp;quot;T&amp;quot;: coords = np.array([[1, 3], [1, 4], [1, 5], [0, 4]]) elif piece == &amp;quot;L&amp;quot;: coords = np.array([[1, 3], [1, 4], [1, 5], [0, 5]]) elif piece == &amp;quot;J&amp;quot;: coords = np.</description>
    </item>
    
  </channel>
</rss>