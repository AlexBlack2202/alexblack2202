<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pose estimation on Phạm Duy Tùng Machine Learning Blog</title>
    <link>/tags/pose-estimation/</link>
    <description>Recent content in pose estimation on Phạm Duy Tùng Machine Learning Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>alexblack2202@gmail.com (Phạm Duy Tùng)</managingEditor>
    <webMaster>alexblack2202@gmail.com (Phạm Duy Tùng)</webMaster>
    <copyright>&amp;copy; 2018 Phạm Duy Tùng. Website chia sẻ kiến thức của Phạm Duy Tùng và Đặng Thị Hằng. Vui lòng liên hệ email alexblack2202@gmail.com nếu bạn có thông tin cần trao đổi.</copyright>
    <lastBuildDate>Thu, 04 Oct 2018 00:19:00 +0300</lastBuildDate>
    <atom:link href="/tags/pose-estimation/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Deep Learning based Human Pose Estimation using OpenCV</title>
      <link>/blog/2018-10-04-deep-learning-base-human-pose-estimation/</link>
      <pubDate>Thu, 04 Oct 2018 00:19:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2018-10-04-deep-learning-base-human-pose-estimation/</guid>
      <description>

&lt;h3 id=&#34;lời-mở-đầu&#34;&gt;Lời mở đầu&lt;/h3&gt;

&lt;p&gt;Để sử dụng được các mô hình trong bài viết này, bạn phải sử dụng phiên bản opencv &amp;gt; 3.4.1.&lt;/p&gt;

&lt;h2 id=&#34;pose-estimation-là-gì&#34;&gt;Pose Estimation là gì?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=ohX-wkLYhdM&#34;&gt;&lt;img src=&#34;http://img.youtube.com/vi/ohX-wkLYhdM/0.jpg&#34; alt=&#34;POST ESTIMATION EXAMPLE - Make by Phạm Duy Tùng&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Post Estimation ( đôi khi được dùng với thuật ngữ Keypoint Detection) là một vấn đề khá phổ biến trong lĩnh vực xử lý ảnh khi chúng ta cần xác định vị trí và hướng của một đối tượng. Mức ý nghĩa ở đây là chúng ta phải rút ra được những đặc điểm chính, những đặc điểm đó là những đặc trưng của đối tượng ( có thể mô tả được đối tượng).&lt;/p&gt;

&lt;p&gt;Ví dụ, trong bài toán face pose estimation ( có tên khác là facial landmark detection), chúng ta cần xác định được đâu là vị trí của những điểm landmark trên khuôn mặt người.&lt;/p&gt;

&lt;p&gt;Một bài toán có liên quan đến bài toán trên là head pose estimation. Chúng ta cần xác định những điểm landmark để mô hình hoá lại được mô hình 3D của đầu người.&lt;/p&gt;

&lt;p&gt;Ở trong bài viết này, chúng ta đề cập đến bài toán human pose estimation, công việc chính là xác định và chỉ ra được một phần/ toàn bộ các phần chính của cơ thể con người (vd vai, khuỷu tay, cổ tay, đầu gối v.v).&lt;/p&gt;

&lt;p&gt;Trong bài viết này, chúng ta sẽ sử dụng mô hình được huấn luyện sẵn để chỉ ra các phần chính của cơ thể con người. Kết quả cơ bản của phần nhận diện này sẽ gần giống như hình bên dưới.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/midu_pose_estimation.png&#34; alt=&#34;Hình ảnh rút trích những thành phần quan trọng trên cơ thể con người&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;sử-dụng-pretrain-model-trong-bài-toán-pose-estimation&#34;&gt;Sử dụng pretrain model trong bài toán Pose Estimation&lt;/h2&gt;

&lt;p&gt;Vào nằm 2016, 2017, Phòng thí nghiệm Perceptual Computing của trường đại học Carnegie Mellon University đã công bố một bài báo có liên quan đến chủ đề Multi-Person Pose Estimation. Và đến nay, họ đã công bố mô hình huấn luyện cho chúng ta sử dụng. Các bạn có nhu cầu tìm hiểu sâu hơn có thể đọc kỹ nguồn dữ liệu của họ công bố ở link &lt;a href=&#34;https://github.com/CMU-Perceptual-Computing-Lab/openpose&#34;&gt;https://github.com/CMU-Perceptual-Computing-Lab/openpose&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Trong bài post này, mình sẽ không đề cập kỹ đến phần kiến trúc mạng neural net họ sử dụng bên dưới, thay vào đó, mình sẽ tập trung hơn vào cách thức sử dụng mô hình để thu được kết quả cần thiết.&lt;/p&gt;

&lt;p&gt;Trước khi bắt đầu vào thực hành, mình sẽ mô tả một chút về mô hình pretrain có sẵn. Ở đây, họ cung cấp cho chúng ta 2 mô hình là MPII model và COCO  model. Đó chính là tên của hai bộ database mà họ sử dụng để đào tạo mô hình. Kết quả trả về của mỗ bộ database là khác nhau hoàn toàn.&lt;/p&gt;

&lt;p&gt;Với bộ COCO dataset, kết quả trả về là 18 đặc trưng gồm các thông tin:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Nose – 0, Neck – 1, Right Shoulder – 2, Right Elbow – 3, Right Wrist – 4,
Left Shoulder – 5, Left Elbow – 6, Left Wrist – 7, Right Hip – 8,
Right Knee – 9, Right Ankle – 10, Left Hip – 11, Left Knee – 12,
LAnkle – 13, Right Eye – 14, Left Eye – 15, Right Ear – 16,
Left Ear – 17, Background – 18
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Với bộ MPII, kết quả trả về là 15 đặc trưng gồm các thông tin:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Head – 0, Neck – 1, Right Shoulder – 2, Right Elbow – 3, Right Wrist – 4,
Left Shoulder – 5, Left Elbow – 6, Left Wrist – 7, Right Hip – 8,
Right Knee – 9, Right Ankle – 10, Left Hip – 11, Left Knee – 12,
Left Ankle – 13, Chest – 14, Background – 15
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Trong phần này, chúng ta sẽ tập trung vào mô hình MPII, mô hình COCO sử dụng tương tự, chỉ việc thay lại đường dẫn file mô hình là được.&lt;/p&gt;

&lt;h2 id=&#34;bắt-đầu-code&#34;&gt;Bắt đầu code.&lt;/h2&gt;

&lt;p&gt;Bước 1: Download mô hình.&lt;/p&gt;

&lt;p&gt;Nhóm tác giả sử dụng caffe để huấn luyện mô hình, do đó, để sử dụng được, chúng ta cần download file mô hình ở đường dẫn &lt;a href=&#34;http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_iter_160000.caffemodel&#34;&gt;http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_iter_160000.caffemodel&lt;/a&gt; và file cấu hình ở đường dẫn &lt;a href=&#34;http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_deploy_linevec.prototxt&#34;&gt;http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_deploy_linevec.prototxt&lt;/a&gt;. Các bạn có thể để đâu đó tuỳ thích, ở đây tôi để trong thư mục pose/mpi để dễ dàng nhận biết với các mô hình khác.&lt;/p&gt;

&lt;p&gt;Bước 2: Load mô hình.&lt;/p&gt;

&lt;p&gt;Để load mô hình lên bộ nhớ chính, đơn giản là chúng ta thực hiện câu lệnh sau trong python&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import cv2
# Specify the paths for the 2 files
protoFile = &amp;quot;pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt&amp;quot;
weightsFile = &amp;quot;pose/mpi/pose_iter_160000.caffemodel&amp;quot;
 
# Read the network into Memory
net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Đơn giản quá phải không các bạn :).&lt;/p&gt;

&lt;p&gt;Bước 3: Đọc ảnh và đưa ảnh vào trong mô hình.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
# Read image
frame = cv2.imread(&amp;quot;img2.jpg&amp;quot;)

frameCopy = np.copy(frame)
frameWidth = frame.shape[1]
frameHeight = frame.shape[0]
t = time.time()
# Specify the input image dimensions
inWidth = 368
inHeight = 368
 
# Prepare the frame to be fed to the network
inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)
 
# Set the prepared object as the input blob of the network
net.setInput(inpBlob)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Chắc không cần phải nói gì thêm, phần comment chú thích đã mô tả khá đầy đủ chức năng của từng phần trong này rồi.&lt;/p&gt;

&lt;p&gt;Bước 4: Thu thập kết quả và trích xuất điểm đặc trưng&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
frameCopy = frame.copy()

output = net.forward()
print(&amp;quot;time taken by network : {:.3f}&amp;quot;.format(time.time() - t))
H = output.shape[2]
W = output.shape[3]

nPoints = 15
POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]


threshold = 0.01
# Empty list to store the detected keypoints
points = []
for i in range(nPoints):
    # confidence map of corresponding body&#39;s part.
    probMap = output[0, i, :, :]
 
    # Find global maxima of the probMap.
    minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)
     
    # Scale the point to fit on the original image
    x = (frameWidth * point[0]) / W
    y = (frameHeight * point[1]) / H

    print(prob)
 
    if prob &amp;gt; threshold : 
        cv2.circle(frame, (int(x), int(y)), 15, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)
        cv2.putText(frame, &amp;quot;{}&amp;quot;.format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 2, lineType=cv2.LINE_AA)
 
        # Add the point to the list if the probability is greater than the threshold
        points.append((int(x), int(y)))
    else :
        points.append(None)
 
# cv2.imshow(&amp;quot;Output-Keypoints&amp;quot;,frame)
# cv2.waitKey(0)
# cv2.destroyAllWindows()

cv2.imwrite(&amp;quot;dot_keypoint.png&amp;quot;,frame)

# Draw Skeleton
for pair in POSE_PAIRS:
    partA = pair[0]
    partB = pair[1]

    if points[partA] and points[partB]:
        cv2.line(frameCopy, points[partA], points[partB], (0, 255, 255), 2)
        cv2.circle(frameCopy, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)
        cv2.circle(frameCopy, points[partB], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)


cv2.imwrite(&amp;quot;line_keypoint.png&amp;quot;,frameCopy)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả của giá trị output là một ma trận 4D, với ý nghĩa của mỗi chiều như sau:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Chiều đầu tiên là image ID (định danh ảnh trong trường hợp bạn truyền nhiều ảnh vào mạng)&lt;/li&gt;
&lt;li&gt;Chiều thứ 2 là chỉ số của các điểm đặc trưng. Tập MPI trả về tập gồm 44 điểm dữ liệu, ta chỉ sử dụng một vài điểm dữ liệu tương ứng với vị trí các điểm đặc trưng mà chúng ta quan tâm.&lt;/li&gt;
&lt;li&gt;Chiều thứ 3 là height của output map.&lt;/li&gt;
&lt;li&gt;Chiều thứ 4 là width của output map.
Một lưu ý ở đây là tôi có sử dụng đặt giá trị chặn dưới threshold để giảm thiểu sự sai sót do nhận diện sai. Và kết quả đạt được là hai hình bên dưới:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/midu_pose_estimation_keypoint.png&#34; alt=&#34;Hình nhữn điểm đặc trưng&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/midu_pose_estimation.png&#34; alt=&#34;Hình khung xương&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hẹn gặp lại các bạn ở những bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>