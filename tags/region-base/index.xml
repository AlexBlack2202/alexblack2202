<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>region base on Phạm Duy Tùng Machine Learning Blog</title>
    <link>/tags/region-base/</link>
    <description>Recent content in region base on Phạm Duy Tùng Machine Learning Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>alexblack2202@gmail.com (Phạm Duy Tùng)</managingEditor>
    <webMaster>alexblack2202@gmail.com (Phạm Duy Tùng)</webMaster>
    <copyright>This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</copyright>
    <lastBuildDate>Wed, 05 Dec 2018 00:19:00 +0300</lastBuildDate>
    <atom:link href="/tags/region-base/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Tìm hiểu region based object detectors</title>
      <link>/blog/2018-12-05-what-do-we-learn-from-object-detection-p1/</link>
      <pubDate>Wed, 05 Dec 2018 00:19:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2018-12-05-what-do-we-learn-from-object-detection-p1/</guid>
      <description>

&lt;h2 id=&#34;sliding-window-detectors&#34;&gt;Sliding-window detectors&lt;/h2&gt;

&lt;p&gt;Bắt đầu từ năm 2012, sau khi mạng AlexNet giành giải nhất cuộc thi 2012 ILSVRC, mọi nghiên cứu về phân lớp dữ liệu đều sử dụng mạng CNN. Kể từ đó đến đây, CNN được coi như là thuật toán thống trị trên mọi publish paper về các bài toán phân lớp đối tượng. Trong khi đó, để nhận dạng 1 đối tượng trong ảnh, các đơn giản nhất là thiết lập một cửa sổ trượt có kích thước là window size trượt từ trái qua phải, từ trên xuống dưới, quét qua toàn bộ bức ảnh. Để phát hiện các đối tượng khác nhau ở các góc nhìn khác nhau, chúng ta sẽ sử dụng cửa sổ trượt có kích thước thay đổi  và ảnh đầu vào có kích thước thay đổi.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/sliding-window.gif&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-base-various-windowsize.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-base-various-windowsize1.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Dựa vào windowsize, chúng ta có thể cắt tấm hình bự thành các tấm hình nhỏ, sau đó sẽ rescale các phần nhỏ của bức ảnh thành các bức ảnh có kích thước cố định.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/fixed-size-image.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Các phần của bức ảnh sau đó sẽ được đem qua bộ phân lớp CNN để rút trích các đặc trưng, sau đó sử dụng một hàm phân lớp (như svm, logictic regression) để xác định lớp của bức hình và sử dụng linear regressor để tìm bao đóng của đối tượng.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/sliding-window-detector.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Mã giả của mô hình&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for window in windows
    patch = get_patch(image, window)
    results = detector(patch)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cách dễ dàng nhất để cải tiến hiệu năng của phương pháp này là giảm số lượng tấm hình nhỏ xuống (ví dụ tăng kích thước window size). Cách này còn được giang hồ gọi là  brute force.&lt;/p&gt;

&lt;h2 id=&#34;selective-search&#34;&gt;Selective Search&lt;/h2&gt;

&lt;p&gt;Thay vì hướng tiếp cận brute force ở trên, chúng ta sử dụng phương pháp region proposal để tạo các region of interest (ROIs) để phát hiện đối tượng. Selective search là một phương pháp nằm trong nhóm region proposal. Trong phương pháp selective search(SS), chúng ta bắt đầu bằng cách xem các pixel là mỗi nhóm, các lần lặp tiếp theo, chúng ta sẽ tính khoảng cách ngữ nghĩa (ví dụ như là màu sắc, cường độ ánh sáng) giữa các nhóm và gom các nhóm có khoảng cách gần nhau về chung 1 nhóm để tìm ra phân vùng có khả năng cao nhất chứa đối tượng (ưu tiên gom những nhóm nhỏ trước).&lt;/p&gt;

&lt;p&gt;Như hình bên dưới, dòng đầu tiên, bức ảnh đâu tiên là ta có một vài nhóm nhỏ ở thời điểm X nào đó, ở hình thứ 2 là thực hiện gom nhớm theo cường độ màu sắc của hình số 1, và ở bước cuối cùng, ta thu được hình số 3. Những hình chữ nhật màu xanh ở dòng thứ 2 là những ROIS mô phỏng quá trình gom nhóm để tìm phân vùng có khả năng chứa đối tượng.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/selectivesearch.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;em&gt;selective search&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;mạng-r-cnn&#34;&gt;Mạng R-CNN&lt;/h2&gt;

&lt;p&gt;Mạng R-CNN sử dụng phương pháp region proposal để tạo ra khoảng 2000 ROIs. Các vùng sau đó sẽ được rescale theo một kích thước cố định nào đó và được đưa vào mô hình CNN có lớp cuối cùng kà một full conected layer để phân lớp đối tượng và để lọc ra boundary box (bao đóng) của đối tượng.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposals-cnn.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;em&gt;Mô phỏng việc sử dụng region proposal&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposals-r-cnn.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;em&gt;Mô phỏng việc sử dụng region proposal của RCNN&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Mã giả của mô hình&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt; ROIs = region_proposal(image)
for ROI in ROIs
    patch = get_patch(image, ROI)
    results = detector(patch)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Với việc sử dụng ít tấm ảnh nhỏ hơn, và chất lượng của mỗi tấm ảnh nhỏ tốt hơn, Mạng R-CNN chạy nhanh hơn và có độ chính xác cao hơn so với mô hình sử dụng cửa sổ trượt.&lt;/p&gt;

&lt;h2 id=&#34;mạng-fast-r-cnn&#34;&gt;Mạng Fast R-CNN&lt;/h2&gt;

&lt;p&gt;Trong thực tế, các phân vùng của mạng R-CNN bị chồng lấp một phần / toàn bộ với các phân vùng khác. Do đó, việc huấn luyện và thực thi ( inference ) mạng R-CNN diễn ra khá chậm. Nếu chúng ta có 2000 proposal của mạng R-CNN, chúng ta phải thực hiện 2000 lần việc rút trích đặc trưng, một con số khác lớn.&lt;/p&gt;

&lt;p&gt;Thay vì phải rút trích đặc trưng của mỗi proposal, chúng ta có thể dùng CNN rút trích đặc trưng của toàn bộ bức ảnh trước (được feature map), đồng thời rút trích các proposal, lấy các proposal tương ứng trên feature map, rescale và cuối cùng là phân lớp và tìm vị trí của object. Với việc không phải lặp lại 2000 lần việc rút trích đặc trưng, Fast R-CNN giảm thời gian xử lý một cách đáng kể.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposals-fast-r-cnn.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;em&gt;Mô phỏngviệc sử dụng propoxal trên feature map và các bước tiếp theo của Fast R-CNN&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposals-fast-r-cnn-network-model.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;em&gt;Đồ hình của Fast R-CNN&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Mã giả của mô hình&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt; feature_maps = process(image)
ROIs = region_proposal(image)
for ROI in ROIs
    patch = roi_pooling(feature_maps, ROI)
    results = detector2(patch)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Với việc không phải lặp đi lặp lại quá trình tìm ra các proposal, tốc độ của thuật toán tăng lên kha khá. Trong thực nghiệm, mô hình Fast R-CNN chạy nhanh hơn gấp 10 lần so với R-CNN trong quá trình huấn luyện. Và nhanh hơn 150 lần trong inferencing.&lt;/p&gt;

&lt;p&gt;Một khác biệt lớn nhất của Fast R-CNN là toàn bộ network (feature extractior, classifier, boundary box regressor) có thể huấn luyện end-to end (nghĩa là từ đầu đến cuối) với 2 hàm độ lỗi (loss funtion) khác nhau cùng lúc (classification loss và localization loss). Điều này làm tăng độ chính xác của mô hình.&lt;/p&gt;

&lt;h2 id=&#34;roi-pooling&#34;&gt;ROI Pooling&lt;/h2&gt;

&lt;p&gt;Vì Fast R-CNN sử dụng full connected layter ở lớp cuối, nên đòi hỏi input của chúng phải có kích thước cố định, nên ta phải resize lại feature về 1 kích thước cố định (do 2000 proposal có kích thước không cố định). Ở đây, các tác giả sử dụng ROI pooling để resize. Thuật toán ở đây được sử dụng như sau:&lt;/p&gt;

&lt;p&gt;Giả sử đơn giản là chúng ta có một proposal có kích thước 5x7, và chúng ta cần resize về hình dạng 2x2. Chúng ta xem kỹ hình bên dưới.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/roi-pooling-example.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;em&gt;Hình ảnh mô phỏng ROI pooling&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Hình ở bên trái là feature map của chúng ta.&lt;/p&gt;

&lt;p&gt;Hình số 2, vùng hình chữ nhật xanh là vùng proposal 5x7.&lt;/p&gt;

&lt;p&gt;Vì chúng ta cần resize về vùng có kích thước 2x2 (4 phần), nên ta chia vùng proposal 5x7 thành 4 phần (&lt;sup&gt;5&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; =2 dư 3, vậy có 1 phần là 2, 1 phần là 3. Tương tự &lt;sup&gt;7&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; = 3 dư 4, vậy có 1 phần 3, một phần 4. Cuối cùng ta có 4 hình chữ nhật có kích thước tương ứng là 2x3, 2x4, 3x3, 3x4) (Hình số 3).&lt;/p&gt;

&lt;p&gt;Hình số 4, từ 4 phần của vùng số 3, ta sẽ lấy giá trị lớn nhất của mỗi vùng.&lt;/p&gt;

&lt;p&gt;Vậy là ta thu được feature proposal có kích thước 2x2 rồi.&lt;/p&gt;

&lt;h2 id=&#34;faster-r-cnn&#34;&gt;Faster R-CNN&lt;/h2&gt;

&lt;p&gt;Nhìn kỹ lại vào thuật toán F-CNN, chúng ta cần phải rút rích 2000 ROIs, và nó là nguyên nhân lớn gây nên sự chậm trể của mô hình&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt; feature_maps = process(image)
ROIs = region_proposal(image)         # Expensive, slow
for ROI in ROIs
    patch = roi_pooling(feature_maps, ROI)
    results = detector2(patch)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thuật toán Faster R-CNN sử dụng mô hình gần như tương tự Fast R-CNN, ngoài việc sử dụng thuật toán interal deep network thay cho selective search để tìm region proposal. Thuật toán mới chạy hiệu quả hơn khi tìm tất cả các ROIs trên mỗi bức ảnh với tốc độ 10ms/&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposals-fater-r-cnn.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;em&gt;Mô hình của Faster R-CNN&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposals-fater-r-cnn-model.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;em&gt;Đồ hình của Faster R-CNN&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;region-proposal-network&#34;&gt;Region proposal network&lt;/h2&gt;

&lt;p&gt;Mạng region proposal sử dụng feature map làm input đầu vào (như hình trên đã mô phỏng). Mạng sử dụng 1 bộ lọc 3x3, sau đó là một mô hình CNN như ZF hoặc VGG hoặc ResNet ( mô hình càng phức tạp thì độ chính xác cao, nhưng bù lại thời gian tìm kiếm sẽ lâu hơn) để dự đoán boundary box và object score (để xét xem trong bodary box trên có chứa đối tượng hay không. Trong thực tế, mạng Faster R-CNN trả về 2 lớp, lớp thứ nhất là có chứa object, lớp thứ 2 là không chứa object ( ví dụ lớp màu nền - background, lớp abc gì gì đó)) .&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposals-r-cnn-example.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;em&gt;Ví dụ Region proposal network&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposal-network-1.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;
&lt;em&gt;Mô hình Region proposal network sử dụng ZF network&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Giả sử tại 1 điểm nào đó trên feature map, RPN có k dự đoán, vậy là chúng ta có tổng cộng 4xk toạ độ điểm và 2xk điểm cho điểm đó. Nhìn ví dụ ở hình bên dưới.&lt;/p&gt;

&lt;p&gt;Hình 1: ta có feature map với kích thước 8x8, vùng hình vuông được tô là filter đang xét có kích thước 3x3.
 Hình 2: Giả sử xét điểm có chấm xanh. Tại điểm đó, ta có k=3 sau khi chạy RPN, và ta được 3 hình chữ nhật như hình.&lt;/p&gt;

&lt;p&gt;Tuy nhiên, tại mỗi điểm, ta chỉ cần 1 boundary box tốt nhất. Cách đơn giản nhất là chọn ngẫu nhiên 1 cái. Nhưng như vậy thì ngay từ đầu ta chọn k=1 luôn cho khoẻ, mắc công gì phải chọn k=3. Trong thực tế, Faster R-CNN không sử dụng phương pháp random select. Thay vào đó, thuật toán một reference boxs hay còn được gọi với tên là anchors và tìm mức độ liên quan của k boundary box với k reference boxs và chọn ra boundary box có độ liên quan lớn nhất.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/anchors-box.png&#34; alt=&#34;Hình ảnh&#34; /&gt;
 &lt;em&gt;Ví dụ anchors box&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Các anchors này được lựa chọn trước đó và được xem là config của mô hình. Faster R-CNN sử dụng 9 anchor boxs (tương ứng với k =3) với 3 box đầu tiên có tỷ lệ width, height khác nhau (ví dụ 2x3, 3x3, 3x2), tiếp đó sẽ scale các box trên với các tỷ lệ khác khau (ví dụ 1.5,3,7) để đạt được 9 anchor boxs.&lt;/p&gt;

&lt;p&gt;Vì mỗi điểm sử dụng 9 anchors, nên ta có tổng cộng 2x9 score và 4x9 location (toạ độ)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/anchorsbox_feature_map.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Anchor box có thể được goijlaf priors hoặc default boundary boxes trong mỗi bài báo khác nhau.&lt;/p&gt;

&lt;h2 id=&#34;hiệu-năng-của-mô-hình-r-cnn&#34;&gt;Hiệu năng của mô hình R-CNN&lt;/h2&gt;

&lt;p&gt;Hình bên dưới mô tả benchmark của các mô hình dẫn xuất từ R-CNN, ta thấy Faster R-CNN có tốc độ tốt nhất.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/f-rcnn-performance.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;region-based-fully-convolutional-networks&#34;&gt;Region-based Fully Convolutional Networks&lt;/h2&gt;

&lt;p&gt;Giả sử chúng ta chỉ có toạ độ của mắt phải trong khuôn mặt, chúng ta có thể nội suy ra được vị trí của khuôn mặt. Vì ta biết rằng mắt phải nằm ở vị trí trái trái trong bức hình, và ta từ đó suy ra vị trí của các phần còn lại (xem hình).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/f-rcnn-image1.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Nếu chúng ta có thêm thông tin khác, ví như toạ độ của mắt trái, mũi, miệng, &amp;hellip; thì chúng ta có thể kết hợp chúng để tăng độ chính xác của phân vùng khuôn mặt.&lt;/p&gt;

&lt;p&gt;Trong Faster R-CNN, chúng ta phải tìm proposal sử dụng một mô hình CNN, với khoảng 2000 ROI, chúng ta sẽ tiêu tốn một khoảng thời gian khá lớn để tìm chúng.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;feature_maps = process(image)
ROIs = region_proposal(feature_maps)
for ROI in ROIs
    patch = roi_pooling(feature_maps, ROI)
    class_scores, box = detector(patch)         # Expensive, slow
    class_probabilities = softmax(class_scores)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Trong khi đó, với Fast R-CNN, chúng ta chỉ cần phải tính max hoặc average, nên Fast R-CNN nhanh hơn Faster R-CNN ở đây.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;feature_maps = process(image)
ROIs = region_proposal(feature_maps)         
score_maps = compute_score_map(feature_maps)
for ROI in ROIs
    V = region_roi_pool(score_maps, ROI)     
    class_scores, box = average(V)                   # Much simpler, faster.
    class_probabilities = softmax(class_scores)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Xét feature map M có kích thước 5x5, trong đó có chứa một hình vuông màu xanh, hình vuông xanh là đối tượng thực tế ta cần tìm.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposals-r-cnn-example1.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Ta chia hình vuông thành phân vùng có kích thước 3x3 (hình 2). Sau đó, chúng ta tạo một feature mới để từ M để tìm ra góc trái trên của hình vuông (chỉ tìm góc trái trên) (hình 3). Feature map mới giống hình thứ 3, chỉ có ô được tô màu vàng ở vị trí [2,2] được bật.&lt;/p&gt;

&lt;p&gt;Với mỗi 9 phần của hình vuông, chúng ta có 9 feature map cho mỗi phần, nhận dạng 9 vùng tương ứng cho một đối tượng. Những feature map này được gọi là position sensitive score map, bởi vì chúng detect ra điểm (score) và sub region của một đối tượng (Xem hình bên dưới).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposals-r-cnn-example2.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Xét ảnh bên dưới, giả sử vùng được tô gạch đỏ là proposal (hình 1). Chúng ta cũng chia nó thành những phân vùng con có kích thước 3x3 (hình 2). Và tìm xem mức độ giống nhau của mỗi vùng con của proposal và vùng con của feature map như thế nào. Kết quả sẽ được lưu vào một ma trận 3x3 như hình số 3.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposals-r-cnn-example3.jpg&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Quá trình ánh xạ điểm từ score maps và ROIS vào mảng vote_array được gọi là position sensitive ROI pool.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposals-r-cnn-example4.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Sau khi tính toán hết các giá trị của position-sensitive ROI pool, chúng ta sẽ tính trung bình của vote_array để lấy điểm của lớp (class score).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposals-r-cnn-example5.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Giả sử mô hình chúng ta phải nhận dạng k lớp, do có thêm lớp background nên chúng ta có tổng cộng k+1 lớp. Với mỗi lớp chúng ta có 3x3 score map, suy ra chúng ta có tổng cộng là (k+1)x3x3 score maps, (k+1) điểm, và dùng softmax ta sẽ thu được xác suất của mỗi lớp.&lt;/p&gt;

&lt;p&gt;Luồng dữ liệu của mô hình&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/region-proposals-r-cnn-data-flow.png&#34; alt=&#34;Hình ảnh&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.&lt;/p&gt;

&lt;p&gt;Bài viết được lược dịch và tham khảo từ nguồn &lt;a href=&#34;https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9&#34;&gt;https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>