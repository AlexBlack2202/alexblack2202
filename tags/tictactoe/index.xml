<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TicTacToe on Phạm Duy Tùng Machine Learning Blog</title>
    <link>/tags/tictactoe/</link>
    <description>Recent content in TicTacToe on Phạm Duy Tùng Machine Learning Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <copyright>Copyright © 2016-{year} Phạm Duy Tùng. All Rights Reserved.</copyright>
    <lastBuildDate>Sun, 27 Dec 2020 00:19:00 +0300</lastBuildDate>
    <atom:link href="/tags/tictactoe/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Reinforcement Learning và tictactoe</title>
      <link>/blog/2020-12-26---tic-tac-toe/</link>
      <pubDate>Sun, 27 Dec 2020 00:19:00 +0300</pubDate>
      <guid>/blog/2020-12-26---tic-tac-toe/</guid>
      <description>Trong khi trong các phương pháp lý thuyết trò chơi nói chung, ví dụ thuật toán min-max, thuật toán luôn giả định chúng ta có một đối thủ hoàn hảo, công việc phải thực hiện là tối đa hóa phần thưởng của mình và giảm thiểu phần thưởng của đối thủ ( tối đa hóa điểm của mình và tối thiểu hóa điểm của đối thủ), trong học củng cố, chúng ta không cần giả định đối thủ của chúng ta là 1 thiên tài xuất chúng, nhưng chung ta vẫn thu được mô hình với kết quả rất tốt.</description>
    </item>
  </channel>
</rss>
