<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>stock prediction on Phạm Duy Tùng Machine Learning Blog</title>
    <link>/tags/stock-prediction/</link>
    <description>Recent content in stock prediction on Phạm Duy Tùng Machine Learning Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>alexblack2202@gmail.com (Phạm Duy Tùng)</managingEditor>
    <webMaster>alexblack2202@gmail.com (Phạm Duy Tùng)</webMaster>
    <copyright>This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</copyright>
    <lastBuildDate>Sat, 10 Nov 2018 00:19:00 +0300</lastBuildDate>
    <atom:link href="/tags/stock-prediction/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Dự đoán giá chứng khoán SP500 sử dụng LSTM</title>
      <link>/blog/2018-11-10-stock-prediction_v1/</link>
      <pubDate>Sat, 10 Nov 2018 00:19:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2018-11-10-stock-prediction_v1/</guid>
      <description>

&lt;h2 id=&#34;lời-mở-đầu&#34;&gt;Lời mở đầu&lt;/h2&gt;

&lt;p&gt;Ở bài viết này, mình sẽ xây dựng mô hình hơn giản để áp dụng vào tập dữ liệu giá chứng khoáng. Mục tiêu của bài này là chúng ta sẽ dự đoán chỉ số S&amp;amp;P 500 sử dụng LSTM. Các bạn có nhu cầu tìm hiểu thêm về chỉ số sp 500 có thể đọc thêm ở &lt;a href=&#34;https://vi.wikipedia.org/wiki/S%26P_500&#34;&gt;https://vi.wikipedia.org/wiki/S%26P_500&lt;/a&gt;. Đây là một ứng dụng nhỏ, không có ý nghĩa nhiều ở thực tế do khi phân tích chứng khoán, ta còn xét thêm rất nhiều yếu tố phụ nữa. Mô hình này thực chất chỉ là một trong những mô hình chơi chơi.&lt;/p&gt;

&lt;h2 id=&#34;dẫn-nhập&#34;&gt;Dẫn nhập&lt;/h2&gt;

&lt;h3 id=&#34;phân-tích-dữ-liệu&#34;&gt;Phân tích dữ liệu&lt;/h3&gt;

&lt;p&gt;Các bạn có thể download dữ liệu ở &lt;a href=&#34;https://github.com/AlexBlack2202/alexmodel/blob/master/GSPC.csv&#34;&gt;https://github.com/AlexBlack2202/alexmodel/blob/master/GSPC.csv&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Đầu tiên, như thường lệ, chúng ta sẽ import các thư viện cần thiết để sử dụng.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

from subprocess import check_output
from keras.layers.core import Dense, Activation, Dropout
from keras.layers.recurrent import LSTM
from keras.models import Sequential
from sklearn.cross_validation import  train_test_split
import time #helper libraries
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
from numpy import newaxis

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Đọc dữ liệu lên:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
file_name =&#39;GSPC.csv&#39;

prices_dataset =  pd.read_csv(file_name, header=0)

``

Xem kích thước của dữ liệu:

```python
print(prices_dataset.shape)

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(17114, 7)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả là ta có  17114 ngàn dòng và 7 cột. Thử show 10 row đầu tiên của dữ liệu lên xem như thế nào.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(prices_dataset.head())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;         Date       Open       High        Low      Close  Adj Close   Volume
0  1950-11-09  19.790001  19.790001  19.790001  19.790001  19.790001  1760000
1  1950-11-10  19.940001  19.940001  19.940001  19.940001  19.940001  1640000
2  1950-11-13  20.010000  20.010000  20.010000  20.010000  20.010000  1630000
3  1950-11-14  19.860001  19.860001  19.860001  19.860001  19.860001  1780000
4  1950-11-15  19.820000  19.820000  19.820000  19.820000  19.820000  1620000

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cột đầu tiên là ngày, sau đó là giá mở cửa, giá giao dịch cao nhất, giá giao dịch thấp nhât, giá đóng cử, giá đóng cửa đã điều chỉnh, khối lượng giao dịch.&lt;/p&gt;

&lt;p&gt;Plot đồ thị của mã SP500 lên:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import matplotlib.pyplot as plt

plt.plot(prices_dataset.Open.values, color=&#39;red&#39;, label=&#39;open&#39;)
plt.plot(prices_dataset.Close.values, color=&#39;green&#39;, label=&#39;close&#39;)
plt.plot(prices_dataset.Low.values, color=&#39;blue&#39;, label=&#39;low&#39;)
plt.plot(prices_dataset.High.values, color=&#39;black&#39;, label=&#39;high&#39;)
plt.title(&#39;stock price&#39;)
plt.xlabel(&#39;time [days]&#39;)
plt.ylabel(&#39;price&#39;)
plt.legend(loc=&#39;best&#39;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/sp500indexv1.png&#34; alt=&#34;Hình ảnh đừng đồ thị của chỉ số sp 500&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hình với số lượng hơi nhiều nên khó phân biệt được giá trị của dữ liệu, chúng ta thử show đồ thị của 50 ngày cuối cùng trong dữ liệu.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;prices_dataset_tail_50 = prices_dataset.tail(50)

plt.plot(prices_dataset_tail_50.Open.values, color=&#39;red&#39;, label=&#39;open&#39;)
plt.plot(prices_dataset_tail_50.Close.values, color=&#39;green&#39;, label=&#39;close&#39;)
plt.plot(prices_dataset_tail_50.Low.values, color=&#39;blue&#39;, label=&#39;low&#39;)
plt.plot(prices_dataset_tail_50.High.values, color=&#39;black&#39;, label=&#39;high&#39;)
plt.title(&#39;stock price&#39;)
plt.xlabel(&#39;time [days]&#39;)
plt.ylabel(&#39;price&#39;)
plt.legend(loc=&#39;best&#39;)
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/sp500index_tail_50.png&#34; alt=&#34;Hình ảnh đừng đồ thị của chỉ số sp 500&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hình ảnh trông khá rõ ràng và trực quan hơn rất nhiều.&lt;/p&gt;

&lt;p&gt;Chúng ta sẽ bỏ đi cột DATE,Adj Close,Volume đi. Các cột đó không cần thiết cho quá trình dự đoán.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
prices_dataset_dropout = prices_dataset.drop([&#39;Date&#39;,&#39;Adj Close&#39;,&#39;Volume&#39;], 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;scale-dữ-liệu&#34;&gt;Scale dữ liệu&lt;/h3&gt;

&lt;p&gt;Khi sử dụng ANN, chúng ta thông thường sẽ scale dữ liệu input về đoạn [-1,1]. Trong python, thư viện sklearn đã hỗ trợ cho chúng ta sẵn các hàm scale dữ liệu cần thiết.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Scale data
def normalize_data(df):
    min_max_scaler = MinMaxScaler()
    df[&#39;Open&#39;] = min_max_scaler.fit_transform(df.Open.values.reshape(-1,1))
    df[&#39;High&#39;] = min_max_scaler.fit_transform(df.High.values.reshape(-1,1))
    df[&#39;Low&#39;] = min_max_scaler.fit_transform(df.Low.values.reshape(-1,1))
    df[&#39;Close&#39;] = min_max_scaler.fit_transform(df.Close.values.reshape(-1,1))
    return df

prices_dataset_norm = normalize_data(prices_dataset_dropout)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;phân-chia-tập-train-và-test&#34;&gt;Phân chia tập train và test.&lt;/h3&gt;

&lt;p&gt;Chúng ta sẽ chia dữ liệu thành 2 phần với 80% là train và 20% còn lại là test. Chọn seq_len=20, các bạn có thể test với các seq len khác, và sau đó chuyển dữ liệu về dạng numpy array để dễ dàng thực hiện các phép chuyển đổi.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
def generate_data(stock_ds, seq_len):
    data_raw = stock_ds.as_matrix()
    data = []
    
    # create all possible sequences of length seq_len
    for index in range(len(data_raw) - seq_len): 
        data.append(data_raw[index: index + seq_len])
    return data

#data as numpy array
def generate_train_test(data_ds,split_percent=0.8):
    print(len(data_ds))
    data = np.asarray(data_ds)
   
    data_size = len(data)
    train_end = int(np.floor(split_percent*data_size))
    
    x_train = data[:train_end,:-1,:]
    y_train = data[:train_end,-1,:]
    
 
    
    x_test = data[train_end:,:-1,:]
    y_test = data[train_end:,-1,:]
    
    return [x_train, y_train, x_test, y_test]



seq_len = 20 # choose sequence length

seq_prices_dataset = generate_data(prices_dataset_norm,seq_len)

x_train, y_train, x_test, y_test = generate_train_test(seq_prices_dataset, 0.8)

print(&#39;x_train.shape = &#39;,x_train.shape)
print(&#39;y_train.shape = &#39;, y_train.shape)
print(&#39;x_test.shape = &#39;, x_test.shape)
print(&#39;y_test.shape = &#39;,y_test.shape)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt; x_train.shape =  (13675, 19, 4)
y_train.shape =  (13675, 4)
x_test.shape =  (3419, 19, 4)
y_test.shape =  (3419, 4)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;xây-dựng-mô-hình-sử-dụng-keras&#34;&gt;Xây dựng mô hình sử dụng keras&lt;/h3&gt;

&lt;p&gt;Ở đây mình sử dụng keras xây dựng mô hình ANN. Mô hình của mình xây dựng gồm:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = Sequential()

model.add(LSTM(
    input_dim=4,
    output_dim=50,
    return_sequences=True))
model.add(Dropout(0.2))

model.add(LSTM(
    100,
    return_sequences=False))
model.add(Dropout(0.2))

model.add(Dense(
    output_dim=4))
model.add(Activation(&#39;linear&#39;))



model.compile(loss=&#39;mean_squared_error&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;])
checkpoint = ModelCheckpoint(filepath=&#39;sp500_stockperdict.h5&#39;, verbose=1, save_best_only=True)
hist = model.fit(x_train, y_train, epochs=300, batch_size=128, verbose=1, callbacks=[checkpoint], validation_split=0.2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sau một thời gian chạy, mình cũng thu được model. Các bạn quan tâm có thể download model của mình huấn luyện được tại &lt;a href=&#34;https://drive.google.com/open?id=1ImHQM9yWmOjpF5tjmSI9oqAi5BORa9Rs&#34;&gt;https://drive.google.com/open?id=1ImHQM9yWmOjpF5tjmSI9oqAi5BORa9Rs&lt;/a&gt; . Tiến hành plot dữ liệu tập test lên xem kết quả như thế nào.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
model =load_model(&#39;sp500_stockperdict.h5&#39;)


y_hat = model.predict(x_test)

ft = 3 # 0 = open, 1 = highest, 2 =lowest , 3 = close

plt.plot( y_test[:,ft], color=&#39;blue&#39;, label=&#39;target&#39;)

plt.plot( y_hat[:,ft], color=&#39;red&#39;, label=&#39;prediction&#39;)

plt.title(&#39;future stock prices&#39;)
plt.xlabel(&#39;time [days]&#39;)
plt.ylabel(&#39;normalized price&#39;)
plt.legend(loc=&#39;best&#39;)

plt.show()

from sklearn.metrics import mean_squared_error

# 0 = open, 1 = highest, 2 =lowest , 3 = close
print(&amp;quot;open error: &amp;quot;)
print(mean_squared_error(y_test[:,0], y_hat[ :,0]))

print(&amp;quot;highest error: &amp;quot;)
print(mean_squared_error(y_test[:,1], y_hat[ :,1]))

print(&amp;quot;lowest error: &amp;quot;)
print(mean_squared_error(y_test[:,2], y_hat[ :,2]))

print(&amp;quot;close error: &amp;quot;)
print(mean_squared_error(y_test[:,3], y_hat[ :,3]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/sp500index_predict.png&#34; alt=&#34;hình chứng khoán&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;open error:
0.0009739211460315127
highest error:
0.0010539412808401607
lowest error:
0.0010066509540756113
close error:
0.0010840500965408758
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hiện đã có bản tensorflow 2 có tích hợp keras, mình update lại code&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt; 
 from re import T
import numpy as np 
# linear algebra 
import pandas as pd 
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from sklearn.preprocessing import MinMaxScaler 
import tensorflow as tf
import joblib

import matplotlib
matplotlib.use(&#39;TkAgg&#39;)
import matplotlib.pyplot as plt 


file_name =&#39;GSPC.csv&#39;


prices_dataset =  pd.read_csv(file_name, header=0)


# prices_dataset_dropout = prices_dataset.drop([&#39;Date&#39;,&#39;Adj Close&#39;,&#39;Volume&#39;], 1)
prices_dataset_dropout=prices_dataset.reset_index()[&#39;Close&#39;]


scaler=MinMaxScaler(feature_range=(0,1))
prices_dataset_norm=scaler.fit_transform(np.array(prices_dataset_dropout).reshape(-1,1))
joblib.dump(scaler, &#39;scaler.alex&#39;)


print(prices_dataset_norm[:10])


def generate_data(stock_ds, seq_len,predict_next_t):
    dataX, dataY = [], []
    for i in range(len(stock_ds)-seq_len-1):
        dataX.append(stock_ds[i:(i+seq_len)])
        dataY.append(stock_ds[i + seq_len+predict_next_t])
    return np.array(dataX), np.array(dataY)

#data as numpy array
def generate_train_test(data_x,data_y,split_percent=0.8):
    
    train_end = int(np.floor(split_percent*data_x.shape[0]))
    
    x_train,x_test=data_x[:train_end,:],data_x[train_end:,:]
    y_train,y_test = data_y[:train_end],data_y[train_end:]
    return x_train,y_train,x_test,y_test



seq_len = 100 # choose sequence length
predict_next_t = 1 # 0 is next date, 1 is 2 next date

data_x, data_y = generate_data(prices_dataset_norm,seq_len,predict_next_t)

x_train,y_train,x_test,y_test = generate_train_test(data_x,data_y, 0.8)


x_train =x_train.reshape(x_train.shape[0],x_train.shape[1] , 1)
x_test = x_test.reshape(x_test.shape[0],x_test.shape[1] , 1)
print(&#39;x_train.shape = &#39;,x_train.shape)
print(&#39;y_train.shape = &#39;, y_train.shape)
print(&#39;x_test.shape = &#39;, x_test.shape)
print(&#39;y_test.shape = &#39;,y_test.shape)



model = Sequential()

    # input_dim=4,
    # output_dim=50,
model.add(LSTM(units=100,input_shape=x_train.shape[1:],
    return_sequences=True))

model.add(LSTM(
    100,
    return_sequences=False))
model.add(Dense(1))


model.compile(loss=&#39;mean_squared_error&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;])
checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=&#39;my_model_stock.h5&#39;, verbose=1, save_best_only=True)
hist = model.fit(x_train, y_train, epochs=3, batch_size=64, verbose=1, callbacks=[checkpoint], validation_split=0.2)

from tensorflow.keras.models import load_model
print(&#39;load model&#39;)
model =load_model(&#39;my_model_stock.h5&#39;)

print(&#39;predict&#39;)
y_test = y_test.reshape(y_test.shape[0])
# train_predict=model.predict(x_train)
test_predict=model.predict(x_test)
print(&#39;invert&#39;)
print(y_test.shape)
# train_predict=scaler.inverse_transform(train_predict)

# scaler = joblib.load(&#39;scaler.alex&#39;)

y_hat=scaler.inverse_transform(test_predict)
y_test=scaler.inverse_transform(y_test.reshape(-1, 1))
print(y_hat.shape)
# y_hat = model.predict(x_test)
# import matplotlib
# matplotlib.use(&#39;GTKAgg&#39;) 
# print(&#39;plot&#39;)

plt.plot( y_test, color=&#39;blue&#39;, label=&#39;target&#39;)

plt.plot( y_hat, color=&#39;red&#39;, label=&#39;prediction&#39;)
print(&#39;plot complete&#39;)
plt.title(&#39;future stock prices&#39;)
plt.xlabel(&#39;time [days]&#39;)
plt.ylabel(&#39;normalized price&#39;)
plt.legend(loc=&#39;best&#39;)
print(&#39;plot show&#39;)
plt.savefig(&amp;quot;mygraph.png&amp;quot;)
plt.show()


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả của mô hình trông khá tốt, về hình dạng thì khá tương đồng với kết quả. Chúng ta có thể cải tiến model bằng cách nâng số lượng layer/ hidden node.&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dự đoán chứng khoán sử dụng tensorflow</title>
      <link>/blog/2018-11-03-stock-prediction/</link>
      <pubDate>Sat, 03 Nov 2018 00:19:00 +0300</pubDate>
      <author>alexblack2202@gmail.com (Phạm Duy Tùng)</author>
      <guid>/blog/2018-11-03-stock-prediction/</guid>
      <description>

&lt;h2 id=&#34;lời-mở-đầu&#34;&gt;Lời mở đầu&lt;/h2&gt;

&lt;p&gt;Ở bài viết này, mình sẽ xây dựng mô hình hơn giản để áp dụng vào tập dữ liệu giá chứng khoán. Mục tiêu của bài này là chúng ta sẽ dự đoán chỉ số S&amp;amp;P 500 dựa trên chỉ số của 500 mã chứng khoán. Các bạn có nhu cầu tìm hiểu thêm về chỉ số sp 500 có thể đọc thêm ở &lt;a href=&#34;https://vi.wikipedia.org/wiki/S%26P_500&#34;&gt;https://vi.wikipedia.org/wiki/S%26P_500&lt;/a&gt;. Đây là một ứng dụng nhỏ, không có ý nghĩa nhiều ở thực tế do khi phân tích chứng khoán, ta còn xét thêm rất nhiều yếu tố phụ nữa. Mô hình này thực chất chỉ là một trong những mô hình chơi chơi.&lt;/p&gt;

&lt;h2 id=&#34;dẫn-nhập&#34;&gt;Dẫn nhập&lt;/h2&gt;

&lt;h3 id=&#34;phân-tích-dữ-liệu&#34;&gt;Phân tích dữ liệu&lt;/h3&gt;

&lt;p&gt;Các bạn có thể download dữ liệu ở &lt;a href=&#34;https://drive.google.com/open?id=1UTlj5Ced-yj6RBRVc6bBM6IWMjfQR3GR&#34;&gt;https://drive.google.com/open?id=1UTlj5Ced-yj6RBRVc6bBM6IWMjfQR3GR&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Đầu tiên, chúng ta sẽ dùng pandas để load mô hình lên:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd

# Import data
data = pd.read_csv(&#39;data_stocks.csv&#39;)


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Xem kích thước của dữ liệu:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(data.shape)

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(41266, 502)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả là ta có hơn 40 ngàn dòng và 502 cột. Thử show 10 row đầu tiên của dữ liệu lên xem như thế nào.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(data.head())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;         DATE      SP500  NASDAQ.AAL  NASDAQ.AAPL  NASDAQ.ADBE  NASDAQ.ADI  \
0  1491226200  2363.6101     42.3300     143.6800     129.6300      82.040   
1  1491226260  2364.1001     42.3600     143.7000     130.3200      82.080   
2  1491226320  2362.6799     42.3100     143.6901     130.2250      82.030   
3  1491226380  2364.3101     42.3700     143.6400     130.0729      82.000   
4  1491226440  2364.8501     42.5378     143.6600     129.8800      82.035   

   NASDAQ.ADP  NASDAQ.ADSK  NASDAQ.AKAM  NASDAQ.ALXN    ...     NYSE.WYN  \
0    102.2300      85.2200       59.760       121.52    ...       84.370   
1    102.1400      85.6500       59.840       121.48    ...       84.370   
2    102.2125      85.5100       59.795       121.93    ...       84.585   
3    102.1400      85.4872       59.620       121.44    ...       84.460   
4    102.0600      85.7001       59.620       121.60    ...       84.470   

   NYSE.XEC  NYSE.XEL  NYSE.XL  NYSE.XOM  NYSE.XRX  NYSE.XYL  NYSE.YUM  \
0   119.035     44.40    39.88     82.03      7.36     50.22     63.86   
1   119.035     44.11    39.88     82.03      7.38     50.22     63.74   
2   119.260     44.09    39.98     82.02      7.36     50.12     63.75   
3   119.260     44.25    39.99     82.02      7.35     50.16     63.88   
4   119.610     44.11    39.96     82.03      7.36     50.20     63.91   

   NYSE.ZBH  NYSE.ZTS  
0   122.000    53.350  
1   121.770    53.350  
2   121.700    53.365  
3   121.700    53.380  
4   121.695    53.240  

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cột đầu tiên là ngày, sau đó là mã chứng khoán. Chúng ta có tổng cộng 500 mã chứng khoán và 1 chỉ số. Để ý cột Date, ta thấy giá trị đầu tiên là 1491226200, giá trị thứ 2 là 1491226260, giá trị thứ 3 là 1491226320, mỗi giá trị cách nhau 60. Chuyển đổi số 1491226200 sang dạng datetime thì ra giá trị  Monday, April 3, 2017 1:30:00 PM giờ GMT, tương tự số 1491226260 ra Monday, April 3, 2017 1:31:00 PM giờ GMT. Ta có thể suy luận ra là giá trị giao dịch lưu theo từng phút một (khoảng interval là 60 giây), và dữ liệu chúng ta có bắt đầu vào 3 tháng 4 năm 2017.&lt;/p&gt;

&lt;p&gt;Plot đồ thị của mã SP500 lên:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import matplotlib.pyplot as plt

plt.plot(data[&#39;SP500&#39;])
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/sp500index.png&#34; alt=&#34;Hình ảnh đừng đồ thị của chỉ số sp 500&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; Notes: Ở đây có một lưu ý nhỏ nhưng rất quan trọng. Đó là tại thời điểm phút thứ t lưu trữ giá trị sp500 của thời điểm phút thứ t+1. Ví dụ với chỉ số sp500, dòng đầu tiên ta thấy là 1491226200  2363.6101, nghĩa là giá thực tế của thời điểm 1491226260 là 2363.6101. Do bài toán của chúng ta là dữ đoán giá tương lại, nên tại thời điểm hiện tại ta sẽ dự đoán giá 1 phút sau sẽ bằng bao nhiêu. Và tập dữ liệu đã tự động dịch chuyển giá trị lên 1 phút cho chúng ta đỡ mất công làm. Còn giá của 500 cỗ phiếu còn lại vẫn là giá tại thời điểm t
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;phân-chia-tập-train-và-test&#34;&gt;Phân chia tập train và test.&lt;/h3&gt;

&lt;p&gt;Chúng ta sẽ chia dữ liệu thành 2 phần với 80% là train và 20% còn lại là test. Do tích chất của dữ liệu là time serial nên chúng ta không thể làm thay đổi thứ tự dữ liệu.&lt;/p&gt;

&lt;p&gt;Chúng ta sẽ bỏ đi cột DATE đầu tiên, và sau đó chuyển dữ liệu về dạng numpy array để dễ dàng thực hiện các phép chuyển đổi.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt; data_ = data_raw.drop([&#39;DATE&#39;], 1)

data = data_.values
# Training and test data
train_start = 0
train_end = int(np.floor(0.8*n))
test_start = train_end
test_end = n
data_train = data[ :train_end]
data_test = data[train_end:]
 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;scale-dữ-liệu&#34;&gt;Scale dữ liệu&lt;/h3&gt;

&lt;p&gt;Khi sử dụng ANN, chúng ta thông thường sẽ scale dữ liệu input về đoạn [-1,1]. Trong python, thư viện sklearn đã hỗ trợ cho chúng ta sẵn các hàm scale dữ liệu cần thiết.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Scale data
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
data_train = scaler.fit_transform(data_train)
data_test = scaler.transform(data_test)
# Build X and y
X_train = data_train[:, 1:]
y_train = data_train[:, 0]
X_test = data_test[:, 1:]
y_test = data_test[:, 0]

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Mình cần dự đoán giá trị của chỉ số sp 500, nên giá trị của sp500 sẽ là cái mình cần dự đoán, chính là cột đầu tiên, còn 500 cái còn lại là input của mình.&lt;/p&gt;

&lt;h3 id=&#34;xây-dựng-mô-hình-sử-dụng-keras&#34;&gt;Xây dựng mô hình sử dụng keras&lt;/h3&gt;

&lt;p&gt;Ở đây mình sử dụng keras xây dựng mô hình ANN. Mô hình của mình xây dựng gồm&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt; from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.callbacks import ModelCheckpoint
from keras.optimizers import SGD

import os
os.environ[&amp;quot;CUDA_DEVICE_ORDER&amp;quot;]=&amp;quot;PCI_BUS_ID&amp;quot;
# The GPU id to use, usually either &amp;quot;0&amp;quot; or &amp;quot;1&amp;quot;
os.environ[&amp;quot;CUDA_VISIBLE_DEVICES&amp;quot;]=&amp;quot;0&amp;quot; 
# create model
model = Sequential()
model.add(Dense(2048, input_dim=input_dim,kernel_initializer=&#39;normal&#39;, activation=&#39;relu&#39;))
model.add(Dense(1024,kernel_initializer=&#39;normal&#39;, activation=&#39;relu&#39;))
model.add(Dense(512,kernel_initializer=&#39;normal&#39;, activation=&#39;relu&#39;))
model.add(Dense(256,kernel_initializer=&#39;normal&#39;, activation=&#39;relu&#39;))
model.add(Dense(128,kernel_initializer=&#39;normal&#39;, activation=&#39;relu&#39;))
model.add(Dense(1,kernel_initializer=&#39;normal&#39;))



model.compile(loss=&#39;mse&#39;, optimizer=&#39;rmsprop&#39;)
checkpoint = ModelCheckpoint(filepath=&#39;my_model3.h5&#39;, verbose=1, save_best_only=True)
model.fit(X_train, y_train, epochs=100, batch_size=256, verbose=1, callbacks=[checkpoint], validation_split=0.2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sau một thời gian chạy, mình cũng thu được model. Các bạn quan tâm có thể download model của mình huấn luyện được tại &lt;a href=&#34;https://drive.google.com/open?id=1BLQZbcADfnLqzIHlkgpsqZBlhljBp1Eb&#34;&gt;https://drive.google.com/open?id=1BLQZbcADfnLqzIHlkgpsqZBlhljBp1Eb&lt;/a&gt; . Tiến hành plot dữ liệu tập test lên xem kết quả như thế nào.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt; 
yhat = model.predict(X_test)


x = np.arange(len(yhat))

plt.plot(x, y_test)
plt.plot(x, yhat)
plt.legend([&#39;real&#39;, &#39;test&#39;], loc=&#39;upper right&#39;)
plt.show()


from sklearn.metrics import mean_squared_error

print(&amp;quot;mse: &amp;quot;+ str(mean_squared_error(y_test, yhat)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post_image/chung_khoan_1.png&#34; alt=&#34;hình chứng khoán&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt; mse: 0.0014582120695331884
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kết quả của mô hình tạm chấp nhận được, về hình dạng thì khá tương đồng với kết quả. Chúng ta có thể cải tiến model bằng cách nâng số lượng layter/ hidden node, hoặc thêm dropout. Hoặc có thể thay thế mô hình bằng RNN. Chúng ta sẽ đề cập đến mô hình RNN trong bài viết sau.&lt;/p&gt;

&lt;p&gt;Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>