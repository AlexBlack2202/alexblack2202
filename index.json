[{"categories":"python","content":"Nội dung bài viết này sẽ đề cập đến các chủ đề\n Hàm trong python   Tham số mặc định Arbitrary Arguments Keyword Arguments Arbitrary Keyword Arguments   Hàm Lambda trong python  Hàm map  Hàm filter  Hàm reduce     Hàm trong python  Hàm là một khối lệnh, được thực thi khi được gọi.\nHàm được định nghĩa bằng từ khoá def.\nHàm có thể nhận dữ liệu truyền vào, được gọi là tham số\nHàm có thể trả về dữ liệu\nVí dụ\n12def isSoChan(x:int): # khai báo hàm có tên là isSoChan, với tham số truyền vào kiểu int 3if x \u0026lt;0: 4return False 5if x % 2 != 0: 6return False 7return True 89isSoChan(5) # gọi thực thi hàm isSoChan, với giá trị của tham số x là 5 Tham số mặc định Một số hàm sẽ có tham số mặc định, sử dụng khi ta bỏ trống, không truyền giá trị cho tham số, ví dụ như là tham số start của hàm range có giá trị mặc định là 0.\n12def printCountry(contry_name = \u0026#34;Việt Nam\u0026#34;): 3print(contry_name) 456printCountry(\u0026#34;USA\u0026#34;) 7printCountry() 89#Kết quả 1011\u0026gt;\u0026gt;\u0026gt; printCountry(\u0026#34;USA\u0026#34;) 12USA 13\u0026gt;\u0026gt;\u0026gt; printCountry() 14Việt Nam Arbitrary Arguments Đôi khi, chúng ta không thể xác định được số lượng tham số truyền vào, python hỗ trợ ta quăng các giá trị truyền dư vào một tham số cấp 1. Tên viết tắt của dạng này là *args\nVí dụ\n1def info(name, *args): 2print(f\u0026#34;input name: {name}\u0026#34;) 3for item in args: 4print(f\u0026#34;other info: {item}\u0026#34;) 56info(\u0026#34;alex\u0026#34;,\u0026#34;18\u0026#34;,\u0026#34;staff\u0026#34;,\u0026#34;samsung\u0026#34;,\u0026#34;apple\u0026#34;) 78#Kết quả: 910input name: alex 11other info: 18 12other info: staff 13other info: samsung 14other info: apple Keyword Arguments Để gọi hàm một cách tường minh, python cho phép truyền tham số bằng cách chỉ rõ tên tham số cần truyền dữ liệu\nVí dụ\n1def info(name, age, position): 2print(f\u0026#34;name {name}age {age}position {position}\u0026#34;) 34info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 567info(name=\u0026#34;bill\u0026#34;, position=\u0026#34;staff\u0026#34; , age=18) 89# Kết quả: 1011\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 12name alex age 18 position staff 13\u0026gt;\u0026gt;\u0026gt; 14\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;bill\u0026#34;, position=\u0026#34;staff\u0026#34; , age=18) 15name bill age 18 position staff Arbitrary Keyword Arguments Trong trường hợp có nhiều tham số quá, chúng ta có thể viết tổng hợp các tham số dưới dạng tham số cấp 2. Tên viết tắt của dạng này là **kwargs\nVí dụ\n12def info(**data): 3print(f\u0026#34;name {data[\u0026#39;name\u0026#39;]}age {data[\u0026#39;age\u0026#39;]}position {data[\u0026#39;position\u0026#39;]}\u0026#34;) 45info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 678info(name=\u0026#34;bill\u0026#34;, position=\u0026#34;staff\u0026#34; , age=18) 91011# Kết quả 1213\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 14name alex age 18 position staff 15\u0026gt;\u0026gt;\u0026gt; 16\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;bill\u0026#34;, position=\u0026#34;staff\u0026#34; , age=18) 17name bill age 18 position staff Hàm Lambda trong python  Hàm Lambda là hàm chỉ có một biểu thức\nHàm Lambda có thể nhận nhiều tham số\nCú pháp\n12lambda arguments : expression Ví dụ:\n12info = lambda name, age, position : f\u0026#34;name {name}age {age}position {position}\u0026#34; 34info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 56# Kết quả 7\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 8\u0026#39;name alex age 18 position staff\u0026#39; Sức mạnh của lambda được khai thác tối đa, khi lamda là tham số của một hàm khác.\nHàm map  Cú pháp\n12map(function, iterable) Do input của map là function, nên nó có thể là một hàm tường minh, hoặc là một lambda function\nVí dụ:\nHãy nhân đôi tất cả các giá trị trong list\n12aList = [1,2,3,4,5] 34# Cách viết thông thường 56def square(x:int): 7return x**2 89newList = [] 10for x in aList: 11newList.append(square(x)) 1213print(newList) 1415# Cách viết sử dụng list comprehension 1617newList = [x**2 for x in newList] 18print(newList) 1920# Cách viết sử dụng map kết hợp lambda 2122newList = list(map(lambda x:x**2,aList)) 2324print(newList) 2526\u0026gt;\u0026gt;\u0026gt; print(newList) 27[1, 4, 9, 16, 25] Hàm filter  Cú pháp\n12filter(function, iterable) Hàm này tựa tựa như list comprehension với if contion\nVí dụ:\nHãy lọc ra các phần tử là số chẵn\n12aList = [1,2,3,4,5] 34# Cách viết thông thường 56def isEven(x:int): 7return x%2==0 89newList = [] 10for x in aList: 11newList.append(isEven(x)) 1213print(newList) 1415# Cách viết sử dụng list comprehension 1617newList = [x for x in newList if x %2 ==0] 18print(newList) 1920# Cách viết sử dụng filter kết hợp lambda 2122newList = list(filter(lambda x:x%2==0,aList)) 2324print(newList) 2526\u0026gt;\u0026gt;\u0026gt; print(newList) 27[2, 4] Hàm reduce  Hàm có nhiệm vụ tích luỹ tất cả các phần tử và trả về một giá trị duy nhất\nCú pháp\n12reduce(function, iterable, [, initializer]) Ví dụ:\nTính tổng các phần tử trong list sử dụng reduce\n12from functools import reduce 34aList = [1,2,3,4,5] 56print(reduce(lambda x,y: x+y,aList)) 78Kết quả: 9\u0026gt;\u0026gt;\u0026gt; print(reduce(lambda x,y: x+y,aList)) 1015 Đếm số lần xuất hiện của số chẵn trong list\n12from functools import reduce 34aList = [1,2,3,5,9] 56print(reduce(lambda acc,x: acc+1 if x%2 == 0 else acc,aList,0)) 78Kết quả: 9\u0026gt;\u0026gt;\u0026gt; print(reduce(lambda x,y: x+y,aList,0)) 1015  --","date":"Jul 16, 2022","img":"","permalink":"/courses/python/5_python_function/","series":["Khóa học python căn bản"],"tags":["python"],"title":"Bài 4: Hàm Trong Python"},{"categories":"python","content":"Trong bài viết này, chúng ta sẽ đề cập tới các câu lệnh điều khiển trong python. Các câu lệnh điều khiển bao gồm if, if-else, for, while\n Câu lệnh điều khiển if  Câu lệnh điều khiển for   Hàm range Kết hợp câu lệnh for với if từ khoá break, từ khoá continue, từ khoá pass   Vòng lặp while  Kỹ thuật duyệt container trong python   Duyệt container sử dụng hàm enumerate Duyệt container sử dụng hàm zip Duyệt dic sử dụng hàm items Duyệt container sử dụng hàm sorted Duyệt container sử dụng hàm reversed   List Comprehension     Câu lệnh điều khiển if  Câu lệnh if là câu lệnh căn bản và quan trong nhất. Câu lệnh được sử dụng để quyết định xem một khối lệnh có được thực hiện hay không. Về cơ bản, chúng ta có thể phân loại thành 3 nhóm câu lệnh if như sau.\nNhóm if loại 1. Câu lệnh if bình thường\n12if \u0026lt;điều kiện\u0026gt;: 3# trường hợp \u0026lt;điều kiện\u0026gt; là đúng 4câu lệnh 1 5... 6câu lệnh n 7câu lệnh n+1 Nhóm if loại 2. Câu lệnh if có else\n12if \u0026lt;điều kiện\u0026gt;: 3# trường hợp \u0026lt;điều kiện\u0026gt; là đúng 4câu lệnh 1 5... 6câu lệnh n 7else: 8# trường hợp \u0026lt;điều kiện\u0026gt; là sai 9câu lệnh 1 10... 11câu lệnh n 1213câu lệnh n+1 Nhóm if loại 3. Câu lệnh if else lồng nhau\n12if \u0026lt;điều kiện 1\u0026gt;: 3# trường hợp \u0026lt;điều kiện\u0026gt; là đúng 4câu lệnh 1 5... 6câu lệnh n 7elif \u0026lt;điều kiện 2\u0026gt;: 8# trường hợp \u0026lt;điều kiện 1\u0026gt; là sai, \u0026lt;điều kiện 2\u0026gt; là đúng 9câu lệnh 1 10... 11câu lệnh n 12... 13elif \u0026lt;điều kiện n\u0026gt;: 1415# trường hợp \u0026lt;điều kiện 1\u0026gt; là sai, \u0026lt;điều kiện 2\u0026gt; là sai, ... \u0026lt;điều kiện n-1\u0026gt; là sai, \u0026lt;điều kiện n\u0026gt; là đúng 16câu lệnh 1 17... 18câu lệnh n 19else: 20# trường hợp \u0026lt;điều kiện 1\u0026gt; là sai, ..., \u0026lt;điều kiện 2\u0026gt; là sai 21câu lệnh 1 22... 23câu lệnh n 242526câu lệnh n+1 Ví dụ:\nMẹ bé Thu trước khi đi làm nói với bé Thu rằng: \u0026ldquo;Nếu trời sắp mưa, con hãy rút quần áo ở dây phơi đồ, hốt lúa cất vào bồ, bế em vào nhà, gài then đóng cửa thật chặt, gài then đóng cửa thật chặt. Con ngoan ở nhà, chiều mẹ về mua kẹo cho con ăn\u0026rdquo;. Chúng ta sẽ biến đổi lời căn dặn của mẹ bé Thu thành câu lệnh if như sau:\n12thoi_tiet = \u0026#39;sap_mua\u0026#39; 3is_be_thu_ngoan = True 4if thoi_tiet == \u0026#39;sap_mua\u0026#39;: 5print(\u0026#39;rút quần áo ở dây phơi đồ\u0026#39;) 6print(\u0026#39;hốt lúa cất vào bồ\u0026#39;) 7print(\u0026#39;bế em vào nhà\u0026#39;) 8print(\u0026#39;gài then đóng cửa thật chặt\u0026#39;) 9print(\u0026#39;rút quần áo ở dây phơi đồ\u0026#39;) 1011if is_be_thu_ngoan: 12print(\u0026#39;Mẹ bé Thu mua kẹo\u0026#39;) 13print(\u0026#39;Mẹ bé Thu cho bé Thu ăn kẹo\u0026#39;) 1415Kết quả 1617rút quần áo ở dây phơi đồ 18hốt lúa cất vào bồ 19bế em vào nhà 20gài then đóng cửa thật chặt 21rút quần áo ở dây phơi đồ 222324Mẹ bé Thu mua kẹo 25Mẹ bé Thu cho bé Thu ăn kẹo Chúng ta có câu tục ngữ: Chuồn chuồn bay thấp thì mưa, bay cao thì nắng, bay vừa thì râm.\nCâu lệnh if else của câu tục ngữ trên là:\n12vi_tri_chuon_chuon = \u0026#39;bay_vua\u0026#39; 34if vi_tri_chuon_chuon == \u0026#39;bay_thap\u0026#39;: 5print(\u0026#39;trời sắp mưa\u0026#39;) 6elif vi_tri_chuon_chuon == \u0026#39;bay_cao\u0026#39;: 7print(\u0026#39;trời nắng\u0026#39;) 8elif vi_tri_chuon_chuon == \u0026#39;bay_vua\u0026#39;: 9print(\u0026#39;trời râm\u0026#39;) 10else: 11print(\u0026#39;không xác định\u0026#39;) 1213# Kết quả 1415trời râm Câu lệnh điều khiển for  Câu lệnh for được sử dụng để duyệt các phần tử trong các container như String, Tuple, List, Set hoặc Dictionary, Array.\nfor trong python tương đương với foreach trong các ngôn ngữ thuộc họ c. Python không có câu lệnh for giống for trong c/c++, c#, java \u0026hellip;\nCú pháp câu lệnh for\n12for item in container: 3#statement Ví dụ\n12brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 34for item in brands: 5print(item) 67#Kết quả 89iphone 10samsung 11xiaomi 12nokia Hàm range cú pháp\n12range(start,stop,steep) Hàm range được sử dụng để trả về một chuỗi các số từ start (mặc định là 0) đến stop, với bước nhảy là steep (mặc định là 1)\nVí dụ:\nTạo một chuỗi các số từ 5 đến 9, in ra các số trên\n12itemRange = range(5,10) 34for item in itemRange: 5print(item) 67# Kết quả 895 106 117 128 139 Hàm range thường được sử dụng với hàm len, để duyệt index của list\n12brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;] 34for x in range(len(brands)): 5print(f\u0026#34;element at {x}in list is {brands[x]}\u0026#34;) 67# Kết quả 89element at 0 in list is iphone 10element at 1 in list is samsung 11element at 2 in list is xiaomi Ngoài ra, còn tuỳ vào bài toán, chúng ta sử dụng hàm range một cách thông minh để code được trong sáng và sạch đẹp hơn.\nKết hợp câu lệnh for với if Hoàng đế Julius Caesar là một nhà quân sự tài ba. Trong lúc ông lãnh đạo quân đội La Mã, để tránh bị rò rỉ nội dung thư tín khi truyền tải cho các tướng sĩ, ông đã thiết lập một bộ mật mã là dịch từng chữ trong thông tin qua 3 chữ cái trong bảng mã ascii. Nghĩa là, thay vì viết chữ a, ông lại viết thành chữ d, thay vì viết chữ b, ông lại viết chữ e, \u0026hellip;., cho đến thay z thành c. Khi tướng sĩ của ông nhận được thư tín, chỉ cần dịch ngược lại với quy luật trên là có được nội dung bức thư.\nVí dụ nội dung bức thư ông gửi.\ngdqk Jdoold qjdb pxrl ed\nKhi tướng sĩ nhận được đoạn lệnh trên, họ tiến hành dịch ngược lại. g tương ứng với chữ d (d+3 =g) \u0026hellip;, và giải mã bức mật thư của hoàng đế gửi là:\ndanh Gallia ngay muoi ba\nChúng ta viết chương trình nhỏ với for và if để mã hoá nội dung thông tin giúp Julius Caesar nhé.\n12input = \u0026#39;danh Gallia ngay muoi ba\u0026#39; 34for c in input: 5if c == \u0026#39;a\u0026#39;: 6print(\u0026#39;d\u0026#39;,end=\u0026#39;\u0026#39;) 7elif c == \u0026#39;b\u0026#39;: 8print(\u0026#39;e\u0026#39;,end=\u0026#39;\u0026#39;) 9elif c == \u0026#39;c\u0026#39;: 10print(\u0026#39;f\u0026#39;,end=\u0026#39;\u0026#39;) 11elif c == \u0026#39;d\u0026#39;: 12print(\u0026#39;g\u0026#39;,end=\u0026#39;\u0026#39;) 13elif c == \u0026#39;e\u0026#39;: 14print(\u0026#39;h\u0026#39;,end=\u0026#39;\u0026#39;) 15elif c == \u0026#39;f\u0026#39;: 16print(\u0026#39;i\u0026#39;,end=\u0026#39;\u0026#39;) 17elif c == \u0026#39;g\u0026#39;: 18print(\u0026#39;j\u0026#39;,end=\u0026#39;\u0026#39;) 19elif c == \u0026#39;h\u0026#39;: 20print(\u0026#39;k\u0026#39;,end=\u0026#39;\u0026#39;) 21elif c == \u0026#39;i\u0026#39;: 22print(\u0026#39;l\u0026#39;,end=\u0026#39;\u0026#39;) 23elif c == \u0026#39;j\u0026#39;: 24print(\u0026#39;m\u0026#39;,end=\u0026#39;\u0026#39;) 25elif c == \u0026#39;k\u0026#39;: 26print(\u0026#39;n\u0026#39;,end=\u0026#39;\u0026#39;) 27elif c == \u0026#39;l\u0026#39;: 28print(\u0026#39;o\u0026#39;,end=\u0026#39;\u0026#39;) 29elif c == \u0026#39;m\u0026#39;: 30print(\u0026#39;p\u0026#39;,end=\u0026#39;\u0026#39;) 31elif c == \u0026#39;n\u0026#39;: 32print(\u0026#39;q\u0026#39;,end=\u0026#39;\u0026#39;) 33elif c == \u0026#39;o\u0026#39;: 34print(\u0026#39;r\u0026#39;,end=\u0026#39;\u0026#39;) 35elif c == \u0026#39;p\u0026#39;: 36print(\u0026#39;s\u0026#39;,end=\u0026#39;\u0026#39;) 37elif c == \u0026#39;q\u0026#39;: 38print(\u0026#39;t\u0026#39;,end=\u0026#39;\u0026#39;) 39elif c == \u0026#39;r\u0026#39;: 40print(\u0026#39;u\u0026#39;,end=\u0026#39;\u0026#39;) 41elif c == \u0026#39;s\u0026#39;: 42print(\u0026#39;v\u0026#39;,end=\u0026#39;\u0026#39;) 43elif c == \u0026#39;t\u0026#39;: 44print(\u0026#39;w\u0026#39;,end=\u0026#39;\u0026#39;) 45elif c == \u0026#39;u\u0026#39;: 46print(\u0026#39;x\u0026#39;,end=\u0026#39;\u0026#39;) 47elif c == \u0026#39;v\u0026#39;: 48print(\u0026#39;y\u0026#39;,end=\u0026#39;\u0026#39;) 49elif c == \u0026#39;w\u0026#39;: 50print(\u0026#39;z\u0026#39;,end=\u0026#39;\u0026#39;) 51elif c == \u0026#39;x\u0026#39;: 52print(\u0026#39;a\u0026#39;,end=\u0026#39;\u0026#39;) 53elif c == \u0026#39;y\u0026#39;: 54print(\u0026#39;b\u0026#39;,end=\u0026#39;\u0026#39;) 55elif c == \u0026#39;z\u0026#39;: 56print(\u0026#39;c\u0026#39;,end=\u0026#39;\u0026#39;) 57else: 58print(c,end=\u0026#39;\u0026#39;) 59print() 6061# Kết quả 6263gdqk Gdoold qjdb pxrl ed Cách viết trên khá cơ bắp, tay to, dài dòng, chúng ta hãy viết đoạn code trên ngắn gọn hơn bằng cách.\n  Tạo ra 2 chuỗi, một chuỗi chứa các ký tự alphabet, một chuỗi chứa bảng mã hoá.\n  Tìm vị trí của từ cần mã hoá trong chuỗi alphabet\n  In ra từ cần lấy trong bảng mã hoá\n  12input = \u0026#39;danh Gallia ngay muoi ba\u0026#39; 34alphabet = \u0026#39;abcdefghijklmnopqrstuvwxyz\u0026#39; 5caesar_cipher = \u0026#39;defghijklmnopqrstuvwxyzabc\u0026#39; 67for c in input: 8index = alphabet.find(c) 9if index \u0026gt;-1: 10print(caesar_cipher[index],end=\u0026#39;\u0026#39;) 11else: 12print(c,end=\u0026#39;\u0026#39;) 1314print(\u0026#39;\u0026#39;) từ khoá break, từ khoá continue, từ khoá pass Để thoát khỏi vòng lặp for, chúng ta sử dụng từ khoá break\nĐể bỏ qua khối lệnh bên dưới, tiếp tục lệnh for, chúng ta sử dụng từ khoá continue.\nĐể giữ chỗ cho tính năng tương lai sẽ phát triển, chúng ta sử dụng từ khoá pass để đánh dấu, và cũng để cho chương trình có thể hoạt động được.\nVí dụ về break\nTìm là in ra 5 số lẻ nguyên dương đầu tiên bé hơn 100\n12count = 0 34for x in range(100): 5if x % 2 != 0: 6print(x) 7count = count + 1 8if count \u0026gt;=5: 9break 1011# Kết quả 12131 143 155 167 179 Ví dụ về continue\nIn ra các số lẻ bé hơn 10\n12for x in range(10): 3if x % 2 == 0: 4continue 5print(x) 67# Kết quả 891 103 115 127 139 Ví dụ về pass\nViết một vòng lặp for lặp 10 lần, để giành đó mai mốt code tiếp\n12for x in range(10): 3pass 45# Kết quả Vòng lặp while  Ý nghĩa: Trong khi điều kiện còn đúng, thì thực hiện câu lệnh.\nKết thúc vòng lặp khi điều kiện sai\nCú pháp\n12while \u0026lt;condition\u0026gt;: 3# statement Ví dụ:\nIn ra các số nguyên bé hơn 10\n123i = 1 4while i \u0026lt; 10: 5print(i) 6i += 1 vòng lặp while có thể sử dụng các từ khoá pass, continue, break giống như for\nKỹ thuật duyệt container trong python  Python hỗ trợ nhiều hàm dựng sẵn, giúp chúng ta có thể duyệt các container một cách dễ dàng.\nViệc sử dụng các hàm duyệt bên dưới, giúp cho coder:\n  Sử dụng nhanh chóng, giảm thời gian coding.\n  Tên hàm chính là từ khoá, mô tả chính xác mục đích sử dụng hàm. Giúp giảm thời gian đọc code, khi so với việc sử dụng for/while.\n  Code ngắng gọn hơn, rõ ràng hơn, so với for \u0026amp; while.\n  Duyệt container sử dụng hàm enumerate Hàm enumerate hỗ trợ trả về index và value của container\nVí dụ:\n123brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 45for index,item in enumerate(brands): 6print(f\u0026#34;element at index {index}in list is {item}\u0026#34;) 789# Kết quả 1011element at index 0 in list is iphone 12element at index 1 in list is samsung 13element at index 2 in list is xiaomi 14element at index 3 in list is nokia Duyệt container sử dụng hàm zip Hàm dựng sẵn zip hỗ trợ chúng ta kết hợp 2 container cùng loại (list với list, dict với dict, string với string) với nhau\nVí dụ:\n12alphabet = \u0026#39;abcdefghijklmnopqrstuvwxyz\u0026#39; 3caesar_cipher = \u0026#39;defghijklmnopqrstuvwxyzabc\u0026#39; 456for decode, encode in zip(alphabet,caesar_cipher): 7print(f\u0026#34;Caesar send {encode}, we have {decode}\u0026#34;) 89# Kết quả 1011Caesar send d, we have a 12Caesar send e, we have b 13Caesar send f, we have c 14Caesar send g, we have d 15Caesar send h, we have e 16Caesar send i, we have f 17Caesar send j, we have g 18Caesar send k, we have h 19Caesar send l, we have i 20Caesar send m, we have j 21Caesar send n, we have k 22Caesar send o, we have l 23Caesar send p, we have m 24Caesar send q, we have n 25Caesar send r, we have o 26Caesar send s, we have p 27Caesar send t, we have q 28Caesar send u, we have r 29Caesar send v, we have s 30Caesar send w, we have t 31Caesar send x, we have u 32Caesar send y, we have v 33Caesar send z, we have w 34Caesar send a, we have x 35Caesar send b, we have y 36Caesar send c, we have z Duyệt dic sử dụng hàm items Ví dụ:\n12profile = {\u0026#39;name\u0026#39;:\u0026#39;alex\u0026#39;,\u0026#39;age\u0026#39;:18,\u0026#39;location\u0026#39;:\u0026#39;vietnam\u0026#39;} 34for key, value in profile.items(): 5print(key,value) 67# Kết quả 89name alex 10age 18 11location vietnam Duyệt container sử dụng hàm sorted Hàm sorted sẽ xắp xếp lại phần tử trong container theo thứ tự (với số thì từ nhỏ đến lớn, với chữ thì theo thứ tự từ điển), và trả về từng phần tử trong container đã được sort.\nVí dụ:\n123brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 45for item in sorted(brands): 6print(item) 78# Kết quả 910iphone 11nokia 12samsung 13xiaomi Duyệt container sử dụng hàm reversed Hàm reversed sẽ duyệt ngược phần tử trong container. Hàm này không làm ảnh hưởng thứ tự của các phần tử trong container\nVí dụ:\n123brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 45for item in reversed(brands): 6print(item) 78# Kết quả 910iphone 11nokia 12samsung 13xiaomi List Comprehension  List comprehension cung cấp cho chúng ta một cú pháp ngắn gọn, súc tích, giúp chúng ta tạo một list, là tập con từ một list lớn.\nCú pháp chung của list comprehension là:\n12newlist = [expression for item in iterable if condition == True] Với condition là điều kiện lọc để giảm số lượng phần tử trả về.\nexpression: có thể là một biểu thức if\nVí dụ:\n12brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 3filter_brands = [] 45for item in brands: 6if \u0026#39;i\u0026#39; in item: 7filter_brands.append(item) 89print(filter_brands) 1011# Kết quả 12\u0026gt;\u0026gt;\u0026gt; print(filter_brands) 13[\u0026#39;iphone\u0026#39;, \u0026#39;xiaomi\u0026#39;, \u0026#39;nokia\u0026#39;] Đoạn mã trên thực hiện việc in ra các hãng có chứa ký tự i trong tên. Chúng ta tốn 3 dòng code (1 vòng for, 1 vòng if, 1 vòng append). Giờ chúng ta sẽ viết lại bằng list comprehension\n123brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 45filter_brands = [item for item in brands if \u0026#39;i\u0026#39; in item] 67print(filter_brands) 89#Kết quả 1011\u0026gt;\u0026gt;\u0026gt; print(filter_brands) 12[\u0026#39;iphone\u0026#39;, \u0026#39;xiaomi\u0026#39;, \u0026#39;nokia\u0026#39;] Ví dụ 2\nViết hoa toàn bộ tên hãng\n12# Mẫu vòng lặp for 34brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 56old_upper_brands = [] 7for brand in brands: 8old_upper_brands.append(brand.upper()) 910# Mẫu list comprehension 1112new_upper_brands = [brand.upper() for brand in brands] Ví dụ 3:\nCho một list có 10 phần tử, lấy ra các phần tử \u0026gt; 5, thay các phần tử lớn hơn 10 bằng 0\n12# Mẫu cũ 3items = [100,5,8,2,9,7,1,20,89,99] 4old_items = [] 5for item in items: 6if item \u0026gt; 5: # chỉ xét những phần tử \u0026gt;5 7if item\u0026gt;10: # thay những phần tử \u0026gt; 10 thành 0 8old_items.append(0) 9else: 10old_items.append(item) 1112print(old_items) 1314new_items = [item if item \u0026lt;=10 else 0 for item in items if item\u0026gt;5] 1516print(new_items) 1718# Kết quả 1920\u0026gt;\u0026gt;\u0026gt; print(old_items) 21[0, 8, 9, 7, 0, 0, 0] 2223\u0026gt;\u0026gt;\u0026gt; print(new_items) 24[0, 8, 9, 7, 0, 0, 0] Cảm ơn các bạn đã theo dõi bài viết.\n","date":"Jul 16, 2022","img":"","permalink":"/courses/python/4_python_conditional_loop/","series":["Khóa học python căn bản"],"tags":["python"],"title":"Bài 3: Câu Lệnh Điều Khiển Trong Python"},{"categories":"python","content":"Trong bài viết này, chúng ta sẽ tìm hiểu các kiểu dữ liệu dạng container trong python\n Kiểu dữ liệu string   Một vài phương thức cơ bản của string  Phương thức isdecimal, isdigit, isnumeric Phương thức isascii, isalpha, isalnum, isspace, isupper Phương thức lstrip, rstrip, strip Phương thức find, index Phương thức format f string     Kiểu dữ liệu tuple   Packing và Unpacking So sánh các biến có kiểu dữ liệu tuple Slicing trong Tuple Các hàm dựng sẵn của Tuple   Kiểu dữ liệu từ điển - dictionary   Thuộc tính của keys trong từ điển. Một vài phương thức của dictionary  copy update del item len Merge   Tổng kết:   Kiểu dữ liệu list   Truy xuất dữ liệu trong list slicing Các phương thức được hỗ trợ  append pop remove reverse   Các hàm được hỗ trợ  len max min     Kiểu dữ liệu set   Một vài phương thức cơ bản của Set  Phương thức Add Phương thức Remove, Discard Phương thức Pop Phương thức Clear     Kiểu dữ liệu array   Một vài phương thức cơ bản của array  Phương thức insert, phương thức append Phương thức truy xuất phần tử theo index Phương thức remove, phương thức pop Phương thức index        Kiểu dữ liệu string  string là tập hợp các bytes được biểu diễn dưới dạng ký tự unicode\nVí dụ\n12hello = \u0026#34;hi, i am alex\u0026#34; 34print(hello) 56greating = \u0026#34;i am from việt Nam\u0026#34; 78print(greating) 91011#Kết quả 1213\u0026gt;\u0026gt;\u0026gt; print(hello) 14hi, i am alex 1516\u0026gt;\u0026gt;\u0026gt; print(greating) 17i am from việt Nam Một vài phương thức cơ bản của string Phương thức isdecimal, isdigit, isnumeric   isdecimal: Trả về true nếu toàn bộ các ký tự là decimal (0-9)\n  isdigit: Trả về true nếu toàn bộ ký tự là digit. Bao gồm các số (0-9), số mũ trên (ví dụ: x2), số mũ dưới (ví dụ: x2).\n  isnumeric: Trả về true nếu toàn bộ ký tự là numeric. Bao gồm các số (0-9), số mũ trên (ví dụ: x2), số mũ dưới (ví dụ: x2) , phân số ( ví dụ: 1⁄2)\n  Ví dụ:\n12# số 18 là: 3print(\u0026#39;18\u0026#39;.isdecimal()) 4print(\u0026#39;18\u0026#39;.isdigit()) 5print(\u0026#39;18\u0026#39;.isnumeric()) 67# Kết quả 89\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;18\u0026#39;.isdecimal()) 10True 11\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;18\u0026#39;.isdigit()) 12True 13\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;18\u0026#39;.isnumeric()) 14True 12# số 2 mũ 3 là: 3print(\u0026#39;2\\u00b3\u0026#39;) 4print(\u0026#39;2\\u00b3\u0026#39;.isdecimal()) 5print(\u0026#39;2\\u00b3\u0026#39;.isdigit()) 6print(\u0026#39;2\\u00b3\u0026#39;.isnumeric()) 78# Kết quả 910\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;2\\u00b3\u0026#39;) 112³ 12\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;2\\u00b3\u0026#39;.isdecimal()) 13False 14\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;2\\u00b3\u0026#39;.isdigit()) 15True 16\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;2\\u00b3\u0026#39;.isnumeric()) 17True 12# số ⅓ là: 3print(\u0026#39;\\u2153\u0026#39;) 4print(\u0026#39;\\u2153\u0026#39;.isdecimal()) 5print(\u0026#39;\\u2153\u0026#39;.isdigit()) 6print(\u0026#39;\\u2153\u0026#39;.isnumeric()) 78# Kết quả 910\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;\\u2153\u0026#39;.isdecimal()) 11False 12\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;\\u2153\u0026#39;.isdigit()) 13False 14\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;\\u2153\u0026#39;.isnumeric()) 15True Phương thức isascii, isalpha, isalnum, isspace, isupper   isalpha: Trả về true nếu toàn bộ ký tự trong bảng alphabet(a-z). Không chứa ký tự khoảng trắng, # @ $ \u0026hellip;\n  isalnum: Trả về true nếu toàn bộ ký tự là alphanumeric (a-z,0-9)\n  isascii: Trả về true nếu toàn bộ là ký tự ascii (a-z)\n  isspace: Trả về true nếu toàn bộ ký tự là khoảng trắng\n  isupper: Trả về true nếu toàn bộ ký tự đều in hoa.\n  Ví dụ:\n12\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex\u0026#34;.isalpha()) 3True 45\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100\u0026#34;.isalpha()) 6False 78\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100\u0026#34;.isalnum()) 9True 1011\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100 $%\u0026#34;.isalnum()) 12False 1314\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100 $%\u0026#34;.isascii()) 15True 161718\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100\u0026#34;.isspace()) 19False 20\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;\u0026#34;.isspace()) 21False 22\u0026gt;\u0026gt;\u0026gt; print(\u0026#34; \u0026#34;.isspace()) 23True 242526\u0026gt;\u0026gt;\u0026gt; print(\u0026#34; \u0026#34;.isupper()) 27False 28\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;abc\u0026#34;.isupper()) 29False 30\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;AA\u0026#34;.isupper()) 31True Phương thức lstrip, rstrip, strip  Phương thức lstrip: Xoá chuỗi dư thừa ở bên trái, mặc định chuỗi dư thừa là khoảng trắng Phương thức rstrip: Xoá chuỗi dư thừa ở bên phải, mặc định chuỗi dư thừa là khoảng trắng Phương thức strip: Xoá chuỗi dư thừa ở hai bên, mặc định chuỗi dư thừa là khoảng trắng  Ví dụ\n12\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;.... alex black ..\u0026#34;.lstrip(\u0026#34;.\u0026#34;)) # chỉ xoá . bên trái 3alex black .. 45\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;.... alex black ..\u0026#34;.rstrip(\u0026#34;.\u0026#34;)) # chỉ xoá . bên phải 6.... alex black 78\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;....alex black..\u0026#34;.strip(\u0026#34;.\u0026#34;)) # xoá . ở hai bên 9alex black 101112\u0026gt;\u0026gt;\u0026gt; print(\u0026#34; ....alex black..\u0026#34;.strip()) # xoá khoảng trắng ở hai bên 13....alex black.. Phương thức find, index Cả hai phương thức find và index được sử dụng để tìm vị trí đầu tiên của phần tử cần tìm\n  Phương thức find: Trả về -1 nếu phần tử không tìm thấy\n  Phương thức index: Trả về lỗi nếu phần tử không tìm thấy\n  Ví dụ:\n12\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.find(\u0026#34;b\u0026#34;)) 35 45\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.index(\u0026#34;b\u0026#34;)) 65 78\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.find(\u0026#34;a\u0026#34;,5)) 97 1011\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.index(\u0026#34;a\u0026#34;,5)) 127 1314\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.find(\u0026#34;z\u0026#34;)) 15-1 1617\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.index(\u0026#34;z\u0026#34;)) 18Traceback (most recent call last): 19File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; 20ValueError: substring not found Phương thức format Phương thức format được sử dụng để định dạng chuỗi.\nVí dụ:\n12greetings = \u0026#34;Hello everyone, my name {name}, i am {age}year old. I come from {location}\u0026#34; 34name = \u0026#34;alex Black\u0026#34; 5age = 18 6location = \u0026#34;the moon\u0026#34; 7print(greetings.format(name=name, age=age, location=location)) 89#Kết quả 1011\u0026gt;\u0026gt;\u0026gt; print(greetings.format(name=name, age=age, location=location)) 12Hello everyone, my name alex Black, i am 18 year old. I come from the moon Cách viết này khá dài dòng lê thê, một cách khác là chúng ta có thể sử dụng f string.\nf string python 3 hỗ trợ f string, giúp format chuỗi, trông đẹp hơn so với phương thức format ở trên.\n12\u0026gt;\u0026gt;\u0026gt; age =18 3\u0026gt;\u0026gt;\u0026gt; name= \u0026#39;Alex Black\u0026#39; 4\u0026gt;\u0026gt;\u0026gt; location=\u0026#39;the moon\u0026#39; 56\u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;hello, my name {name}. I am {age}years old. I come from {location}\u0026#34;) 7hello, my name Alex Black. I am 18 years old. I come from the moon Kiểu dữ liệu tuple  Tuple là tập cho phép chúng ta gán nhiều biến vào một biến. Ví dụ:\n1tupinfo = (\u0026#39;Alex\u0026#39;, \u0026#39;Black\u0026#39;,\u0026#39;1978\u0026#39;,\u0026#39;Emprise\u0026#39;, \u0026#39;Engineer\u0026#39;,\u0026#39;Ho Chi Minh\u0026#39;); 2tupinfo = (1,3,5,7,9,9); 3print(tupinfo[0]) 4print(tupinfo[1:4]) 56#kết quả 7\u0026gt;\u0026gt;\u0026gt; print(tupinfo[0]) 81 9\u0026gt;\u0026gt;\u0026gt; print(tupinfo[1:4]) 10(3, 5, 7) 11\u0026gt;\u0026gt;\u0026gt; Packing và Unpacking Thuật ngữ packing ám chỉ việc ta thêm giá trị vào tuple.\nThuật ngữ unpacking ám chỉ việc ta phân giải các giá trị của tuple ra nhiều biến.\nChúng ta cùng xem ví dụ:\n12a = (\u0026#34;alex\u0026#34; , 18, \u0026#34;Staff\u0026#34;) # tuple packing 34(name, age, position) = a # unpacking tuple 56print(name) 7print(age) 8print(position) 910# Kết quả 1112\u0026gt;\u0026gt;\u0026gt; print(name) 13alex 14\u0026gt;\u0026gt;\u0026gt; print(age) 1518 16\u0026gt;\u0026gt;\u0026gt; print(position) 17Staff So sánh các biến có kiểu dữ liệu tuple Python cho phép so sánh các biến thuộc kiểu dữ liệu tuple với nhau. Chúng ta có thể thực hiện các phép so sánh bằng, so sánh lớn hơn, so sánh bé hơn. Việc so sánh được thực hiện lần lượt bằng cách so sánh giá trị của từng phần tử với nhau theo thứ tự. Phần tử thứ nhất sẽ so sánh với phần tử thứ nhất, phần tử thứ hai sẽ so sánh với phần tử thứ hai\u0026hellip;.\nVí dụ:\n12num1 = (3,5,7) 34num2 = (3,6,4) 56print(num1\u0026gt;num2) 7print(num1==num2) 8print(num1\u0026lt;num2) 910Kết quả: 1112\u0026gt;\u0026gt;\u0026gt; print(num1\u0026gt;num2) 13False 14\u0026gt;\u0026gt;\u0026gt; print(num1==num2) 15False 16\u0026gt;\u0026gt;\u0026gt; print(num1\u0026lt;num2) # do 6 lớn hơn 5, nên num2 lớn hơn num1 17True Một lưu ý nhỏ là ở python, phép so sánh bằng sẽ là hai dấu bằng (==), không phải một dấu =. Dấu = đại diện cho phép gán giá trị cho biến.\nSlicing trong Tuple Để lấy ra một nhóm các phần tử liền kề nhau trong tuple, chúng ta sử dụng một hàm có tên là slicing. Slicing có thể áp dụng cho tuple, array, list.\nVí dụ:\n12ages = (18,16,15,18,15,17,19,18,17) 3print(ages[2:4]) 4\u0026gt;\u0026gt;\u0026gt; print(ages[2:4]) 5(15, 18) Các hàm dựng sẵn của Tuple Để thực hiện các công việc khác nhau, kiểu dữ liệu tuple có xây dựng một số hàm để chúng ta sử dụng, như là all(), any(), enumerate(), max(), min(), sorted(), len(), tuple(), etc.\nKiểu dữ liệu từ điển - dictionary  Trong python, kiểu từ điển là tập hợp các dữ liệu có dạng key-value. Trong đó, Key là duy nhất trong từ điển. Value có thể là list, tuple, dictionary, số, chuỗi, túm lại là value không bị giới hạn về kiểu dữ liệu, thích lưu kiểu gì cũng được. Có hai cách để tạo biến có kiểu dữ liệu từ điển, một là dùng từ khoá dict(), hai là dùng dấu đóng mở ngoặc nhọn {}.\nVí dụ\n12info = {\u0026#39;name\u0026#39;: \u0026#34;alex\u0026#34;, age:18, \u0026#39;position\u0026#39;: \u0026#34;Staff\u0026#34; } 3print(info) 45Kết quả: 67\u0026gt;\u0026gt;\u0026gt; print(info) 8{\u0026#39;alex\u0026#39;: \u0026#39;alex\u0026#39;, 18: 18, \u0026#39;position\u0026#39;: \u0026#39;Staff\u0026#39;} Qua 10 triệu lần test trên con máy apple m1 của mình, mình thấy rằng khai báo biến dictionary bằng dấu {} sẽ chạy nhanh hơn so với khai báo sử dụng dict()\nThuộc tính của keys trong từ điển. Có ba điểm quan trọng về key của dictionary chúng ta cần phải nhớ:\n  Một là key không cho phép trùng nhau.\n  Key phải là thuộc nhóm bất biến - immutable, như number, tuple , string.\n  Key có phân biệt hoa thường.\n  Ví dụ:\n123item = {\u0026#34;name\u0026#34;:\u0026#34; iPhone 13 Pro Max 512GB\u0026#34;,\u0026#34;Price\u0026#34;:\u0026#34;34.690.000\u0026#34;,\u0026#34;Brand\u0026#34;:\u0026#34;Apple\u0026#34;,\u0026#34;BRAND\u0026#34;:\u0026#34;Apple\u0026#34;} 45print(item[\u0026#34;Brand\u0026#34;]) 67\u0026gt;\u0026gt;\u0026gt; print(item[\u0026#34;Brand\u0026#34;]) 8Apple Một vài phương thức của dictionary copy Phương thức này được sử dụng để copy phần tử của biến này sang biến khác.\nVí dụ:\n12item = {\u0026#34;Điện thoại iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.690.000\u0026#34;,\u0026#34;Điện thoại iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 34item_new = item.copy() 56print(item_new) 78\u0026gt;\u0026gt;\u0026gt; print(item_new) 9{\u0026#39;Điện thoại iPhone 13 Pro Max 512GB\u0026#39;: \u0026#39;34.690.000\u0026#39;, \u0026#39;Điện thoại iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;} update Phương thức update được sử dụng để cập nhật dữ liệu nếu key đã có, nếu key chưa có thì thêm cặp key-value vào từ điển.\nVí dụ:\n12item = {\u0026#34;Điện thoại iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.790.000\u0026#34;,\u0026#34;Điện thoại iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 34item_new = item.copy() 5item_new.update({\u0026#34;Điện thoại iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.690.000\u0026#34;}) # cập nhật giá trị, vì key đã tồn tại 67item_new.update({\u0026#34;Điện thoại iPhone 13 Pro Max 128GB\u0026#34; :\u0026#34;28.390.000\u0026#34;}) # thêm cặp key-value vào biến item_new 89print(item) 10print(item_new) 1112#Kết quả 1314\u0026gt;\u0026gt;\u0026gt; print(item) 15{\u0026#39;Điện thoại iPhone 13 Pro Max 512GB\u0026#39;: \u0026#39;34.790.000\u0026#39;, \u0026#39;Điện thoại iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;} 16\u0026gt;\u0026gt;\u0026gt; print(item_new) 17{\u0026#39;Điện thoại iPhone 13 Pro Max 512GB\u0026#39;: \u0026#39;34.690.000\u0026#39;, \u0026#39;Điện thoại iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;, \u0026#39;Điện thoại iPhone 13 Pro Max 128GB\u0026#39;: \u0026#39;28.390.000\u0026#39;} del Để xoá một key ra khỏi từ điển, chúng ta dùng từ khoá del\n12item = {\u0026#34;Điện thoại iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.790.000\u0026#34;,\u0026#34;Điện thoại iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 34del item[\u0026#34;Điện thoại iPhone 13 Pro Max 512GB\u0026#34;] 56print(item) 78#Kết quả 910\u0026gt;\u0026gt;\u0026gt; print(item) 11{\u0026#39;Điện thoại iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;} item Phương thức items trả về giá trị của từ điển dưới dạng list tuple (key,value)\n12info = {\u0026#34;name\u0026#34;:\u0026#34;Alex\u0026#34;,\u0026#34;age\u0026#34;:18,\u0026#34;position\u0026#34;:\u0026#34;staff\u0026#34;} 3print(info.items()) 45# Kết quả 67\u0026gt;\u0026gt;\u0026gt; print(info.items()) 8dict_items([(\u0026#39;name\u0026#39;, \u0026#39;Alex\u0026#39;), (\u0026#39;age\u0026#39;, 18), (\u0026#39;position\u0026#39;, \u0026#39;staff\u0026#39;)]) len Phương thức len trả về số lượng phần tử trong từ điển\n12item = {\u0026#34;Điện thoại iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.790.000\u0026#34;,\u0026#34;Điện thoại iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 34print(len(item)) 56#Kết quả 78\u0026gt;\u0026gt;\u0026gt; print(len(item)) 92 Merge Để nối hai hay nhiều từ điển vào làm một, có một số cách sau:\n  Sử dụng hàm update, hàm này đã được mình nói rõ ở trên, mình không nhắc lại nữa\n  Sử dụng Kwargs **.\n  Từ phiên bản 3.5 trở lên, python hỗ trợ \u0026ldquo;đối số từ khóa\u0026rdquo; - Kwargs - keyword arguments là **, và lúc này, chúng ta có thể sử dụng ** ở trước tên biến.\nVí dụ\n12itemApple = {\u0026#34;Điện thoại iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.790.000\u0026#34;,\u0026#34;Điện thoại iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 345itemSamsung = {\u0026#34;Điện thoại Samsung Galaxy S22 Ultra 5G 128GB \u0026#34;:\u0026#34;27.990.000\u0026#34;,\u0026#34;Điện thoại Samsung Galaxy S22 Ultra 5G 512GB\u0026#34;:\u0026#34;33.990.000\u0026#34;} 67itemPhone = {**itemApple,**itemSamsung} 89print(itemPhone) 101112\u0026gt;\u0026gt;\u0026gt; print(itemPhone) 13{\u0026#39;Điện thoại iPhone 13 Pro Max 512GB\u0026#39;: \u0026#39;34.790.000\u0026#39;, \u0026#39;Điện thoại iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;, \u0026#39;Điện thoại Samsung Galaxy S22 Ultra 5G 128GB \u0026#39;: \u0026#39;27.990.000\u0026#39;, \u0026#39;Điện thoại Samsung Galaxy S22 Ultra 5G 512GB\u0026#39;: \u0026#39;33.990.000\u0026#39;} Tổng kết:   Kiểu dữ liệu từ điển lưu dữ liệu dưới dạng key-value\n  Key-value được ngăn cách với nhau bởi dấu hai chấm (:)\n  Cặp key-value được ngăn cách với cặp khác bởi dấu phẩy\n  Key trong kiểu dữ liệu từ điển là duy nhất\n  Kiểu từ điển không lưu thông tin theo một thứ tự cụ thể, thông tin khi lấy ra có thể khác thứ tự với thông tin khi nhập vào. Tuy nhiên, từ phiên bản python3.7 trở đi, kiểu từ điển đã được sắp xếp theo thứ tự của key\n  Kiểu dữ liệu list  List là cái thùng chứa, để chứa tập các dữ liệu. Để khai báo kiểu dữ liệu list, ta có thể dụng dấu đóng mở ngoặc vuông ([]), hoặc dùng từ khoá list()\n12lsta = [1,2,3,4,5] # đây là khai báo list chính thống của python 34lstb = list((1,2,3,4,5)) # đây là sử dụng hàm để tạo list 56print(lsta) 78print(lstb) Truy xuất dữ liệu trong list Dữ liệu trong list có thể được truy xuất thông qua index. Index là vị trí đứng của phần tử trong list.\nVí dụ, nếu ta muốn lấy ra giá trị ở vị trí 0 của list có tên là lsta, ta thực hiện như sau: lst[0]\n12lsta = [5,3,6,9] 34print(lsta[0]) 5print(lsta[2]) 67\u0026gt;\u0026gt;\u0026gt; print(lsta[0]) 85 9\u0026gt;\u0026gt;\u0026gt; print(lsta[2]) 106 slicing slicing là lấy một nhóm các phần tử trong list ra, cách thực hiện giống như tuple\n1lsta = [5,3,6,9,3,5,1,2,9,6] 23print(lsta[1:5]) 45\u0026gt;\u0026gt;\u0026gt; print(lsta[1:5]) 6[3, 6, 9, 3] Tuy nhiên, không giống như tuple, giá trị của tuple không thể thay đổi được, giá trị của list có thể thay đổi được, nên chúng ta có thể cập nhật giá trị cho list sử dụng slicing\n12lsta = [5,3,6,9,3,5,1,2,9,6] 34print(lsta) 56print(lsta[2:4]) 78lsta[2:4] = [8,8] 910print(lsta) 1112print(lsta[2:4]) 131415#Kết quả 1617\u0026gt;\u0026gt;\u0026gt; print(lsta[2:4]) 18[6, 9] 19\u0026gt;\u0026gt;\u0026gt; 20\u0026gt;\u0026gt;\u0026gt; lsta[2:4] = [8,8] 21\u0026gt;\u0026gt;\u0026gt; 22\u0026gt;\u0026gt;\u0026gt; print(lsta) 23[5, 3, 8, 8, 3, 5, 1, 2, 9, 6] 24\u0026gt;\u0026gt;\u0026gt; 25\u0026gt;\u0026gt;\u0026gt; print(lsta[2:4]) 26[8, 8] Một điều khá thú vị, là list hỗ trợ index ngược, ví dụ, nếu chúng ta muốn lấy phần tử cuối cùng, ta có thể sử dụng index [-1], dùng [-2] nếu muốn lấy phần tử kế cuối .\nví dụ\n123lsta = [5,3,6,9,3,5,1,2,9,6] 45print(lsta[-1]) 67print(lsta[-2]) 89#Kết quả 1011\u0026gt;\u0026gt;\u0026gt; print(lsta[-1]) 126 13\u0026gt;\u0026gt;\u0026gt; 14\u0026gt;\u0026gt;\u0026gt; print(lsta[-2]) 159 Hệ quả của index ngược, là chúng ta có slicing với số âm\n12lsta = [5,3,6,9,3,5,1,2,9,6] 34print(lsta[5:-1]) 56print(lsta[5:-2]) 78#Kết quả 910\u0026gt;\u0026gt;\u0026gt; print(lsta[5:-1]) 11[5, 1, 2, 9] 12\u0026gt;\u0026gt;\u0026gt; 13\u0026gt;\u0026gt;\u0026gt; print(lsta[5:-2]) 14[5, 1, 2] Các phương thức được hỗ trợ append Phương thức append dùng để thêm phần tử vào list\n12lsta = [5,3,6,9,3,5,1,2,9,6] 34lsta.append(1) 56lsta.append([11,12]) 78print(lsta) 91011# Kết quả 1213\u0026gt;\u0026gt;\u0026gt; print(lsta) 14[5, 3, 6, 9, 3, 5, 1, 2, 9, 6, 1, [11, 12]] pop Phương thức pop dùng để xoá phần tử ở vị trí index ra khỏi list\n12lsta = [5,3,6,9,3,5,1,2,9,6] 34lsta.pop(0) 56print(lsta) 78# Kết quả 910\u0026gt;\u0026gt;\u0026gt; print(lsta) 11[3, 6, 9, 3, 5, 1, 2, 9, 6] remove Phương thức remove dùng để xoá phần tử ra khỏi list, nếu có nhiều phần tử có cùng giá trị với phần tử cần xoá, thì chỉ xoá thằng đầu tiên\n12lsta = [5,3,6,9,3,5,1,2,9,6] 34lsta.remove(9) 56print(lsta) 789# Kết quả 1011\u0026gt;\u0026gt;\u0026gt; print(lsta) 12[5, 3, 6, 3, 5, 1, 2, 9, 6] reverse Phương thức reverse được dùng để đảo ngược list\n12lsta = [5,3,6,9,3,5,1,2,9,6] 34lsta.reverse() 56print(lsta) 789# Kết quả 1011\u0026gt;\u0026gt;\u0026gt; print(lsta) 12[6, 9, 2, 1, 5, 3, 9, 6, 3, 5] Các hàm được hỗ trợ len Hàm len trả về số lượng phần tử trong list\n12lsta = [5,3,6,9,3,5,1,2,9,6] 34print(len(lsta)) 567# Kết quả 89\u0026gt;\u0026gt;\u0026gt; print(len(lsta)) 1010 max Hàm max trả về phần tử có giá trị lớn nhất trong list\n12lsta = [5,3,6,9,3,5,1,2,9,6] 34print(max(lsta)) 567# Kết quả 89\u0026gt;\u0026gt;\u0026gt; print(max(lsta)) 109 min Hàm min trả về phần tử có giá trị nhỏ nhất trong list\n12lsta = [5,3,6,9,3,5,1,2,9,6] 34print(min(lsta)) 567# Kết quả 89\u0026gt;\u0026gt;\u0026gt; print(min(lsta)) 101 Kiểu dữ liệu set  Trong python, set là tập hợp không có thứ tự các dữ liệu. Dữ liệu trong set là duy nhất.\nĐể tạo một set, chúng ta sử dụng hàm set(), hoặc dùng dấu đóng mở ngoặc nhọn {}\nVí dụ:\n12item_samsung = set([\u0026#34;Samsung Galaxy S22 Ultra 5G\u0026#34;,\u0026#34;Samsung Galaxy A13\u0026#34;]) 34item_iphone = {\u0026#34;Iphone 12\u0026#34;,\u0026#34;Iphone 13\u0026#34;} 56print(item_samsung) 78print(item_iphone) 910#Kết quả 1112\u0026gt;\u0026gt;\u0026gt; print(item_samsung) 13{\u0026#39;Samsung Galaxy S22 Ultra 5G\u0026#39;, \u0026#39;Samsung Galaxy A13\u0026#39;} 14\u0026gt;\u0026gt;\u0026gt; 15\u0026gt;\u0026gt;\u0026gt; print(item_iphone) 16{\u0026#39;Iphone 13\u0026#39;, \u0026#39;Iphone 12\u0026#39;} Một vài phương thức cơ bản của Set Phương thức Add Phương thức này có nhiệm vụ thêm phần tử và Set\nVí dụ:\n12item = set() 34item.add(\u0026#34;Iphone\u0026#34;) 56item.add(\u0026#34;Samsung\u0026#34;) 78print(item) 91011# Kết quả 1213\u0026gt;\u0026gt;\u0026gt; print(item) 14{\u0026#39;Samsung\u0026#39;, \u0026#39;Iphone\u0026#39;} Phương thức Remove, Discard Phương thức này dùng để xoá phần tử ra khỏi set. Điểm khác nhau của hai phương thức này là:\n  Phương thức remove: Xoá phần tử ra khỏi set, nếu không tồn tại phần tử cần xoá trong set, chương trình sẽ trả về lỗi KeyError\n  Phương thức discard: Xoá phần tử ra khỏi set, nếu không tồn tại phần tử cần xoá trong set, chương trình vẫn hoạt động bình thường.\n  Ví dụ:\n123item = set() 45item.add(\u0026#34;Iphone\u0026#34;) 67item.add(\u0026#34;Samsung\u0026#34;) 89print(item) 1011item.discard(\u0026#34;Samsung\u0026#34;) 1213item.discard(\u0026#34;Xiaomi\u0026#34;) 1415item.remove(\u0026#34;Oppo\u0026#34;) 1617# Kết quả 1819\u0026gt;\u0026gt;\u0026gt; print(item) 20{\u0026#39;Samsung\u0026#39;, \u0026#39;Iphone\u0026#39;} 21\u0026gt;\u0026gt;\u0026gt; 22\u0026gt;\u0026gt;\u0026gt; item.discard(\u0026#34;Samsung\u0026#34;) # xoá bình thường 23\u0026gt;\u0026gt;\u0026gt; 24\u0026gt;\u0026gt;\u0026gt; item.discard(\u0026#34;Xiaomi\u0026#34;) # Xiaomi không tồn tại trong set item, chương trình vẫn không búng ra lỗi 25\u0026gt;\u0026gt;\u0026gt; 26\u0026gt;\u0026gt;\u0026gt; item.remove(\u0026#34;Oppo\u0026#34;) # Oppo không tồn tại trong set item, chương trình báo lỗi KeyError 27Traceback (most recent call last): 28File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; 29KeyError: \u0026#39;Oppo\u0026#39; Phương thức Pop Phương thức pop được sử dụng để lấy phần tử đầu tiên của set ra, và loại phần tử cuối đó ra khỏi set.\nVí dụ:\n123item = {1,5,6,4,3,8,10} 45print(item) 67print(item.pop()) 89print(item) 101112# Kết quả 1314\u0026gt;\u0026gt;\u0026gt; item = {1,5,6,4,3,8,10} 15\u0026gt;\u0026gt;\u0026gt; 16\u0026gt;\u0026gt;\u0026gt; print(item) 17{1, 3, 4, 5, 6, 8, 10} 18\u0026gt;\u0026gt;\u0026gt; 19\u0026gt;\u0026gt;\u0026gt; print(item.pop()) 201 21\u0026gt;\u0026gt;\u0026gt; 22\u0026gt;\u0026gt;\u0026gt; print(item) 23{3, 4, 5, 6, 8, 10} Phương thức Clear Phương thức clear được sử dụng để xoá mọi phần tử trong set. Kết quả là chúng ta được một set rỗng\n123item_iphone = {\u0026#34;Iphone 12\u0026#34;,\u0026#34;Iphone 13\u0026#34;} 45item_iphone.clear() 67print(item_iphone) 8910# Kết quả 1112\u0026gt;\u0026gt;\u0026gt; print(item_iphone) 13set() Kiểu dữ liệu array  Array là tập các phần tử được lưu trữ có thứ tự trong bộ nhớ. Các phần tử trong array phải có cùng kiểu dữ liệu. Kiểu dữ liệu array giống kiểu array trong c++.\nVí dụ:\n12import array as arr 34item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5]) 56print(item_number) 789item_number_decimal = arr.array(\u0026#39;d\u0026#39;,[5.391,6.626,1.054,1.616]) 101112print(item_number_decimal) 13141516#Kết quả 1718\u0026gt;\u0026gt;\u0026gt; print(item_number) 19array(\u0026#39;i\u0026#39;, [1, 2, 3, 5]) 2021\u0026gt;\u0026gt;\u0026gt; print(item_number_decimal) 22array(\u0026#39;d\u0026#39;, [5.391, 6.626, 1.054, 1.616]) Một vài phương thức cơ bản của array Phương thức insert, phương thức append Phương thức insert và append được sử dụng để thêm phần tử vào array, điểm khác biệt của hai phương thức là:\n  Phương thức insert: được sử dụng để chèn phần tử vào vị trí tuỳ ý.\n  Phương thức append: Chèn vào cuối array.\n  Ví dụ:\n12import array as arr 34item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5]) 56item_number.insert(2,4) 78print(item_number) 910item_number.append(1) 1112print(item_number) 1314#Kết quả 15\u0026gt;\u0026gt;\u0026gt; item_number.insert(2,4) 16\u0026gt;\u0026gt;\u0026gt; print(item_number) 17array(\u0026#39;i\u0026#39;, [1, 2, 4, 3, 5]) 1819\u0026gt;\u0026gt;\u0026gt; item_number.append(1) 20\u0026gt;\u0026gt;\u0026gt; print(item_number) 21array(\u0026#39;i\u0026#39;, [1, 2, 4, 3, 5, 1]) Phương thức truy xuất phần tử theo index Để truy xuất phần tử theo index, chúng ta sử dụng dấu ngoặc vuông [], kèm theo vị trí của phần tử cần truy xuất.\n1234import array as arr 56item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5]) 78print(item_number[2]) 91011#Kết quả 1213\u0026gt;\u0026gt;\u0026gt; print(item_number[2]) 143 Phương thức remove, phương thức pop Phương thức remove và pop được sử dụng để xoá phần tử ra khỏi array.\n  Phương thức remove: Xoá phần tử ra khỏi mảng, nếu mảng có nhiều phần tử trùng với phần tử cần xoá thì chỉ xoá phần tử xuất hiện đầu tiên. Nếu phần tử không có trong mảng, chương trình sẽ búng ra lỗi.\n  Phương thức pop: Xoá phần tử ở vị trí index ra khỏi mảng, trả về là giá trị của phần tử bị remove. Nếu không truyền vào vị trí cần xoá, thì sẽ xoá phần tử cuối cùng trong mảng.\n  123import array as arr 45item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5,2]) 67print(item_number) 89item_number.remove(2) 1011print(item_number) 1213print(item_number.pop(2)) 1415print(item_number) 161718#Kết quả 1920\u0026gt;\u0026gt;\u0026gt; print(item_number) 21array(\u0026#39;i\u0026#39;, [1, 2, 3, 5, 2]) 22\u0026gt;\u0026gt;\u0026gt; item_number.remove(2) # xoá số 2 đi 23\u0026gt;\u0026gt;\u0026gt; 24\u0026gt;\u0026gt;\u0026gt; print(item_number) 25array(\u0026#39;i\u0026#39;, [1, 3, 5, 2]) # Chỉ số 2 đầu tiên bị xoá 26\u0026gt;\u0026gt;\u0026gt; 27\u0026gt;\u0026gt;\u0026gt; print(item_number.pop(2)) # xoá phần tử ở vị trí số 2 285 # Phần tử ở vị trí số 2 là 5, phần tử 5 đã bị xoá 29\u0026gt;\u0026gt;\u0026gt; 30\u0026gt;\u0026gt;\u0026gt; print(item_number) 31array(\u0026#39;i\u0026#39;, [1, 3, 2]) Phương thức index Phương thức này được sử dụng để tìm vị trí của phần tử trong array\n12import array as arr 34item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5,2]) 56print(item_number.index(2)) 789print(item_number.index(2,2)) 10111213#Kết quả 1415\u0026gt;\u0026gt;\u0026gt; print(item_number.index(2)) #Tìm vị trí của số 2 161 17\u0026gt;\u0026gt;\u0026gt; 18\u0026gt;\u0026gt;\u0026gt; print(item_number.index(2,2))# Tìm vị trí của số 2, bắt đầu từ vị trí 2 194 Chúc các bạn học thật tốt.\n","date":"Jul 10, 2022","img":"","permalink":"/courses/python/3_python_data_struct/","series":["Khóa học python căn bản"],"tags":["python"],"title":"Bài 2: Kiểu Dữ Liệu Trong Python"},{"categories":"python","content":"Trong bài viết này, chúng ta sẽ tìm hiểu các mục sau\n Cài đặt python  Cài đặt phần mềm để lập trình python (IDE) Chương trình python đầu tiên - Hello word Biến trong python  Kiểu dữ liệu Khai báo và sử dụng biến trong python Ép kiểu dữ liệu Xem kiểu dữ liệu      Cài đặt python  Để cài đặt python, các bạn truy cập vào đường dẫn https://www.python.org/downloads/ và download phiên bản python mới nhất, phù hợp với hệ điều hành của bạn. Tại thời điểm mình viết bài viết này, phiên bản python mới nhất là 3.10.4. Nếu các bạn sử dụng hệ điều hành window, công việc sẽ hết sức đơn giản, các bạn chỉ cần download file cài đặt python về, ấn next -\u0026gt; next -\u0026gt; next \u0026hellip; finish. Xong\nĐối với hệ điều hành macos hoặc linux, thông thường thì đã được cài đặt sẵn python, nên các bạn có thể bỏ qua bước này.\nHãy liên hệ mình qua chat message nếu các bạn gặp bất kỳ khó khăn hoặc lỗi gì khi cài đặt python nhé.\nCài đặt phần mềm để lập trình python (IDE) Ở đây, chúng ta sẽ sử dụng Visual studio code, một IDE nhẹ nhàng, hỗ trợ nhiều tính năng, hỗ trợ nhiều môi trường. Các bạn hãy truy cập vào đường dẫn https://code.visualstudio.com/download và download file cài đặt về. Với hệ điều hành window thì chúng ta chỉ cần next -\u0026gt; next \u0026hellip; finish.\nChương trình python đầu tiên - Hello word Chúng ta hãy mở chương trình visual studio code lên, chọn File -\u0026gt; New File -\u0026gt; đặt tên file là hello_word.py\nGõ vào dòng lệnh\n1print (\u0026#34;Hello World!\u0026#34;) Chọn File -\u0026gt; Save hoặc ấn tổ hợp phím ctr + s (window - ubuntu) hoặc command + s (macos)\nChọn Terminal -\u0026gt; New Terminal\nGõ vào trong terminal dòng lệnh\n1python3 hello_word.py Cửa sổ terminal sẽ hiện ra như sau:\n1python3 hello_word.py 2\u0026gt;\u0026gt;\u0026gt;Hello World! Biến trong python Biến là nơi lưu trữ các giá trị. Giá trị được gán vào biến thông qua dấu =\nVí dụ:\n12name = \u0026#39;alex\u0026#39; # name là tên biến, giá trị của name là alex 34age = 18 # age là tên biến, giá trị của age là 18 Kiểu dữ liệu Mỗi giá trị trong python đều thuộc một kiểu dữ liệu nào đó. Các kiểu dữ liệu được định nghĩa sẵn trong python là string, number, list, dictionary, set. Ngoài ra, chúng ta có thể tự định nghĩa các kiểu dữ liệu để đáp ứng nhu cầu trong bài toán của mình. Ví dụ kiểu dữ liệu con mèo, con chó, động vật, cây, xe đạp, xe hơi \u0026hellip;\nKhai báo và sử dụng biến trong python Python không có câu lệnh khai báo biến. Biến được tạo ra tại thời điểm chúng được gán giá trị.\nVí dụ:\n1x = 5 # biến x được tạo ra, có giá trị là 5, kiểu dữ liệu là int 23x = \u0026#34;Alex\u0026#34; # biến x được gán giá trị là Alex, kiểu dữ liệu là string Ép kiểu dữ liệu Ép kiểu, nghĩa là biến đang có kiểu dữ liệu này, chúng ta muốn biến nó thành kiểu dữ liệu nọ. Ví dụ, một biến đang có kiểu dữ liệu là int, bài toán yêu cầu chuyển sang kiểu dữ liệu float rồi tính toán\n123x = 5 # kiểu dữ liệu của x là int 45x = float(x) # kiểu dữ liệu của x là float 67x = str(x) # kiểu dữ liệu của x giờ là string Xem kiểu dữ liệu Để xem kiểu dữ liệu của một biến, chúng ta sử dụng hàm type\n12x = 9 34y = \u0026#39;alex\u0026#39; 567print(type(x)) 89\u0026gt;\u0026gt;\u0026gt; \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; 1011print(type(y)) 1213\u0026gt;\u0026gt;\u0026gt; \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; ","date":"Jun 5, 2022","img":"","permalink":"/courses/python/2_python_basic/","series":["Khóa học python căn bản"],"tags":["python"],"title":"Bài 1: Căn Bản Về Python"},{"categories":null,"content":"Chỉ số MACD, là tên gọi tắt của moving average convergence/divergence, là một chỉ số giao dịch được sử dụng trong phân tích kỹ thuật trên giá cổ phiếu. Chỉ số được phát triển bởi Gerald Appel vào những năm cuối thập niên 70 của thế kỷ 20.\nChỉ số MACD giúp chúng ta xác định sự thay đổi của sức mạnh, hướng, động lượng ( momentum), và khoảng thời gian của xu hướng giá cổ phiếu. Để làm được điều này, MACD sử dụng 3 chuỗi thời gian EMA khác nhau, theo sách vở kinh điển là EMA12, EMA26 và EMA9. Chỉ số MACD dùng 3 chuỗi EMA trên, được ký hiệu là MACD(12,26,9). Do chỉ sử dụng lịch sử giá của quá khứ, nên chỉ số MACD được xếp vào nhóm chỉ số dự báo muộn.\nMô hình MACD Đường MACD $$ MACD = EMA_{12} - EMA_{26} $$\nMACD được cấu tạo bằng cách lấy chu kỳ ngắn hạn trừ chu kỳ dài hạn (EMA12 - EMA26). Thị trường tăng giá là tại thời điểm MACD chuyển trạng thái giá trị từ âm sang dương. Ngược lại, thị trường giảm giá là tại thời điểm MACD chuyển trạng thái từ dương sang âm\n$$ signal = EMA_9 $$\nĐường tín hiệu đi song song với đường MACD, và xảy ra các trường hợp sau\n  Xu hướng tăng giá: Đường MACD cắt đường tín hiệu, MACD đi từ dưới lên\n  Xu hướng giảm giá: Đường MACD cắt đường tín hiệu, MADC đi từ trên xuống\n  $$ histogram = MACD - signal $$\nĐường histogram: đo khoảng cách chên lệch giữa MACD và signal. Như hình 1 phía trên, giá trị của histotram được biểu diễn là các đường trụ hình vuông, có giá trị dài ngắn khác nhau. Giá trị histogram phản ánh giá trị động lượng (momemtum) về giá. Nếu MACD lớn hơn đường tín hiệu thì chúng ta sẽ có vùng đồi dương.\nNếu để ý kỹ, chúng ta có thể thấy rằng, nếu lực mua vẫn dương, đồi vẫn dương, nhưng giá trị histogram ngắn lại, gần 0, đó có thể là tín hiệu của việc giá có thể giảm.\nViết bot mua chứng khoán mã MWG, tự động, dựa trên MACD, kiểm thử lợi nhuận Dưới tư cách là lập trình viên, mình sẽ coding một con bot nhỏ, chỉ sử dụng MACD, và xem thử lợi nhuận như thế nào.\nBài toán giả định:\n  Cho dư 100 triệu VND trong tay\n  Đầu tư cổ phiếu của tập đoàn thế giới Di động, mã cổ phiếu MWG\n  Thời gian: Từ ngày 1/1/2021 đến 31/12/2021\n  Đầu tư toàn bộ trong một lần, không DCA, không xét yếu tố T+3, giá mua và giá chốt lời là giá tại thời điểm close.\n  Lấy dữ liệu: Mình sử dụng thư viện vnquant của anh Phạm Khánh Đình. Mã nguồn của thư viện ở địa chỉ https://github.com/phamdinhkhanh/vnquant. DataSource được dùng là của vndirect. Thư viện của anh Khánh tại thời điểm mình sử dụng bị lỗi khi load data vndirect, mình có rewrite lại.\nĐể tính EMA, mình xài hàm ewm có sẵn của pandas.\nKết quả: Như hình 1 mình đã show phía trên, hi hi.\n1Profit gained from the MACD strategy by investing $100M in MWG : 15619726.64 2Profit percentage of the MACD strategy : 15% Nếu mình đầu tư 100 triệu ở đầu năm 2021, sử dụng MACD với các tham số (12, 26, 9), đến cuối năm mình thu được thêm 15 triệu 6 trăm 19 ngàn 7 trăm 26 đồng. Lợi nhận hơn 15%, cao hơn tiền lời gửi ngân hàng.\nTham số 12,16,9 theo sách vở, mình không ưng lắm, thế là mình đã cho chạy grid search tìm tham số tốt nhất, kết quả ở hình 2. Cuối cùng mình đã tìm được vài tổ hợp như (9,25,6) hoặc (10,26,5) cho ra lợi nhuận đạt 40%.\nHình 2: MWG grid search\nCho dù các tổ hợp ở trên khá cao, nhưng mình quyết định chọn cặp tổ hợp (11,31,5) cho các bài toán trong tương lai. Lý do là lợi nhuận của tập tổ hợp cũng khá cao, đạt 39%, thứ hai là tập tổ hợp trên chứa toàn số nguyên tố.\nBOT mua chứng khoán, rỗ VN30 Tương tự như mua cổ phiếu MWG. Mình sẽ thực hiện test mua cổ phiếu trong rỗ VN30, gồm các mã cổ phiếu VPB, HPG, MBB, POW, STB, TCB, SSI, CTG, VRE, TCH, VHM, NVL, PDR, BID, FPT, HDB, TPB, SBT, MWG, VIC, BVH, VNM, PLX, MSN, PNJ, VCB, VJC, KDH, REE, GAS như sau:\n  Mỗi loại cổ phiếu được cấp vốn 100 triệu, tổng cộng 30 mã cổ phiếu, có 3 tỷ\n  Sử dụng tổ hợp MACD(11,31,5)\n  Thống kê lợi nhuận cuối năm\n  Kết quả\n   Stock code Profit Profit Percent     VPB 59531568.83 59   HPG 47797426.41 47   MBB 43655931.7 43   POW 11334630.9 11   STB 68945860.5 68   TCB 30909090.6 30   SSI 88181694.47 88   CTG 16023538.94 16   VRE 13112161.55 13   TCH 61063208.12 61   VHM 5633657.62 5   NVL 83612690.71 83   PDR 73030645.91 73   BID -10671169.9 -11   FPT 16548330.46 16   HDB 42686713.83 42   TPB 30960123.75 30   SBT 25536989.15 25   MWG 39039335.94 39   VIC 30392688.88 30   BVH -3770737.5 -4   VNM -13891787.01 -14   PLX 5485716.75 5   MSN 8503902.24 8   PNJ -6325266.73 -7   VCB -7289353.31 -8   VJC -2464227.2 -3   KDH 44801727.18 44   REE 26242537.2 26   GAS 41354753.12 41    Có ông lời, có ông lỗ. Tổng lời là 869.972.383 triệu, trên tỷ lệ đầu tư là 3 tỷ. Đạt tỷ lệ lợi nhuận 28%.\nỞ trên, mình chỉ sử dụng đường xu hướng để quyết định mua / bán, chưa hề sử dụng giá trị động lượng của histogram để xét việc chốt lời hiệu quả. Nên hiệu quả đầu tư vẫn còn nhỏ.\nMình điều chỉnh lại một chút, nếu giá trị histogram giảm bé hơn 10% so với thời điểm cao nhất ở thời điểm đồi dương, mình sẽ chốt lời ngay. Ngoài ra, chúng ta sẽ kết hợp với mây Ichimoku để lọc lại các thời điểm mua cho hợp lý hơn.\nCảm ơn các bạn đã theo dõi bài viết, hẹn gặp lại ở bài tiếp theo.\n","date":"Apr 11, 2022","img":"","permalink":"/courses/stocks/1_macd/","series":["Chứng khoán căn bản"],"tags":["stock"],"title":"Chỉ Số Dự Báo MACD"},{"categories":null,"content":"Tại sao chúng ta cần chuẩn hóa layer Mình nghĩ, câu trả lời thỏa đáng nhất là bởi vì nó làm tăng độ chính xác của mô hình. Trong quá trình thực nghiệm, các nhà nghiên cứu nhận thấy rằng việc thêm Layer Normalization cho kết quả test tốt hơn/ chạy nhanh hơn, hội tụ sớm hơn \u0026hellip; Và từ đó, các nhà nghiên cứu đổ hết tâm sức khai phá, đào bới nó ra thử sai , cải tiến, đề xuất các mô hình chuẩn hóa liên lục, tạo nên các mô hình mà mình sẽ liệt kê ở dưới.\nThật ra, một ý tưởng nào hay thì cũng có nhiều nhà nghiên cứu đổ hết tâm huyết vào nghiên cứu, đào sâu tận cùng nó ra, để cống hiến cho nhân loại.\nBatch Normalization Đây là một trong các phương pháp chuẩn hóa lâu đời và được sử dụng rộng rãi nhất. Ngay cả mình khi test các data mới cũng xài nó vì sự tiện lợi và nhanh chóng của nó. Các bạn có thể tìm đọc paper có tựa đề Batch normalization: Accelerating deep network training by reducing internal covariate shift. Những phần bên dưới, mình sẽ thay chữ Batch Normalization thành BN để cho câu chữ được ngắng gọn và tập trung vào ý chính hơn.\nBatch Normalization (BN) đề cập đến việc chuẩn hóa giá trị input của layer bất kỳ. Chuẩn hóa có nghĩa là đưa phân phối của layer về xấp xỉ phân phối chuẩn với trung bình xấp xỉ 0 và phương sai xấp xỉ 1. Về mặc toán học, Batch Normalization (BN) thực hiện như sau: với mỗi layer, BN tính giá trị trung bình và phương sai của nó. Sau đó sẽ lấy giá trị đặc trưng trừ giá trị trung bình , sau đó chia cho độ lệch chuẩn. Thực tế, chúng ta hay chia tập train thành từng batch với kích thước là 16,32,64 ,128 \u0026hellip; hình, hay còn gọi là 1 mini-batch size 16,32,64,128 \u0026hellip;. BN được tính toán trên các mini-batch đó.\nCông thức tính trung bình của mini-batch\n$$ \\mu_B \\leftarrow \\frac{1}{m}\\sum^{m}_{i=1}x_i $$\nCông thức tính phương sai của mini-batch\n$$ \\sigma^2_\\beta \\leftarrow \\frac{1}{m}\\sum^{m}_{i=1}(x_i-\\mu_B)^2 $$\nChuẩn hóa\n$$ \\hat{x}_i \\frac{x_i - \\mu_B}{\\sqrt{\\sigma^2_B + \\epsilon}} $$\nPhía trên mà mô tả toán học phép biến đổi Batch Normalizing , sử dụng cho hàm kích hoạt x trên mini-batch.\nThực tế, đôi khi mô hình lại hoạt động hiệu quả với một giá trị trung bình và phương sai khác, nên tác giả thêm 2 siêu tham số là gamma - scale và beta - shift để có tính tổng quát.\n$$ y_i \\leftarrow \\gamma\\hat{x}_i + \\beta $$\nBatch Normalization hoạt động như thế nào Về mặc trực quan, chúng ta biết rằng, trong gradient descent, mạng NN tính giá trị đạo hàm và giảm trọng số của nó dựa vào hướng đi của đạo hàm. Nhưng do các layer được xếp chồng lên nhau, phân phối của dữ liệu đầu vào sẽ bị thay đổi dần do việc cập nhật trọng số của các layer trước đó, làm cho phân phối của đầu vào của các layer phía sau sẽ khác xa so với phân phối của data input. BN giúp cố định phân phối của dữ liệu về phân phối chuẩn, qua tất cả các lớp, dẫn tới tính chất phân phối của dữ liệu không thay đổi qua các lớp.\nKhuyết điểm của Batch Normalization   BN thực hiện lại các phép tính trình bày phía trên qua các lần lặp, cho nên, về lý thuyết, chúng ta cần batch size đủ lớn để phân phối của mini-batch xấp xỉ phân phối của dữ liệu. Điều này gây khó khăn cho các mô hình đòi hỏi ảnh đầu vào có chất lượng cao (1920x1080) như object detection, semantic segmentation, \u0026hellip; Việc huấn luyện với batch size lớn làm mô hình phải tính toán nhiều và chậm.\n  Với Batch size = 1, giá trị phương sai sẽ là 0. Do đó BN sẽ không hoạt động hiệu quả.\n  BN không hoạt động tốt với RNN. Lý do là RNN có các kết nối lặp lại với các timestamps trước đó, và yêu cầu các giá trị beta và gamma khác nhau cho mỗi timestep, dẫn đến độ phức tạp tăng lên gấp nhiều lần, và gây khó khăn cho việc sử dụng BN trong RNN.\n  Trong quá trình test, BN không tính toán lại giá trị trung bình và phương sai của tập test. Mà sử dụng giá trị trung bình và phương sai được tính toán từ tập train. Điều này làm cho việc tính toán tăng thêm. Ỏ pytorch, hàm model.eval() giúp chúng ta thiết lập mô hình ở chế độ evaluation. Ở chế độ này, BN layer sẽ sử dụng các giá trị trung bình và phương sai được tính toán từ trước trong dữ liệu huấn luyện. Giúp cho chúng ta không phải tính đi tính lại giá trị này.\n  Weight Normalization Tham khảo https://arxiv.org/pdf/1602.07868.pdf Do các bất lợi của BN, T. Saliman và P. Kingma đề xuất cách tính khác, và đặt tên là Weight Normalization. Ý tưởng của tác giả là tách trọng số thành 2 thành phần là giá trị của trọng số và hướng của trọng số. Nhằm mục đích tăng tốc tốc độ train.\nTác giả đề xuất sử dụng hai giá trị g( cho giá trị trọng số ) và v cho hướng của trọng số thay vì sử dụng 1 giá trị w nguyên thủy.\n$$ w = \\frac{g}{||v||}v $$\nVới g là giá trị scala, v là vector. Công thức này nhanh do chúng ta đã fixed được giá trị chuẩn của w. Do chuẩn của w lúc này bằng g.\nKhông giống như BN, WN hoạt động được trong mô hình RNN. Tuy nhiên, về thực nghiệm cho thấy mô hình với WN thường không ổn định, nên ít khi được sử dụng trong thực tế\nLayer Normalization Tham khảo https://arxiv.org/pdf/1607.06450.pdf\nLấy cảm hứng từ BN, Geoffrey Hinton và các đồng sự đã đề xuất Layer Normalization. Phép chuẩn hóa được sử dụng trên từng layer như sau\n$$ \\mu^l =\\frac{1}{H}\\sum^{H}_{i=1}\\alpha^l_i $$\n$$ \\sigma^l = \\sqrt{\\frac{1}{H}\\sum^{H}_{i=1}(\\alpha^l_i-\\mu^l)^2} $$\nVới H là số lượng phần tử trong một hidden layer.\nCái khác nhau chính giữa BN và LN là LN sử dụng chung một giá trị trung bình và phương sai trong 1 hidden layer. LN không phụ thuộc vào mini-batch, nên có thể train được với batch-size = 1 mà không gặp vấn đề gì cả.\nNgoài ra LN cũng có thể được sử dụng trong RNN mà không gặp trở ngại nào như BN.\nInstance Normalization Instance Normalization còn có tên gọi khác là contrast normalization\nÝ tưởng ở đây là chúng ta sẽ chuẩn hoá trên từng channel của từng batch.\nGroup Normalization Tham khảo https://arxiv.org/pdf/1803.08494.pdf\nĐược đề xuất bởi Kaiming He và cộng sự , Group Normalization có cách thức hoạt động tương tự LN, chỉ một khác biệt duy nhất là thuật toán sẽ chia các layer thành từng nhóm và thực hiện chuẩn hóa trên các nhóm đó. Chúng ta phải turning tham số num_groups để tìm số lượng nhóm cho kết quả tốt nhất.\nHai cái chuẩn hoá cuối khá đơn giản, mình không đề cập chi tiết nhiều. Nếu có bạn nào quan tâm thì vui lòng để lại lời nhắn, mình sẽ update thông tin các bạn cần.\nNguồn ảnh : https://medium.com/syncedreview/facebook-ai-proposes-group-normalization-alternative-to-batch-normalization-fb0699bffae7\nJournalist: Tony Peng| Editor: Michael Sarazen\nNguồn tham khảo @inproceedings{ioffe2015batch, title={Batch normalization: Accelerating deep network training by reducing internal covariate shift}, author={Ioffe, Sergey and Szegedy, Christian}, booktitle={International conference on machine learning}, pages={448\u0026ndash;456}, year={2015}, organization={PMLR} }\nhttps://analyticsindiamag.com/understanding-normalization-methods-in-deep-learning/\nhttps://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8\nhttps://towardsdatascience.com/different-normalization-layers-in-deep-learning-1a7214ff71d6\nhttps://arxiv.org/pdf/1602.07868.pdf\nhttps://arxiv.org/pdf/1607.06450.pdf\nhttps://arxiv.org/pdf/1803.08494.pdf\nhttps://medium.com/syncedreview/facebook-ai-proposes-group-normalization-alternative-to-batch-normalization-fb0699bffae7\n","date":"Feb 25, 2022","img":"","permalink":"/blog/2022-02-25-normalization/","series":null,"tags":["machine learning","normalization","deep learning"],"title":"Các Kỹ Thuật Chuẩn Hóa Trong Deep Learning"},{"categories":"dataset","content":"1. CASIA-WebFace Dataset có kích thước tầm 4.1G, bao gồm 494,414 hình khuôn mặt của 10,575 người thật được thu thập trên web và đã gán nhãn đầy đủ. Dataset này phục vụ cho bài toán face verification và face identification .\nhttps://archive.org/download/NudeNet_classifier_dataset_v1/NudeNet_Classifier_train_data_x320.zip\nĐối với các bạn muốn mì ăn liền, thì có thể tải pretrain model NudeNet trên pip về rồi thử.\n2. MS-Celeb-1M Tập dataset khuôn mặt gốc được microsoft công bố năm 2016 phục vụ cho bài toán nhận diện khuôn mặt. Tập này chứa tầm 10 triệu ảnh của 100,000 cá nhân khác nhau, đa số là các diễn viên Hollywood (nên có thêm từ Celeb - viết tắt của celebrity).\nNguồn microsoft.com\nHiện nay dataset này đã bị xóa bỏ khỏi website gốc msceleb.org và dự án này của microsoft đã bị kết thúc vì một lý do nào đó.\nLink download: https://academictorrents.com/details/9e67eb7cc23c9417f39778a8e06cca5e26196a97\nCác bạn cân nhắc kỹ trước khi download. Do không phải là link chính chủ\nMã lệnh convert tsv file sang hình ảnh\n1import argparse 2import base64 3import csv 4import os 5# import magic # Detect image type from buffer contents (disabled, all are jpg) 67parser = argparse.ArgumentParser() 8parser.add_argument(\u0026#39;--croppedTSV\u0026#39;, type=str) 9parser.add_argument(\u0026#39;--outputDir\u0026#39;, type=str, default=\u0026#39;raw\u0026#39;) 10args = parser.parse_args() 1112with open(args.croppedTSV, \u0026#39;r\u0026#39;) as tsvF: 13reader = csv.reader(tsvF, delimiter=\u0026#39;\\t\u0026#39;) 14i = 0 15for row in reader: 16MID, imgSearchRank, faceID, data = row[0], row[1], row[4], base64.b64decode(row[-1]) 1718saveDir = os.path.join(args.outputDir, MID) 19savePath = os.path.join(saveDir, \u0026#34;{}-{}.jpg\u0026#34;.format(imgSearchRank, faceID)) 2021# assert(magic.from_buffer(data) == \u0026#39;JPEG image data, JFIF standard 1.01\u0026#39;) 2223os.makedirs(saveDir, exist_ok=True) 24with open(savePath, \u0026#39;wb\u0026#39;) as f: 25f.write(data) 2627i += 1 2829if i % 1000 == 0: 30print(\u0026#34;Extracted {}images.\u0026#34;.format(i)) 3132# Nguồn https://github.com/EB-Dodo/C-MS-Celeb/issues/1#issuecomment-844894295 Dữ liệu gốc của MS-Celeb-1M có nhiều hình ảnh trùng, gán sai. Có nhiều task đã được implement để làm sạch dataset trên. Một trong những task mình thấy khá ổn là\nhttps://github.com/EB-Dodo/C-MS-Celeb\nTác giả đã xử lý, rút trích, giữ lại tầm 6.5 triệu hình của 94,682 người nổi tiếng\n3. VGG Face và VGG Face2 Dataset bao gồm 494,414 hình khuôn mặt của 10,575 người. Các bạn có thể download tại link chính chủ\nhttps://www.robots.ox.ac.uk/~vgg/data/vgg_face/vgg_face_dataset.tar.gz\ntập VGG Face2 đã bị xóa trên trang chủ do vi phạm bản quyền. Nên hiện thời không có link chính chủ\n","date":"Feb 25, 2022","img":"","permalink":"/courses/ml_dataset/web_face/","series":["Machine learning dataset"],"tags":["dataset"],"title":"Dataset Nhận Dạng Khuông Mặt"},{"categories":"dataset","content":"Có đôi khi, mình muốn test một model nào đó, nhưng mà mình lại tốn rất nhiều thời gian để tìm kiếm test data. Vì vậy, mình tạo cái tut này để lưu lại những data mình lượm lặt được, phục vụ cho việc tìm kiếm sau này dễ dàng hơn.\nDataset này cung cấp tầm 19G hình ảnh nhạy cảm. Phục vụ cho các bài toán phân loại, nhận dạng và kiểm duyệt nội dung hình ảnh/ video.\nhttps://archive.org/download/NudeNet_classifier_dataset_v1/NudeNet_Classifier_train_data_x320.zip\nĐối với các bạn muốn mì ăn liền, thì có thể tải pretrain model NudeNet trên pip về rồi thử.\n","date":"Feb 25, 2022","img":"","permalink":"/courses/ml_dataset/nunet/","series":["Machine learning dataset"],"tags":["dataset"],"title":"NudeNet Dataset [Dataset Nhạy Cảm, 18+ Only]"},{"categories":"c++","content":"Lịch sử hình thành, phát triển ngôn ngữ c++ C++ là ngôn ngữ lập trình \u0026ldquo;bậc trung\u0026rdquo; được phát triển bởi Bjarne Stroustrup vào năm 1979 tại phòng thí nghiệm Bell Labs. C++ hoạt động được trên nhiều nền tảng khác nhau như Windows, Mac OS, và các phiên bản của UNIX. Series bài học này hướng tới một khóa học đơn giản, với đầy đủ các kiến thức nền tảng của C++ cho người bắt đầu học.\nLý do nên học ngôn ngữ C++   C++ là một trong những ngôn ngữ lập trình phổ biến trên thế giới.\n  C++ được sử dụng để phát triển nhiều ứng dụng khác nhau, ví dụ như lập trình game, lập trình hệ điều hành, phát triển các ứng dụng nhúng, làm website \u0026hellip;\n  C++ phát triển phần mềm chạy trên nhiều nền tảng.\n  C++ có cộng đồng developer mạnh mẽ\n  C++ chạy nhanh\n  Hàng tỷ lý do khác nữa, mình liệt kê không nổi.\n  C ++ là một ngôn ngữ lập trình tuyệt vời và nó giải quyết được nhiều nhu cầu cụ thể. Ngôn ngữ lập trình này đã tồn tại được gần 40 năm, nên hầu hết các vấn đề trong việc phát triển phần mềm có thể được giải quyết bằng các thư viện open-source và các frameworks. Hiện nay, điểm nổi bật của C ++ là nó được tạo ra để có tốc độ cực nhanh, nhưng nó cũng phụ thuộc vào tốc độ chạy của bộ xử lý. Một trong những điểm nổi bật khác là C ++ là một ngôn ngữ biên dịch, cho phép nó được thực thi một cách hiệu quả. Điều này là do ngôn ngữ biên dịch được thực thi trực tiếp, hoàn toàn ngược lại với một ngôn ngữ thông dịch. C ++ dịch từ một nguồn sang mã máy, trong khi một ngôn ngữ thông dịch như JavaScript hoặc Python được dịch khi trình thông dịch xử lý mã nguồn.\nC ++ cung cấp các cơ chế trừu tượng, cho phép các thuật toán công nghiệp phức tạp được đóng gói trong các thư viện bổ sung, tốn ít chi phí hơn so với việc phát triển từ đầu. Có hàng ngàn thư viện như này đã được xuất bản trong nhiều năm và các ứng dụng thường có thể nhanh chóng triển khai các thuật toán điều chỉnh này để đạt được các hiệu quả mong muốn với hiệu suất máy gần như tối ưu. Đây là một yếu tố phát huy tác dụng làm cho việc phát triển phần mềm trên C ++ trở nên nhanh chóng.\nTốc độ của C ++ cũng khiến nó trở thành sự lựa chọn tuyệt vời cho các hệ thống nhúng như NASA, robot và thậm chí là các trò chơi quy mô lớn được xếp hạng hàng đầu như bạn có, chẳng hạn như Assassin\u0026rsquo;s Creed, Battlefield, Call of Duty và Doom. Và nếu bạn nghĩ về điều đó, các trò chơi này cần phải vắt kiệt từng phần hiệu suất và thực hiện các phép tính nhanh và tính toán lại nhanh chóng, điều mà C ++ đã làm cho điều đó xảy ra.\nLý do không nên học C++ Mặt khác, C ++ là một ngôn ngữ rất nghiêm ngặt, rất mạnh và rất phức tạp. Và điều này làm cho C ++ trở nên cực kỳ khó học, ngay cả đối với các nhà phát triển dày dạn kinh nghiệm. Nếu bạn thực hiện tìm kiếm trên Google cho “ngôn ngữ lập trình khó nhất”, bạn sẽ nhanh chóng thấy rằng C ++ được liệt kê là ứng cử viên hàng đầu.\nTrên hết, C ++ không phải là lựa chọn phù hợp cho nhiều dự án và ứng dụng. Nếu bạn đang xem xét C ++ để xây dựng các API web, ứng dụng máy tính để bàn, ứng dụng iPhone, v.v., thì C ++ không nên là lựa chọn của bạn trừ khi bạn có kế hoạch cho các ứng dụng của mình nhận được hàng trăm nghìn lượt truy cập mỗi giây. Hầu hết các ứng dụng không cần những mức tăng hiệu suất này. Mặc dù, trong phần trên, tôi cũng đã nói về việc C ++ là một lựa chọn tuyệt vời cho các hệ thống nhúng, một khía cạnh khác để phát triển nhúng là tăng hiệu suất bộ xử lý, dung lượng bộ nhớ khả dụng và tiêu chuẩn hóa trên nền tảng 32 và 64-bit. Và điều này cho phép các ngôn ngữ như Java, Lua và Python được sử dụng trong các hệ thống nhúng sâu và đây là những ngôn ngữ dễ sử dụng hơn.\nNgay cả các hệ thống trò chơi điện tử cũng phát triển nhanh đến mức những trò chơi quy mô lớn này hiện đang sử dụng Unity hoặc C #. Vì vậy, mọi người đang chọn những ngôn ngữ này vì chúng cung cấp khả năng tương thích đa nền tảng giống như C ++, nhưng chúng dễ làm việc hơn nhiều. Bạn có thể vào các trang tìm việc ở Việt Nam như ItViec, hoặc các trang freelacer như Upwork để tìm hiểu số lượng việc làm C++ so với python , javascrip , C# để kiểm chứng. Tại thời điểm viết bài viết này, mình search trên trang itviec và với từ khóa .NET, mình tìm thấy 238 jobs , c++ là 78 jobs, python là 264 jobs, javascrip là 484 jobs. Các bạn có thể tự đưa ra kết luận cho riêng mình dựa vào các con số trên.\nKết luận Mình hi vọng có thể cung cấp đủ thông tin để giúp bạn quyết định xem việc học C ++ có xứng đáng với bạn hay không. C ++ là một trong những ngôn ngữ lập trình hàng đầu, vì vậy hãy yên tâm rằng ngôn ngữ lập trình này sẽ không biến mất khỏi ngành công nghệ. Nhưng bạn chỉ nên học C ++ nếu nó được yêu cầu trong vai trò công việc của bạn hoặc trong lĩnh vực mà nó được sử dụng rộng rãi. Ngược lại, bạn hãy quay xe đúng lúc. Mình sẽ biên soạn thêm nhiều bộ giáo trình học các ngôn ngữ lập trình khác nữa. See Ya\n","date":"Feb 20, 2022","img":"","permalink":"/courses/cplusplus/1_introduction/","series":["Khóa học c++ căn bản"],"tags":["c++"],"title":"Bài 1: Giới Thiệu Về C++"},{"categories":"c++","content":"Lời giới thiệu Chúng ta cần một phần mềm có chất lượng tốt tốt một chút để hỗ trợ coding nhanh, gọn, lẹ. Các bạn có thể sử dụng các phần mềm miễn phí như Eclipse, NetBean, CodeBlock, Notepad++ \u0026hellip;.\nTrong bài viết này, mình đề nghị các bạn cài visual studio hoặc visual studio code. Visual stuido là một phần khá bá đạo, hỗ trợ mạnh mẽ, giúp các bạn lập trình viên coding một cách thoải mái mà không phải vướng bận các vấn đề cấu hình bên ngoài. Nếu có điều kiện, các bạn nên sử dụng phiên bản visual studio enterpise, được mở khóa tất cả các tính năng giúp chúng ta chỉ cần tập trung vào coding.\nCài đặt trên Windows Tại thời điểm mình viết bài viết này, Visual Studio 2022 là phiên bản mới nhất. Các bạn có thể cài phiên bản Visual Studio 2019 vẫn được. Hãy download bộ cài visual studio tại link https://visualstudio.microsoft.com/downloads/ và cài đặt bình thường.\nTrên MacOS   Cài Visual studio code bản mới nhất từ trang chủ microsoft\n  Cài extentsion c/c++\n  Cài Clang\nCâu lệnh để kiểm tra clang đã được cài hay chưa\n1clang --version Nếu chưa , mở terminal lên và paste đoạn lệnh này vào để cài\n1xcode-select --install   Online Compilers Thử tưởng tượng bạn đang ngồi trên xe buýt, trên tay có 1 chiếc điện thoại trang bị 4G đầy đủ, bạn có 1 ý tưởng lóe lên về một hàm nào đấy. Bạn phải làm sao ???\nCác đơn giản nhất là truy cập vào một website compiler c++ online, dev ngay cái ý tưởng của bạn và chạy thử xem như thế nào. Hiện nay, có rất nhiều trang web hỗ trợ chúng ta biên dịch mã nguồn c++ online và xem kết quả tức thì. Trong bài viết này, mình giới thiệu các bạn trang http://cpp.sh/. Lý do là trang này không có chứa quảng cáo, những trang khác ít nhiều có chèn quảng cáo, mình không thích.\ntrang web cpp.sh\nTrang này hỗ trợ 3 trình biên dịch là c++98, c++11 và c++ 14. Ngoài ra, trang web còn hỗ trợ chúng ta sinh ra shot link để gửi mã nguồn ý tưởng của chúng ta cho bạn bè, khá tiện lợi.\n","date":"Feb 20, 2022","img":"","permalink":"/courses/cplusplus/2_ide/","series":["Khóa học c++ căn bản"],"tags":["c++"],"title":"Bài 2: Cài Đặt Công Cụ Hỗ Trợ"},{"categories":"c++","content":"Chương trình đầu tiên, Hello World Mã nguồn\n1#include \u0026lt;iostream\u0026gt;2using namespace std; 34// main() is where program execution begins. 5int main() { 6cout \u0026lt;\u0026lt; \u0026#34;Hello World. My name AlexBlack.\u0026#34;; // prints Hello World. My name AlexBlack. 7 return 0; 8} Các bạn hãy thực hiện các bước mình mô tả kỹ ở bên dưới\n  Mở text editor bất kỳ, ví dụ visual studio code.\n  Tạo 1 file text, đặt tên là main.cpp\n  Copy đoạn mã lệnh bên dưới, quăng vào file main.cpp vừa tạo\n  Mở terminal (cmd trên windown), cd vào thư mục chưa file main.cpp bạn vừa tạo.\n  Gõ \u0026lsquo;g++ hello.cpp\u0026rsquo; và ấn nút enter. Nếu không có bất kỳ lỗi nào xảy ra, sau khi thực thi xong đoạn lệnh trên, chương trình sẽ sinh ra 1 file có tên là a.out\n  gõ \u0026lsquo;a.out\u0026rsquo; để chạy chương trình\n  Bạn sẽ nhìn thấy dòng chữ \u0026ldquo;Hello World. My name AlexBlack.\u0026rdquo; trên màn hình terminal của bạn\n  1g++ main.cpp 2./a.out 3Hello World. My name AlexBlack. Giải thích:\nMột chương trình c++ là một tổ hợp bao gồm nhiều câu lệnh, mỗi câu lệnh có nhiệm vụ và chức năng khác nhau, với đoạn code helloworld phía trên, chương trình có chứa các thành phần.\n  Dòng đầu tiên, khai báo header thư viện mà chúng ta sử dụng. Ở đây, chúng ta sử dụng thư viện iostream. Đây là thư viện cơ bản, nằm trong bộ thư viện chuẩn của c++.\n  Dòng tiếp theo using namespace std; báo cho trình biên dịch biết sử dụng namespace std. Khái niệm namespace mình sẽ đề cập ở các chương tiếp theo, đến chương đó, các bạn sẽ hiểu lý do dùng nó, có nên xóa nó đi hay không. Ở bước cơ bản này, các bạn chỉ việc copy đoạn lệnh này rồi quăng vào xài, đừng thắc mắc, phân tâm.\n  Dòng tiếp theo // main() is where program execution begins. Đây là đoạn comment 1 dòng trong c++. Trình biên dịch gặp // thì sẽ bỏ qua, không biên dịch nội dung ở sau đoạn //. Comment 1 dòng được bắt đầu bởi dấu //, và kết thúc bởi ký tự xuống dòng.\n  Dòng *int main() * là tên hàm chính. Bất kỳ một chương trình c++ nào, đều có hàm bắt đầu là main. Trình biên dịch sẽ tìm hàm main để bắt đầu chạy thực thi.\n  Dòng cout \u0026laquo; \u0026ldquo;Hello World. My name AlexBlack.\u0026rdquo;; // prints Hello World. My name AlexBlack. in ra dòng chữ Hello World. My name AlexBlack. lên màn hình\n  Dòng *return 0; * kết thúc chương trình, trả về giá trị 0 cho chương trình cha gọi chương trình của mình đang viết.\n  Ở tiếng việt, chúng ta kết thúc câu bởi dấu \u0026lsquo;chấm(.)\u0026rsquo;. Ngôn ngữ C/C++ kết thúc câu bởi dấu chấm phẩy \u0026lsquo;;\u0026rsquo;. Ở ví dụ trên, câu \u0026lsquo;cout \u0026laquo; \u0026ldquo;Hello World. My name AlexBlack.\u0026rdquo;;\u0026rsquo; được kết thúc bởi dấu chấm phẩy. Nếu thiếu dấu chấm phẩy, trình biên dịch sẽ báo lỗi cú pháp (có đề cập ở mục lỗi, bên dưới)\n  Comment trong c++ C++ hỗ trợ hai loại comment. Comment một dòng và comment nhiều dòng\nComment một dòng, bắt đầu bằng dấu // kết thúc bằng ký tự xuống dòng. Ví dụ như đoạn mã lệnh hello world ở trên, có 2 cái comment 1 dòng.\nVí dụ:\n1trời nắng, đường vắng Comment nhiều dòng, bắt đầu bằng dấu /*, kết thúc bằng đấu */. Khi bạn muốn viết 1 đoạn chú thích dài, nêu nổi bật vấn đề đang gặp phải, hoặc cách xử lý hay của bạn, hoặc bất kỳ vấn đề gì mà bạn muốn note lại để sau này đọc rõ hơn.\n1/* hôm nay trời nắng chang chang 2mèo con đi học chẳng mang thứ gì */ Một câu hỏi thường được đặt ra là có nên comment hay không. Theo ý kiến riêng của mình là nên. Comment càng nhiều càng tốt, càng chi tiết càng tốt. Tất nhiên là chúng ta phải comment trọng tâm của vấn đề, tránh comment lang mang.\nThử đặt trường hợp, bạn viết 1 hàm tìm điểm rơi của viên bi sắt có khối lượng x khi ném bằng tay phải với góc ném y và lực ném z. 1 tuần sau bạn đọc lại đoạn mã nguồn đó, bạn tự tin rằng mình sẽ hiểu bao nhiêu phần?\nErrors and Warnings Lỗi là một hoạt động bất hợp pháp được thực hiện bởi người dùng dẫn đến hoạt động bất thường của chương trình.\nCác lỗi lập trình thường không bị phát hiện cho đến khi chương trình được biên dịch hoặc thực thi. Một số lỗi ngăn cản chương trình được biên dịch hoặc thực thi. Vì vậy, các lỗi cần được loại bỏ trước khi biên dịch và thực thi.\nCác lỗi phổ biến nhất có thể được phân loại như sau.\n  Lỗi trong C++    Syntax errors Run-time Errors Linker Errors Logical Errors     1. Syntax errors (lỗi cú pháp) Là lỗi khi mình vi phạm các luật của việc viết code c++. Các lỗi dạng này thường được phát hiện bởi trình biên dịch, nên nó còn có tên gọi khác là compile-time errors. Khi gặp lỗi này, chúng ta sẽ không biên dịch thành công mã nguồn của chương trình.\nMột số lỗi cú pháp phổ biến:\n  Viết thiếu dấu ;\n  Viết thiếu dấu đóng ngoặc/mở ngoặc.\n  Sử dụng biến chưa được khai báo.\n  1// C++ program to illustrate syntax error 2 3#include \u0026lt;iostream\u0026gt;4 5int main() 6{ 7int x = 10; 8int y = 15; 910std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; x\u0026lt;\u0026lt; z \u0026lt;\u0026lt;std::endl // semicolon missed 11 12return 0; 13} 1415//Mã nguồn này được viết và chia sẻ bởi Phạm Duy Tùng. Khi chạy dòng code lên, ta sẽ gặp thông báo lỗi:\n1main.cpp:11:41: error: expected \u0026#39;;\u0026#39; after expression 2std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; x\u0026lt;\u0026lt; z \u0026lt;\u0026lt;std::endl // semicolon missed 3^ 4; 5main.cpp:11:28: error: use of undeclared identifier \u0026#39;z\u0026#39; 6std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; x\u0026lt;\u0026lt; z \u0026lt;\u0026lt;std::endl // semicolon missed 7^ 82 errors generated. Đoạn báo lỗi trên nhắc là chúng ta thiếu đấu ; sau biểu thước ở dòng 11 cột 41. Và sử dụng biến z chưa được khai báo.\n2. Run-time Errors Lỗi xảy ra trong quá trình chạy chương trình, khi chương trình đã build thành công. Một lỗi phổ biến trong nhóm lỗi này là lỗi chia cho 0.\n1// C++ program to illustrate Run-time error 2 3#include \u0026lt;iostream\u0026gt;4 5int main() 6{ 7int x = 10; 8int x = 0; 9std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; x/ z \u0026lt;\u0026lt;std::endl; // run-time error 10 11return 0; 12} 1314//Mã nguồn này được viết và chia sẻ bởi Phạm Duy Tùng. 3. Linker Errors Lỗi này xảy ra khi ta viết chương trình có sử dụng thêm thư viện ngoài, hoặc thư viện do chính chúng ta viết. Trong quá trình biên dịch, trình biên dịch đã biên dịch thành công các file, nhưng không thể liên kết các file lại với nhau.\n1// C++ program to illustrate Linker error 2#include \u0026lt;iostream\u0026gt;3int Main() 4{ 5return 0; 6} 78//Mã nguồn này được viết và chia sẻ bởi Phạm Duy Tùng. Trong C/C++ quy định hàm main phải là chữ main (viết thường), ở đây chương trình không tìm được hàm main để bắt đầu thực thi, nên báo lỗi như bên dưới.\n1Undefined symbols for architecture arm64: 2\u0026#34;_main\u0026#34;, referenced from: 3implicit entry/start for main executable 4ld: symbol(s) not found for architecture arm64 5clang: error: linker command failed with exit code 1 (use -v to see invocation) 4. Logical Errors Lỗi này xảy ra khi chúng ta nhỡ tay gõ một cái gì đó sai trái làm cho đoạn chương trình không làm đúng theo logic đã được thiết kế từ trước.\n1// C++ program to illustrate Logical error 2#include\u0026lt;iostream\u0026gt;3using namespace std; 45int main(){ 6// logical error : a semicolon after loop 7 int i=1; 8while (true); 9{ 10i++; 11if(i\u0026gt;10)return i; 12} 1314return 0; 15} 16//Mã nguồn này được viết và chia sẻ bởi Phạm Duy Tùng. Ví dụ trên, mình đã nhỡ tay gõ thêm ký tự ; sau vòng lặp while, làm chương trình lặp vô tận và không có lối thoát.\n1main.cpp:7:17: warning: while loop has empty body [-Wempty-body] 2while (true); 3^ 4main.cpp:7:17: note: put the semicolon on a separate line to silence this warning 51 warning generated. Trong trường hợp mình mắc các lỗi phổ biến, trình biên dịch có thể đưa ra cảnh báo và đưa ra nhắc nhở cho chúng ta.\nCâu lệnh và hàm Câu lệnh Câu lệnh là một phần chương trình c/c++, được thực thi một cách tuần tự.\nVí dụ\n1// C++ program to illustrate statement 2#include\u0026lt;iostream\u0026gt;3using namespace std; 45int main(){ 6// logical error : a semicolon after loop 7 int i=1; // câu lệnh khai báo declaration statement 8 while (true) //Câu lệnh điều kiện 9 { 10i++; //Câu lệnh biểu thức 11 if(i\u0026gt;10) //Câu lệnh điều kiện 12 return i; //Câu lệnh return 13 } 1415return 0; //Câu lệnh return. 16} 17//Mã nguồn này được viết và chia sẻ bởi Phạm Duy Tùng. Hàm Hàm là nhóm các câu lệnh lại với nhau, để thực hiện một nhiệm vụ. Một chương trình c++ có ít nhất 1 hàm main.\nBạn có thể tùy ý tách các đoạn code nhỏ ra thành nhiều hàm khác nhau. Phụ thuộc vào phong cách code của bạn. Không ai quy định phải tách hàm như thế nào cả. Thông thường, các lập trình viên sẽ tách hàm theo chức năng, công dụng của hàm.\nCấu trúc một hàm bao gồm :\n1return_type function_name( parameter list ){ 2body ; 3} Trong thư viện c++ chuẩn có cung cấp cho chúng ta kha khá các hàm được xây dựng sẵn, ví dụ hàm làm tròn lên ceil, hàm làm tròn xuống floor. Các bạn có tham khảo trong https://en.cppreference.com/w/cpp/header.\nNhập, xuất dữ liệu Thư viện C++ hỗ trợ chúng ta nhiều thư viện nhập xuất. Trong C++, dữ liệu được thực hiện là một chuỗi tuần tự các byte. Từ chuyên ngành là streams. Vì vây, nên chia làm 2 dạng.\n  Input stream: Chuỗi các byte được đưa từ bên ngoài (bàn phím, mạng lan, file \u0026hellip;) vào trong bộ nhớ -\u0026gt; gọi là chuỗi dữ liệu nhập , hay gọi là nhập liệu.\n  Output stream: chuỗi các byte từ bộ nhớ chính đi ra (hiển thị lên màn hình, , qua mạng lan, ra đèn led \u0026hellip; ) -\u0026gt; gọi là chuỗi dữ liệu xuất.\n  Ở đây, mình sẽ sử dụng iostream có trong thư viện cơ sở của C++ làm ví dụ minh họa, ngoài ra, c++ còn có iomanip và fstream, các bạn có thể tìm hiểu thêm\n12// C++ program to illustrate data stream 3#include\u0026lt;iostream\u0026gt;4using namespace std; 56int main(){ 7int age; 89cout \u0026lt;\u0026lt; \u0026#34;nhap vao so tuoi cua ban: \u0026#34;; 10cin \u0026gt;\u0026gt; age; 11cout \u0026lt;\u0026lt; endl\u0026lt;\u0026lt;\u0026#34;Tuoi cua ban la: \u0026#34; \u0026lt;\u0026lt; age\u0026lt;\u0026lt;endl; 1213return 0; 14} 1516//Mã nguồn này được viết và chia sẻ bởi Phạm Duy Tùng. Trong ví dụ trên, mình sử dụng hàm nhập liệu là cin ( đọc là xi in), có sẵn trong iostream. Hàm sẽ nhận các ký tự mình gõ trên bàn phím, kết thúc bởi dấu enter ( giả sử mình nhập số 5 rồi ấn enter). Bản chất bên trong là các ký tự mình gõ trên bàn phím sẽ biến thành mỗi chuỗi tuần tự các byte (stream) và đẩy vào trong bộ nhớ ram.\nĐể hiển thị lên màn hình, chúng ta dùng hàm cout ( đọc là xi ao). Bản chất bên trong là dữ liệu chúng ta muốn hiển thị lên màn hình sẽ mã hóa thành chuỗi tuần tự byte và đẩy ra các thiết bị ngoại vi.\n1nhap vao so tuoi cua ban: 5 23Tuoi cua ban la: 5 Phân biệt C++ Standard library và STL STL và C++ Standard library là 2 ông khác biệt hoàn toàn, phân biệt như sau.\nC++ Standard library C++ Standard library là tập các thư viện chuẩn của C Standard Library, được viết lại dưới dạng tên khác, thông thường là bị xóa .h đi và thêm chữ c ở đầu. Ví dụ thư viện time.h trong c sẽ được xào nấu thành ctime\nSTL STL là từ viết tắt của Standard Template Library , là thư viện bao gồm 4 thành phần chính là algorithms, containers, Numeric, và iterators. Giúp tăng sự linh hoạt và mềm dẻo của C++. Cụ thể\nContainer Containers - tiếng việt dịch ra là thùng chứa, là đối tượng dùng để chứa các đối tượng khác. Container lưu trữ và quản lý các đối tượng, cung cấp các hàm để truy xuất đến các đối tượng.\nContainer được phân loại như sau:\n  Sequence containers\n vector deque list    Associative containers\n set multiset map multimap hash_set hash_map hash_multiset hash_multimap    Containers adpators\n Stack Queue Priority_queue    Phụ thuộc vào bài toán mà chúng ta sẽ lựa chọn container phù hợp để đáp ứng độ phức tạp và thời gian thực thi. Không nên xài đại 1 loại container nào đó.\nIterators Iterators là đối tượng giúp lập trình viên duyệt containers. Chỉ có 2 loại nhóm container là Sequence container và Associative container mới có iterator\nCó 5 loại iterators được hỗ trợ trong c++ là:\n input (dùng để đọc chuỗi giá trị) output (dùng để ghi chuỗi giá trị) forward ( đọc, ghi, di chuyển lên đến 1 vùng khác) bidirectional (đọc, ghi , di chuyển lên, di chuyển xuống) random access (nhảy tự do đến 1 bước khác)  Algorithms Algorithms chứa tập các hàm giúp xử lý nhiều phần tử. Ví dụ sort dùng để xắp xếp các phần tử theo thứ tự. binary_search giúp tìm kiếm dữ liệu dạng nhị phân, cho tốc độ tìm kiếm cao hơn\u0026hellip;.\nNumeric Là tập các thư viện hỗ trợ lập trình viên thực hiện các phép toán trên số. Ví dụ complex hỗ trợ các template và các hàm tính toán số phức.\n","date":"Feb 20, 2022","img":"","permalink":"/courses/cplusplus/3_steep/","series":["Khóa học c++ căn bản"],"tags":["c++"],"title":"Bài 3: Làm Quen Với C++"},{"categories":null,"content":"Tools sinh mật khẩu thông minh, tự động, tránh làm lộ mật khẩu\nChiều dài:     Generate Password   Ký tự thường: abcd     Ký tự hoa: ABCD      Ký số: 1234     Ký tự đặc biệt @#$!       Pass của bạn:  copy \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp;   function makeCopy(){ var textarea = document.getElementById(\"final_pass\"); textarea.select(); document.execCommand('copy'); } function init(){ const weak_elem = document.getElementById(\"opg_weak\"); for(var loop_index=6;loop_indexx.toUpperCase()); const SYMBOLS = '!£$%^\u0026*()@~:;,./?{}=-_'.split(''); const NUMBERS = '1234567890'.split(''); function containsLowerCase(str) { if (is_lower_case){ return LOWER_CASE_CHARS.some((x) = str.includes(x)); } return true; } function containsUpperCase(str) { if (is_upper_case){ return UPPER_CASE_CHARS.some((x) = str.includes(x)); } return true; } function containsSymbol(str) { if (is_symbol){ return SYMBOLS.some((x) = str.includes(x)); } return true; } function containsNumber(str) { if (is_number){ return NUMBERS.some((x) = str.includes(x)); } return true; } var ramdom_list =[]; var is_lower_case=false; var is_upper_case=false; var is_number=false; var is_symbol=false; if(lower_case){ is_lower_case=true; ramdom_list.push(...LOWER_CASE_CHARS); } if(upper_case){ is_upper_case=true; ramdom_list.push(...UPPER_CASE_CHARS); } if(numbers){ is_number=true; ramdom_list.push(...NUMBERS); } if(symbols){ is_symbol=true; ramdom_list.push(...SYMBOLS); } function isValidPassword(password) { return containsLowerCase(password) \u0026\u0026 containsUpperCase(password) \u0026\u0026 containsSymbol(password) \u0026\u0026containsNumber(password) ; } var arr_length = ramdom_list.length; if(arr_lengthramdom_list[x % arr_length]).join(''); } while (!isValidPassword(generatedPassword)); return generatedPassword; } document.getElementById(\"final_pass\").value = generateStrongPassword(random_length); }   Một số lưu ý khi đặt mật khẩu Để tránh cho mật khẩu bị tấn công bởi yếu hacker bằng kỹ thuật tấn công từ điển, tấn công từ điển, tấn công bằng social engineering, và giữ cho tài khoảng online của bạn được an toàn, bạn nên thực hiện những điều sau:\n   Không nên sử dụng chung mật khẩu, câu hỏi bảo mật, câu trả lời bảo nhật cho cùng các tài khoảng quang trọng như ngân hàng, email, facebook\u0026hellip;    Sử dụng mật khẩu có chiều dài ít nhất là 16 ký tự, trong đó ít nhất phải chứa 1 ký số, 1 ký tự viết hoa và 1 ký tự đặc biệt.    Không nên sử dụng họ/tên của mình hoặc những người trong gia đình, tên thú cưng, ngày tháng năm sinh của mình/gia đình mình để đặt mật khẩu    Không nên sử dụng mã bưu chính, số nhà, tên đường, số điện thoại, ngày sinh nhật, số chứng minh nhân dân / căn cước công dân, số bảo hiểm xã hội, số bảo hiểm y tế, bất kỳ số gì mà có thể định danh là bạn làm mật khẩu.    Không nên sử dụng những mật khẩu đã bị công bố tên internet làm mật khẩu. Ví dụ như 123456, iloveyou, qwerty\u0026hellip;    Không nên sử dụng mật khẩu có đoạn ký tự trùng nhau, ví dụ iloveyoupacpac, cualolocua, \u0026hellip;    Không nên sử dụng những thứ có thể bị copy (mà bạn không thể thay đổi) làm mật khẩu. ví dụ như là xác thực bằng vân tay, khuôn mặt (Trong điều kiện bạn muốn an toàn tuyệt đối, thì không nên bật xác thực vân tay và xác thực khuôn mặt trên iphone , hi hi).    Không nên cho phép trình duyệt lưu toàn bộ mật khẩu (các trình duyệt hỗ trợ lưu mật khẩu như FireFox, Chrome, Safari, Opera, IE, Microsoft Edge ). bởi vì chúng ta có thể dễ dàng lấy lại mật khẩu từ trình duyệt.    Không nên đăng nhập vào tài khoảng quang trọng trên máy người lạ. Không nên đăng nhập vào tài khoảng quang trọng khi sử dụng wifi công cộng, free VPN, free web proxy, tor\u0026hellip;    Không nên gửi các thông tin quang trọng qua các giao thức chưa được mã hóa( ví dụ HTTP, FTP ), bởi vì các thông tin đó có thể được đánh cắp một cách dễ dàng qua kỹ thuật sniffed. Bạn nên sử dụng các giao thức đã được mã hóa như là HTTPS, SFTP, FTPS, SMTPS, IPSec bất cứ khi nào có thể.    Khi đi du lịch, và sử dụng mạng internet / wifi miễn phí, nếu có thể, hãy mã hóa thông tin của bạn trước khi gửi đi. Ví dụ, bạn có thể sử dụng phần mềm hỗ trợ tạo VPN cá nhân hỗ trợ giao thức WireGuard( hoặc IKEv2, OpenVPN, SSTP, L2TP over IPSec ) vào server cá nhân của bạn( máy tính ở nhà, server bạn dựng trên AWS, VPS\u0026hellip;). Hoặc bạn có thể thiết lập mã hóa kết nối SSH giữa máy bạn và server của bạn, và sau đó cấu hình cho Chrome hoặc FireFox sử dụng socks proxy của bạn. Do đó, ngay cả khi người xấu đã sniff được mảnh dữ liệu thông tin của bạn, họ cũng không thể xem được nó, bởi vì dữ liệu đã được mã hóa.    Thông thường, người dùng sẽ rất tự tin rằng mật khẩu họ đặt rất mạnh và khó bị hack. Nhưng trong thực tế, không có gì có thể bảo đảm được điều đó. Một trong những cách có thể kiểm tra là bạn sử dụng một chương trình hash md5 mật khẩu của bạn lại, kiểm tra trên các trạng MD5 decryption website, và kiểm tra xem đoạn md5 của bạn sẽ bị crack trong vòng bao lâu.    Khuyến cáo là nên đổi mật khẩu mỗi 10 tuần 1 lần, đối với các tài khoảng quang trọng. Một số tổ chức ngân hàng như techcombank ở Việt Nam có thực hiện theo khuyến nghị này, nhưng với số tuần dài hơn.    Thông thường, chúng ta không thể nhớ hết tất cả toàn bộ mật khẩu của chúng ta dã đặt ra. Vì vậy, có một cách khác để thực hiện là chỉ nhớ mật khẩu của những tài khoảng quang trọng. Đối với những tài khoảng ít quang trọng hơn, chúng ta có thể lưu dưới dạng text file và mã hóa file text này bằng các phần mềm như 7-zip, GPG hoặc BitLocker.    Nên sao lưu bản mã hóa file text mật khẩu ở một vài nơi, ví dụ đẩy lên email, lưu ở ổ phụ. Để nhỡ xui rủi, vì một lý do nào đó, bạn không thể truy xuất vào máy tính của bạn và lấy lại mật khẩu. Thì bạn có thể dễ dàng xem và lấy lại mật khẩu của những tài khoảng khác.    Bật xác minh hai bước bất cứ khi nào có thể.    Không nên lưu mật khẩu quang trọng trên mây    Truy cập những trang web quan trọng như paypal, ngân hàng, mail\u0026hellip; từ bookmark. Nếu truy cập từ link lại, nên check kỹ domain xem đã chính xác hay chưa. Một mẹo nhỏ là chúng ta có thể kiểm tra độ phổ biến của website bằng công cụ Alexa toolbar để chắc chắn rằng domail bạn đang truy cập không phải là hàng giả    Bảo vệ máy tính bạn bằng tường lửa và chương trình diệt virus. Chặn tất cả các kết nối vào và tất cả các kết nối ra không cần thiết bằng tường lửa. Tải các phần mềm từ các site chính thống. Check mã MD5 / SHA1 / SHA256 checksum hoặc GPG signature của phần mềm nếu có thể.    Cập nhật hệ điều hành, các phần mềm duyệt web trong máy tính của bạn lên phiên bản mới nhất để fix các lỗi bảo mật    Nếu trong máy của bạn có lưu những file cực kỳ quang trọng, ví dụ như bảng lương của công ty, tin nhắn private với trà xanh \u0026hellip; , thì nãy kiểm tra kỹ xem trong máy có chứa phần mềm keyloggers, hoặc phần cứng keyloggers( vd wireless keyboard sniffer ), hoặc camera ẩn. Những thứ ví dụ ở trên là một mối nguy hại rất lớn.    Bật tính năng khóa màn hình máy tính / máy tính bảng/ điện thoại ngay khi bạn không sử dụng chúng    Mã hóa toàn bộ ổ đĩa cứng bằng các phần mềm mã hóa như VeraCrypt, FileVault, LUKS, \u0026hellip; để bảo vệ các file quan trọng trong máy. Hãy hủy vật lý ổ cứng cũ có chứa thông tin quan trọng của bạn (thay vì ném vào sọt rác, bán ve chai)    Nếu được, hãy dùng ít nhất 3 email để nhận mail. Một mail để nhận các thông tin quang trọng từ ngân hàng, paypal hoặc những gì có yếu tố ảnh hưởng đến túi tiền của bạn. Mail thứ hai dùng để xác thực/ nhận mail từ những site không quan trọng. Mail thứ 3 nhận pasword - reset mail khi mail số 1 bị hack. Một lưu ý là mail thứ 3 nên dùng một nền tảng mail khác mail 1. Ví dụ mail 1 dùng gmail thì mail 3 dùng outlook.    Nếu được, hãy sử dụng ít nhất 2 số điện thoại. Số điện thoại đầu tiên để xác thực 2 bước với các site quang trọng như ngân hàng. Không cho gia đình, người thân, bạn bè, đồng nghiệp biết số điện thoại số 1. Số điện thoại 2 là số điện thoại public, cho bạn bè người thân liên lạc, đăng ký các app/ web ít quang trọng hơn, vd là số điện thoại đặt hàng tiki, shopee, bách hóa xanh, điện máy xanh, mua trà sửa, tán anh hàng xóm\u0026hellip;.    Đừng click vào link trong email/SMS, hãy kiểm tra đường dẫn thật kỹ, và copy paste vào new tab nếu link chính xác, không phải giả mạo. Nếu bạn xác định nó giả mạo, nãy xóa nó đi, hoặc đánh dấu spam rồi xóa nó đi.    Không gửi mật khẩu của bạn cho người khác qua email.    Cẩn thận với các chương trình online paste tools và chương trình chụp ảnh màn hình download ở trên mạng.    Nếu bạn dev web, hãy làm có tâm một chút, đừng lưu mật khẩu của người dùng dạng plain text vào database. Bạn nên lưu bản mã hóa SHA1, SHA256 hoặc SHA512, kèm thêm một chút muối, tiêu, để bảo vệ người dùng. Một ý tưởng hay là lưu thêm mã hash định danh thiết bị người dùng đang sử dụng (vd hệ điều hành, kích thước màn hình, số cpu/ram \u0026hellip;). Khi người dùng đăng nhập sai mật khẩu, và thiết bị người dùng sử dụng không giống với thiết bị đã sử dụng trước đó. Thì hãy bật xác thực 2 bước qua số điện thoại/ email sau khi người dùng đã đăng nhập được.    Nếu bạn là nhà phát triển phần mềm, hãy cố gắng cung cấp mã private key sử dụng GnuPG hoặc SHA-256 file ứng dụng của bạn để người dùng có thể kiểm tra xem file đã bị chỉnh sửa hay chưa. Nếu bạn kinh doanh online, hãy đăng ký một domain, thiết lập tài khoảng email tương ứng với domain. Điều này là cần thiết bởi vì bạn sẽ không đánh mất các thông tin liên lạc, và tài khoảng email của bạn sẽ không bị nhà cung cấp nào có thể xóa đi cả.    ","date":"Feb 20, 2022","img":"","permalink":"/utils/gen_paswords/","series":null,"tags":["password","random password","password generator"],"title":"Chương Trình Sinh Pasword Ngẫu Nhiên"},{"categories":"python","content":"Nội dung khóa học Bài 1: Giới thiệu về C++\nTổng quan ngôn ngữ C++ Tại sao nên học ngôn ngữ C++ Bài 2: Cài đặt môi trường phát triển (IDE) Visual studio 2015\nGiới thiệu Microsoft Visual Studio Hướng dẫn download và cài đặt visual studio Bài 3: Xây dựng chương trình C++ đầu tiên với Visual Studio 2015\nMột số kiến thức cần lưu ý Cách tạo và biên dịch chương trình C++ đầu tiên trên Visual Studio Một số vấn đề thường gặp đối với lập trình viên mới Bài 4: Cấu trúc một chương trình C++ (Structure of a program)\nCấu trúc của một chương trình C++ Cú pháp và lỗi cú pháp trong C++ (Syntax and syntax errors) Bài 5: Ghi chú trong C++ (Comments in C++)\nCú pháp comment trong C++ Một số kinh nghiệm khi comment trong lập trình Bài 6: Biến trong C++ (Variables in C++)\nBiến trong C++ Khởi tạo biến trong C++ (Defining a variable) Định nghĩa biến ở đâu (Where to define variables) Bài 7: Số tự nhiên và Số chấm động trong C++ (Integer, Floating point)\nTổng quan về kiểu dữ liệu cơ bản trong C++ Kiểu số nguyên (Integer) Số chấm động (Floating point numbers) Bài 8: Kiểu ký tự trong C++ (Character)\nTổng quan về kiểu ký tự (Character) Khai báo, khởi tạo và gán giá trị một biến ký tự In ký tự ra màn hình In ký tự từ số nguyên và ngược lại (Casting) Escape sequences Newline ‘\\n’ và std::endl Dấu nháy đơn ‘K’ và dấu nháy kép “Kteam” Bài 9: Kiểu luận lý và cơ bản về Câu điều kiện If (Boolean and If statements)\nTổng quan về kiểu luận lý (Boolean) Cơ bản về câu điều kiện If và Boolean Bài 10: Nhập, Xuất và Định dạng dữ liệu trong C++ (Input and Output)\nXuất dữ liệu với std::cout trong C++ Nhập dữ liệu với std::cin trong C++ Định dạng dữ liệu nhập xuất trong C++ Bài 11: Hằng số trong C++ (Constants)\nTổng quan hằng số (Constants) Hằng số với từ khóa const Hằng số với chỉ thị tiền xử lý #define Nên định nghĩa hằng số ở đâu Bài 12: Toán tử số học, toán tử tăng giảm, toán tử gán số học trong C++ (Operators)\nTổng quan về toán tử Toán tử số học trong C++ (Arithmetic operators) Toán tử gán số học trong C++ (Arithmetic assignment operators) Bài 13: Toán tử quan hệ, logic, bitwise, misc và độ ưu tiên toán tử trong C++\nToán tử quan hệ trong C++ (Relational operators) Toán tử logic trong C++ (Logical operators) Toán tử trên bit trong C++ (Bitwise operators) Các toán tử hỗn hợp trong C++ (Misc Operators) Độ ưu tiên và quy tắc kết hợp toán tử trong C++ Bài 14: Cơ bản về chuỗi ký tự trong C++ (An introduction to std::string)\nTổng quan về chuỗi ký tự (std::string) Khai báo, khởi tạo và gán giá trị một chuỗi ký tự Xuất một chuỗi ký tự (string output): Nhập một chuỗi ký tự (string input) Một số thao tác cơ bản với chuỗi ký tự Bài 15: Biến cục bộ trong C++ (Local variables in C++)\nTổng quan về tầm vực của biến Biến cục bộ (Local variables) Bài 16: Biến toàn cục trong C++ (Global variables in C++)\nTổng quan về tầm vực của biến Biến toàn cục (Global variables) Sử dụng biến toàn cục là nguy hiểm Khi nào cần sử dụng biến toàn cục (non-const) Bài 17: Biến tĩnh trong C++ (Static variables in C++)\nTổng quan về biến tĩnh (static variables) Khi nào nên sử dụng biến tĩnh Bài 18: Ép kiểu ngầm định trong C++ (Implicit type conversion in C++)\nTổng quan về ép kiểu dữ liệu Ép kiểu ngầm định trong C++ (Implicit type conversion) Bài 19: Ép kiểu tường minh trong C++ (Explicit type conversion in C++)\nÉp kiểu tường minh trong C++ (Explicit type conversion) Bài 20: Cơ bản về Hàm và Giá trị trả về (Basic of functions and return values)\nTổng quan về hàm (functions overview) Giá trị trả về (return values) Giá trị trả về của kiểu void (return values of type void) Bài 21: Truyền Giá Trị cho Hàm (Passing Arguments by Value)\nTham số và đối số của hàm (Function parameters and arguments) Truyền giá trị cho hàm (Passing arguments by value) Tổng kết về phương pháp truyền giá trị cho hàm (Passing argument by value) Bài 22: Truyền Tham Chiếu cho Hàm (Passing Arguments by Reference)\nTruyền tham chiếu cho hàm (Passing arguments by reference) Truyền tham chiếu hằng (Pass by const reference) Tổng kết về phương pháp truyền tham chiếu cho hàm (Passing arguments by reference) Bài 23: Tiền khai báo và Định nghĩa Hàm (Forward declarations and Definitions of Functions)\nLỗi “identifier not found” Tiền khai báo và nguyên mẫu hàm (Forward declaration and function prototypes) Khai báo và định nghĩa trong C++ (Declarations and definitions in C++) Bài 24: Giới thiệu về cấu trúc điều khiển (Control flow introduction)\nTổng quan về cấu trúc điều khiển trong C++ Câu lệnh dừng (halt) Câu lệnh nhảy (Jumps) Cấu trúc rẽ nhánh có điều kiện (Conditional branches) Cấu trúc vòng lặp (Loops) Xử lý ngoại lệ (Exceptions handling) Bài 25: Câu điều kiện If và Toán tử điều kiện (If statements and Conditional operator)\nCâu điều kiện If Toán tử điều kiện (Conditional operator) Bài 26: Câu điều kiện Switch trong C++ (Switch statements)\nCâu điều kiện Switch (Switch statements) Khai báo và khởi tạo biến bên trong case statement Bài 27: Câu lệnh Goto trong C++ (Goto statements)\nTổng quan về câu lệnh Goto trong C++ Một số vấn đề của câu lệnh Goto Bài 28: Vòng lặp While trong C++ (While statements)\nTổng quan về cấu trúc vòng lặp Vòng lặp while (while statements) Bài 29: Vòng lặp Do while trong C++ (Do while statements)\nVòng lặp do while (do while statements) Bài 30: Vòng lặp For trong C++ (For statements)\nVòng lặp for (for statements) Bài 31: Từ khóa Break and continue trong C++\nTừ khóa break Từ khóa continue Bài 32: Phát sinh số ngẫu nhiên trong C++ (Random number generation)\nTổng quan về phát sinh số ngẫu nhiên Phát sinh số ngẫu nhiên trong C++ Phát sinh số ngẫu nhiên trong C++ 11 Bài 33: Mảng 1 chiều trong C++ (Arrays)\nTại sao lại sử dụng mảng? Tổng quan về mảng 1 chiều Khai báo và khởi tạo mảng 1 chiều Xuất các phần tử mảng 1 chiều Nhập dữ liệu cho mảng 1 chiều Phát sinh dữ liệu ngẫu nhiên cho mảng 1 chiều Bài 34: Các thao tác trên Mảng một chiều\nTruyền mảng vào hàm (passing arrays to functions) Nhập và xuất mảng 1 chiều Sao chép mảng 1 chiều Tìm kiếm phần tử trong mảng Sắp xếp mảng 1 chiều Thêm và xóa một phần tử trong mảng Bài 35: Mảng 2 chiều trong C++ (Two-dimensional arrays)\nMảng 2 chiều là gì? Khai báo và khởi tạo mảng 2 chiều Xuất các phần tử mảng 2 chiều Nhập các phần tử mảng 2 chiều Bài 36: Các thao tác trên Mảng 2 chiều\nTruyền mảng vào hàm (passing arrays to functions) Nhập và xuất mảng 2 chiều Tính tổng các phần tử trong mảng Tìm giá trị lớn nhất của mảng 2 chiều Bài 37: Mảng ký tự trong C++ (C-style strings)\nMảng ký tự (C-style strings) là gì? Khai báo và khởi tạo mảng ký tự (C-style strings) Xuất mảng ký tự (C-style strings) với std::cout Nhập mảng ký tự (C-style strings) với std::cin Bài 38: Các thao tác trên Mảng ký tự (C-style strings)\nMột số thao tác với mảng ký tự (C-style strings)\nhttps://www.freecodecamp.org/news/learn-c-with-free-31-hour-course/\n⌨️ (0:00:00) Introduction to data structures ⌨️ (0:06:33) Data Structures: List as abstract data type ⌨️ (0:19:40) Introduction to linked list ⌨️ (0:36:50) Arrays vs Linked Lists ⌨️ (0:49:05) Linked List - Implementation in C/C++ ⌨️ (1:03:02) Linked List in C/C++ - Inserting a node at beginning ⌨️ (1:15:50) Linked List in C/C++ - Insert a node at nth position ⌨️ (1:31:04) Linked List in C/C++ - Delete a node at nth position ⌨️ (1:43:32) Reverse a linked list - Iterative method ⌨️ (1:57:21) Print elements of a linked list in forward and reverse order using recursion ⌨️ (2:11:43) Reverse a linked list using recursion ⌨️ (2:20:38) Introduction to Doubly Linked List ⌨️ (2:27:50) Doubly Linked List - Implementation in C/C++ ⌨️ (2:43:09) Introduction to stack ⌨️ (2:51:34) Array implementation of stacks ⌨️ (3:04:42) Linked List implementation of stacks ⌨️ (3:15:39) Reverse a string or linked list using stack. ⌨️ (3:32:03) Check for balanced parentheses using stack ⌨️ (3:46:14) Infix, Prefix and Postfix ⌨️ (3:59:14) Evaluation of Prefix and Postfix expressions using stack ⌨️ (4:14:00) Infix to Postfix using stack ⌨️ (4:32:17) Introduction to Queues ⌨️ (4:41:35) Array implementation of Queue ⌨️ (4:56:33) Linked List implementation of Queue ⌨️ (5:10:48) Introduction to Trees ⌨️ (5:26:37) Binary Tree ⌨️ (5:42:51) Binary Search Tree ⌨️ (6:02:17) Binary search tree - Implementation in C/C++ ⌨️ (6:20:52) BST implementation - memory allocation in stack and heap ⌨️ (6:33:55) Find min and max element in a binary search tree ⌨️ (6:39:41) Find height of a binary tree ⌨️ (6:46:50) Binary tree traversal - breadth-first and depth-first strategies ⌨️ (6:58:43) Binary tree: Level Order Traversal ⌨️ (7:10:05) Binary tree traversal: Preorder, Inorder, Postorder ⌨️ (7:24:33) Check if a binary tree is binary search tree or not ⌨️ (7:41:01) Delete a node from Binary Search Tree ⌨️ (7:59:27) Inorder Successor in a binary search tree ⌨️ (8:17:23) Introduction to graphs ⌨️ (8:34:05) Properties of Graphs ⌨️ (8:49:19) Graph Representation part 01 - Edge List ⌨️ (9:03:03) Graph Representation part 02 - Adjacency Matrix ⌨️ (9:17:46) Graph Representation part 03 - Adjacency List\n","date":"Feb 20, 2022","img":"","permalink":"/courses/python/1_introduction/introduction/","series":["Khóa học python căn bản"],"tags":["c++"],"title":"Giới Thiệu Về Python"},{"categories":null,"content":"Tools sinh số ngẫu nhiên Việc phát sinh một con số được gọi là ngẫu nhiên được sử dụng rộng rãi vì nhiều thứ trong thế giới thực được xem là được xuất hiện một cách ngẫu nhiên. Vì vậy, để mô phỏng những quá trình xảy ra như ở thế giới thực, chúng ta cần sinh các con số một cách ngẫu nhiên. Ví dụ, hình dạng của đám mây, hình dạng của các dãy núi, rừng cây, khối đá, quá trình phát triển tế bào, quá trình tiến hóa, vân vân và mây mây.\nhttps://en.wikipedia.org/wiki/Randomized_algorithm Các bạn có thể tìm đọc để hiểu thêm về các thuật toán random/giả random.\n  Quay   \u0026nbsp;     // A $( document ).ready() block. function getRndInteger(min, max) { return Math.floor(Math.random() * (max - min + 1) ) + min; } var globalRamdom = getRndInteger(0,100); function myRandom(){ var min_number = document.getElementById(\"min_number\").value || 0; var max_number = document.getElementById(\"max_number\").value || 100; min_number = parseInt(min_number) max_number = parseInt(max_number) if (max_number  min_number){ globalRamdom = getRndInteger(min_number, max_number); document.getElementById(\"result\").value = globalRamdom; }else{ document.getElementById(\"result\").value =\"min - max không hợp lệ\"; } } function copyToClipboard(){ navigator.clipboard.writeText(globalRamdom).then(function() { console.log('Async: Copying to clipboard was successful!'); }, function(err) { console.error('Async: Could not copy text: ', err); }); }  ","date":"Feb 20, 2022","img":"","permalink":"/utils/random/","series":null,"tags":["tools"],"title":"Sinh Số Ngẫu Nhiên"},{"categories":null,"content":"Giới thiệu Thu thập, tổng hợp thông tin là một ngành nghề đặc thù, có đặc điểm lâu đời. Việc ứng dụng công nghệ thông tin và tự động hoá giúp người dùng tiếp cận thông tin nhanh hơn và đưa ra quyết định chính các hơn. Trong bài viết này, mình sẽ đưa ra một vài gợI ý giúp các bạn là chuyên gia cào cấu dữ liệu có ý tưỞng để tạo nên các sản phẩm đặc biệt phục vụ nhu cầu người dùng. Tất nhiên, đây chỉ là một phần nhỏ trong thế giới phần mềm bao ra, rộng lớn ở ngoài kia thôi.\nThu thập thông tin đánh giá Nhu cầu đánh giá thông tin là một nhu cầu rất cơ bản của con người. Khi người dùng có trong tay một khoảng tiền và muốn mua một chiếc điện thoại, họ phân vân (ở thời điểm hiện tại mình viết bài viết này) có nên mua iphone 12 pro plus hay là mua iphone 13. Một website đánh giá 2 loại trên là cái mà người dùng đang mong đợi.\nMột số lĩnh vực mình gợi ý:\n  Đánh giá địa điểm du lịch\n  Đánh giá sản phẩm\n  Đánh giá các trung tâm anh văn\n  Đánh giá các trường trọng điểm\n  Đánh giá nhà hàng, khách sạn\n  Đánh giá món ăn\n  Tạo trang so sánh giá Phần lớn người dùng chỉ săm soi vào giá , họ sẽ chọn nơi nào bán giá thấp nhất, mà không care lắm về chất lượng dịch vụ. Chúng ta có thể cung cấp cho họ một trang so sánh giá chi tiết và gợi ý họ các địa điểm mua với giá rẻ nhất theo nhu cầu của họ.\n  So sánh giá điện thoại\n  So sánh giá laptop\n  So sánh giá tivi, tủ lạnh\n  Tất nhiên, ngườI dùng chỉ tìm nơi bán rẻ nhất đối với hàng mới, chính hãng, có chính sách bảo hành đàng hoàng từ hãng. Ở đây mình đề cập tới các sản phẩm được gọi là chính hãng nha.\nMột nhóm nhỏ người dùng cũng quan tâm tới hàng cũ giá rẻ, hoặc nhu cầu họ chỉ cần sản phẩm đã qua sử dụng nhưng còn tốt là được rồi. Nhóm này cũng khá đông.\nCó thể kết hợp trang so sánh giá với review chất lượng sản phẩm\nXây dựng chương trình tư vấn đầu tư cổ phiếu Hiện thời, có một nhóm nhỏ các \u0026ldquo;chuyên gia\u0026rdquo; bán các khoá học online với giá vài triệu, \u0026ldquo;dạy\u0026rdquo; ngườI dùng cách đầu tư cổ phiếu. Với các code lọc cơ bản như lọc những mã sản phẩm có giá trị giao dịch realtime \u0026gt; 10 tỷ, 5 tỷ, lọc sp có MA(25) \u0026gt; MA(100) để mua, MA(25) \u0026lt; MA(100), bộ lọc MACD, bộ lọc RSI, \u0026hellip;., Rất nhiều các chỉ số cơ bản từ các cuốn sách chứng khoáng, các bạn IT có thể code lại dễ dàng.\nỞ nước ngoài, các công ty phân tích có riêng một team BI analyst chuyên dựa vào các chỉ số , đưa ra các phân tích, nhìn nhận, đánh giá và thay đổi. Có thể kết hợp thêm yếu tố NLP trên twitter, reddit \u0026hellip;. để xác định xu hướng tăng giảm và auto đưa ra các lệnh mua bán phù hợp.\nNếu các bạn có sẵn một số tiền nhàn rỗi, và có kỹ năng it tốt, muốn thử sức kiếm thêm thu nhập, thì tại sao lại không tự viết 1 chương trình đánh giá cổ phiếu thật xịn xò cho riêng mình nhỉ.\nCác yêu cầu cơ bản   Có niềm đam mê. Tất nhiên, nếu bạn không có đam mê thì bạn thường dễ nản và bỏ cuộc, vì vậy, bạn hãy chọn lĩnh vực mà bạn đam mê và bỏ ít thời gian để thực hiện nó.\n  Tìm hiểu cách cào dữ liệu sử dụng các thư viện như http request vá beautifull soup , selenium của python, hoặc cheerio , Puppeteer của nodejs\n  Tìm hiểu cách rút trích các thông tin cần lấy và lưu vào cơ sở dữ liệu\n  Phân tích dữ liệu, rút ra các, các đặc trưng, mapping , xào chẻ dữ liệu\n  Xây dựng website tạo các bản biểu, report, notify \u0026hellip; phụ thuộc vào nhu cầu của các bạn.\n  Kiếm tiền từ nội dung bạn tạo ra. Khi bạn đã phát triển đam mê của mình ở một mức đủ lớn, hãy lan toả nó và kiếm tiền từ nó, có thể chạy quảng cáo, hoặc nhận lời đánh giá sản phẩm một cách công tâm nhất. Có nhiều cách có thể kiếm thêm thu nhập, phụ thuộc vào năng lực của các bạn.\n  Lời kết Còn nhiều ứng dụng nữa, các bạn có thể tự làm dựa vào khả năng của bạn, ví dụ như chương trình thu thập thông tin facebook, instagram \u0026hellip; , thu thập thông tin thời tiết, thu thập thông tin giá vàng. Có vô vàng các thứ đang chờ các bạn khám phá.\nCảm ơn các bạn đã theo dõi bài viết. Hẹn gặp lại ở các bài viết tiếp theo.\n","date":"Nov 6, 2021","img":"","permalink":"/blog/2021-11-06-some-way-make-momey-from-web-scrapping/","series":null,"tags":["machine learning","scraping"],"title":"Một Số Cách Kiếm Thêm Thu Nhập Từ Cách Cào Dữ Liệu"},{"categories":null,"content":"Giới thiệu Cờ tướng là một môn thể thao khá phổ biến ở Việt Nam. Các bạn có thể bắt gặp các bàn cờ ở các con hẻm của mỗi góc phố. Hoặc là khi các bộ bàn ghế đá thì người mua cũng thường nhờ thợ khắc lên bàn cờ tướng để hàng xóm láng giềng giải trí ngày cuối tuần. Trong bài viết này, mình sẽ hướng dẫn step by step ứng dụng chơi game cờ tướng đơn giản với một chút AI. Hi vọng sẽ giúp được các bạn trên con đường thực hành máy học.\nCác việc cần làm:\n  Tạo bàn cờ và sinh nước đi\n  Lượng giá bàn cờ\n  Áp dụng minimax\n  Áp dụng cắt tỉa alpha, beta\n  Bạn có thể chơi thử game cờ tướng mình có post ở đây: https://www.phamduytung.com/games/china_chess/\nBước 1: Tạo bàn cờ và sinh nước đi Mình không có gỏi lắm trong việc thiết kế mấy icon cho mấy con tướng, sĩ, tượng. Ngoài ra, công việc chính của chúng ta là phần làm sao cho máy tự đánh được, nên phần này mình sẽ xài các open source có sẵn, lượn lờ một chút trên mạng thì mình đã lụm được cái bàn cờ ở link https://github.com/lengyanyu258/xiangqiboardjs và thư viện sinh nước đi xiangqi.js. Thư viện xiangqi.js đã có sẵn các hàm kiểm tra tính hợp lệ của nước đi, nên mình chỉ việc lấy ra rồi dùng thôi, khỏi mất công phải viết lại.\nBàn cờ được chia làm 2 đội, là đội đen (black, ký hiệu b) và đội đỏ (red , ký hiệu r), mỗi đội gồm 16 quân, bao gồm 1 con tướng (General hoặc king , ký hiệu k), 2 con sỹ (Advisor hoặc guards, ministers, ký hiệu là a), 2 con tượng (Elephants hoặc bishops - ký hiệu là b), 2 con mã (Horses hoặc knights - ký hiệu là n, do chữ k trùng với king là con tướng, nên người ta xài chữ n), 2 con xe (Chariot hoặc rooks - ký hiệu là r), 2 con pháo (canons, ký hiệu là c ), 5 con chốt (Soldiers , ký hiệu là p ( do con chốt ở cờ đen và cờ đỏ có phiên âm tiếng trung khác nhau, chốt cờ đen đọc gần giống chữ \u0026ldquo;zú\u0026rdquo; (\u0026ldquo;pawn\u0026rdquo; hoặc \u0026ldquo;private\u0026rdquo; - tiếng anh), còn chốt cờ đỏ đọc là bing (\u0026ldquo;soldier\u0026rdquo; - tiếng anh) )).\nTổng cộng, ta có tướng, sỹ, tượng, mã, xe, pháo, chốt, 7 loại quân, tương đương với 7 ký hiệu, tổ hợp với 2 đội là đỏ và đen, tổ hợp với nhau, ta xác định được\nĐể bắt đầu, chúng ta sẽ code một hàm random bước đi đơn giản. Hàm có nhiệm vụ lấy ngẫu nhiên một bước đi trong danh sách các bước có thể đi, sau đó máy sẽ đánh bước đi đó.\n123function makeRandomMove () { 4let possibleMoves = game.moves(); 56// game over 7 if (possibleMoves.length === 0) return; // Không còn nước nào có thể đi, end game 8 9let randomIdx = Math.floor(Math.random() * possibleMoves.length); // bốc đại 1 nước đi trong danh sách các bước có thể đi 10 game.move(possibleMoves[randomIdx]); 11board.position(game.fen()); 12} Do thuật toán chúng ta cho máy chạy khá là ngốc, nên nó đánh cũng hơi ngốc. :)\nBước 2: Hàm lượng giá Dựa vào mức độ cơ động, tầm quang trọng của mỗi quân lính trên bàn cờ, chúng ta sẽ gán cho mỗi quân cờ một trọng số khác nhau thể hiện điều đó.\nVí dụ, chúng ta set các trọng số như sau:\ntướng của ta là 900 điểm, tướng của đối thủ là -900 điểm\nsỹ của ta là 20 điểm, sỹ của đối thủ là -20 điểm\ntượng của ta là 20 điểm, tượng của đối thủ là -20 điểm\nmã của ta là 40 điểm, mã của đối thủ là -40 điểm\nxe của ta là 90 điểm, xe của đối thủ là -90 điểm\npháo của ta là 45 điểm, pháo của đối thủ là -45 điểm\nchốt của ta là 15 điểm, chốt của đối thủ là -15 điểm\nHàm lượng giá ở trên khá ngây thơ, mọi quân cờ đều có điểm ngang nhau, không quan tâm vị trí đứng của nó.\nTrên thực tế, chúng ta thấy rằng, con tướng ở vị trí trung tâm thường là an toàn nhất, một khi tướng leo lên lầu 1 hoặc leo lầu 2, nghĩa là con tướng có khả năng bị đột tử cao hơn, nên chúng ta phải tinh chỉnh lại điểm của con tướng trong trường hợp này.\nMột ví dụ nữa là vị trí con mã, mã gần với thành của tướng địch hơn thì khả năng con xe chiếu bí tướng địch sẽ cao hơn con mã chưa qua sông.\nGiá trị lượng giá cho cờ tướng, các bạn có thể tham khảo ở link https://github.com/markdirish/xiangqi/blob/master/evaluate.js\nChúng ta sẽ duyệt lần lượt từ trái qua phải, từ trên xuống dưới, tính điểm của bàn cờ hiện tại.\nHàm lượng giá của bàn cờ xét như sau:\n1234function evaluateBoard(board) { 5var totalEvaluation = 0; 6for (var i = 0; i \u0026lt; 10; i++) { 7for (var j = 0; j \u0026lt; 9; j++) { 8totalEvaluation = totalEvaluation + getPieceValue(board[i][j], i ,j); 9} 10} 11return totalEvaluation; 12} 13141516function getPieceValue(piece, x, y) { 17if (piece === null) { 18return 0; 19} 20var getAbsoluteValue = function (piece, isRed, x ,y) { 21if (piece.type === \u0026#39;p\u0026#39;) { //chốt 22 return 15 + ( isRed ? pEvalRed[x][y] : pEvalBlack[x][y] ); 23} else if (piece.type === \u0026#39;r\u0026#39;) { //Xe 24 return 90 +( isRed ? rEvalRed[x][y] : rEvalBlack[x][y] ); 25} else if (piece.type === \u0026#39;c\u0026#39;) { //pháo 26 return 45 +( isRed ? cEvalRed[x][y] : cEvalBlack[x][y] ); 27} else if (piece.type === \u0026#39;n\u0026#39;) { // mã 28 return 40 +( isRed ? nEvalRed[x][y] : nEvalBlack[x][y] ); 29} else if (piece.type === \u0026#39;b\u0026#39;) { // tượng 30 return 20 +( isRed ? bEvalRed[x][y] : bEvalBlack[x][y] ); 31} else if (piece.type === \u0026#39;a\u0026#39;) { // sỹ 32 return 20 +( isRed ? aEvalRed[x][y] : aEvalBlack[x][y] ); 33} else if (piece.type === \u0026#39;k\u0026#39;) { // tướng 34 return 900 +( isRed ? kEvalRed[x][y] : kEvalBlack[x][y] ); 35} 36throw \u0026#34;Unknown piece type: \u0026#34; + piece.type; 37}; 3839var absoluteValue = getAbsoluteValue(piece, piece.color === \u0026#39;r\u0026#39;, x ,y); 40return piece.color === \u0026#39;r\u0026#39; ? absoluteValue : -absoluteValue; 41} Bây giờ, chúng ta chỉ cần duyệt qua toàn bộ các nước có thể đi, tính xem nước đi nào có điểm số là lớn nhất, thì máy sẽ đi theo nước đi đó.\n123function getBestMove(game) { 45var newGameMoves = game.moves(); 6var bestMove = null; 7// set đại một số âm vô hạn 8var bestValue = -9999; 910for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 11var newGameMove = newGameMoves[i]; 12game.move(newGameMove); 1314var boardValue = -evaluateBoard(game.board()) 15game.undo(); 16if (boardValue \u0026gt; bestValue) { 17bestValue = boardValue; 18bestMove = newGameMove 19} 20} 2122return bestMove; 2324}; Vì vậy, ngoài việc xét điểm cho các loại quân, chúng ta sẽ có một bảng xét điểm cho các con\nKết quả có vẻ tốt hơn so với việc random bước đi trước đó, nhưng thuật toán vẫn còn hơi dốt dốt xíu, do máy chỉ tính 1 nước đi và chọn ra nước đi tốt nhất. Nên máy chưa có cái nhìn dài hơn. Có nhiều cách để cho máy có thể có góc nhìn xa hơn về thế cục của bàn cờ, một trong các cách được giới thiệu ở đây là sử dụng minimax\nBước 3. Tìm kiếm cây sử dụng minimax Thuật toán minimax thuộc nhóm duyệt theo chiều sâu (depth first search). Hai người chơi, một người được gọi là MAX, người còn lại gọi là MIN. Thuật toán được thiết kế để tìm nước đi tối ưu cho người MAX. Người MAX sẽ giữ node gốc, lần lượt duyệt đệ quy qua tất cả các node con theo chiều sâu nhất định đến khi duyệt qua tất cả các node hoặc là tìm được một đường đi mà đạt MAX.\nChi tiết hơn, người MAX sẽ đi đầu tiên. Nhiệm vụ của MAX là tìm nước đi sao cho điểm số của mình là cao nhất, nhiệm vụ của MIN là tìm nước đi để cực tiểu hoá điểm số của MAX.\nCác bạn có thể đọc thêm ở link https://en.wikipedia.org/wiki/Minimax.\nĐể triển khai minimax, đầu tiên, chúng ta sẽ sửa lại hàm getBestMove ở trên, thay vì gọi lượng giá bàn cờ evaluateBoard, chúng ta sẽ gọi hàm minimax\n123function minimaxRoot(depth, game, isMaximisingPlayer) { 4var newGameMoves = game.moves(); 5var bestMove = -9999; 6var bestMoveFound; 78for(var i = 0; i \u0026lt; newGameMoves.length; i++) { 9var newGameMove = newGameMoves[i] 10game.move(newGameMove); 11var value = minimax(depth - 1, game, !isMaximisingPlayer); 12game.undo(); 13if(value \u0026gt;= bestMove) { 14bestMove = value; 15bestMoveFound = newGameMove; 16} 17} 18return bestMoveFound; 19} với hàm minimax cũng cùng ý tưởng với hàm getBestMove ở trên, nhưng ta sẽ gọi đệ quy, luân phiên tính điểm máy, sau đó tính điểm người \u0026hellip; theo độ sâu ta đã thiết lập, để tìm ra đường đi có số điểm là lớn nhất.\n12function minimax (depth, game, isMaximisingPlayer) { 3if (depth === 0) { 4return -evaluateBoard(game.board()); 5} 6var newGameMoves = game.moves(); 7if (isMaximisingPlayer) { 8var bestMove = -9999; 9for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 10game.move(newGameMoves[i]); 11bestMove = Math.max(bestMove, minimax(depth - 1, game, !isMaximisingPlayer)); 12game.undo(); 13} 14return bestMove; 15} else { 16var bestMove = 9999; 17for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 18game.move(newGameMoves[i]); 19bestMove = Math.min(bestMove, minimax(depth - 1, game, !isMaximisingPlayer)); 20game.undo(); 21} 22return bestMove; 23} 24}; Thuật toán này hoạt động khá hiệu quả, nhưng có một điểm yếu là nó sẽ vét cạn toàn bộ các trường hợp để tìm ra đường đi tối ưu nhất. Vì vậy, với giá trị độ sâu càng lớn thì thuật toán chạy càng chậm.\nBước 4: Cắt tỉa Alpha - Beta Cắt tỉa Alpha - Beta là một phương pháp tối ưu hoá của thuật toán minimax, phương pháp này giúp chúng ta bỏ qua một vài nhánh trong quá trình tìm kiếm, làm giới hạn phạm vi tìm kiếm, giúp mô hình hoạt động nhanh hơn.\nThuật toán sẽ hoạt động hiệu quả hơn nếu những bước tìm kiếm đầu tiên là những nước đi tốt nhất :)\nHàm minimax với alpla, beta được viết lại như sau\n1234function minimax(depth, game, alpha, beta, isMaximisingPlayer) { 5positionCount++; 6if (depth === 0) { 7return -evaluateBoard(game.board()); 8} 910var newGameMoves = game.moves(); 1112if (isMaximisingPlayer) { 13var bestMove = -9999; 14for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 15game.moves(newGameMoves[i]); 16bestMove = Math.max(bestMove, minimax(depth - 1, game, alpha, beta, !isMaximisingPlayer)); 17game.undo(); 18alpha = Math.max(alpha, bestMove); 19if (beta \u0026lt;= alpha) { 20return bestMove; 21} 22} 23return bestMove; 24} else { 25var bestMove = 9999; 26for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 27game.moves(newGameMoves[i]); 28bestMove = Math.min(bestMove, minimax(depth - 1, game, alpha, beta, !isMaximisingPlayer)); 29game.undo(); 30beta = Math.min(beta, bestMove); 31if (beta \u0026lt;= alpha) { 32return bestMove; 33} 34} 35return bestMove; 36} 37} Cảm ơn các bạn đã theo dõi bài viết. Xin chào và hẹn gặp lại các bạn ở bài viết kế tiếp.\nCác bạn có thể chơi game ở đây nha , link https://www.phamduytung.com/games/china_chess/\nMình sẽ update dần giao diện để cho game trở nên đẹp đẹp hơn.\n","date":"Aug 12, 2021","img":"","permalink":"/blog/2021-08-12-china_chess_alpha_beta_ai/","series":null,"tags":["machine learning","ai","china chess","cờ tướng","minimax","alpha beta pruning"],"title":"Xây Dựng Chương Trình AI Đơn Giản Cho Game Cờ Tướng"},{"categories":null,"content":"Giới thiệu PyCaret là thư viện open-source machinelearning trong python, Thư viện tích hợp sẵn các mô hình cần thiết, giúp chúng ta train mô hình một lần trên nhiều thuật toán máy học khác nhau. Thư viện có hỗ trợ train trên GPU. Phiên bản hiện tại lúc mình viết bài viết này là 2.3.3. Các bạn có thể tham khảo thông tin thêm của thư viện ở link github https://github.com/pycaret/pycaret\nĐể cài đặt pycaret, các bạn sử dụng lệnh sau\n12pip install pycaret 34pip install pycaret[full] Bản full có cài thêm nhiều gói thư viện khác, các bạn có thể tham khảo các gói thư viện được cài thêm ở bản full qua link https://github.com/pycaret/pycaret/blob/master/requirements-optional.txt\nMình quan sát sơ qua thì bàn full có cài thêm mấy cái thư viện kết nối aws và gcs khá dư thừa, mình không xài tới, với ổ cứng máy mình cũng có hạn. Nên mình chỉ cài bản cơ bản và các thư viện cần thiết như scikit-optimize, tune-sklearn, xgboost \u0026hellip;\nVòng đời khi xây dựng chương trình máy học   Business Problem : Như những ứng dụng khác, một ứng dụng máy học cũng được bắt đầu bằng một vấn đề thực tế trong cuộc sống, trong công việc. Phụ thuộc vào sự phức tạp của vấn đề, và các chi phí liên quan về mặt kinh doanh, chúng ta sẽ phân tích các yếu tố liên quan để xem xét có cần thiết phải phát triển chương trình sử dụng máy học hoặc tìm một giải pháp thay thế tốt hơn theo toàn bộ tiêu chí (thuyết vị lợi).\n  Data Sourcing \u0026amp; ETL : Sau khi hiểu bài toán, chúng ta sẽ thu thập các dữ liệu cần thiết.\n  Exploratory Data Analysis (EDA) : Dữ liệu ở trên là dữ liệu thô, chưa qua xử lý, nên có thể sẽ bị thu thập không đủ, thu thập thiếu. Chúng ta cần phải nắm rõ dữ liệu, phân tích sự cân bằng/ độ lệch của dữ liệu, xử lý nhiễu, xem phân bố của dữ liệu, xem độ tương quan giữa các đặc trưng, \u0026hellip;\n  Data Preparation : Sau khi phân tích, xào nấu dữ liệu đẹp đẽ, trơn tru, chúng ta sẽ bắt đầu chuẩn bị dữ liệu cho mô hình train, ví dụ chia dữ liệu thành tập train,test,validation, one-hot encoding, feature engineering, feature selection \u0026hellip;\n  Model Training \u0026amp; Selection : Đây là phần nhàm chán nhất, thử nghiệm dữ liệu với các mô hình và tham số khác nhau, lựa chọn mô hình có kết quả tốt nhất trên tập validation. chờ mô hình train xong\n  Deployment \u0026amp; Monitoring : Sau khi có được mô hình tốt nhất, chúng ta sẽ deploy ứng dụng, và theo dõi, tương tự như những ứng dụng khác thôi.\n  Trong việc phát triển phần mềm, có một khái niệm đang nổi gần đây (lúc mình đang viết bài viết này) là devops. Giúp cho một số công việc nhàm chám được thực hiện một cách tự động. Trong máy học, chúng ta sẽ có khái niệm MLOps.\nMLOps là gì Định nghĩa theo wikipedia:\n12MLOps or ML Ops is a set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently Một bức hình bằng vạn câu chữ, xem bức hình trên, các bạn chắc về cơ bản cũng hiểu công việc của MLOps là gì rồi hen.\nÀ, đọc đến đây, các bạn có lẽ sẽ thắc mắc là sao đang giới thiệu Pycaret, mà sao lại lang mang qua MLOps làm gì? Thì mình cũng trả lời luôn là Pycaret là một trong những package giúp chúng ta MLOps ==\u0026gt; bớt nhàm chán khi phát triển ứng dụng machine learning rồi đó.\nVí dụ sử dụng Pycaret Mình sẽ trình bày phần này đúng theo machine learning life cycle, để đảm bảo việc giả lập sát với thực tế.\nBusiness Problem Bài toán Sarah Gets a Diamond, link chi tiết của bài toán ở https://hbsp.harvard.edu/product/UV0869-PDF-ENG. Bài toán này giúp người học khoá đó hiểu được sự khác nhau của linear-model, log-liner model, log-log mode. Nếu các bạn có nhu cầu tìm hiểu các model trên, có thể đăng ký khoá học trên hen. Ở đây, mình chỉ lấy mô tả chi tiết và data của khoá học.\nBối cảnh của bài toán diễn ra như sau. Grey muốn mua một chiếc nhẫn để cầu hôn Sarah. Sau một hồi tham khảo mấy thằng bạn từ thời nối khố, Grey quyết định sẽ mua nhẫn kim cương. Grey tiến hành đi thu thập thông tin của 6000 chiếc nhẫn kim cương khác nhau về giá, màu sắc, hình dạng \u0026hellip;\nMay mắn thay Grey có share dữ liệu này cho Pycaret, và chúng ta có thể sử dụng dữ liệu trên bằng cách load từ dataset của Pycaret\n12# load the dataset from pycaret 3from pycaret.datasets import get_data 4data = get_data(\u0026#39;diamond\u0026#39;) Và top 5 dữ liệu mẫu mà Grey thu thập là:\n12Carat Weight\tCut\tColor\tClarity\tPolish\tSymmetry\tReport\tPrice 30\t1.10\tIdeal\tH\tSI1\tVG\tEX\tGIA\t5169 41\t0.83\tIdeal\tH\tVS1\tID\tID\tAGSL\t3470 52\t0.85\tIdeal\tH\tSI1\tEX\tEX\tGIA\t3183 63\t0.91\tIdeal\tE\tSI1\tVG\tVG\tGIA\t4370 74\t0.83\tIdeal\tG\tSI1\tEX\tEX\tGIA\t3171 Exploratory Data Analysis Bước này sẽ phụ thuộc vào kinh nghiệm của người làm data. Kinh nghiệm của mình thì đầu tiên sẽ phân tích phân bố dữ liệu và phân tích mối tương quan giữa các biến liên tục trước đã, sau đó sẽ phân tích các yếu tố chuyên sâu hơn dựa vào cảm quan nhận được từ hai cái trên.\nQuan sát dữ liệu, chúng ta thấy rằng chỉ có hai thuộc tính Carat Weight và Price thuộc nhóm numerical variable, các thuộc tính còn lại thuộc nhóm categorical variable, nên mình không cần tính độ tương quan làm gì hết.\nMình có học từ link ở tài liệu tham khảo phía dưới, thư viện plotly.express, mình tham khảo thử thì thấy hàm vẽ scatter của thư viện có nhiều thuộc tính khá hay. Ví dụ mình thử phân tích kích thước viên đá kim cương với giá của chiếc nhẫn, chia theo màu sắc thì như thế nào\n1fig = px.scatter(data,x=\u0026#39;Carat Weight\u0026#39;, y=\u0026#39;Price\u0026#39;, animation_group=\u0026#39;Color\u0026#39;, 2facet_col = \u0026#39;Color\u0026#39;, opacity = 0.25, template = \u0026#39;plotly_dark\u0026#39;, trendline=\u0026#39;ols\u0026#39;, 3color=\u0026#34;Color\u0026#34;, trendline_color_override = \u0026#39;red\u0026#39;, title = \u0026#39;SARAH GETS A DIAMOND - A CASE STUDY\u0026#39;) 4fig.show() Nhìn hình trên, mình thấy rằng cùng 1 kích thước, màu H và màu I có giá xêm xêm nhau, màu E và F cũng tương tự, màu D có mức giá cao nhất. với kích thước 2.74, giá của chiếc nhẫn kim cương màu D cao hơn gấp đôi so với giá của nhẫn kim cương có màu H hoặc màu I\nCác bạn có thể thay thuộc tính facet_col = \u0026lsquo;Color\u0026rsquo; của hàm scatter bằng các tên cột như Cut\thoặc Clarity\thoặc\tSymmetry, sẽ có vài thứ hay ho có thể rút ra đó.\nSau khi phân tích dữ liệu, có cái nhìn sơ lược về các thuộc tính cũng như mối tương quang giữa chúng, chúng ta thường sẽ thường thực hiện các phép biến đổi để chuẩn hoá dữ liệu. Các phép biến đổi thường được xài là:\n  Chuẩn hoá dữ liệu: Scale dữ liệu về cùng một đoạn, ví dụ [-1,1] hoặc [0-1], 2 phương pháp phổ biến hay được sử dụng:\n Min-Max Z score    Xử lý dữ liệu lệch: Các cột thuộc tính numberric sẽ được chuẩn hoá về phân phối chuẩn.\n  Tổng hợp dữ liệu: Sử dụng các thuộc tính có sẵn, kết hợp lại để tạo nên các thuộc tính mới.\n  Trước hết, chúng ta sẽ xem histogram của biến Price\nTa thấy rằng, phân phối có ít quan sát hơn ở phía bên phải =\u0026gt; mô hình bị lệch phải (right-skewed hoặc skewed right, positively skewed distribution). Với dữ liệu bị bịnh này thì chúng ta sẽ dùng thuốc chữa là căn bậc hai, căn bậc ba hoặc là log.\nMình sẽ xài thuốc log. Sử dụng hàm log trong thư viện numpy\n12import numpy as np 3# create a copy of data 4data_copy = data.copy() 5# create a new feature Log_Price 6data_copy[\u0026#39;Log_Price\u0026#39;] = np.log(data[\u0026#39;Price\u0026#39;]) 7# plot histogram 8fig = px.histogram(data_copy, x=[\u0026#34;Log_Price\u0026#34;], title = \u0026#39;Histgram of Log Price\u0026#39;, template = \u0026#39;plotly_dark\u0026#39;) 9fig.show() Dữ liệu được đưa về dạng giống giống cái chuông úp, hình dạng của phân phối chuẩn.\nData Preparation Xài thư viện PyCaret khá sướng, chúng ta chỉ cần gọi hàm setup của thư viện là đủ\n12# initialize setup 3from pycaret.regression import * 4s = setup(data, target = \u0026#39;Price\u0026#39;, transform_target = True,transform_target_method=\u0026#34;yeo-johnson\u0026#34;, log_experiment = True, experiment_name = \u0026#39;diamond\u0026#39;) Bài toán thuộc dạng hồi quy, nên mình sẽ load toàn bộ các hàm thuộc regression vào.\nMọi việc còn lại, từ việc tính log của cột Price, đến việc tiền xử lý dữ liệu , \u0026hellip; đã được PyCaret lo hết. Chúng ta chỉ cần chịu khó đọc doc của thư viện để hiểu các tham số và ứng dụng nó vào là ổn.\nMột lưu ý là hàm transform mặc định xài box-cox, và pycaret ở thời điểm hiện tại chỉ hỗ trợ \u0026ldquo;box-cox\u0026rdquo; hoặc \u0026ldquo;yeo-johnson\u0026rdquo;. Nếu các bạn muốn xài log cho cột Price, thì phải thêm cột mới. Mình sẽ xài yeo-johnson thay cho mặc định box-cox.\nModel Training \u0026 Selection Tiếp đến việc train model và lựa chọn model cũng hết sức đơn giản, chúng ta chỉ cần gọi 1 dòng lệnh duy nhất\n12# compare all models 3best = compare_models() Xong. Thư viện tự động điều chỉnh tham số, lựa chọn tham số tốt nhất và mô hình tốt nhất cho chúng ta. Chúng ta chỉ cần ngồi, đợi máy chạy, xem kết quả.\nMột lưu ý là các bạn nếu không cài bản full thì nên xem file log để xem có báo lỗi thiếu thư viện hay không hen.\nSau khi có được thuật toán với mô hình tốt nhất , và các trọng số tốt nhất, chúng ta sẽ lưu mô hình lại vào file để sau này sử dụng.\n12# finalize the model 3final_best = finalize_model(best) 4# save model to disk 5save_model(final_best, \u0026#39;diamond-pipeline\u0026#39;) Deployment \u0026 Monitoring Đến phần này thì đơn giản rồi, các bạn có thể viết webapi như flask hoặc fastapi để sử dụng.\nPycaret có hỗ trợ mlflow, dùng để xem đường dẫn các model đã được huấn luyện, cũng như chi tiết các thông tin tham số, độ lỗi. Các bạn hãy gõ lệnh\n1!mlflow ui Nếu bạn chạy bằng terminal , thì chỉ cần gõ mlflow ui thôi, không cần dấu ! đâu, do mình chạy trên jupiter notebook nên phải thêm dấu ! câu lệnh mới hoạt động.\nSau khi chạy lện trên, bạn hãy mở trình duyệt web lên và nhập và địa chỉ http://localhost:5000, cái này cũng không có gì nhiều để đề cập, nên mình không show chi tiết ở đây, các bạn cứ vào đó vọc vạch, quậy phá hen.\nCác bạn có thể testing best model bằng câu lệnh sau\n12# create a copy of data and drop Price 3data1 = data.copy() 4# data1.drop(\u0026#39;Price\u0026#39;, axis=1, inplace=True) 5# generate predictions 6from pycaret.regression import predict_model 7predictions = predict_model(final_best, data=data1) 8predictions.head() Cột Label chính là cột giá của mô hình. Mình giữ lại cột giá để tiện so sánh.\n12Carat Weight\tCut\tColor\tClarity\tPolish\tSymmetry\tReport\tPrice\tLabel 30\t1.10\tIdeal\tH\tSI1\tVG\tEX\tGIA\t5169\t5365.265635 41\t0.83\tIdeal\tH\tVS1\tID\tID\tAGSL\t3470\t3525.863059 52\t0.85\tIdeal\tH\tSI1\tEX\tEX\tGIA\t3183\t3352.882096 63\t0.91\tIdeal\tE\tSI1\tVG\tVG\tGIA\t4370\t4485.753572 74\t0.83\tIdeal\tG\tSI1\tEX\tEX\tGIA\t3171\t3327.363225 Top 5 phần tử đầu tiên hiện ra cho mình thấy rằng, có vẻ mô hình dự đoán giá cao hơn một chút so với giá gốc.\nCảm ơn các bạn nhiều. Hẹn gặp lại trong các bài viết tiếp theo\nTham khảo\nhttps://github.com/pycaret/pycaret\nhttps://towardsdatascience.com/build-with-pycaret-deploy-with-fastapi-333c710dc786\nhttps://towardsdatascience.com/easy-mlops-with-pycaret-mlflow-7fbcbf1e38c6\n","date":"Jul 27, 2021","img":"","permalink":"/blog/2021-07-28-pycaret-flaskapi/","series":null,"tags":["wls2"],"title":"Tìm Hiểu Package PyCaret Trong Python"},{"categories":null,"content":"Giới thiệu  Danh sách điều khiển truy cập - Access Control List  Điều khiển truy cập bắt buộc - Mandatory Access Control  Điều khiển truy cập tùy quyền - Discretionary Access Control (DAC)  Điều khiển truy cập theo vai - Role Based Access Control (RBAC)  Điều khiển truy cập theo thuộc tính - Attribute Based Access Control (ABAC)   Danh sách điều khiển truy cập - Access Control List (ACL)  Là mô hình cấp quyền truy cập dựa vào danh sách các quyền\nMô hình:\nSubject được quyền ( action ) trên object\rTuỳ từng bài toán khác nhau mà subject, action, object là khác nhau\rVí dụ: Trong môi trường phân quyền tập tin linux, subject là user, thread, action là READ/WRITE/ EXECUTE object là file, directory, tcp/udp port, thiết bị nhập xuất ...\r Ví dụ:\nTrong hệ thống phân quyền của linux\rUser Alice được quyền đọc/ghi/thực thi trên file alice.sh\rUser Bob được quyền đọc trên file alice.sh\r Ứng dụng:\nMô hình được ứng dụng trong Filesystem ACLs, POSIX ACL, NFSv4 ACL, Active Directory ACLs, Networking ACLs, SQL implementations.  Tham khảo:\n https://en.wikipedia.org/wiki/Access-control_list  Điều khiển truy cập bắt buộc - Mandatory Access Control (MAC)  Về cơ bản thì mô hình này cũng \u0026quot; là mô hình cấp quyền truy cập dựa vào danh sách các quyền\u0026quot;. Tuy nhiên, mô hình này sẽ kiểm soát quyền truy cập đến từng object của subject\nMô hình:\nSubject được quyền ( action ) trên object\rObject được quyền (action) bởi object\rVì ràng ở mức 2 đầu, nên mô hình này được ràng chặc chẽ hơn\r Ví dụ:\nVí dụ: Ở một số tổ chức, user có quyền đọc ghi file (subject - action - object), tuy nhiên, có một số file tuyệt mật được phân quyền đọc/ ghi cho giám đốc (object - action - subject), nên user bình thường không thể đọc được.\rCác bạn có thể đọc thêm 3 ví dụ trong link của cornell mình có để bên dưới\r Ứng dụng:\nSELinux\rWindows Vista và Windows Server 2008\r...\r Tham khảo:\nhttps://en.wikipedia.org/wiki/Mandatory_access_control\rhttp://www.cs.cornell.edu/courses/cs5430/2015sp/notes/mac.php\r Điều khiển truy cập tùy quyền - Discretionary Access Control (DAC)  Là mô hình cấp quyền truy cập dựa vào danh sách các quyền. Mô hình này giống với ACL, chỉ có 1 điểm khác là subject có thể chuyển quyền mình đang có cho một subject khác\nMô hình:\nSubject được quyền ( action ) trên object\rSubject gán quyền (grant : action - object) cho Subject khác\r Ví dụ: Alice có quyền đọc, ghi, thực thi file Alice.sh\nAlice gán quyền đọc file Alice.sh cho Bob\r Ứng dụng:\nPhân quyền file trong hệ điều hành\r...\r Điều khiển truy cập theo vai - Role Based Access Control (RBAC)  Mô hình còn có tên gọi khác là Role Based Security, là mô hình cấp quyền truy cập dựa vào danh sách các quyền. Tuy nhiên, các subject sẽ được gán vào trong các Role và chúng ta sẽ cấp quyền cho các role.\nMô hình này có thể kết hợp với mô hình DAC (để tăng khả năng cấp quyền), hoặc MAC (để tăng tính bảo mật) mà không xung đột với 2 mô hình trên.\nMô hình:\nSubject thuộc Roles\rRoles được quyền ( action ) trên object\r=\u0026gt; các subject thuộc Roles được quyền (action) trên object\r Ví dụ:\nAlice thuộc Role NhanVienTuyenDung, NhanVienIT\nRole NhanVienTuyenDung có quyền read, execute file\nRole NhanVienIT có quyền write file\n=\u0026gt; Alice có quyền read, write, execute file\nỨng dụng:\nCó rất nhiều ứng dụng của mô hình này, ví dụ các forum mã nguồn mở, cấp quyền trong hệ điều hành ....\r Để tìm hiểu kỹ hơn về mô hình RBAC, các bạn có thể đọc quyển sách tham khảo ở dưới\nTham khảo :\nDavid F. Ferraiolo; D. Richard Kuhn; Ramaswamy Chandramouli (2007). Role-based Access Control (2nd ed.). Artech House. ISBN 978-1-59693-113-8.\rhttps://en.wikipedia.org/wiki/Role-based_access_control\r Điều khiển truy cập theo thuộc tính - Attribute Based Access Control (ABAC)  Mô hình còn có tên gọi khác là Policy Based Access Control hoặc Claims Based Access Control (CBAC), là mô hình cấp quyền truy cập dựa vào danh sách các quyền kết hợp với các thuộc tính.\nKiến trúc: Theo NIST đề xuất, kiến trúc của ABAC nên có các thành phần sau:\n- Policy Enforcement Point PEP: chịu trách nhiệm phân tích các yêu cầu truy xuất và gửi đến PDP để chứng thực.\r- Policy Decision Point PDP: nhận thông tin từ PEP và chịu trách nhiệm chứng thực yêu cầu có quyền truy xuất tới các tài nguyên hay không, trả về đồng ý hoặc từ chối. Nếu thiếu tông tin thì - Policy Information Point PIP: trả về các attribute mà PDP yêu cầu.\r Thuộc tính: Bất kể thứ gì trên đời này đều có thể là thuộc tính. Tuy nhiên, chúng sẽ thường được phân làm 4 nhóm chính sau:\n- Subject attributes: Các thuộc tính về thông tin người dùng, ví dụ họ tên, ngày tháng năm sinh, quê quán, quốc tịch, địa chỉ, phòng ban, chức vụ, tên công việc, số cmnd, ....\r- Action attributes: Các thuộc tính về hành động như chạy , nảy, xoá, thêm, đọc, ghi ...\r- Object attributes: Các thuộc tính về thông tin của đối tượng muốn truy xuất, ví dụ như loại file, phần đuôi mở rộng, vị trí, ....\r- Contextual (environment) attributes: Các thuộc tính liên quan đến kịch bản diễn ra. Ví dụ hệ điều hành, ram, cpu, thời gian, múi giờ, ...\r Ví dụ:\nToàn bộ nhân viên không được truy xuất database sau 21h đêm\rNhân viên Nguyễn Thị Lụa của GHN được quyền đổ danh sách freelancer ở Hà Nội, Hải Phòng, Hưng Yên\r Ứng dụng:\nCó thể ứng dụng ABAC vào rất nhiều ứng dụng khác nhau để kiểm soát luồng truy cập tài nguyên của hệ thống. Tuy nhiên, việc xây dựng mô hình ACBA khá tốn kém về tài nguyên và đòi hỏi người quản lý phải có tư duy hệ thống vững chắc\r Để tìm hiểu kỹ hơn về mô hình ABAC, các bạn có thể đọc quyển sách tham khảo ở dưới\nTham khảo :\nhttps://nvlpubs.nist.gov/nistpubs/specialpublications/NIST.SP.800-162.pdf\rhttps://arxiv.org/pdf/1306.2401.pdf\rhttps://en.wikipedia.org/wiki/Attribute-based_access_control\r Cảm ơn các bạn đã chú ý quan tâm theo dõi. Xin chào và hẹn gặp lại ở các bài viết tiếp theo.\n","date":"Jul 2, 2021","img":"","permalink":"/blog/2021-07-02-mo-hinh-phan-quyen/","series":null,"tags":["ACL","mac","dac","rbac","abac"],"title":"Mô Hình Phân Quyền - Access Control"},{"categories":null,"content":"Giới thiệu Microsoft đã trình làng phiên bản WLS 2 với nhiều điểm cải tiến nổi trội. Trong bài viết này, mình sẽ hướng dẫn các bạn cài đặt wls 2 và upgrade các distro linux của mình xài WLS 2. Mình có một lưu ý nhỏ là nếu các distro linux của bạn không bị ràng gì thì các bạn nên xóa các linux distro hiện tại và cài mới lại linux. Vì quá trình upgrade chạy rất là lâu.\nYêu cầu Để cài đặt WLS 2, Các bạn bắc buộc phải nâng cấp lên các phiên bản \u0026ldquo;Windows 10 May 2020 (2004), Windows 10 May 2019 (1903), or Windows 10 November 2019 (1909)\u0026rdquo; hoặc các bản cập nhật sau đó.\nĐỂ xác định xem máy bạn đang xài phiên bản bao nhiêu, bạn nãy gõ mở cmd lên và gõ lệnh\n1systeminfo | findstr \u0026#34;OS\u0026#34; 23------ 45OS Name: Microsoft Windows 10 Home Single Language 6OS Version: 10.0.19043 N/A Build 19043 7OS Manufacturer: Microsoft Corporation 8OS Configuration: Standalone Workstation 9OS Build Type: Multiprocessor Free 10BIOS Version: American Megatrends Inc. S551LN.209, 7/8/2014 Nếu thỏa mãn các điều kiện trên, thì các bước chúng ta phải làm là:\n1dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 23------ 45Deployment Image Servicing and Management tool 6Version: 10.0.19041.844 78Image Version: 10.0.19043.1023 910Enabling feature(s) 11[==========================100.0%==========================] 12The operation completed successfully. Tiếp theo, chúng ta chạy lệnh\n123dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 45---------- 67Deployment Image Servicing and Management tool 8Version: 10.0.19041.844 910Image Version: 10.0.19043.1023 1112Enabling feature(s) 13[==========================100.0%==========================] 14The operation completed successfully. Sau đó, bạn phải khởi động lại máy để window tiến hành cập nhật các gói thư viện cần thiết.\nSau khi khởi động lại máy xong, chúng ta sẽ gọi lệnh set phiên bản mặc định của wsl là bản 2 bằng lệnh:\n12wsl --set-default-version 2 Sau khi chạy lệnh này, sẽ có 1 trong 2 trường hợp xảy ra. Trường hợp 1\n1For information on key differences with WSL 2 please visit https://aka.ms/wsl2 Thì chúc mừng bạn, bạn đã enable thành công WSL 2\nTrường hợp thứ 2, bạn sẽ gặp output như thế này:\n1WSL 2 requires an update to its kernel component. For information please visit https://aka.ms/wsl2kernel. Thì bạn này vào trang https://aka.ms/wsl2kernel như hướng dẫn, đọc kỹ file, down về file msi để cài Linux kernel vào. Sau đó chạy lại lệnh \u0026ldquo;wsl \u0026ndash;set-default-version 2\u0026rdquo;\nSau đó, các bạn tiến hành check lại phiên bản linux mình đang sử dụng\n12wsl --list --verbose 34----- 56NAME STATE VERSION 7* Ubuntu-18.04 Running 1 8kali-linux Stopped 1 Như các bạn thấy ở trên, bản ubuntu 18.4 mình đang sử dụng đang ở version 1. Mình sẽ convert qua version 2 bằng lệnh\n12wsl --set-version Ubuntu-18.04 2 34------- 5Conversion in progress, this may take a few minutes... 6For information on key differences with WSL 2 please visit https://aka.ms/wsl2 Sau khi chạy dòng lệnh trên, các bạn chịu khó ngồi chờ một xíu, nó phụ thuộc vào cấu hình máy của các bạn. Kinh nghiệm của mình khi upgrade vài máy là nên tắt chương trình diệt virus như kaspersky, norton, BKAV, bit \u0026hellip;. đi. Tắt những ứng dụng sử dụng nhiều ram thì việc convert sẽ chạy nhanh hơn một chút.\nKết quả sau khi mình convert.\n12NAME STATE VERSION 3* Ubuntu-18.04 Stopped 2 4kali-linux Stopped 1 Cảm ơn các bạn đã chú ý theo dõi. Hẹn gặp lại ở các bài viết tiếp theo.\nLink hướng dẫn gốc từ trang chủ microsoft\nhttps://docs.microsoft.com/en-us/windows/wsl/install-win10\n","date":"May 30, 2021","img":"","permalink":"/blog/2021-05-30-upgrade-wls-to-wls2/","series":null,"tags":["wls2"],"title":"Nâng Cấp WSL Lên Bản WSL 2 Trên Window 10"},{"categories":null,"content":"Giới thiệu Trong quá trình giải các bài toán có sử dụng machine learning, vì để làm nhanh nên đôi khi mình sẽ sử dụng các tham số mặc định của mô hình để train. Một phần vì lý do chúng ta không biết cách chỉnh các tham só như thế nào, so với cái gì để có mô hình huấn luyện là tốt nhất. Ở bài viết này, mình sẽ sử dụng Learning Curves để tối ưu hóa các tham số của XGBoost. Các mô hình khác cũng làm tương tự thôi. Mình chọn XGBoost vì mô hình này thường cho kết quả khá tốt trên các cuộc thi ở Kaggle.\nBắt đầu Để bắt đầu thí nghiệm, chúng ta sẽ sinh ngẫu nhiên 60 ngàn dữ liệu có 1 ngàn thuộc tính bằng cách sử dụng hàm make_classification, sau đó sẽ chia dữ liệu thành 2 tập train và test với tỷ lệ 10% là tập test\n1X, y = make_classification(n_samples=60000, n_features=1000, n_informative=50, n_redundant=0, random_state=1) 2# split data into train and test sets 3X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1) Load mô hình XGBClassifier với các tham số là mặc định. Mô hình này được xem như là baseline và các cải tiến tham số ở sau sẽ so sánh kết quả trên mô hình này.\n123model = XGBClassifier() 45evalset = [(X_train, y_train), (X_test, y_test)] 67model.fit(X_train, y_train, eval_metric=\u0026#39;logloss\u0026#39;, eval_set=evalset) 8# evaluate performance 9yhat = model.predict(X_test) 10score = accuracy_score(y_test, yhat) 11print(\u0026#39;Accuracy: %.3f\u0026#39; % score) 12# retrieve performance metrics 13results = model.evals_result() 14# plot learning curves 15pyplot.plot(results[\u0026#39;validation_0\u0026#39;][\u0026#39;logloss\u0026#39;], label=\u0026#39;train\u0026#39;) 16pyplot.plot(results[\u0026#39;validation_1\u0026#39;][\u0026#39;logloss\u0026#39;], label=\u0026#39;test\u0026#39;) 17# show the legend 18pyplot.legend() 19# show the plot 20pyplot.show() Độ chính xác: Accuracy: 0.962. Lưu ý ràng độ chính xác khi thực nghiệm của mỗi lần chạy sẽ khác nhau, do data sinh ngẫu nhiên và một phần do sự ngẫu nhiên trong XGBoost.\nNhìn vào hình trên, chúng ta thấy rằng đường cong của tập train (đường màu xanh) có độ lỗi tốt hơn so với đường cong của tập test( đường màu đỏ)\nTiến hành turning Đầu tiên, nhìn vào đồ thị, ta thấy rằng đường cong vẫn còn có độ dốc, nên việc tăng số lần lặp có thể sẽ làm tăng thêm độ chính xác, thử thay đổi số lần lặp lên 500 xem sao.\nTrong XGBoost số lần lặp được tham số hóa bởi tham số n_estimators, chỉnh lại đoạn mã lệnh ở trên với một thay đổi nhỏ rồi chạy lại\n12model = XGBClassifier(n_estimators=500) Độ chính xác của mô hình tăng lên 1 chút, đối với thực nghiệm của mình là Accuracy: 0.981\nQuan sát đường cong của hình trên, ta thấy phần đuôi đoạn số lần lặp từ 270 đến 500 có độ dốc nhỏ, hầu như là bằng phẳng, có thể kết luận là việc huấn luyện ở đoạn này hầu như không cải tiến gì nhiều.\nMột nhận xét nữa là đoạn trước 150 có độ dốc khá lớn, có khả năng là hệ số học (learning reate) quá lớn, làm cho mô hình chưa đạt được cực tiểu, thử điều chỉnh hệ số học này nhỏ hơn là 0.01, thay vì 0.3 như giá trị mặc định xem sao.\nMột lưu ý là hệ số học nhỏ thì sẽ lâu hội tụ, nên chúng ta phải tăng số lần lặp lên. Ở đây đồng thời với việc giảm hệ số học xuống 0.01, mình còn tăng số lần lặp lên 1000.\nTrong XGBoost hệ số học được tham số hóa bởi tham số eta\n12model = XGBClassifier(n_estimators=1000, eta=0.01) Độ chính xác đạt được: Accuracy: 0.954\nTuy mô hình có độ chính xác giảm, nhưng nhìn vào đồ thị thì ta thấy mô hình vẫn còn độ dốc, nghĩa là mô hình sẽ cho kết quả tốt hơn nữa nếu ta tăng số vòng lặp.\nMột cách khách là thay đổi các chuẩn hóa (regularization ) bằng cách giảm các tham số số mẫu ( samples) và số đặc trưng (features) được dùng để xây dựng cây trong tập hợp. Hai tham số này được tham số hóa bởi tham số subsample và colsample_bytree. Giá trị mặc định của chúng là 1. Chúng ta sẽ thay đổi thành 0.35 xem sao nhé\n12model = XGBClassifier(n_estimators=5000, eta=0.01, subsample=0.35, colsample_bytree=0.35) Kết quả Accuracy: 0.970 Ở hai lần thí nghiệm trên, mình có các hướng xử lý có thể đi tiếp, một là tăng số lần lặp lên, vì độ dốc của mô hình vẫn còn, nên chúng ta hoàn toàn có thể thu được kết quả tốt hơn. Một cách khác là tăng learning rate lên để quá trình hội tụ được xảy ra nhanh hơn, ví dụ để eta = 0.05 hoặc 0.75 chẳn hạn.\nQuá trình này có thể tiếp tục, dựa vào quan sát của các bạn trên đường cong và hơn hết là sự hiệu biết thấu đáo của các bạn trên các tham số mà mô hình của bạn đang sử dụng. Chúc các bạn sẽ có một hướng đi tốt để giảm thiểu thời gian mò mẫm.\nCảm ơn các bạn đã chú ý theo dõi. Hẹn gặp lại ở các bài viết tiếp theo.\nNguồn tham khảo\nhttps://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\nhttps://machinelearningmastery.com/tune-xgboost-performance-with-learning-curves/\nhttps://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/\n","date":"Apr 11, 2021","img":"","permalink":"/blog/2021-04-11-xgboost_learning_curves/","series":null,"tags":["python"],"title":"Tinh Chỉnh Thuật Toán XGBoost  Với Learning Curves"},{"categories":null,"content":"Giới thiệu Hi các bạn, lại là mình đây, hôm nay mình sẽ cùng các bạn tìm hiểu thuật toán tối ưu hóa AdaBelief. Thuật toán này được sử dụng để thay cho thuật toán Adam optimizer mà các bạn hiện đang xài để huấn luyện mô hình Deep learning. Nào, chúng ta cùng bắt đầu tìm hiểu nhé.\nẨn sâu bên trong các thuật toán sử dụng Neural Network và một vài thuật toán machine learning đều sử dụng các hàm tối ưu hóa. Chúng ta có thể liệt kê ra một vài cái tên như RMSprop, SGD (Stochastic Gradient Descent), Adam (Adaptive Moment Estimation).\nMột vài các yếu tố hay được sử dụng để đánh giá một thuật toán optimizer:\n  Hội tụ nhanh (trong quá trình train)\n  Sự tổng quát hóa cao (vẫn nhận dạng được những mẫu chưa từng được huấn luyện)\n  Độ chính xác cao\n  Các thuật toán tối ưu thuộc họ Adaptive thường có tốc độ hội tụ nhanh. Trong khi đó, các thuật toán thuộc họ SGD thường có sự tổng quát hóa cao. Gần đây, Juntang Zhuang và các cộng sự thuộc đại học Yale đã nghiên cứu và tạo ra thuật toán AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients. Thuật toán này theo lời tác giả, hội tụ cả hai ưu điểm của họ Adaptive và SGD, là vừa có tốc độ hội tụ nhanh, vừa có tính tổng quát hóa cao Mã nguồn được tác giả công bố ở link https://github.com/juntang-zhuang/Adabelief-Optimizer.\nLời của tác giả:\n We propose the AdaBelief optimizer, which adaptively scales the stepsize by the difference betweenpredicted gradient and observed gradient. To our knowledge, AdaBelief is the first optimizer toachieve three goals simultaneously: fast convergence as in adaptive methods, good generalization asin SGD, and training stability in complex settings such as GANs. Furthermore, Adabelief has the same parameters as Adam, hence is easy to tune. We validate the benefits of AdaBelief with intuitive examples, theoretical convergence analysis in both convex and non-convex cases, and extensiveexperiments on real-world datasets\n Để hiểu về AdaBelief, trước tiên, chúng ta phải có một ít kiến thức cơ bản về SGD và Adam, nên chúng ta sẽ bắt đầu nói về SGD trước\nSGD - Stochastic Gradient Descent Thuật toán SGD là thuật toán tối ưu hóa cơ bản theo họ gradient. Thuật toán này rất triển khai, có nền tảng lý thuyết vững chắc, cực kỳ ổn định trong quá trình huấn luyện, kết quả đạt được có thể so sánh với các thuật toán khác. Ý tưởng của thuật toán khá đơn giản, đó là \u0026ldquo;tính giá trị gradient của mỗi tham số, và đi một bước nhỏ theo chiều của gradient\u0026rdquo;. Nếu chúng ta lặp đi lặp lại quá trình này, và ngẫu nhiên chọn (stochastic) một tập batch trong tập huấn luyện, mô hình chúng ta sẽ được cải tiến dần đến đểm hội tụ.\nTrong quá khứ, phần khó nhất của SGD là việc tính lại giá trị gradient cho toàn bộ các tham số trong mô hình. Nhưng hiện nay, các framwork máy học như Tensorflow, PyTouch, Caffee, Theano, \u0026hellip;. đã giúp chúng ta tính các giá trị gradient một cách tự động. Do đó, công việc của chúng ta hiện thời đơn giản hơn\n$$for \\text{ } i \\text{ } in \\text{ } range (m): $$ $$\\theta_i = \\theta_i - \\alpha ( \\hat y^{i} - y^i) x^i_j$$\nMột vấn đề chúng ta gặp phải trong quá trình huấn luyện DL với SGD là chậm, siêu chậm. Do thuật toán phải cập nhật toàn bộ các tham số, nên số lượng phép tính và lượng tài nguyên phần cứng được sử dụng rất là nhiều. Rất nhiều các biến thể của SGD đã được đề xuất để giải quyết vấn đề trên.\nAdam - Adaptive Moment Estimation Adam optimizer là một thuật toán kết hợp kỹ thuật của RMS prop và momentum. Thuật toán sử dụng hai internal states momentum (m) và squared momentum (v) của gradient cho các tham số. Sau mỗi batch huấn luyện, giá trị của m và v được cập nhật lại sử dụng exponential weighted averaging.\nMã giải của việc cập nhật m và v\n$$m_t = \\beta_1m_t-_1 + (1-\\beta_1)g_t $$ $$v_t = \\beta_2v_t-_1 + (1-\\beta_2)g^2_t$$\ntrong đó, beta được xem như là một siêu tham số. Công thức cập nhật theta như sau:\n$$\\theta_t = \\theta_t-_1 - \\alpha\\frac{m_t}{\\sqrt{v_t}+ \\epsilon }$$\ntrong đó, alpha là learning rate, epsion là giá trị được thêm vào để ngăng việc chia cho 0\nĐể việc descent được thực hiện nhanh hơn, thuật toán đã sử dụng hai kỹ thuật:\n  Tính exponential moving average của giá trị đạo hàm lưu vào biến m và sử dụng nó là tử số của việc cập nhật hướng. Với ý nghĩa là nếu m có giá trị lớn, thì việc descent đang đi đúng hướng và chúng ta cần bước nhảy lớn hơn để đi nhanh hơn. Tương tự, nếu giá trị m nhỏ, phần descent có thể không đi về hướng tối tiểu và chúng ta nên đi 1 bước nhỏ để thăm dò. Đây là phần momentum của thuật toán.\n  Tính exponential moving average của bình phương gía trị đạo hàm lưu vào biến v và sử dụng nó là phần mẫu số của việc cập nhật hướng. Với ý nghĩa như sau: Giả sử gradient mang các giá trị dương, âm lẫn lộn, thì khi cộng các giá trị lại theo công thức tính m ta sẽ được giá trị m gần số 0. Do âm dương lẫn lộn nên nó bị triệt tiêu lẫn nhau. Nhưng trong trường hợp này thì v sẽ mang giá trị lớn. Do đó, trong trường hợp này, chúng ta sẽ không hướng tới cực tiểu, chúng ta sẽ không muốn đi theo hướng đạo hàm trong trường hợp này. Chúng ta để v ở phần mẫu vì khi chia cho một giá trị cao, giá trị của các phần cập nhật sẽ nhỏ, và khi v có giá trị thấp, phần cập nhật sẽ lớn. Đây chính là phần tối ưu RMSProp của thuật toán.\n  Ở đây, m được xem như là moment thứ nhất, v xem như là moment thứ hai, nên thuật toán có tên là \u0026ldquo;Adaptive moment estimation\u0026rdquo;.\nĐể lý giải vì sao Adam lại hội tụ nhanh hơn so với SGD, chúng ta có thể giải thích như sau: Exponential weighted averaging cho chúng ta giá trị xấp xỉ gradient mượt hơn qua mỗi lần lặp, dẫn tới tăng tínhs dừng. Sau đó, việc chia cho căng bậc 2 của giá trị v làm số lước của chúng ta giảm mạnh khi phương sai của giá trị gradient tăng lên. Điều này , như giải thích ở trên, có nghĩa là, khi hướng đi của mô hình chỉ ra không rõ ràng, thuật toán Adam thực hiện các bước đi nhỏ coi như là thăm dò thôi. Và sẽ thực hiện các bước đi lớn, nhanh khi hướng đi rõ ràng.\nThuật toán Adam hoạt động khá hiệu quả, nhưng bản thân nó cũng có những vấn đề. Tác giả của AdaBelief đã chỉ ra một vài điểm không hiệu quả của thuật toán\nAdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients ![Hình ảnh AdaBelief - Nguồn https://arxiv.org/pdf/2010.07468v5.pdf ] (adam_error.jpg)\nHãy nhìn vào hình trên, ở mục đánh dấu là số 3, giá trị G lớn vì đường cong ở đoạn đó dốc. Giá trị v cũng lớn. Do đó, nếu sử dụng thuật toán Adam ở đây, bước đi sẽ rất nhỏ. Việc di chuyển một bước đi nhỏ ở đây sẽ làm chậm quá trình hội tụ và không cần thiết. Bởi vì chúng ta tin tưởng rằng chúng ta đang đi đúng hướng, và chúng ta cần một bước đi dài hơn.\nAdaBelief sửa lỗi này bằng một thay đổi nhỏ trong thuật toán của adam. Thay vì tính bình phương của gradient, AdaBelief sẽ tính phương sai của gradient. Một sự thay đổi nhỏ nhưng mang lại giá trị to lớn.\n$$v_t = \\beta_2v_t-_1 + (1-\\beta_2)g^2_t $$ $$s_t = \\beta_2v_t-_1 + (1-\\beta_2)(g_t-m_t)^2$$\nTác giả không dùng biến v nữa, mà thay bằng biến s.\nVới việc dùng biến s. Trong trường hợp trên, g lớn và m lớn, thì s sẽ nhỏ. Và khi s ở phần mẫu nhỏ, chúng ta sẽ có bước đi xa hơn. Ở đây, AdaBelief đã giải quyết vấn đề\nQua đây, chúng ta cũng có thể giải thích vì sao có chữ \u0026ldquo;belief\u0026rdquo; trong từ AdaBelief. Giá trị phương sai được tính dựa vào kỳ vọng của giá trị gradient.\nMột chú ý nhỏ ở đây là mục số 1 và mục số 3 được coi là cải tiến của Adam so với momentum và SGD. Tất nhiên, AdaBelief cũng kế thừa mấy cái này.\n  Ở mục đánh dấu số 1 trên hình, đường cong khá phẳng và giá trị đạo hàm gần như bằng 0. Nếu sử dụng SGD, chúng ta sẽ có một bước đi nhỏ. Trong khi đó, họ Adam sẽ cho chúng ta bước đi lớn hơn vì giá trị căng bậc hai của s hoặc v ở mẫu số sẽ cho ra một kết quả rất nhỏ.\n  Ở mục đánh dấu số 2, đường cong ở đây rất dốc và hẹp, g và delta g ở đây rất lớn, cho nên ở đây chúng ta cần một bước di chuyển nhỏ. Nếu sử dụng SGD hoặc momentum thì sẽ đi một bước đi rất lớn do nhân với một lượng moving averages lớn. Trong khi đó, với Adam hoặc AdaBelief, chúng ta sẽ có giá trị căng bậc hai của s hoặc v ở mẫu số lớn nên bước đi sẽ nhỏ hơn.\n  Về tốc độ hội tụ, tác giả có đề cập rõ và chi tiết trong bài báo, mình không đề cập lại nó nữa ở đây. Các bạn tự xem nhé.\nKết luận   AdaBelief là thuật toán tối ưu hóa có nguồn gốc từ thuật toán Adam, không có thêm tham số ngoài, chỉ thay đổi 1 dòng code.\n  Thuật toán đã tăng tốc độ hội tụ cũng như mức tổng quát hóa.\n  Thuật toán thực hiện các bước đi dựa vào \u0026ldquo;belief\u0026rdquo; của hướng gradient ở thời điểm hiện tại.\n  Thuật toán giải quyết vấn đề \u0026ldquo;Large gradient, small curvature\u0026rdquo; bằng cách xem xét biên độ và dấu của gradient.\n  Nguồn:\n  https://arxiv.org/abs/2010.07468\n  https://medium.com/the-dl/understanding-the-new-adabelief-optimizer-2db70ef6de1e\n  https://towardsdatascience.com/adabelief-optimizer-fast-as-adam-generalizes-as-good-as-sgd-71a919597af\n  ","date":"Jan 15, 2021","img":"","permalink":"/blog/2021-01-15-adabelief-optimizer/","series":null,"tags":["python","optimizer","SGD","opencv"],"title":"Tìm Hiểu Thuật Toán Tối Ưu Hóa Adabelief Optimizer"},{"categories":null,"content":"Advantages of Reinforcement Learning Trong khi trong các phương pháp lý thuyết trò chơi nói chung, ví dụ thuật toán min-max, thuật toán luôn giả định chúng ta có một đối thủ hoàn hảo, công việc phải thực hiện là tối đa hóa phần thưởng của mình và giảm thiểu phần thưởng của đối thủ ( tối đa hóa điểm của mình và tối thiểu hóa điểm của đối thủ), trong học củng cố, chúng ta không cần giả định đối thủ của chúng ta là 1 thiên tài xuất chúng, nhưng chung ta vẫn thu được mô hình với kết quả rất tốt.\nBằng cách coi đối thủ là một phần của môi trường mà chúng ta có thể tương tác, sau một số lần lặp lại nhất định, đối thủ có thể lập kế hoạch trước mà không cần chúng ta phải làm gì cả. Ưu điểm của phương pháp này là giảm số lượng không gian tìm kiếm và giảm số phép toán suy luận phải thực hiện, nhưng nó có thể đạt được kỹ năng hiện đại chỉ bằng cách thử và học.\nTrong bài viết này, chúng ta sẽ làm các công việc sau:\n  Thứ nhất, huấn luyện mô hình cho 2 máy đấu với nhau mà thu được các trọng số cần thiết.\n  Thứ hai, cho người đánh với máy\n  Để hình thành bài toán học củng cố Reinforcement Learning , chúng ta cần phải xác định rõ 3 thành phần chính:\n  State\n  Action\n  Reward\n  Với:\nState chính là bàn cờ với các nước đi của các người chơi. Chúng ta sẽ tạo một bàn cờ có kích thước 3x3, giá trị của mỗi ô cờ đều là 0. Vị trí người chơi 1 đặt quân sẽ được gán là 1. Vị trí người chơi 2 đặt quân sẽ được gán là -1.\nAction là vị trí người chơi sẽ đi quân khi biết state hiện tại (nghĩa là biết đối thủ đi nước nào, và có những nước nào hiện đang trên bàn cờ).\nReward: mang giá trị 0 hoặc 1. Khi kết thúc game sẽ trả về giá trị cho reward.\nỞ phần dưới đây, mình sẽ note lại code và sẽ comment trong code để cho rõ ý\nThiết lập bàn cờ Khởi tạo bàn cờ 12def __init__(self, p1, p2): 3self.board = np.zeros((BOARD_ROWS, BOARD_COLS)) 4self.p1 = p1 5self.p2 = p2 6self.isEnd = False 7self.boardHash = None 8# init p1 plays first 9self.playerSymbol = 1 Chúng ta sẽ tạo một bàn cờ có kích thước 3x3, 2 biến người chơi. Người 1 là người chơi đầu tiên.\n12# Trả về danh sách các nước có thể đi 3def availablePositions(self): 4positions = [] 5for i in range(BOARD_ROWS): 6for j in range(BOARD_COLS): 7if self.board[i, j] == 0: 8positions.append((i, j)) # need to be tuple 9return positions 1011# Cập nhật lại lên bàn cờ vị trí của người chơi đặt quân 1213def updateState(self, position): 14self.board[position] = self.playerSymbol 15# switch to another player 16self.playerSymbol = -1 if self.playerSymbol == 1 else 1 17Kiểm tra Reward Sau mỗi nước đi của các kỳ thủ, chúng ta cần 1 hàm để kiểm tra xem kỳ thủ thắng hay thua và trả về kết quả cho reward như đề cập ở trên\n12def winner(self): 34# Kiểm tra theo dòng 56for i in range(BOARD_ROWS): 7if sum(self.board[i, :]) == 3: 8self.isEnd = True 9return 1 10if sum(self.board[i, :]) == -3: 11self.isEnd = True 12return -1 13# kiểm tra theo cột 1415for i in range(BOARD_COLS): 16if sum(self.board[:, i]) == 3: 17self.isEnd = True 18return 1 19if sum(self.board[:, i]) == -3: 20self.isEnd = True 21return -1 2223# kiểm tra theo đường chéo chính và theo đường chéo phụ 2425diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)]) # đường chéo chính 2627diag_sum2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)]) # đường chéo phụ 2829diag_sum = max(abs(diag_sum1), abs(diag_sum2)) # lấy trị tuyệt đối của các nước đi, nếu bằng 3 nghĩa là có người chơi chiến thắng 3031if diag_sum == 3: 32self.isEnd = True 33if diag_sum1 == 3 or diag_sum2 == 3: 34return 1 35else: 36return -1 3738# Kiểm tra xem còn nước đi hay không 39if len(self.availablePositions()) == 0: 40self.isEnd = True 41return 0 4243# not end 44self.isEnd = False 45return None 4647# only when game ends 48def giveReward(self): 49result = self.winner() 50# backpropagate reward 51if result == 1: 52self.p1.feedReward(1) 53self.p2.feedReward(0) 54elif result == -1: 55self.p1.feedReward(0) 56self.p2.feedReward(1) 57else: 58self.p1.feedReward(0.1) 59self.p2.feedReward(0.5) Ở đây có một lưu ý. Khi cờ hòa thì chúng ta cũng xem rằng người đi trước thua, nên hệ số lúc cờ hòa sẽ là 0.1-0.5. Các bạn có thể thiết lập một giá trị khác, ví dụ 0.2-0.5 hoặc 0.5-0.5 tùy thích.\nThiết lập người chơi Người chơi cần có các phương thức sau:\n  Chọn nước đi dựa trên trạng thái hiện tại của bàn cờ.\n  Lưu lại trạng thái của ván cờ.\n  Cập nhật lại giá trị trạng thái sau mỗi ván.\n  Lưu và load các trọng số lên.\n  Khởi tạo 12def __init__(self, name, exp_rate=0.2): 3self.name = name 4self.states = [] # record all positions taken 5self.lr = 0.2 6self.exp_rate = exp_rate 7self.decay_gamma = 0.9 8self.states_value = {} # state -\u0026gt; value Chọn nước đi 12def chooseAction(self, positions, current_board, symbol): 3randValue = np.random.uniform(0, 1) 4value_max = value = -999 5if randValue\u0026gt; self.exp_rate: 67for p in positions: 8next_board = current_board.copy() 9next_board[p] = symbol 10next_boardHash = self.getHash(next_board) 11value = -999 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash) 12# print(\u0026#34;value\u0026#34;, value) 13if value \u0026gt;= value_max: 14value_max = value 15action = p 1617if value_max == -999 : 18# take random action 19idx = np.random.choice(len(positions)) 20action = positions[idx] 2122# print(\u0026#34;{} takes action {}\u0026#34;.format(self.name, action)) 23return action Cập nhật trạng thái Chúng ta sẽ cập nhật trạng thái với công thức sau\n$$ V(S_t) = V(S_t) + \\alpha [V(S_{t+1}) - V(S_t)] $$\nDiễn giải ra tiếng việt, giá trị của trạng thái tại thời điểm t bằng giá trị tại thời điểm hiện tại cộng với độ lệch của trạng thái hiện tại và trạng thái tiếp theo nhân với một hệ số học alpha.\n12# at the end of game, backpropagate and update states value 3def feedReward(self, reward): 4for st in reversed(self.states): 5if self.states_value.get(st) is None: 6self.states_value[st] = 0 7self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st]) 8reward = self.states_value[st] Huấn luyện mô hình Phần này nằm trong lớp State. Chúng ta sẽ lần lượt đi qua các quá trình luân phiên nhau giữa người chơi 1 và người chơi 2\nngười chơi chọn nước có thể đi -\u0026gt; cập nhật trạng thái -\u0026gt; kiểm tra thắng/thua -\u0026gt; người chơi chọn nước có thể đi \u0026hellip;\n12def play(self, rounds=100): 3for i in range(rounds): 4if i % 1000 == 0: 5print(\u0026#34;Rounds {}\u0026#34;.format(i)) 6while not self.isEnd: 7# Player 1 8positions = self.availablePositions() 9p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol) 10# take action and upate board state 11self.updateState(p1_action) 12board_hash = self.getHash() 13self.p1.addState(board_hash) 14# check board status if it is end 1516win = self.winner() 17if win is not None: 18# self.showBoard() 19# ended with p1 either win or draw 20self.giveReward() 21self.p1.reset() 22self.p2.reset() 23self.reset() 24break 2526else: 27# Player 2 28positions = self.availablePositions() 29p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol) 30self.updateState(p2_action) 31board_hash = self.getHash() 32self.p2.addState(board_hash) 3334win = self.winner() 35if win is not None: 36# self.showBoard() 37# ended with p2 either win or draw 38self.giveReward() 39self.p1.reset() 40self.p2.reset() 41self.reset() 42break Sau khi huấn luyện 100 ngàn lần, chúng ta sẽ chơi với máy, chỉ là 1 thay đổi nhỏ trong hàm chooseAction là thay vì lấy nước đi có trọng số lớn nhất, chúng ta sẽ cho người dùng nhập từ bàn phím dòng và cột vào\n123def chooseAction(self, positions): 4while True: 5row = int(input(\u0026#34;Input your action row:\u0026#34;)) 6col = int(input(\u0026#34;Input your action col:\u0026#34;)) 7action = (row, col) 8if action in positions: 9return action Và sửa lại hàm play một chút, bỏ loop 100k lần đi, bỏ gọi hàm cập nhật thưởng và bỏ các hàm reset đi\n123# play with human 4def play2(self): 5while not self.isEnd: 6# Player 1 7positions = self.availablePositions() 8p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol) 9# take action and upate board state 10self.updateState(p1_action) 11self.showBoard() 12# check board status if it is end 13win = self.winner() 14if win is not None: 15if win == 1: 16print(self.p1.name, \u0026#34;wins!\u0026#34;) 17else: 18print(\u0026#34;tie!\u0026#34;) 19self.reset() 20break 2122else: 23# Player 2 24positions = self.availablePositions() 25p2_action = self.p2.chooseAction(positions) 2627self.updateState(p2_action) 28self.showBoard() 29win = self.winner() 30if win is not None: 31if win == -1: 32print(self.p2.name, \u0026#34;wins!\u0026#34;) 33else: 34print(\u0026#34;tie!\u0026#34;) 35self.reset() 36break Mã nguồn hoàn chỉnh của chương trình\n12import numpy as np 3import pickle 45BOARD_ROWS = 3 6BOARD_COLS = 3 789class State: 10def __init__(self, p1, p2): 11self.board = np.zeros((BOARD_ROWS, BOARD_COLS)) 12self.p1 = p1 13self.p2 = p2 14self.isEnd = False 15self.boardHash = None 16# init p1 plays first 17self.playerSymbol = 1 1819# get unique hash of current board state 20def getHash(self): 21self.boardHash = str(self.board.reshape(BOARD_COLS * BOARD_ROWS)) 22return self.boardHash 2324def winner(self): 25# row 26for i in range(BOARD_ROWS): 27if sum(self.board[i, :]) == 3: 28self.isEnd = True 29return 1 30if sum(self.board[i, :]) == -3: 31self.isEnd = True 32return -1 33# col 34for i in range(BOARD_COLS): 35if sum(self.board[:, i]) == 3: 36self.isEnd = True 37return 1 38if sum(self.board[:, i]) == -3: 39self.isEnd = True 40return -1 41# diagonal 42diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)]) 43diag_sum2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)]) 44diag_sum = max(abs(diag_sum1), abs(diag_sum2)) 45if diag_sum == 3: 46self.isEnd = True 47if diag_sum1 == 3 or diag_sum2 == 3: 48return 1 49else: 50return -1 5152# tie 53# no available positions 54if len(self.availablePositions()) == 0: 55self.isEnd = True 56return 0 57# not end 58self.isEnd = False 59return None 6061def availablePositions(self): 62positions = [] 63for i in range(BOARD_ROWS): 64for j in range(BOARD_COLS): 65if self.board[i, j] == 0: 66positions.append((i, j)) # need to be tuple 67return positions 6869def updateState(self, position): 70self.board[position] = self.playerSymbol 71# switch to another player 72self.playerSymbol = -1 if self.playerSymbol == 1 else 1 7374# only when game ends 75def giveReward(self): 76result = self.winner() 77# backpropagate reward 78if result == 1: 79self.p1.feedReward(1) 80self.p2.feedReward(0) 81elif result == -1: 82self.p1.feedReward(0) 83self.p2.feedReward(1) 84else: 85self.p1.feedReward(0.1) 86self.p2.feedReward(0.5) 8788# board reset 89def reset(self): 90self.board = np.zeros((BOARD_ROWS, BOARD_COLS)) 91self.boardHash = None 92self.isEnd = False 93self.playerSymbol = 1 9495def play(self, rounds=100): 96for i in range(rounds): 97if i % 1000 == 0: 98print(\u0026#34;Rounds {}\u0026#34;.format(i)) 99while not self.isEnd: 100# Player 1 101positions = self.availablePositions() 102p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol) 103# take action and upate board state 104self.updateState(p1_action) 105board_hash = self.getHash() 106self.p1.addState(board_hash) 107# check board status if it is end 108109win = self.winner() 110if win is not None: 111# self.showBoard() 112# ended with p1 either win or draw 113self.giveReward() 114self.p1.reset() 115self.p2.reset() 116self.reset() 117break 118119else: 120# Player 2 121positions = self.availablePositions() 122p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol) 123self.updateState(p2_action) 124board_hash = self.getHash() 125self.p2.addState(board_hash) 126127win = self.winner() 128if win is not None: 129# self.showBoard() 130# ended with p2 either win or draw 131self.giveReward() 132self.p1.reset() 133self.p2.reset() 134self.reset() 135break 136137138# play with human 139def play2(self): 140while not self.isEnd: 141# Player 1 142positions = self.availablePositions() 143p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol) 144# take action and upate board state 145self.updateState(p1_action) 146self.showBoard() 147# check board status if it is end 148win = self.winner() 149if win is not None: 150if win == 1: 151print(self.p1.name, \u0026#34;wins!\u0026#34;) 152else: 153print(\u0026#34;tie!\u0026#34;) 154self.reset() 155break 156157else: 158# Player 2 159positions = self.availablePositions() 160p2_action = self.p2.chooseAction(positions) 161162self.updateState(p2_action) 163self.showBoard() 164win = self.winner() 165if win is not None: 166if win == -1: 167print(self.p2.name, \u0026#34;wins!\u0026#34;) 168else: 169print(\u0026#34;tie!\u0026#34;) 170self.reset() 171break 172173174def showBoard(self): 175# p1: x p2: o 176for i in range(0, BOARD_ROWS): 177print(\u0026#39;-------------\u0026#39;) 178out = \u0026#39;| \u0026#39; 179for j in range(0, BOARD_COLS): 180token = \u0026#34;\u0026#34; 181if self.board[i, j] == 1: 182token = \u0026#39;x\u0026#39; 183if self.board[i, j] == -1: 184token = \u0026#39;o\u0026#39; 185if self.board[i, j] == 0: 186token = \u0026#39; \u0026#39; 187out += token + \u0026#39; | \u0026#39; 188print(out) 189print(\u0026#39;-------------\u0026#39;) 190191192class Player: 193def __init__(self, name, exp_rate=0.3): 194self.name = name 195self.states = [] # record all positions taken 196self.lr = 0.3 197self.exp_rate = exp_rate 198self.decay_gamma = 0.9 199self.states_value = {} # state -\u0026gt; value 200201def getHash(self, board): 202boardHash = str(board.reshape(BOARD_COLS * BOARD_ROWS)) 203return boardHash 204205def chooseAction(self, positions, current_board, symbol): 206randValue = np.random.uniform(0, 1) 207value_max = value = -999 208if randValue\u0026gt; self.exp_rate: 209210for p in positions: 211next_board = current_board.copy() 212next_board[p] = symbol 213next_boardHash = self.getHash(next_board) 214value = -999 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash) 215# print(\u0026#34;value\u0026#34;, value) 216if value \u0026gt;= value_max: 217value_max = value 218action = p 219220if value_max == -999 : 221# take random action 222idx = np.random.choice(len(positions)) 223action = positions[idx] 224225# print(\u0026#34;{} takes action {}\u0026#34;.format(self.name, action)) 226return action 227228# append a hash state 229def addState(self, state): 230self.states.append(state) 231232# at the end of game, backpropagate and update states value 233def feedReward(self, reward): 234for st in reversed(self.states): 235if self.states_value.get(st) is None: 236self.states_value[st] = 0 237self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st]) 238reward = self.states_value[st] 239240def reset(self): 241self.states = [] 242243def savePolicy(self): 244fw = open(\u0026#39;policy_\u0026#39; + str(self.name), \u0026#39;wb\u0026#39;) 245pickle.dump(self.states_value, fw) 246fw.close() 247248def loadPolicy(self, file): 249fr = open(file, \u0026#39;rb\u0026#39;) 250self.states_value = pickle.load(fr) 251fr.close() 252253254class HumanPlayer: 255def __init__(self, name): 256self.name = name 257258def chooseAction(self, positions): 259while True: 260row = int(input(\u0026#34;Input your action row:\u0026#34;)) 261col = int(input(\u0026#34;Input your action col:\u0026#34;)) 262action = (row, col) 263if action in positions: 264return action 265266# append a hash state 267def addState(self, state): 268pass 269270# at the end of game, backpropagate and update states value 271def feedReward(self, reward): 272pass 273274def reset(self): 275pass 276277278if __name__ == \u0026#34;__main__\u0026#34;: 279# training 280p1 = Player(\u0026#34;p1\u0026#34;) 281p2 = Player(\u0026#34;p2\u0026#34;) 282283st = State(p1, p2) 284print(\u0026#34;training...\u0026#34;) 285st.play(100000) 286287p1.savePolicy() 288289# play with human 290p1 = Player(\u0026#34;computer\u0026#34;, exp_rate=0) 291p1.loadPolicy(\u0026#34;policy_p1\u0026#34;) 292293p2 = HumanPlayer(\u0026#34;human\u0026#34;) 294295st = State(p1, p2) 296st.play2() Nguồn\n  Reinforcement Learning: An Introduction phiên bản 2 của Richard S. Sutton and Andrew G. Barto\n  https://towardsdatascience.com/reinforcement-learning-implement-tictactoe-189582bea542\n  ","date":"Dec 27, 2020","img":"","permalink":"/blog/2020-12-26-tic-tac-toe/","series":null,"tags":["python","tetris","opencv"],"title":"Reinforcement Learning Và Tictactoe"},{"categories":null,"content":"Mã nguồn 12import cv2 3import numpy as np 4from random import choice 56def getColor(): 7lstColor = [[255,64,64],[255,165,0],[255,244,79],[102,255,0],[172,229,238],[148,87,235],[148,87,235],[241,156,187]] 8return choice(lstColor) 910def getInfo(piece): 11if piece == \u0026#34;\u0026#34;: 12coords = np.array([[0, 0]]) 13elif piece == \u0026#34;I\u0026#34;: 14coords = np.array([[0, 3], [0, 4], [0, 5], [0, 6]]) 15elif piece == \u0026#34;T\u0026#34;: 16coords = np.array([[1, 3], [1, 4], [1, 5], [0, 4]]) 17elif piece == \u0026#34;L\u0026#34;: 18coords = np.array([[1, 3], [1, 4], [1, 5], [0, 5]]) 19elif piece == \u0026#34;J\u0026#34;: 20coords = np.array([[1, 3], [1, 4], [1, 5], [0, 3]]) 21elif piece == \u0026#34;S\u0026#34;: 22coords = np.array([[1, 5], [1, 4], [0, 3], [0, 4]]) 23elif piece == \u0026#34;Z\u0026#34;: 24coords = np.array([[1, 3], [1, 4], [0, 4], [0, 5]]) 25else: 26coords = np.array([[0, 4], [0, 5], [1, 4], [1, 5]]) 2728return coords, getColor() 2930def display(board, coords, color, next_info, held_info, score, SPEED): 31# Generates the display 3233border = np.uint8(127 - np.zeros([20, 1, 3])) 34border_ = np.uint8(127 - np.zeros([1, 23, 3])) 3536dummy = board.copy() 37dummy[coords[:,0], coords[:,1]] = color 3839right = np.uint8(np.zeros([20, 10, 3])) 40right[next_info[0][:,0] + 2, next_info[0][:,1]] = next_info[1] 4142dummy = np.concatenate(( border, dummy, border, right, border), 1) 43dummy = np.concatenate((border_, dummy, border_), 0) 44dummy = dummy.repeat(20, 0).repeat(20, 1) 45dummy = cv2.putText(dummy, str(score), (325, 150), cv2.FONT_HERSHEY_DUPLEX, 1, [0, 0, 255], 2) 4647# Instructions for the player 48index_pos = 300 49x_index_pos = 300 50dummy = cv2.putText(dummy, \u0026#34;A - left\u0026#34;, (x_index_pos, index_pos), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 234]) 51dummy = cv2.putText(dummy, \u0026#34;D - right\u0026#34;, (x_index_pos, index_pos+25), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 234]) 52dummy = cv2.putText(dummy, \u0026#34;S - drain\u0026#34;, (x_index_pos, index_pos+50), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 234]) 53dummy = cv2.putText(dummy, \u0026#34;W - rotate\u0026#34;, (x_index_pos, index_pos+75), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 234]) 54# dummy = cv2.putText(dummy, \u0026#34;J - rotate left\u0026#34;, (45, 300), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 255]) 55# dummy = cv2.putText(dummy, \u0026#34;L - rotate right\u0026#34;, (45, 325), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 255]) 56# dummy = cv2.putText(dummy, \u0026#34;I - hold\u0026#34;, (45, 350), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 255]) 5758cv2.imshow(\u0026#34;Tetris\u0026#34;, dummy) 59key = cv2.waitKey(int(1000/SPEED)) 6061return key 6263def getNextPiece(): 64next_piece = choice([\u0026#34;O\u0026#34;, \u0026#34;I\u0026#34;, \u0026#34;S\u0026#34;, \u0026#34;Z\u0026#34;, \u0026#34;L\u0026#34;, \u0026#34;J\u0026#34;, \u0026#34;T\u0026#34;]) 6566return next_piece 6768SPEED = 1 # Controls the speed of the tetris pieces 6970# Make a board 7172board = np.uint8(np.zeros([20, 10, 3])) 7374# Initialize some variables 7576quit = False 77place = False 78drop = False 79switch = False 80held_piece = \u0026#34;\u0026#34; 81flag = 0 82score = 0 83next_piece =\u0026#34;\u0026#34; 84current_piece = \u0026#34;\u0026#34; 85# All the tetris pieces 86878889if __name__ == \u0026#34;__main__\u0026#34;: 90next_piece = getNextPiece() 91while not quit: 92# Check if user wants to swap held and current pieces 93if switch: 94# swap held_piece and current_piece 95held_piece, current_piece = current_piece, held_piece 96switch = False 97else: 98# Generates the next piece and updates the current piece 99current_piece = next_piece 100next_piece = getNextPiece() 101102if flag \u0026gt; 0: 103flag -= 1 104105# Determines the color and position of the current, next, and held pieces 106107held_info = getInfo(held_piece) 108109next_info = getInfo(next_piece) 110111coords, color = getInfo(current_piece) 112if current_piece == \u0026#34;I\u0026#34;: 113top_left = [-2, 3] 114115if not np.all(board[coords[:,0], coords[:,1]] == 0): 116break 117118while True: 119# Shows the board and gets the key press 120key = display(board, coords, color, next_info, held_info, score, SPEED) 121# Create a copy of the position 122dummy = coords.copy() 123print(\u0026#34;speed \u0026#34;,SPEED, \u0026#34;key \u0026#34;,key,\u0026#34; \u0026#34;, ord(\u0026#34;s\u0026#34;)) 124125if key == ord(\u0026#34;s\u0026#34;): 126drop = True 127128elif key == ord(\u0026#34;a\u0026#34;): 129# Moves the piece left if it isn\u0026#39;t against the left wall 130if np.min(coords[:,1]) \u0026gt; 0: 131coords[:,1] -= 1 132if current_piece == \u0026#34;I\u0026#34;: 133top_left[1] -= 1 134elif key == ord(\u0026#34;d\u0026#34;): 135# Moves the piece right if it isn\u0026#39;t against the right wall 136if np.max(coords[:,1]) \u0026lt; 9: 137coords[:,1] += 1 138if current_piece == \u0026#34;I\u0026#34;: 139top_left[1] += 1 140# elif key == ord(\u0026#34;j\u0026#34;) or key == ord(\u0026#34;l\u0026#34;): 141# # Rotation mechanism 142# # arr is the array of nearby points which get rotated and pov is the indexes of the blocks within arr 143144# if current_piece != \u0026#34;I\u0026#34; and current_piece != \u0026#34;O\u0026#34;: 145# if coords[1,1] \u0026gt; 0 and coords[1,1] \u0026lt; 9: 146# arr = coords[1] - 1 + np.array([[[x, y] for y in range(3)] for x in range(3)]) 147# pov = coords - coords[1] + 1 148149# elif current_piece == \u0026#34;I\u0026#34;: 150# # The straight piece has a 4x4 array, so it needs seperate code 151152# arr = top_left + np.array([[[x, y] for y in range(4)] for x in range(4)]) 153# pov = np.array([np.where(np.logical_and(arr[:,:,0] == pos[0], arr[:,:,1] == pos[1])) for pos in coords]) 154# pov = np.array([k[0] for k in np.swapaxes(pov, 1, 2)]) 155156# # Rotates the array and repositions the piece to where it is now 157158# if current_piece != \u0026#34;O\u0026#34;: 159# if key == ord(\u0026#34;j\u0026#34;): 160# arr = np.rot90(arr, -1) 161# else: 162# arr = np.rot90(arr) 163# coords = arr[pov[:,0], pov[:,1]] 164165elif key == ord(\u0026#34;w\u0026#34;): 166# Rotation mechanism 167# arr is the array of nearby points which get rotated and pov is the indexes of the blocks within arr 168169if current_piece != \u0026#34;I\u0026#34; and current_piece != \u0026#34;O\u0026#34;: 170if coords[1,1] \u0026gt; 0 and coords[1,1] \u0026lt; 9: 171arr = coords[1] - 1 + np.array([[[x, y] for y in range(3)] for x in range(3)]) 172pov = coords - coords[1] + 1 173174elif current_piece == \u0026#34;I\u0026#34;: 175# The straight piece has a 4x4 array, so it needs seperate code 176177arr = top_left + np.array([[[x, y] for y in range(4)] for x in range(4)]) 178pov = np.array([np.where(np.logical_and(arr[:,:,0] == pos[0], arr[:,:,1] == pos[1])) for pos in coords]) 179pov = np.array([k[0] for k in np.swapaxes(pov, 1, 2)]) 180181# Rotates the array and repositions the piece to where it is now 182183if current_piece != \u0026#34;O\u0026#34;: 184if key == ord(\u0026#34;j\u0026#34;): 185arr = np.rot90(arr, -1) 186else: 187arr = np.rot90(arr) 188coords = arr[pov[:,0], pov[:,1]] 189# Hard drop set to true 190# drop = True 191# elif key == ord(\u0026#34;i\u0026#34;): 192# # Goes out of the loop and tells the program to switch held and current pieces 193# if flag == 0: 194# if held_piece == \u0026#34;\u0026#34;: 195# held_piece = current_piece 196# else: 197# switch = True 198# flag = 2 199# break 200elif key == 8 or key == 27: 201quit = True 202break 203204# Checks if the piece is overlapping with other pieces or if it\u0026#39;s outside the board, and if so, changes the position to the position before anything happened 205206if np.max(coords[:,0]) \u0026lt; 20 and np.min(coords[:,0]) \u0026gt;= 0: 207if not (current_piece == \u0026#34;I\u0026#34; and (np.max(coords[:,1]) \u0026gt;= 10 or np.min(coords[:,1]) \u0026lt; 0)): 208if not np.all(board[coords[:,0], coords[:,1]] == 0): 209coords = dummy.copy() 210else: 211coords = dummy.copy() 212else: 213coords = dummy.copy() 214215if drop: 216# Every iteration of the loop moves the piece down by 1 and if the piece is resting on the ground or another piece, then it stops and places it 217218while not place: 219if np.max(coords[:,0]) != 19: 220# Checks if the piece is resting on something 221for pos in coords: 222if not np.array_equal(board[pos[0] + 1, pos[1]], [0, 0, 0]): 223place = True 224break 225else: 226# If the position of the piece is at the ground level, then it places 227place = True 228229if place: 230break 231232# Keeps going down and checking when the piece needs to be placed 233234coords[:,0] += 1 235236if current_piece == \u0026#34;I\u0026#34;: 237top_left[0] += 1 238239drop = False 240241else: 242# Checks if the piece needs to be placed 243if np.max(coords[:,0]) != 19: 244for pos in coords: 245if not np.array_equal(board[pos[0] + 1, pos[1]], [0, 0, 0]): 246place = True 247break 248else: 249place = True 250251if place: 252# Places the piece where it is on the board 253for pos in coords: 254board[tuple(pos)] = color 255256# Resets place to False 257place = False 258break 259260# Moves down by 1 261262coords[:,0] += 1 263if current_piece == \u0026#34;I\u0026#34;: 264top_left[0] += 1 265266# Clears lines and also counts how many lines have been cleared and updates the score 267268lines = 0 269270for line in range(20): 271if np.all([np.any(pos != 0) for pos in board[line]]): 272lines += 1 273board[1:line+1] = board[:line] 274275276score += lines*10 Mã nguồn này được kế thừa từ bài viết https://www.learnopencv.com/tetris-with-opencv-python/ và mình có modify lại theo sở thích cá nhân của mình. Còn một số bug mà mình chưa fix hết. Bạn đọc nào ghé ngang có đóng góp gì thì để lại comment giúp mình hen.\n","date":"Dec 26, 2020","img":"","permalink":"/blog/2020-12-25-tetric/","series":null,"tags":["python","tetris","opencv"],"title":"Xây Dựng Game Xếp Gạch Bằng Opencv Và Python"},{"categories":null,"content":"Giá trị ngưỡng: Nói theo kiểu lúa hóa, trong opencv, ngưỡng là một số nằm trong đoạn từ 0 đến 255. Giá trị ngưỡng sẽ chia tách giá trị độ xám của ảnh thành 2 miền riêng biệt. Miền thứ nhất là tập hợp các điểm ảnh có giá trị nhỏ hơn giá trị ngưỡng. Miền thứ hai là tập hợp các các điểm ảnh có giá trị lớn hơn hoặc bằng giá trị ngưỡng.\nĐầu vào của một thuật toán phân ngưỡng trong opencv thường có input là ảnh nguồn (source image) và giá trị ngưỡng. Đầu ra là ảnh đích đã được phân ngưỡng (destination image). Một số thuật toán phân ngưỡng sẽ kèm thêm vài giá trị râu ria khác nữa, chúng ta sẽ không quan tâm đến chúng\nMã giải của thuật toán phân ngưỡng:\n1if src[i] \u0026gt;= T: 2dest[i] = MAXVAL 3else: 4dest [i] = 0 Có rất nhiều thuật toán phân ngưỡng dựa trên cách chúng ta xác định ngưỡng. Chúng ta sẽ tìm hiểu lần lượt các thuật toán trên.\nThuật toán Simple Thresholding Simple Thresholding thực hiện phân ngưỡng bằng cách thay thế giá trị lớn hơn hoặc bằng và giá trị bé hơn giá trị ngưỡng bằng một giá trị mới. Cụ thể chúng ta có thể xem mã nguồn bên dưới\n12import cv2 3import numpy as np 4from matplotlib import pyplot as plt 56img = cv2.imread(\u0026#39;gradient.png\u0026#39;,0) 7ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY) 8ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV) 9ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC) 10ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO) 11ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV) 1213titles = [\u0026#39;Original Image\u0026#39;,\u0026#39;BINARY\u0026#39;,\u0026#39;BINARY_INV\u0026#39;,\u0026#39;TRUNC\u0026#39;,\u0026#39;TOZERO\u0026#39;,\u0026#39;TOZERO_INV\u0026#39;] 14images = [img, thresh1, thresh2, thresh3, thresh4, thresh5] 1516for i in xrange(6): 17plt.subplot(2,3,i+1),plt.imshow(images[i],\u0026#39;gray\u0026#39;) 18plt.title(titles[i]) 19plt.xticks([]),plt.yticks([]) 2021plt.show() Hình ảnh và thuật toán của mô hình được lấy từ trang opencv-python-tutroals.readthedocs.io\nỞ đoạn code trên, chúng ta thiết lập giá trị ngưỡng là 127, với các điểm ảnh có giá trị lớn hơn hoặc bằng 127, chúng ta sẽ gán lại giá trị của nó thành 255. Và các điểm ảnh có giá trị bé hơn 127 sẽ được gán bằng 0 (mặc định).\n123double cv::threshold\t(\tInputArray src, 4OutputArray dst, 5double thresh, 6double maxval, 7int type 8)\tThuật toán sample thresholding của opencv còn có 1 tham số nữa khá quan trọng nữa là loại ngưỡng (type). Hiện tại lúc mình viết bài viết này thì opencv hỗ trợ 8 loại là: THRESH_BINARY, THRESH_BINARY_INV, THRESH_TRUNC, THRESH_TOZERO, THRESH_TOZERO_INV, THRESH_MASK, THRESH_OTSU, THRESH_TRIANGLE. Ý nghĩa của từng loại như sau:\n  THRESH_BINARY: Có thể dịch là ngưỡng nhị phân. Ý nghĩa y hệt những gì mình đề cập ở trên.\n  THRESH_BINARY_INV: Ngưỡng nhị phân đảo ngược. Có thể hiểu là nó sẽ đảo ngược lại kết quả của THRESH_BINARY.\n  THRESH_TRUNC: Những giá trị điểm ảnh bé hơn ngưỡng sẽ giữ nguyên giá trị, những điểm ảnh lớn hơn hoặc ngưỡng sẽ được gán lại là maxvalue.\n  THRESH_TOZERO: Những điểm ảnh bé hơn ngưỡng sẽ bị gán thành 0, những điểm còn lại giữ nguyên.\n  THRESH_TOZERO_INV: Những điểm ảnh nhỏ hơn giá trị ngưỡng sẽ được giữ nguyên, những điểm ảnh còn lại sẽ bị gán thành 0.\n  THRESH_MASK: Ở bạn opencv4, hầu như không được xài.\n  THRESH_OTSU: Sử dụng thuật toán Otsu để xác định giá trị ngưỡng.\n  THRESH_TRIANGLE: Sử dụng thuật toán Triangle để xác định giá trị ngưỡng.\n  Giá trị 127 là giá trị trung bình cộng của 0 và 255 làm tròn xuống. Giá trị ngưỡng của thuật toán này đòi hỏi người sử dụng phải có mức độ hiểu biết nhất định về các loại ảnh mình đang xử lý để chọn ngưỡng cho phù hợp.\nAdaptive Thresholding Thuật toán simple thresholding hoạt động khá tốt. Tuy nhiên, nó có 1 nhược điểm là giá trị ngưỡng bị/được gán toàn cục. Thực tế khi chụp, hình ảnh chúng ta nhận được thường bị ảnh hưởng của nhiễu, ví dụ như là bị phơi sáng, bị đèn flask, \u0026hellip;\nMột trong những cách được sử dụng để giải quyết vấn đề trên là chia nhỏ bức ảnh thành những vùng nhỏ (region), và đặt giá trị ngưỡng trên những vùng nhỏ đó -\u0026gt; adaptive thresholding ra đời. Opencv cung cấp cho chúng ta hai cách xác định những vùng nhỏ\n1import cv2 as cv 2import numpy as np 3from matplotlib import pyplot as plt 4img = cv.imread(\u0026#39;sudoku.png\u0026#39;,0) 5img = cv.medianBlur(img,5) 6ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY) 7th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\ 8cv.THRESH_BINARY,11,2) 9th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\ 10cv.THRESH_BINARY,11,2) 11titles = [\u0026#39;Original Image\u0026#39;, \u0026#39;Global Thresholding (v = 127)\u0026#39;, 12\u0026#39;Adaptive Mean Thresholding\u0026#39;, \u0026#39;Adaptive Gaussian Thresholding\u0026#39;] 13images = [img, th1, th2, th3] 14for i in xrange(4): 15plt.subplot(2,2,i+1),plt.imshow(images[i],\u0026#39;gray\u0026#39;) 16plt.title(titles[i]) 17plt.xticks([]),plt.yticks([]) 18plt.show() Hình ảnh và thuật toán của mô hình được lấy từ trang docs.opencv.org\n123void cv::adaptiveThreshold\t(\tInputArray src, 4OutputArray dst, 5double maxValue, 6int adaptiveMethod, 7int thresholdType, 8int blockSize, 9double C 10)\tỞ đây:\nblockSize: Kích thước của vùng, bắt buộc phải là một số lẻ lớn hơn 0.\nC: hằng số, giá trị từ -255 đến 255. Có thể gán C bằng 0 để đỡ rối.\nadaptiveMethod nhận vào một trong hai giá trị là cv.ADAPTIVE_THRESH_MEAN_C và cv.ADAPTIVE_THRESH_GAUSSIAN_C, đó là các phương pháp tính ngưỡng.\n  ADAPTIVE_THRESH_MEAN_C: Tính trung bình các láng giềng xung quanh điểm cần xét trong vùng blockSize * blockSize trừ đi giá trị hằng số C.\n  ADAPTIVE_THRESH_GAUSSIAN_C: Nhân giá trị xung quanh điểm cần xét với trọng số gauss rồi tính trung bình của nó, sau đó trừ đi giá trị hằng số C.\n  thresholdType: Tương tự như Simple Thresholding đã trình bày ở trên.\nCảm ơn các bạn đã quan tâm và theo dõi bài viết, hẹn gặp bạn ở các bài viết tiếp theo.\nTham khảo\n  https://www.geeksforgeeks.org/python-thresholding-techniques-using-opencv-set-1-simple-thresholding/\n  https://www.learnopencv.com/opencv-threshold-python-cpp/\n  https://medium.com/@anupriyam/basic-image-thresholding-in-opencv-5af9020f2472\n  ","date":"Dec 25, 2020","img":"","permalink":"/blog/2020-12-24-thresholding/","series":null,"tags":["python","thresholding","contour","opencv"],"title":"Ngưỡng (Thresholding) Trong Opencv"},{"categories":null,"content":"Việc huấn luyên mô hình máy học có thể sẽ gây ra cho bạn một chút khó khăn nếu bạn không hiểu những thứ bạn dang làm là đúng hay sai. Trong hầu hết các trường hợp, các mô hình học máy là các \u0026ldquo;hộp đen\u0026rdquo;, chúng ta chỉ có thể \u0026ldquo;nhìn thấy\u0026rdquo; dữ liệu đầu vào và độ chính xác mà mô hình trả ra. Chúng ta không biết bên trong nó đang làm cái gì. Việc hiểu lý do tại sao mô hình cho ra kết quả tệ hại là chìa khóa cho cái \u0026ldquo;cách\u0026rdquo; mà bạn cải tiến nó.\n  Tìm hiểu lý do \u0026ldquo;tại sao\u0026rdquo; mô hình cho ra kết quả tệ hại bằng cách \u0026ldquo;xác định bias và variance\u0026rdquo;.\n  Tìm hiểu \u0026ldquo;cách\u0026rdquo; cải tiến mô hình bằng việc thực hiện \u0026ldquo;giảm bias và variance\u0026rdquo;.\n  Xác định bias và variance Trước hết, chúng ta hãy bắt đầu nói về lỗi. Lỗi là phần không chính xác của mô hình trên tập test.\n$$ error = 1 - testing accuracy $$\nNếu mô hình đạt độ chính xác là 86% trên tập test, điều đó đồng nghĩa với độ lỗi là 14%. Trong 14% đó bao gồm bias và variance.\nBiểu đồ bias - variance. Nguồn towardsdatascience.com\nHai ý chính của hình trên cần làm rõ ở đây:\n  Bias là lỗi trên tập huấn luyện.\n  Variance là gap giữa độ chính xác trên tập train và độ chính xác trên tập test.\n  Bạn hãy hình thật kỹ vào hình ở trên, nhìn đi nhìn lại 2, 3 lần. Nhắm mắt lại và nghiền ngẫm thật kỹ hai ý chính mình vừa đề cập ở trên.\nBias Bias mô tả khả năng học của mô hình. Giá trị bias lớn đồng nghĩa với việc mô hình cần phải học nhiều hơn nữa từ tập huấn luyện.\nNếu mô hình có độ chính xác 90% trên tập train, điều đó đồng nghĩa với việc bạn có 10% bias. Bias cũng được chia làm 2 nhóm, nhóm bias có thể tránh được (avoidable bias) và nhóm bias không thể tránh được (unavoidable bias).\n$$ bias = 1 - trainning accuracy $$\nUnavoidable bias Unavoidable bias hay còn được sử dụng dưới tên là optimal error rate. Đây là giới hạn trên của mô hình. Trong một số bài toán, ví dụ như là bài toán dự đoán giá chứng khoán, chúng ta - con người - không thể dự đoán chính xác 100%. Do đó, trong điều kiện lý tưởng nhất, tại một thời điểm nào đó, mô hình của chúng ta vẫn cứ trả ra kết quả sai.\nNếu bạn quyết định rằng mô hình có độ sai ít nhất là 4%. Nghĩa là chúng ta có 4% unavoidable bias.\nAvoidable bias Khác với optimal error rate và trainning error. Độ lỗi này xảy ra khi mô hình chúng ta chưa đủ độ tới. Chúng ta hoàn toàn có thể cái tiến mô hình này để giảm độ lỗi này về mức 0, v\nBiểu đồ bias - variance. Nguồn towardsdatascience.com\nBạn hãy để ý kỹ phần bias ở hình trên. Bias được chia làm 2 phần. Ở trên phần nét đứt là Unavoidable bias. Nó là điểm tới hạn của mô hình. Việc cần làm của chúng ta là huấn luyện, cải tiến mô hình, để cho đường trainning accuracy màu đỏ tiến sát với đường nét đứt.\nVariance Variance ý nghĩa của nó là mô tả mức độ tổng quát hóa của mô hình của bạn đối với dữ liệu mà nó chưa được huấn luyện. Và định nghĩa của nó là phần sai lệch giữa độ chính xác trên tập huấn luyện và độ chính xác tên tập test.\n$$ Variance = trainning accuracy - testing accuracy $$\nBiểu đồ variance. Nguồn towardsdatascience.com\nTradeoff giữa bias và variance Sự đánh đổi giữa bias và variace. Nguồn towardsdatascience.com\nMình nghĩ hình trên đủ nói lên tất cả ý mình muốn nói. Khi mô hình cảng trở nên phức tạp, thì bias sẽ giảm, nhưng mức độ tổng quát hóa cũng giảm theo (đồng nghĩa với việc variace sẽ tăng).\nCách giảm bias và variance Cách giảm bias Như đã nói ở phần trên, bias được chia thành 2 nhóm là Avoidable bias và unavoidable bias. Chúng ta không thể nào giảm Avoidable bias, nhưng chúng ta có thể giảm unavoidable bias bằng một trong các cách sau.\nTăng kích thước mô hình Việc tăng kích thước mô hình là một trong những cách làm giảm avoidable bias. Mô hình càng lớn thì có càng nhiều tham số phải điều chỉnh. Có nhiều tham sos đồng nghĩa với việc mô hình sẽ học được nhiều mối quan hệ phức tạp hơn. Chúng ta có thể tăng kích thước mô hình bằng cách thêm nhiều layer hơn nữa, hoặc thêm nhiều node hơn nữa cho mỗi layer.\nGiảm Regulation Việc giảm regulation cũng giúp mô hình tăng độ chính xác trên tập huấn luyên. Tuy nhiên, nếu chúng ta giảm regularization quá đà, mô hình sẽ không đạt được mức độ tổng quát hóa, và làm tăng variance. Đây là ví dụ dễ thấy nhất nhất về sự đánh đổi giữa bias và variance.\nGiảm Regulation . Nguồn towardsdatascience.com\nThay đổi kiến trúc mô hình Việc thay đổi kiến trúc mô hình cũng có thể giúp chúng ta đạt được độ chính xác cao hơn.\nMột số mục có thể thay đổi:\n  Thay đổi activation function ( ví dụ tanh, ReLU, sigmoid, LeakyReLU)\n  Thay đổi loại mô hình (ANN, CNN, RNN, KNNKNN, \u0026hellip;)\n  Thay đổi các tham số (learning rate, image size, \u0026hellip;)\n  Thay đổi thuật toán tối ưu (Adam, SGD, RMSprop, …)\n  Thêm đặc trưng mới Việc thêm đặc trưng mới giúp chúng ta cung cấp cho mô hình nhiều thông tin hơn. Chúng ta có thể thực hiện điều này thông qua kỹ thuật feature engineering.\nGiảm variance Thêm nhiều dữ liệu Thêm dữ liệu là cách đơn giản nhất, thường gặp nhất để tăng độ chính xác của mô hình trong trường hợp mô hình huấn luyện của chúng ta bị hight variance. Hiệu quả của việc thêm nhiều dữ liệu vào mô hình đã được đề cập ở bài báo có tựa đề là The Unreasonable Effectiveness of Recurrent Neural Networks của Andrej Karpathy (link: http://karpathy.github.io/2015/05/21/rnn-effectiveness/). Việc thêm dữ liệu thường không ảnh hưởng đến độ lỗi bias, giúp làm giảm variance, nên đây là cách thường được sử dụng nhất.\nTăng Regularization Việc tăng Regularization giúp mô hình chống overfitting. Qua đó giúp giảm variance, và tăng bias :(. Một só cách Regularization hot ở thời điểm hiện lại là dropout ( với biến thể là Monte Carlo Dropout), BatchNorm\u0026hellip;\nGiảm kích thước mô hình Việc giảm kích thước mô hình giúp cho chúng ta giảm overfitting trên tập train. Mục tiêu của Việc này làm giảm khả năng liên kết những pattern của dữ liệu. Bởi vậy, mục tiêu của nó hoàn toàn tương tự như tăng Regularization. Trong thực tế, chúng ta thường sử dụng tăng thêm Regularization hơn là giảm kích thước mô hình để chống variace.\nLựa chọn đặc trưng (feature selection) Giảm chiều dữ liệu, bằng cách bỏ đi các đặc trưng thừa, giúp giảm nhiễu, là cách thường được sử dụng để giảm variace. Chúng ta có thể sử dụng PCA (Principal Component Analysis) để lọc ra các đặc trưng tốt hoặc kết hợp chúng với nhau để tạo các đặc trưng tốt hơn.\nBức tranh tổng quát Sau tất cả, chúng ta sẽ xây dựng được một bức tranh tổng quan về lỗi chúng ta đang mắc phải là gì và chúng ta nên làm gì để giảm độ lỗi đó.\nTổng quan . Nguồn towardsdatascience.com\nTổng kết   Reducing Bias\n  Increase model size\n  Reduce regularization\n  Change model architecture\n  Add features\n    Reducing Variance\n  Add More data\n  Decrease model size\n  Add regularization\n  Feature selection\n    Cảm ơn các bạn đã quan tâm và theo dõi bài viết, hẹn gặp bạn ở các bài viết tiếp theo.\nBài viết được lược dịch từ link https://towardsdatascience.com/two-important-machine-learning-concepts-to-improve-every-model-62fd058916b\nNguồn tự liệu từ bài viết được sử dụng trong cuốn sách Machine Learning Yearning của Andrew Ng. Các bạn có thể search theo từ khóa trên hoặc đăng ký trên site http://deeplearning.net/\n","date":"Jan 26, 2020","img":"","permalink":"/blog/2020-04-16-two-important-machine-learning-concepts-to-improve-every-model/","series":null,"tags":["machine learning","deep learning","bias","variance"],"title":"Hai Khái Niệm Quan Trọng Giúp Tăng Độ Chính Xác Của Các Mô Hình Trong Machine Learning"},{"categories":null,"content":"Đặt vấn đề Giả sử bạn và tôi đều thích nghe nhạc trên trang mp3.zing.vn. Mỗi người đều nghe khoảng 100 bài nhạc khác nhau. Để đo sự giống nhau giữa danh sách bài hát bạn nghe và danh sách bài hát tôi nghe, thông thường chúng ta sẽ dùng độ đo Jaccard Similarity, được đo bằng cách lấy phần giao (intersection ) chia cho phần hợp (union). Nghĩa là đếm số lượng bài hát cả hai cùng nghe (phần giao) chia cho tổng số bài hát không lặp của cả hai.\nTrong trường hợp bạn và tôi đều nghe 100 bài, trong đó có 30 bài giống nhau, vậy phần giao là 30, phần hợp là 170, giá trị Jaccard Similarity sẽ là 30/170.\nĐộ đo Jaccard Similarity được sử dụng ở phương pháp apriori , FP Growth, \u0026hellip; mà các bạn đã có dịp học trong môn khai phá dữ liệu ở Đại học.\nBài toán tìm kiếm văn bản tương đồng Giả sử bạn quản lý một số lượng lớn văn bản (N= 1 tỷ), và xếp của bạn có nhu cầu nhóm những bài viết giống nhau thành từng cụm. Để:\n  Loại bỏ bớt những kết quả trùng trong khung search.\n  Nhóm những bài viết vào từng nhóm sự kiện theo dòng thời gian, ví dụ sự kiện \u0026lsquo;cô gái giao gà\u0026rsquo;, sự kiện \u0026lsquo;dịch cúm corona\u0026rsquo;, \u0026hellip;\n  Vì một bất kể lý do nào đó mà trong lúc viết bài này tác giả chưa nghĩ ra.\n  Khi đó, các vấn đều sau có thể sẽ phát sinh:\n  Nhiều phần nhỏ của văn bản này xuất hiện ở một vị trí lộn xộn nào ở một hoặc nhiều văn bản khác.\n  Văn bản quá dài nên không thể lưu trữ hết lên bộ nhớ chính (RAM).\n  Có quá nhiều cặp văn bản cần phải so sánh.\n  Để giải quyết bài toán trên, chúng ta sẽ tiếp cận theo hướng sau:\n  Shingling: Chuyển văn bản thành tập ký tự, tập từ \u0026hellip;.\n  Min-Hashing: Chuyển tập ký tự thành 1 chuỗi số hash định danh.\n  Locality-Sensitive Hashing: Tìm các văn bản tương đồng dựa vào chuỗi số định danh.\n  Ở bài viết này, mình chỉ đề cập bước thứ 2 là Min-Hashing. Bước 1 và bước 3 bạn có thể tham khảo thêm trong khóa học, mình có để link bên dưới.\nVì sao phải dùng Min-Hashing Như bài toán đặt ra ở trên, chúng ta có 1 tỷ văn bản, chúng ta cần N(N-1)/2 = 5*10^17 phép tính Jaccard Similarity. Chúng ta có một server có thể thực hiện 5x10^6 phép so sánh, thì chúng ta phải mất 10^11 giây tương đương 31,710 năm để thực hiện xong.\nThuật toán MinHash sẽ giúp chúng ta một giá trị xấp xỉ giá trị của Jaccard Similarity của hai tập dữ liệu. Ưu điểm của MinHash:\n  Có chiều dài đầu ra cố định\n  Không phụ thuộc vào chiều dài đầu vào.\n  Để tính giá trị xấp xỉ Jaccard Similarity (MinHash signatures), đầu tiên ta sẽ tính MinHash của hai tập data, được 2 giá trị hash, sau đó đếm giá trị trùng nhau của 2 chuỗi hash và chia chiều dài gía trị hash, chúng ta sẽ được một giá trị xấp xỉ giá trị Jaccard Similarity.\nVí dụ ta có hai tập tập dữ liệu {a,x,c,d} và {a,x,d,e} hai giá trị hash ta có tương ứng là 1234 và 1235, số ký tự trùng nhau là 3 (1,2,3), chiều dài là 4, vậy ta có giá trị Jaccard Similarity là 3/4.\nPhép tính này sẽ hơn việc tính Jaccard Similarity truyền thống, lý do là chúng ta không cần phải tính phần giao và phần hợp của hai tập dữ liệu ( trong trường hợp hai tập có nhiều giá trị thì việc tính càng lâu), và giá trị hash thường có chiều dài ngắn hơn so với số lượng phần trử trong tập dữ liệu, ngoài ra phép so sánh cũng đơn giản hơn nhiều.\nThuật toán MinHash Ý tưởng của thuật toán khá đơn giản:\nta có hàm hash:\n$$ h(x) = (ax+b)%c $$\nTrong đó:\n  x là số nguyên đầu vào, a và b là hai số được chọn ngẫu nhiên với điều kiện a và b \u0026lt; x\n  c là số nguyên tố được chọn ngẫu nhiên, với điều kiện c lớn hơn x.\n  Cách thuật toán thực hiện như sau:\nVới 1 văn bản, chạy thuật toán hash 10 lần, do ta có số a và b là ngẫu nhiên nên 10 lần chạy sẽ cho ra các kết quả khác nhau, lấy giá trị hash nhỏ nhất (do đó thuật toán có tên là min hash) làm thành phần đầu tiên của MinHash signature. Lặp lại quá trình trên 10 lần, chúng ta có MinHash signature với 10 giá trị.\nXong thuật toán, quá dễ.\nCảm ơn các bạn đã quan tâm và theo dõi bài viết, hẹn gặp bạn ở các bài viết tiếp theo.\nTham khảo\n  Khóa học Mining of Massive Datasets chương 3 http://www.mmds.org/\n  https://mccormickml.com/2015/06/12/minhash-tutorial-with-python-code/\n  ","date":"Jan 26, 2020","img":"","permalink":"/blog/2020-01-26-simhash/","series":null,"tags":["python","hash"],"title":"Simhash"},{"categories":null,"content":"Built-In Hashing Python có xây dựng sẵn cho chúng ta một hàm hash, chúng ta cứ việc gọi ra và sử dụng.\n1hash(\u0026#34;pham duy tung\u0026#34;) 2-7141560399917772220 Một lưu ý nhỏ là giá trị của hàm hash sẽ khác nhau giữa các phiên bản python. Ví dụ ở trên mình xài python 3.8, với bản 3.6 sẽ là\n1hash(\u0026#34;pham duy tung\u0026#34;) 21568935795476364190 Checksums Chúng ta có thể sử dụng checksums để hash dữ liệu. Checksum được sử dụng trong thuật toán nén file ZIP để đảm bảo toàn vẹn dữ liệu sau khi nén. Thư viện zlib của python hỗ trợ 2 hàm tính checksum là adler32 và crc32. Để đảm bảo tốc độ chương trình và chỉ cần lấy hash đơn giản, chúng ta có thể sử dụng hàm Adler32. Tuy nhiên, nếu bạn muốn chương trình có độ tin cậy cao hoặc đơn giản là checksums, hãy sử dụng crc32. Các bạn có thể đọc bài viết ở đây https://www.leviathansecurity.com/blog/analysis-of-adler32 để hiểu hơn.\n1\u0026gt;\u0026gt;\u0026gt; import zlib 2\u0026gt;\u0026gt;\u0026gt; zlib.adler32(b\u0026#34;Pham Duy Tung\u0026#34;) 3524616855 4\u0026gt;\u0026gt;\u0026gt; zlib.crc32(b\u0026#34;Pham Duy Tung\u0026#34;) 53750031252 Secure Hashing Mã hóa an toàn (Secure Hashing) và bảo mật dữ liệu đã được nghiên cứu và ứng dụng từ nhiều năm về trước. Tiền thân là thuật toán MD5 đến SHA1, SHA256, SHA512\u0026hellip;. Mỗi thuật toán ra đời sau sẽ cải tiến độ bảo mật và giảm đụng độ của các thuật toán trước đó.\nMột số hàm hash phổ biến:\nMD5– 16 bytes/128 bit Chuỗi đầu ra của MD5 có kích thước 16 bytes hay 16*8 = 128 bits. Ở thời điểm hiện tại MD5 không còn là thuật toán phổ biến và không được khuyến khích dùng bởi các tổ chức bảo mật.\n1\u0026gt;\u0026gt;\u0026gt; import hashlib 2\u0026gt;\u0026gt;\u0026gt; hashlib.md5(b\u0026#34;Pham Duy Tung\u0026#34;).hexdigest() 3\u0026#39;58067430b9caa44f5ac1220b171f45c8\u0026#39; 4\u0026gt;\u0026gt;\u0026gt; len(hashlib.md5(b\u0026#34;Pham Duy Tung\u0026#34;).digest()) # Chiều dài của đầu ra là 16 bytes 516 Chú ý: Hàm hexdigest biểu diễn một byte thành một ký tự hex (2 ký tự đầu 58 của ví dụ trên là giá trị hex của số 88 trong hệ thập phân)\nSHA1–20 bytes/160 bits Đầu ra của SHA1 có chiều dài là 20 bytes tương ứng với 160 bit. Cũng giống như MD5, SHA1 cũng không được khuyến khích sử dụng ở trong các ứng dụng bảo mật.\n1\u0026gt;\u0026gt;\u0026gt; import hashlib 2\u0026gt;\u0026gt;\u0026gt; hashlib.sha1(b\u0026#34;Pham Duy Tung\u0026#34;).hexdigest() 3\u0026#39;b95b8716f15d89b6db67e2e788dea42d3fba5ee8\u0026#39; 4\u0026gt;\u0026gt;\u0026gt; len(hashlib.sha1(b\u0026#34;Pham Duy Tung\u0026#34;).digest()) 520 SHA256–32 bytes/256 bit và SHA512–64 bytes/512 bit Đây là hai hàm hash được khuyên là nên dùng ở thời điểm hiện tại\n1\u0026gt;\u0026gt;\u0026gt; hashlib.sha256(b\u0026#34;Pham Duy Tung\u0026#34;).hexdigest() 2\u0026#39;611b322b6b8ee570831c6061408ac5aa77fcdb572206d5d443855f5d3c1383c6\u0026#39; 3\u0026gt;\u0026gt;\u0026gt; len(hashlib.sha256(b\u0026#34;Pham Duy Tung\u0026#34;).digest()) 432 5\u0026gt;\u0026gt;\u0026gt; hashlib.sha512(b\u0026#34;Pham Duy Tung\u0026#34;).hexdigest() 6\u0026#39;ac1f6a2dd234bc15c1fa2be1db4e55ad4af8c476abb8e3d9ac3d4c74d3e151c23314e20925616e90a0bcb13a38b5531e064c586d65fed54504d713fdabee03f9\u0026#39; 7\u0026gt;\u0026gt;\u0026gt; len(hashlib.sha512(b\u0026#34;Pham Duy Tung\u0026#34;).digest()) 864 Near-Duplicate Detection Các thuật toán được giới thiệu ở trên, khi chúng ta thay đổi giá trị đầu vào, dù chỉ một giá trị nhỏ thôi ở một vài vị trí nào đó, thì kết quả trả ra lại khác nhau khá lớn. Tuy nhiên, đôi khi chúng ta gặp những bài toán tìm nội dung tương tự nhau hoặc gần như tương tự nhau. Ví dụ giống như google crawler dữ liệu xác định những bài văn copy paste từ những trang web khác nhau, hoặc phát hiện đạo văn, phát hiện đạo nhạc \u0026hellip;\nMột thuật toán khá phổ biến nằm trong nhóm này là SimHash. Thuật toán được google sử dụng để tìm ra các trang gần trùng nhau (theo wiki https://en.wikipedia.org/wiki/SimHash). Tác giả của thuật toán là Moses Charikar.\nĐể dùng Simhash, chúng ta phải cài đặt package từ kho của python\n1from simhash import Simhash 23\u0026gt;\u0026gt;\u0026gt; Simhash(\u0026#34;Pham Duy Tung\u0026#34;).value 417022061268703429674 5\u0026gt;\u0026gt;\u0026gt; Simhash(\u0026#34;Pham Duy Tung1\u0026#34;).value 617184261516160517290 Một trong những lưu ý quan trọng khi sử dụng SimHash ( tham khảo https://stackoverflow.com/questions/49820228/how-to-compare-the-similarity-of-documents-with-simhash-algorithm/49831194#49831194)\n  SimHash thật sự hữu ích trong bài toán phát hiện văn bản trùng lắp.\n  Để tìm văn bản trùng lắp chính xác, dúng ta có thể sử dụng các thuật toán đơn giản mà hiệu quả như md5, sha1sha1.\n  Thuật toán phù hợp các văn bản lớn, không phù hợp cho các câu văn nhỏ.\n  Đoạn code bên dưới là một ví dụ được dùng để tìm các văn bản có đạo nội dung.\n1#assuming that you have a dictionary with document id as the key and the document as the value:  2# documents = { doc_id: doc } you can do: 34from simhash import simhash 56def split_hash(str, num): 7return [ str[start:start+num] for start in range(0, len(str), num) ] 89hashes = {} 10for doc_id, doc in documents.items(): 11hash = simhash(doc) 1213# you can either use the whole hash for higher precision or split into chunks for higher recall 14hash_chunks = split_hash(hash, 4) 1516for chunk in hash_chunks: 17if chunk not in hashes: 18hashes[chunk] = [] 19hashes[chunk].append(doc_id) 2021# now you can print the duplicate documents: 22for hash, doc_list in hashes: 23if doc_list \u0026gt; 1: 24print(\u0026#34;Duplicates documents: \u0026#34;, doc_list) Ngoài SimHash, còn một thuật toán hash khá nổi tiếng nữa cũng được google sử dụng trong việc cá nhân hóa người dùng, đó là MinHash. Ở các bài viết tiếp theo mình sẽ viết về thuật toán này.\nPerceptual Hashing Loại hash cuối cùng chúng ta đề cập ở đây là perceptual hashing. Loại hash này được sử dụng để phát hiện sự khác nhau trong tập hình ảnh hoặc trong video.\nMột ví dụ của các thuật toán thuộc nhóm là là được dùng để phát hiện các frame ảnh trùng lắp trong video. Thuật toán được dùng để loại bỏ những nội dung trùng lắp, giúp tiết kiệm lưu trữ. Hoặc dùng trong các thuật toán tóm tắt video.\nẢnh 1 Ảnh 2\n1\u0026gt;\u0026gt;\u0026gt; import hashlib 2\u0026gt;\u0026gt;\u0026gt; from PIL import Image 3\u0026gt;\u0026gt;\u0026gt; image1 = Image.open(\u0026#34;google_free_ds1.png\u0026#34;) 4\u0026gt;\u0026gt;\u0026gt; image1 = Image.open(\u0026#34;google_free_ds_1.png\u0026#34;) 5\u0026gt;\u0026gt;\u0026gt; image2 = Image.open(\u0026#34;google_free_ds_2.png\u0026#34;) 6\u0026gt;\u0026gt;\u0026gt; hashlib.sha256(image1.tobytes()).hexdigest() 7\u0026#39;c57d0b5b1ca64077b45bdb65f817497834675232a2fc2ed76d6b8aa7955126b9\u0026#39; 8\u0026gt;\u0026gt;\u0026gt; hashlib.sha256(image2.tobytes()).hexdigest() 9\u0026#39;02ea5e51b19cf3748f91f9bbe26976e9e14dca4b47e0aaff88ab20030a695f44\u0026#39; Giá trị hash khác xa nhau, có vẻ chúng ta không thể nào sử dụng SHA256 trong bài toán này được. Lúc này, chúng ta sẽ tìm tới các thư viện thuộc nhóm Perceptual Hashing, một trong số chúng là ImageHash.\n1\u0026gt;\u0026gt;\u0026gt; import imagehash 2\u0026gt;\u0026gt;\u0026gt; hash1 = imagehash.average_hash(image1) 3\u0026gt;\u0026gt;\u0026gt; hash2 = imagehash.average_hash(image2) 4\u0026gt;\u0026gt;\u0026gt; hash1-hash2 524 Giá trị hash của hai ảnh trên là khác nhau, nhưng sự khác nhau là rất ít. Chứng tỏ hai ảnh trên có thể là bản sao của nhau.\nKết luận Trong bài viết này, chúng ta đã đề cập qua các cách khác nhau để hash dữ liệu trong Python. Phụ thuộc vào bài toán, chúng ta sẽ sử dụng các thuật toán với các tham số phù hợp. Hi vọng bài viết này sẽ ít nhiều giúp ích được cho các bạn.\nChú thích:\n  Ảnh cover của bài viết là ảnh của chùm sao thất tinh bắc đẩu mình chụp từ trang https://stellarium-web.org/.\n  hash collision : Khi cho 2 input khác nhau vào hàm hash mà cùng ra một output -\u0026gt; collision.\n  Nguồn bài viết:\nhttps://medium.com/better-programming/how-to-hash-in-python-8bf181806141\n","date":"Jan 25, 2020","img":"","permalink":"/blog/2020-01-13-hash-in-python/","series":null,"tags":["python","hash"],"title":"Các Hàm Hash Có Sẵn Trong Python"},{"categories":null,"content":"Đặt vấn đề Sau khi thực hiện object detection feed một ảnh qua mạng neural, chúng ta sẽ thu được rất nhiều proposals (như hình ở dưới). Ở trạng thái này, có rất nhiều proposals là boding box cho một object duy nhất, điều này dẫn tới việc dư thừa. Chúng ta sử dụng thuật toán Non-maximum suppression (NMS) để giải quyết bài toán này.\nHình 1: Proposals box, hình được cắt từ bài báo\nThuật toán NMS Đầu vào:\nTập danh sách các proposals box ký hiệu là B với B ={b1,b2,\u0026hellip;,bn}, với bi là proposal thứ i.\nTập điểm của mỗi proposal box ký hiệu là S với S={s1,s2,\u0026hellip;,sn}, si là điểm confidence của box bi\nGiá trị ngưỡng overlap threshold N.\nCả hai giá trị bi và si đều là output của mạng neural network.\nĐầu ra:\nMột tập các proposals box D là tập các proposals đã loại bỏ dư thừa tương ứng với từng object trong hình.\nThuật toán:\nBước 1: Khởi tạo tập output D = {}\nBước 2: Chọn ra proposal box có điểm confidence cao nhất trong tập S, loại box đó ra khỏi tập S, B và thêm nó vào tập D.\nBước 3: Tính giá trị IOU giữa proposal box mới vừa loại ra ở bước 2 với toàn bộ proposal box trong tập B. Nếu có bất kỳ box nào đó có giá trị IOU lớn hơn giá trị ngưỡng N thì loại box đó ra khỏi B, S.\nBước 4: Lặp lại bước 2 đến khi nào không còn box nào có trong tập B.\nĐiểm yếu của thuật toán:\nNếu bạn đọc kỹ thuật toán, bạn sẽ thấy rằng toàn bộ quá trình loai bỏ những box dư thừa đều phụ thuộc vào giá trị ngưỡng N. Việc chọn lựa giá trị N chính là chìa khóa thành công của mô hình. Tuy nhiên, việc chọn giá trị ngưỡng này trong các bài toán khá khó. Và với việc chỉ sử dụng giá trị N, chúng ta sẽ gặp trường hợp dưới đây.\nGiả sửa giá trị ngưỡng N bạn chọn là 0.5. Có nghĩa là nếu box có giá trị lớn IOU đều bị loại bỏ, ngay cả với trường hợp điểm score si của nó có giá trị cao. Ngược lại, giả sử box có điểm score si thấp nhưng IOU của nó nhỏ hơn 0.5, ví dụ o.49, thì nó lại được nhận.\nVà để giải quyết bài toán này Navaneeth Bodla đã đề xuất một cải tiến nhỏ và đặt tên thuật toán là Soft-NMS. ý tưởng được đề ra như sau: Thay vì phải loại bỏ hoàn toàn proposal, chúng ta sẽ giảm giá trị confidence của box đi.\nsoft-nms, hình được cắt từ bài báo\nVới giá trị si được cập nhật lại như sau:\nsoft-nms, hình được cắt từ bài báo\nCảm ơn các bạn đã theo dõi bài viết. Hẹn gặp lại các bạn ở những bài viết tiếp theo.\nTham khảo\nhttps://medium.com/@yusuken/object-detction-1-nms-ed00d16fdcf9\nhttps://towardsdatascience.com/non-maximum-suppression-nms-93ce178e177c\nhttps://arxiv.org/pdf/1704.04503.pdf\nhttps://arxiv.org/pdf/1705.02950.pdf\n","date":"Dec 13, 2019","img":"","permalink":"/blog/2019-12-25-nms/","series":null,"tags":["Machine learning","Deeplearning","AlexNet"],"title":"Tìm Hiểu Non-Maximum Suppression (NMS)"},{"categories":null,"content":"Trong bài viết này, chúng ta sẽ tìm hiểu mô hình AlexNet từ nhóm của giáo sư Hinton. Tới thời điểm hiện tại (2019-05-27), bài viết của giáo sư đã có hơn 40316 lượt trích dẫn. Bài báo này có bước đóng góp cực kỳ quan trọng, là một đột phá lớn trong lĩnh vực deep learning, mở đầu cho sự quay lại của mạng neural network và đóng góp trực tiếp vào thành công của những chương trình trí tuệ nhân tạo tại thời điểm hiện tại.\nVề bài báo gốc của tác giả, mình có để ở phần trích dẫn bên dưới. Các bạn có nhu cầu tìm hiểu có thể tìm và đọc. Theo ý kiến riêng của mình, đây là một bài báo rất nên đọc và phải đọc. Trước đây mình đã có viết 1 bài về tập AlexNet nhưng chưa đầy đủ, bài đó mình chỉ giới thiệu phớt phớt qua mạng AlexNet. Trong bài viết này, mình sẽ trình bày kỹ hơn.\nSơ lược một chút, tập dữ liệu ImageNet là tập dataset có khoảng 15 triệu hình ảnh có độ phân giải cao đã được gán nhãn (có khoảng 22000 nhãn). Cuộc thi ILSVRC sử dụng một phần nhỏ của tập ImageNet với khoảng 1.2 triệu ảnh của 1000 nhãn (trung bình mỗi nhãn có khoảng 1.2 ngàn hình ảnh) làm tập train, 50000 ảnh làm tập validation và 150000 ảnh làm tập test (tập validation và tập test đều có 1000 nhãn thuộc tập train).\nKiến trúc mạng AlexNet Kiến trúc mô hình AlexNet\nMạng AlexNet bao gồm 8 lớp (tính luôn lớp input là 9), bao gồm:\nInput: có kích thước 224x224x3 (Scale ảnh đầu vào về dạng 224x224x3, thực chất ảnh của tập ImageNet có size tùy ý)\nLớp thứ nhất:\nConvolution Layer có kích thước 11x11x3 với stride size = 4 và pad = 0. Kết quả sau bước này ta được tập feature map có kích thước 55x55x96 (mình nghĩ là các bạn sẽ biết cách tính sao cho ra số 55, mình cũng đã đề cập vấn đề cách tính này ở 1 bài viết trước đây).\rTiếp theo là một Overlapping Max Pooling 3x3 có stride =2 =\u0026gt; feature maps = 27x27x96.\rTiếp theo là Local Response Normalization =\u0026gt; feature maps = 27x27x96.\rXong lớp thứ nhất\r Lớp thứ hai:\nConvolutional Layer: 256 kernels có kích thước 5x5x48 (stride size = 1, pad = 2) =\u0026gt; 27x27x256 feature maps.\rOverlapping Max Pooling 3x3 có stride =2 =\u0026gt; feature maps = 13x13x256.\rTiếp theo là Local Response Normalization =\u0026gt; feature maps = 13x13x256.\r Lớp thứ ba:\nConvolutional Layer: 384 kernels có kích thước 3x3x256 (stride size = 1, pad = 1) =\u0026gt; 13x13x384 feature maps.\r Lớp thứ bốn: 384 kernels có kích thước 3x3x192 (stride size = 1, pad = 1) =\u0026gt; 13x13x384 feature maps.\nLớp thứ năm:\nConvolutional Layer: 256 kernels có kích thước 3x3x192 (stride size = 1, pad = 1) =\u0026gt; 13x13x256 feature maps.\rOverlapping Max Pooling 3x3 có stride =2 =\u0026gt; feature maps = 6x6x256.\r Lớp thứ sáu:\nFull connected (hay còn gọi là Dense layer) với 4096 neurals\r Lớp thứ bảy:\nFull connected với 4096 neurals\r Lớp thứ tám:\nFull connected ra output 1000 neural (do có 1000 lớp)\r Hàm độ lỗi được sử dụng là Softmax.\nTổng cộng, chúng ta có 60 triệu tham số được sử dụng để huấn luyện.\nCải tiến của mô hình để giảm error rate Sử dụng ReLU thay cho TanH Hàm kích hoạt ReLU và TanH\nCác mô hình neural network trước khi bài báo ra đời thường sử dụng hàm Tanh làm hàm kích hoạt. Mô hình AlexNet không sử dụng hàm TanH mà giới thiệu một hàm kích hoạt mới là ReLU. ReLU giúp cho quá trình huấn luyện chạy nhanh hơn gấp 6 lần so với kiến trúc tương tự sử dụng TanH, góp một phần vào việc độ lỗi trên tập huấn luyện là 25%.\nLocal Response Normalization Local Response Normalization và Batch Normalization\nTrong mạng AlexNet, nhóm tác giả sử dụng hàm chuẩn hóa là Local Response Normalization. Hàm này không phải là Batch Normalization mà các bạn hay sử dụng ở thời điểm hiện tại (xem hình ở trên, hai hàm có công thức tính toán hoàn toàn khác nhau). Việc sử dụng chuẩn hóa (Normalization) giúp tăng tốc độ hội tụ. Ngày nay, chúng ta không còn sử dụng Local Response Normalization nữa. Thay vào đó, chúng ta sử dụng Batch Normalization làm hàm chuẩn hóa.\nVới việc sử dụng hàm chuẩn hóa Local Response Normalization, độ lỗi top-1 error rate giảm 1.4%, top-5 giảm 1.2%.\nOverlapping Pooling Overlapping Pooling là pooling với stride nhỏ hơn kernel size. Một khái niệm ngược với Overlapping Pooling là Non-Overlapping Pooling với stride lớn hoăn hoặc bằng kernel.\nMạng AlexNet sử dụng Overlapping Pooling ở hidden layer thứ 1, 2 và 5 (Kernel size = 3x3, stride =2).\nVới việc sử dụng overlapping pooling, top-1 error rates giảm 0.4%, top-5 error rate giảm 0.3%.\nSử dụng Data Augmentation Dữ liệu của tập huấn luyện khá nhiều, 1.2 triệu mẫu. Nhưng chia ra cho 1000 lớp thì mỗi lớp có khoảng 1200, khá khiêm tốn phải không. Cho nên, tác giả đã nghĩ ra một cách khá hay để tăng số lượng hình ảnh mà vẫn giữ được tính IID của dữ liệu, đó là sử dụng các phép biến đổi affine trên dữ liệu ảnh gốc để thu thêm nhiều ảnh hơn.\nCó hai dạng Data Augentation được tác giả sử dụng\nDạng thứ nhất: Image translation và horizontal reflection (mirroring)\nImage translation được hiểu như sau: ảnh ImageNet gốc có kích thước 256x256 pixel, tác giả rút ra một ảnh con có kích thước 224x224 pixel, sau đó dịch qua trái 1 pixel và lấy 1 ảnh con tiếp theo có kích thước 224x224. Làm như vậy theo hàng, hết hàng làm theo cột. Cuối cùng tác giả có thể từ một bức hình 256x256 ban đầu rút trích thành 1024 hình có kích thước 224x224\nhorizontal reflection (mirroring) được hiểu là lấy ảnh phản chiếu của ánh gốc qua đường chéo chính. Ví dụ con báo dang có hướng tai của nó từ trái qua phải, ta lấy horizontal reflection của ảnh đó thì sẽ được con báo hướng tai từ phải qua trái.\nVới việc kết hợp Image translation và horizontal reflection (mirroring), tác giả có thể rút tối đa 2048 bức ảnh khác nhau chỉ từ 1 bức ảnh gốc =\u0026gt; với hơn 1000 bức ảnh của 1 nhãn có thể sinh ra tối đa là 2048000 bức ảnh, một con số khá lớn phải không các bạn.\nỞ tập test, tác giả sử dụng 4 hình 224x224 ở bốn góc cộng với 1 hình 224x224 ở trung tâm =\u0026gt; được 5 hình, đem 5 hình đó sử dụng horizontal reflection thì thu được 10 hình cho mỗi file test.\nDạng thứ hai: Thay đổi độ sáng\nThực hiện tính PCA trên tập train. Với mỗi hình trên tập train, thay đổi giá trị độ sáng\n$$[p_1, p_2, p_3][\\alpha_1 \\gamma_1, \\alpha_2 \\gamma_2, \\alpha_3 \\gamma_3]^T$$\nvới pi và gammai là giá trị trị riêng và vector riêng thứ i của ma trận hiệp phương sai 3x3 của ảnh, và alpha i là một giá trị ngẫu nhiên thuộc đoạn 1 và độ lệch chuẩn 0.1..\nVới việc sử dụng data augmentation, top-1 error rate giảm 1% độ lỗi.\nDropout Dropout\nVới mỗi layer sử dụng dropout, mỗi neural sẽ có cơ hội không đóng góp vào feed forward và backpropagation. Do đó, mỗi neural đều có cơ hội rất lớn đóng góp vào thuật toán, và chúng ta sẽ giảm thiểu tình trạng phụ thuộc vào một vài neural.\nKhông sử dụng dropout trong tập quá trình test.\nMạng AlexNet sử dụng giá trị xác xuất của dropout là 0.5 ở hai fully-connected layer. Dopout được xem như là một kỹ thuật chuẩn hóa nhằm mục đích giảm overfitting.\nSử dụng nhiều GPU Tại năm 2012, nhóm tác giả sử dụng card đồ họa NIVIDIA GTX 580 có 3GB bộ nhớ RAM. Cho nên, để có thể huấn luyện được mô hình AlexNet trên GPU, mô hình cần sử dụng 2 GPU.\nvì vậy việc sử dụng 2 hoặc nhiều GPU là do vấn đề thiếu bộ nhớ, chứ không phải là vấn đề tăng tốc quá trình train hơn so với 1 GPU\nNgoài ra, do giới hạn của GPU, nên mô hình AlexNet được tách ra làm 2 phần, mỗi phần được huấn luyện trên 1 GPU. Phiên bản 1 GPU của mô hình có tên là CaffeNet, và đòi hỏi chúng ta phải sử dụng GPU có bộ nhớ RAM lớn hơn hoặc bằng 6GB.\nMột số chi tiết khác về các learning param Batch size: 128\nMomemtum: 0.9\nWeight Decay: 0.0005\nLearning rate: 0.01, giá trị learning rate sẽ giảm đi 10 lần nếu validation error rate không thay đổi trong 1 khoảng thời gian. Số lần giảm là 3.\nEpoch: 90\nNhóm tác giả đã sử dụng 2 GPU 580 có 3GB GPU RAM và tốn 6 ngày để huấn luyện.\nKết quả Độ lỗi của AlexNet trên ILSVRC 2010\nTrong cuộc thi ILSVRC 2010, AlexNet đạt độ chính xác top-1 error 37.5% và top-5 error là 17.0%, kết quả này tốt hơn vượt trội so với các cách tiếp cận khác.\nĐộ lỗi của AlexNet trên ILSVRC 2012\nĐến cuộc thi ILSVRC 2012, độ lỗi của AlexNet trên tập validation giảm còn 18.2%.\nNếu lấy trung bình của dự đoán trên 5 mạng AlexNet được huấn luyện khác nhau, độ lỗi giảm còn 16.4%. Các lấy trung bình trên nhiều hơn 1 mạng CNN là một kỹ thuật boosting và được sử dụng trước đó ở bài toán phân loại số của mạng LeNet.\nỞ dòng số 3 là mạng AlexNet nhưng được thêm 1 convolution layer nữa (nên được ký hiệu là 1CNN*), độ lỗi trên tập validation giảm còn 16.4%.\nNếu lấy kết quả trung bình của 2 mạng neural net được chỉnh sửa (thêm 1 convolution layer) và 5 mạng AlexNet gốc (=\u0026gt; chúng ta có 7CNN*), độ lỗi trên tập validation giảm xuống 15.4%\nDemo kết quả top-5 của mạng AlexNet\nMạng CaffeNet Mạng này là phiên bản kiến trúc 1-GPU của AlexNet. Kiến trúc của mạng caffeNet như hình bên dưới:\nMạng caffeNet\nBạn thấy đó, thay vì có 2 phần trên và dưới như mô ình AlexNet ở trên, mô hình CaffeNet chỉ có 1 phần. Ví dụ lớp hidden layer thứ 7 mạng AlexNet gồm 2 phần, mỗi phần có kích thước 2048, còn ở phiên bản CaffeNet thì đã gộp lại thành 1 phần.\nTài liệu tham khảo\nhttps://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\nhttp://www.image-net.org/challenges/LSVRC/\nCảm ơn các bạn đã theo dõi bài viết, có chỗ nào bạn chưa rõ hoặc mình viết bị sai, các bạn vui lòng để lại comment để mình sửa lại cho đúng.\n","date":"May 27, 2019","img":"","permalink":"/blog/2019-05-27-alexnet/","series":null,"tags":["machine learning","deep learning","AlexNet","ILSVRC","dropout"],"title":"Tìm Hiểu Mạng AlexNet, Mô Hình Giành Chiến Thắng Tại Cuộc Thi ILSVRC 2012"},{"categories":null,"content":"Trong bài viết này, chúng ta sẽ tìm hiểu mô hình MobileNetV1 từ nhóm tác giả đến từ Google. Điểm cải tiến (chắc là cải tiến :) của mô hình là sử dụng một cách tính tích chập có tên là Depthwise Separable Convolution để giảm kích thước mô hình và giảm độ phức tạp tính toán. Do đó, mô hình sẽ hữu ích khi chạy các ứng dụng trên di động và các thiết bị nhúng.\nLý do:\n  Mô hình có ít tham số hơn -\u0026gt; kích thước model sẽ nhỏ hơn.\n  Mô hình có ít phép tính cộng trừ nhân chia hơn -\u0026gt; độ phức tạp sẽ nhỏ hơn.\n  Hiện tại (2019-05-26), tại thời điểm viết bài, bài viết gốc của tác giả đã được 1594 lượt trích dẫn. Các bạn có thể tìm đọc bài báo gốc của tác giả tại trang https://arxiv.org/abs/1704.04861\nSố lượt trích dẫn bài báo MobileNets Efficient Convolutional Neural Networks for Mobile Vision Applications\nChi tiết về mạng MobileNet Mô hình kiến trúc Kiến trúc mạng MobileNet được trình bày bên dưới. Hình bên dưới được trích từ bài báo gốc của tác giả\nMô hình kiến trúc mạng MobileNet\nDiễn dịch ra ngôn ngữ tự nhiên, chúng ta thấy rằng mô hình có 30 lớp với các đặc điểm sau:\n  Lớp 1: Convolution layer với stride bằng 2\n  Lớp 2: Depthwise layer\n  Lớp 3: Pointwise layer\n  Lớp 4: Depthwise layer với stride bằng 2 (khác với bước 2, dw lớp 2 có stride size bằng 1)\n  Lớp 5: Pointwise layer\n  Lớp 30: Softmax, dùng để phân lớp.\n  Depthwise Separable Convolution Depthwise separable convolution là một depthwise convolution theo sau bởi một pointwise convolution như hình bên dưới:\nCấu trúc của một Depthwise Separable Convolution\n  Depthwise convolution: là một channel-wise DK×DK spatial convolution. Ví dụ ở hình trên, ta có 5 channels (các bạn để ý cục đầu tiên có 5 khối hộp, cục thứ 2 là phân tách 5 khối hộp ra thành ma trận mxn, cục thứ 3 là spatial convolution có kích thước kxk, cục thứ 4 là kết quả sau khi convolution, cục thứ 5 là ráp 5 cái kết quả của convolution lại ), do đó chúng ta sẽ có 5 DK×DK spatial convolution tương ứng với 5 channel trên.\n  Pointwise convolution: đơn giản là một convolution có kích thước 1x1 (như hình ở trên).\n  Với M là số lượng input channel, N là số lượng output channel, Dk là kernel size, Df là feature map size (với dataset ImageNet thì input có kích thước là 224, do đó feature map ban đầu có Df = 224), chúng ta có thể tính được:\nChi phí tính toán của Depthwise convolution là :\n$$D_k \\cdot D_k \\cdot M \\cdot D_f \\cdot D_f$$\nChi phí tính toán của Pointwise convolution là :\n$$M \\cdot N \\cdot D_f \\cdot D_f$$\nTổng chi phí tính toán của Depthwise Separable Convolution là:\n$$D_k \\cdot D_k \\cdot M \\cdot D_f \\cdot D_f + M \\cdot N \\cdot D_f \\cdot D_f$$\nNếu chúng ta không sử dụng Depthwise Separable Convolution mà sử dụng phép convolution như bình thường, chi phí tính toán là\n$$ D_k \\cdot D_k \\cdot M \\cdot N \\cdot D_f \\cdot D_f$$\nDo đó, chi phí tính toán sẽ giảm:\n$$\\frac{D_k \\cdot D_k \\cdot M \\cdot D_f \\cdot D_f + M \\cdot N \\dot D_f \\cdot D_f}{D_k \\cdot D_k \\cdot M \\cdot N \\cdot D_f \\cdot D_f} = \\frac{1}{N} + \\frac{1}{D^2_k}$$\nGiả sử, chúng ta chọn kernel size Dk = 3, chúng ta sẽ giảm từ 8 đến 9 lần phép tính nhân =\u0026gt; giảm chi phí tính toán đi rất nhiều.\nMột chú ý nhỏ về kiến trúc ở đây, là sau mỗi convolution MobileNet sẽ sử dụng Batch Normalization (BN) và ReLU như hình bên dưới:\nStandard Convolution bên trái, Depthwise separable convolution với BN và ReLU bên phải\nSo sánh kết quả của việc sử dụng mạng 30 layer sử dụng thuần Convolution và mạng 30 layer sử dụng Depthwise Separable Convolution (MobileNet) trên tập dữ liệu ImageNet, chúng ta có bảng kết quả bên dưới\nStandard Convolution bên trái, Depthwise separable convolution với BN và ReLU bên phải\nMobileNet giảm 1% độ chính xác, nhưng số lượng tham số của mô hình và số lượng phép tính toán giảm đi rất rất nhiều, gần xấp xỉ 90%. Một con số đáng kinh ngạc.\nLàm mô hình gọn nhẹ hơn nữa Với mong muốn làm mô hình gọn nhẹ hơn nữa, nhóm tác giả đã thêm vào hai tham số alpha và rho.\nTham số alpha: Điều khiển số lượng channel (M và N).\nChi phí tính toán của depthwise separable convolution khi sử dụng thêm tham số alpha.\n$$D_k \\cdot D_k \\cdot \\alpha M \\cdot D_f \\cdot D_f + \\alpha M \\cdot \\alpha N \\cdot D_f \\cdot D_f$$\nGiá trị alpha nằm trong đoạn [0,1], nhóm tác giả set giá trị alpha có bước nhảy là 0.25, các giá trị cần xét là 0.25, 0.5, 0.75, 1. Trường hợp alpha = 1 chính là mạng MobileNet baseline của mình. Trong trường hợp thay đổi alpha, số phép tính toán, số tham số, cũng giảm đi rất nhiều, và tất nhiên, độ chính xác cũng giảm đi tương ứng.\nMạng MobileNet với alpha thay đổi\nPhân tích kỹ hình ở trên, ta thấy rằng với alpha bằng 0.75 và 0.5 giá trị độ chính xác còn nằm ở mức miễn cưỡng có thể chấp nhận được. Nhưng với alpha bằng 0.25 thì khó mà có thể chấp nhận được kết quả đó. Việc giảm phép tính toán và số lượng tham số dẫn đến kết quả tệ như trên quả là một điều không nên. Mình nghĩ ở đây nhóm tác giả để con số để có ý nghĩa so sánh.\nTham số rho: Tham số này được sử dụng để điều khiển độ phân giải của ảnh input.\nChi phí tính toán của depthwise separable convolution khi sử dụng thêm tham số rho.\n$$D_k \\cdot D_k \\cdot \\alpha M \\cdot \\rho D_f \\cdot \\rho D_f + \\alpha M \\cdot \\alpha N \\cdot \\rho D_f \\cdot \\rho D_f$$\nGiá trị rho cũng nằm trong đoạn [0,1]. Nhóm tác giả sử dụng các giá trị độ phân giải là 224 (độ phân giải gốc, tương ứng với rho =1), 192, 160, 128.\nMạng MobileNet với rho thay đổi\nGiá trị độ chính xác thay đổi theo hướng giảm khá mượt. Việc thay đổi rho chỉ làm giảm số lượng phép tính toán, không làm giảm số lượng tham số. Việc giảm độ chính xác có thể lý giải lý do là có một số hình có kích thước nhỏ nên khi giảm kích thước sẽ làm mất những đặc trưng cần thiết của đối tượng cần xét.\nSo sánh MobileNet với các State-of-the-art đương thời Khi so sánh 1.0 MobileNet-224 với GoogleNet và VGG 16 (hình bên dưới), chúng ta thấy rằng độ chính xác của cả 3 thuật toán là hầu như tương đương nhau. Nhưng 1.0 MobileNet-224 có số lượng tham số ít (75% so với GoogleNet) và số lượng phép toán nhỏ hơn rất nhiều =\u0026gt; chạy nhanh hơn.\nSo sánh 1.0 MobileNet-224 với GoogleNet và VGG 16 trên tập ImageNet\nVới mô hình 0.50 MobileNet-160, chúng ta có thể so sánh với mô hình Squeezenet và AlexNet (mô hình thắng giải nhất cuộc thi ILSVRC 2012). Một lần nữa, mô hình 0.50 MobileNet-160 cho kết quả tốt hơn, nhưng có số lượng phép tính toán ít hơn rất nhiều (hơi đáng buồn là số lượng tham số của mô hình 0.50 MobileNet-160 khá cao, số lượng tham số gấp đôi so với AlexNet và gần bằng Squeezenet) =\u0026gt; 0.50 MobileNet-160 train nhanh hơn, predict cũng nhanh hơn so với Squeezenet và AlexNet, nhưng tốn bộ nhớ RAM hơn.\nSo sánh 0.50 MobileNet-160 với Squeezenet và AlexNet trên tập ImageNet\nSo với mô hình Inception-v3 (mô hình thắng giải nhất cuộc thi ILSVRC 2015), MobileNet cho kết quả khá tốt, nhưng số tham số và số lượng phép tính toán nhỏ hơn rất nhiều\nSo sánh Mobile net và Inception-v3 trên tập Stanford Dog\nCác thí nghiệm ở dưới trên các tập dataset khác nhau chứng minh mức độ hiệu quả của MobileNet GPS Localization Via Photos\nFace Attribute Classification\nMMicrosoft COCO Object Detection Dataset\nFace Recognition\nKết luận MobileNet cho kết quả tốt ngang ngữa các state-of-the-art thắng giải nhất ở quá khứ, nhưng với mô hình có số lượng tham số nhỏ hơn và số phép tính toán ít hơn. Điều này đạt được là nhờ vào việc sử dụng Depthwise Separable Convolution.\nCảm ơn các bạn đã theo dõi bài viết, có chỗ nào bạn chưa rõ hoặc mình viết bị sai, các bạn vui lòng để lại comment để mình sửa lại cho đúng.\n","date":"May 25, 2019","img":"","permalink":"/blog/2019-05-26-mobilenetv1/","series":null,"tags":["machine learning","deep learning","MobileNetV1","Depthwise Separable Convolution","Light Weight Model","Width Multiplier","Resolution Multiplier"],"title":"Tìm Hiểu Mạng MobileNetV1"},{"categories":null,"content":"Contour là gì Các bạn có thể hiểu contour là \u0026ldquo;tập các điểm-liên-tục tạo thành một đường cong (curve) (boundary), và không có khoảng hở trong đường cong đó, đặc điểm chung trong một contour là các các điểm có cùng /gần xấu xỉ một giá trị màu, hoặc cùng mật độ. Contour là một công cụ hữu ích được dùng để phân tích hình dạng đối tượng, phát hiện đối tượng và nhận dạng đối tượng\u0026rdquo;.\nĐể tìm contour chính xác, chúng ta cần phải nhị phân hóa bức ảnh (nhớ là ảnh nhị phân nha các bạn, không phải ảnh grayscale đâu). Các kỹ thuật nhị phân hóa ảnh ở xử lý ảnh cơ bản có thể liệt kê đến là đặt ngưỡng, hoặc candy edge detection. Chúng ta sẽ không bàn kỹ về các cách đặt ngưỡng ( mặc dù có khá nhiều cách đặt ngưỡng, và trong opencv cũng có implement một vài phương pháp, nhưng nó không phải là mục tiêu của bài này, nên mình không đề cập ở đây) hoặc edge detection ở bài viết này, mà chúng ta sẽ đi vào các tìm contours bằng các sử dụng opencv luôn.\nTrong opencv, việc tìm một contour là việc tìm một đối tượng có màu trắng trên nền đen. Cho nên, các bạn hãy nhớ rằng hãy set đối tượng thành màu trắng và để nền là màu đen, đừng làm ngược lại nha.\nMột lưu ý nhỏ là tại thời điểm mình viết bài viết này, mình sử dụng phiên bản opencv3.6. Các bạn có thể sử dụng phiên bản opencv mới hơn, nhưng có thể những sample code mình để bên dưới sẽ không work, do không tương thích.\nSử dụng contour trong opencv Opencv hỗ trợ cho chúng ta hàm để tìm contour của một bức ảnh\n1modifiedImage, contours, hierarchy = cv2.findContours(binaryImage, typeofContour, methodofContour) Trong đó:\n  contours: Danh sách các contour có trong bức ảnh nhị phân. Mỗi một contour được lưu trữ dưới dạng vector các điểm\n  hierarchy: Danh sách các vector, chứa mối quan hệ giữa các contour.\n  modifiedImage: Ảnh sau khi sử dụng contour, thường chúng ta không xài đối số này\n  binaryImage: Ảnh nhị phân gốc. Một chú ý quan trọng ở đây là sau khi sử dụng hàm findContours thì giá trị của binaryImage cũng thay đổi theo, nên khi sử dụng bạn có thể áp dụng binaryImage.copy() để không làm thay đổi giá trị của binaryImage\n  typeofContour: có các dạng sau: RETR_EXTERNAL, RETR_LIST, RETR_CCOMP, RETR_TREE, RETR_FLOODFILL.\n  methodofContour: Có các phương thức sau: CHAIN_APPROX_NONE, CHAIN_APPROX_SIMPLE, CHAIN_APPROX_TC89_L1, CHAIN_APPROX_TC89_KCOS.\n  Ví dụ về các sử dụng hàm\n12import numpy as np 3import cv2 45im = cv2.imread(\u0026#39;test.jpg\u0026#39;) # đọc ảnh màu 6imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) # chuyển ảnh màu sang dạng grayscale 7ret,thresh = cv2.threshold(imgray,127,255,0) # nhị phân hóa bức ảnh bằng cách đặt ngưỡng, với giá trị của ngưỡng là 127 8im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) # tìm contour Opencv hỗ trợ chúng ta hàm để vẽ contor lên bức ảnh, giúp chúng ta nhìn rõ ràng hơn\n1cv2.drawContours(image, contours, contourIndex, colorCode, thickness) Với:\n  imgage: ảnh, có thể là ảnh grayscale hoặc ảnh màu.\n  contours: danh sách các contour, là vector, nếu bạn muốn vẽ một contour, thì bạn phải cho nó vào trong một list.\n  contourIndex Vị trí của contor, thông thường chúng ta để -1\n  colorCode: Giá trị màu của contour chúng ta muốn vẽ, ở dạng BGR, nếu bạn muốn vẽ contour màu xanh lá cây thì set là (0,255,0).\n  thickness : độ dày của đường contour cần vẽ, giá trị thickness càng lớn thì đường contor vẽ càng bự\n  Ví dụ: Đếm số lượng quả bóng bay trong hình Giả sử chúng ta có bức ảnh Bong bóng bay\nChúng ta thực hiện tìm contour của ảnh trên bằng cách\n12import numpy as np 3import cv2 45im = cv2.imread(\u0026#39;colorfull_ballon.jpg\u0026#39;) 6imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) # chuyển ảnh xám thành ảnh grayscale 7thresh = cv2.Canny(imgray, 127, 255) # nhị phân hóa ảnh 8_, contours, _ = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) 910cv2.drawContours(im, contours, -1, (0, 255, 0), 2) # vẽ lại ảnh contour vào ảnh gốc 1112# show ảnh lên 13cv2.imshow(\u0026#34;ballons\u0026#34;, im) 14cv2.waitKey(0) Kết quả:\nContour màu xanh là đường curve bao quanh dữ liệu được rút trích được\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.\n","date":"May 24, 2019","img":"","permalink":"/blog/2019-05-26-contours/","series":null,"tags":["machine learning","deep learning","opencv","xủ lý ảnh"],"title":"Contour"},{"categories":null,"content":"1. Dropout là gì, nó có ý nghĩa gì trong mạng neural network Theo Wikipedia, thuật ngữ \u0026ldquo;dropout\u0026rdquo; đề cập đến việc bỏ qua các đơn vị (unit) (cả hai hidden unit và visible unit) trong mạng neural network.\nHiểu đơn giản là, trong mạng neural network, kỹ thuật dropout là việc chúng ta sẽ bỏ qua một vài unit trong suốt quá trình train trong mô hình, những unit bị bỏ qua được lựa chọn ngẫu nhiên. Ở đây, chúng ta hiểu \u0026ldquo;bỏ qua - ignoring\u0026rdquo; là unit đó sẽ không tham gia và đóng góp vào quá trình huấn luyện (lan truyền tiến và lan truyền ngược).\nVề mặt kỹ thuật, tại mỗi giai đoạn huấn luyện, mỗi node có xác suất bị bỏ qua là 1-p và xác suất được chọn là p\n2. Tạo sao chúng ta cần dropout Giả sử rằng bạn hiểu hoàn toàn những gì đã nói ở phần 1, câu hỏi đặt ra là tại sao chúng ta cần đến dropout, tại sao chúng ta cần phải loại bỏ một vài các unit nào đó trong mạng neural network?\nCâu trả lời cho câu hỏi này là để chống over-fitting\nKhi chúng ta sử dụng full connected layer, các neural sẽ phụ thuộc \u0026ldquo;mạnh\u0026rdquo; lẫn nhau trong suốt quá trình huấn luyện, điều này làm giảm sức mạng cho mỗi neural và dẫn đến bị over-fitting tập train.\n3. Dropout Đọc đến đây, bạn đã có một khái niệm cơ bản về dropout và động lực - động cơ để chúng ta sử dụng nó. Nếu bạn chỉ muốn có cái nhìn tổng quan về dropout trong neural network, hai sections trên đã cung cấp đầy đủ thông tin cho bạn, bạn có thể dừng tại đây. Phần tiếp theo, chúng ta sẽ nói kỹ hơn về mặt kỹ thuật của dropout.\nTrước đây, trong machine learning, người ta thường sử dụng regularization để ngăng chặn over-fititng. Regularization làm giảm over-fitting bằng cách thêm yếu tố \u0026ldquo;phạt\u0026rdquo; vào hàm độ lỗi (loss function). Bằng việc thêm vào điểm phạt này, mô hình được huấn luyện sẽ giúp các features weights giảm đi sự phụ thuộc lẫn nhau. Đối với những ai đã sử dụng Logistic Regression rồi thì sẽ không xa lạ với thuật ngữ phạt L1(Laplacian) và L2 (Gaussian).\nDropout là một kỹ thuật khác, một cách tiếp cận khác để regularization trong mạng neural netwoks.\nKỹ thuật dropout được thực hiện như sau:\nTrong pha train: với mỗi hidden layer, với mỗi trainning sample, với mỗi lần lặp, chọn ngẫu nhiên p phần trăm số node và bỏ qua nó (bỏ qua luôn hàm kích hoạt cho các node bị bỏ qua).\nTrong pha test: Sử dụng toàn bộ activations, nhưng giảm chúng với tỷ lệ p (do chúng ta bị miss p% hàm activation trong quá trình train).\nMô tả về kiến trúc mạng có và không có dropout\n4. Một số đặc điểm rút ra được khi huấn luyện nhiều mô hình khác nhau sử dụng dropout   Dropout ép mạng neural phải tìm ra nhiều robust features hơn, với đặc điểm là chúng phải hữu ích hơn, tốt hơn, ngon hơn khi kết hợp với nhiều neuron khác.\n  Dropout đòi hỏi phải gấp đôi quá trình huấn luyện để đạt được sự hội tụ. Tuy nhiên, thời gian huấn luyện cho mỗi epoch sẽ ít hơn.\n  Với H unit trong mô hình, mỗi unit đều có xác xuất bị bỏ qua hoặc được chọn, chúng ta sẽ có 2^H mô hình có thể có. Trong pha test, toàn bộ network được sử dụng và mỗi hàm activation được giảm đi với hệ số p.\n  Một số nghiên cứu chỉ ra rằng, khi sử dụng Dropout và Batch Normalization (BN) cùng nhau thì kết quả rất tệ, trong cả lý thuyết và thực nghiệm, ví dụ nghiên cứu ở papper \u0026ldquo;Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift\u0026rdquo;, nguồn https://arxiv.org/abs/1801.05134, nhóm tác giả giải thích về mặt lý thuyết rằng: \u0026ldquo;đối với một neural, Dropout sẽ thay đổi phương sai của nó khi chúng ta chuyển trạng thái từ trian sang test. Còn BN thì không, BN vẫn tích luỹ đầy đủ thông tin trong quá trình huấn luyện. Do Dropout làm thay đổi phương sai nên sẽ xảy ra hiện tượng không đồng nhất về phương sai, dẫn đến hành vi suy luận không chắc chắn dẫn đến suy luận bị sai nhiều. Đặc biệt là khi kết hợp dropout và BN thì khiến cho suy luận càng sai lầm trầm trọng. \u0026ldquo;. Cho nên, trong một số trường hợp/bài toán chúng ta có thể dùng Dropout, trong một số trường hợp/ bài toán, người ta sử dụng BN và không sử dụng dropout.\n  Người ta thường dùng hệ số dropout là 0.5. Lý giải cho việc này, bạn có thể đọc bài báo http://papers.nips.cc/paper/4878-understanding-dropout.pdf. Nói nôm là việc sử dụng giảm 50% của dropout giúp kết quả đạt được là tốt nhất so với các phương pháp chuẩn hoá khác.\n  5. Thực nghiệm trong keras Những vấn đề nói ở trên chỉ là lý thuyết. Bây giờ chúng ta sẽ bắt tay vào làm thực tế. Để xem thử dropout hoạt động như thế nào, chúng ta sẽ xây dựng mô hình deep net sử dụng keras và sử dụng tập dữ liệu cifar-10. Mô hình chúng ta xây dựng có 3 hidden layer với kích thước lần lượt là 64, 128, 256 và 1 full connected layer có kích thước 512 và output layer có kích thước 10 (do mình có 10 lớp).\nChúng ta sử dụng hàm kích hoạt là ReLU trên các hidden layer và sử dụng hàm sigmoid trên output layer. Sử dụng hàm lỗi categorical cross-entropy.\nTrong trường hợp mô hình có sử dụng dropout, chúng ta sẽ set dropout ở tất cả các layer và thay đổi tỷ lệ dropout nằm trong khoảng từ 0.0 đến 0.9 với bước nhảy là 0.1.\nMô hình setup với số epochs là 20. Bắt đầu xem nào.\nĐầu tiên, chúng ta sẽ load một vài thư viện cần thiết\n1import numpy as np 2import os 34import keras 56from keras.datasets import cifar10 7from keras.models import Sequential 8from keras.layers import Dense, Dropout, Activation, Flatten 9from keras.layers import Convolution2D, MaxPooling2D 10from keras.optimizers import SGD 11from keras.utils import np_utils 12from keras.preprocessing.image import ImageDataGenerator 13import matplotlib.pyplot as plt 1415from pylab import rcParams 16rcParams[\u0026#39;figure.figsize\u0026#39;] = 20, 20 1718from keras.datasets import cifar10 1920(X_train, y_train), (X_test, y_test) = cifar10.load_data() 212223print(\u0026#34;Training data:\u0026#34;) 24print(\u0026#34;Number of examples: \u0026#34;, X_train.shape[0]) 25print(\u0026#34;Number of channels:\u0026#34;,X_train.shape[3]) 26print(\u0026#34;Image size:\u0026#34;,X_train.shape[1], X_train.shape[2], X_train.shape[3]) 2728print(\u0026#34;Test data:\u0026#34;) 29print(\u0026#34;Number of examples:\u0026#34;, X_test.shape[0]) 30print(\u0026#34;Number of channels:\u0026#34;, X_test.shape[3]) 31print(\u0026#34;Image size:\u0026#34;,X_test.shape[1], X_test.shape[2], X_test.shape[3]) Kết quả\n1Training data: 2Number of examples: 50000 3Number of channels: 3 4Image size: 32 32 3 5Test data: 6Number of examples: 10000 7Number of channels: 3 8Image size: 32 32 3 Chúng ta có 50000 hình train, và 10000 hình test. Mỗi hình là một ảnh RGB có kích thước 33x32x3 pixel.\ndataset cifar 10\nTiếp theo, chúng ta sẽ chuẩn hoá dữ liệu. Đây là 1 bước quan trọng trước khi huấn luyện mô hình\n1print( \u0026#34;mean before normalization:\u0026#34;, np.mean(X_train)) 2print( \u0026#34;std before normalization:\u0026#34;, np.std(X_train)) 34mean=[0,0,0] 5std=[0,0,0] 6newX_train = np.ones(X_train.shape) 7newX_test = np.ones(X_test.shape) 8for i in range(3): 9mean[i] = np.mean(X_train[:,i,:,:]) 10std[i] = np.std(X_train[:,i,:,:]) 1112for i in range(3): 13newX_train[:,i,:,:] = X_train[:,i,:,:] - mean[i] 14newX_train[:,i,:,:] = newX_train[:,i,:,:] / std[i] 15newX_test[:,i,:,:] = X_test[:,i,:,:] - mean[i] 16newX_test[:,i,:,:] = newX_test[:,i,:,:] / std[i] 171819X_train = newX_train 20X_test = newX_test 2122print(\u0026#34;mean after normalization:\u0026#34;, np.mean(X_train)) 23print(\u0026#34;std after normalization:\u0026#34;, np.std(X_train)) 1mean before normalization: 120.70756512369792 2std before normalization: 64.1500758911213 3mean after normalization: 0.9062499999999979 4std after normalization: 0.4227421643271468 Full code đoạn huấn luyện\n123# In[3]:Specify Training Parameters 45batchSize = 512 #-- Training Batch Size 6num_classes = 10 #-- Number of classes in CIFAR-10 dataset 7num_epochs = 100 #-- Number of epochs for training  8learningRate= 0.001 #-- Learning rate for the network 9lr_weight_decay = 0.95 #-- Learning weight decay. Reduce the learn rate by 0.95 after epoch 101112img_rows, img_cols = 32, 32 #-- input image dimensions 1314Y_train = np_utils.to_categorical(y_train, num_classes) 15Y_test = np_utils.to_categorical(y_test, num_classes) 16171819batchSize = 512 #-- Training Batch Size 20num_classes = 10 #-- Number of classes in CIFAR-10 dataset 21num_epochs = 100 #-- Number of epochs for training  22learningRate= 0.001 #-- Learning rate for the network 23lr_weight_decay = 0.95 #-- Learning weight decay. Reduce the learn rate by 0.95 after epoch 242526img_rows, img_cols = 32, 32 #-- input image dimensions 2728Y_train = np_utils.to_categorical(y_train, num_classes) 29Y_test = np_utils.to_categorical(y_test, num_classes) 303132# In[4]:VGGnet-10 333435from keras.layers import Conv2D 36import copy 37result = {} 38y = {} 39loss = [] 40acc = [] 41dropouts = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] 42for dropout in dropouts: 43print(\u0026#34;Dropout: \u0026#34;, (dropout)) 44model = Sequential() 4546#-- layer 1 47model.add(Conv2D(64, (3, 3), 48border_mode=\u0026#39;valid\u0026#39;, 49input_shape=( img_rows, img_cols,3))) 50model.add(Dropout(dropout)) 51model.add(Conv2D(64, (3, 3))) 52model.add(Dropout(dropout)) 53model.add(Activation(\u0026#39;relu\u0026#39;)) 54model.add(MaxPooling2D(pool_size=(2, 2))) 5556##--layer 2  57model.add(Conv2D(128, (3, 3))) 58model.add(Dropout(dropout)) 59model.add(Activation(\u0026#39;relu\u0026#39;)) 60model.add(MaxPooling2D(pool_size=(2, 2))) 6162##--layer 3  63model.add(Conv2D(256, (3, 3))) 64model.add(Dropout(dropout)) 65model.add(Activation(\u0026#39;relu\u0026#39;)) 66model.add(MaxPooling2D(pool_size=(2, 2))) 6768##-- layer 4 69model.add(Flatten()) 70model.add(Dense(512)) 71model.add(Activation(\u0026#39;relu\u0026#39;)) 7273#-- layer 5 74model.add(Dense(num_classes)) 7576#-- loss 77model.add(Activation(\u0026#39;softmax\u0026#39;)) 7879sgd = SGD(lr=learningRate, decay = lr_weight_decay) 80model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, 81optimizer=\u0026#39;sgd\u0026#39;, 82metrics=[\u0026#39;accuracy\u0026#39;]) 8384model_cce = model.fit(X_train, Y_train, batch_size=batchSize, epochs=20, verbose=1, shuffle=True, validation_data=(X_test, Y_test)) 85score = model.evaluate(X_test, Y_test, verbose=0) 86y[dropout] = model.predict(X_test) 87print(\u0026#39;Test score:\u0026#39;, score[0]) 88print(\u0026#39;Test accuracy:\u0026#39;, score[1]) 89result[dropout] = copy.deepcopy(model_cce.history) 90loss.append(score[0]) 91acc.append(score[1]) 92939495# In[5]: plot dropout  96import numpy as np 97import matplotlib.pyplot as plt 9899width = 0.1 100101plt.bar(dropouts, acc, width, align=\u0026#39;center\u0026#39;) 102103plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;major\u0026#39;, labelsize=35) 104plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;minor\u0026#39;, labelsize=35) 105106plt.ylabel(\u0026#39;Accuracy\u0026#39;,size = 30) 107plt.xlabel(\u0026#39;Dropout\u0026#39;, size = 30) 108plt.show() 109110111# In[6]: plot non drop out 112113import numpy as np 114import matplotlib.pyplot as plt 115116width = 0.1 117118plt.bar(dropouts, loss, width, align=\u0026#39;center\u0026#39;,color = \u0026#39;green\u0026#39;) 119120plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;major\u0026#39;, labelsize=35) 121plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;minor\u0026#39;, labelsize=35) 122123plt.ylabel(\u0026#39;Loss\u0026#39;,size = 30) 124plt.xlabel(\u0026#39;Dropout\u0026#39;, size = 30) 125plt.show() Kết quả\nNhìn hình kết quả ở trên, chúng ta có một số kết luận nhỏ như sau:\nGiá trị dropout tốt nhất là 0.2, khoảng dropout cho giá trị chấp nhận được là nằm trong đoạn từ 0 đến 0.5. Nếu dropout lớn hơn 0.5 thì kết quả hàm huấn luyện trả về khá tệ.\nGiá trị độ chính xác còn khá thấp =\u0026gt; 20 epochs là chưa đủ, cần huấn luyện nhiều hơn nữa.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.\n","date":"May 5, 2019","img":"","permalink":"/blog/2019-05-05-deep-learning-dropout/","series":null,"tags":["machine learning","deep learning","dropout","deep net"],"title":"Tìm Hiểu Về Dropout Trong Deep Learning, Machine Learning"},{"categories":null,"content":"Lấy mẫu dữ liệu là một kỹ thuật rất quang trọng trong thống kê, là yếu tố quan trọng góp phần xác định độ chính xác của research/ survey. Nếu có bất kỳ sai sót gì trong quá trình lấy mẫu, nó sẽ ảnh hưởng trực tiếp đến kết quả cuối cùng. Có rất nhiều kỹ thuật giúp chúng ta thu thập mẫu dựa trên nhu cầu và tình huống chúng ta cần. Bài viết này sẽ giải thích một số kỹ thuật phổ biến nhất.\nĐể bắt đầu bài viết, chúng ta sẽ làm rõ mốt số khái niệm cơ bản là Quần thể - Population,mẫu - Sample và lấy mẫu - sampling\nQuần thể - population là tập hợp của các cá thể có một hoặc một số đặc điểm chung. Kích thước của một quần thể là số lượng cá thể trong quần thể đó.\nMẫu - sample là một tập con của quần thể. Quá trình chọn một mẫu được gọi là lấy mẫu -sampling. Kích thước mẫu là số lượng cá thể trong tập mẫu.\nHình 1: Ví dụ về lấy mẫu dữ liệu\nCó rất nhiều kỹ thuật lấy mẫu dữ liệu khác nhau, nhưng chúng ta có thể gom chúng vào 2 nhóm chính:\n  Lấy mẫu ngẫu nhiên - Probability Sampling\n  Lấy mẫu phi ngẫu nhiên - non-probability sampling\n  Hình 2: Ví dụ so về lấy mẫu ngẫu nhiên và lấy mẫu phi ngẫu nhiên\nSự khác biệt của hai nhóm trên là phương pháp lấy mẫu có sử dụng \u0026ldquo;hàm ngẫu nhiên\u0026rdquo; hay không. Với việc sử dụng hàm ngẫu nhiên, mỗi cá thể đều có cơ hội được lựa chọn ngang nhau và đều có cơ hội là một cá thể trong tập mẫu.\nLấy mẫu ngẫu nhiên Những thuật toán trong nhóm này sử dụng hàm \u0026ldquo;ngẫu nhiên\u0026rdquo; để đảm bảo rằng mọi phần tử đều có cơ hội lựa chọn ngang nhau. Một tên khác của phương pháp này là random sampling.\nMột số phương pháp thuộc nhóm này\n  Simple Random Sampling\n  Stratified sampling\n  Systematic sampling\n  Cluster Sampling\n  Multi stage Sampling\n  Simple Random Sampling Mỗi cá thể đều có cơ hội lựa chọn ngang nhau vào tập mẫu. Phương pháp này được sử dụng khi chúng ta không có bất kỳ thông tin gì về tập population.\nVí dụ: Chọn ngẫu nhiên 20 sinh viên trong lớp học 50 sinh viên. Mỗi sinh viên đều có cơ hội được chọn ngang nhau là 1/50.\nStratified sampling Kỹ thuật này phân chia mỗi cá thể trong quần thể thành từng nhóm nhỏ dựa trên sự tương đồng (similarity), nghĩa là các cá thể trong cùng 1 nhóm sẽ đồng nhất với nhau về một khía cạnh nào đó, và sẽ không giống với các nhóm khác về khía cạnh đó. Và chúng ta sẽ chọn ngẫu nhiên các các thể trong mỗi nhóm. Ở phương pháp này, chúng ta cần thông tin cho trước về tập quần thể để tạo các nhóm con.\nHình 2: lấy mẫu Stratified sampling\nỞ ví dụ trên, chúng ta sẽ chia tập quần thể thành các nhóm con mặc áo đỏ, mặc áo xanh, mặc áo vàng (phải biết trước được trong quần thể thằng nào mặc áo màu gì). Sau đó sẽ lựa chọn ngẫu nhiên 2 các thể trong mỗi nhóm.\nCluster Sampling Toàn bộ tập quần thể sẽ được chia thành từ cụm hoặc thành từng phần. Sau đó chúng ta sẽ chọn ngẫu nhiên từng cụm. Tất cả các cá thể trong cụm đó sẽ được sử dụng làm tập mẫu. Các cụm được định danh dựa trên các yếu tố xác định trước. Ví dụ ở trong hình ở trên, các cụm được định danh dựa vào màu sắc của áo mà người đó mặc. Điểm khác biệt ở phương pháp này so với phương pháp ở trên là phương pháp ở trên lựa chọn ngẫu nhiên một số các cá thể trong mỗi cụm. Còn phương pháp này sẽ lựa chọn ngẫu nhiên các cụm, và chọn hết tất cả các các thể trong cụm đó.\nMột số chiến lược để lựa chọn cụm:\nSingle Stage Cluster Sampling: Các cụm được lựa chọn ngẫu nhiên\nHình 3: Single Stage Cluster Sampling\nTwo Stage Cluster Sampling: Ở phương pháp này, chúng ta sẽ lựa chọn ngẫu nhiên các cụm, sau đó, trong mỗi cụm, chúng ta sẽ lựa chọn ngẫu nhiên các cá thể trong mỗi cụm\nHình 4: Two Stage Cluster Sampling\nSystematic Clustering Ở phương pháp này, việc lựa chọn cá thể là có quy luật và không ngẫu nhiên, từ cá thể đầu tiên. Các cá thể của tập mẫu được chọn ra từ tập quần thể dựa vào một quy luật nào đó. Đầu tiên, tất cả các cá thể trong tập quần thể phải được xắp xếp có thứ tự. Sau đó chúng ta sẽ lựa chọn ngẫu nhiên cá thể đầu tiên (mỗi cá thể đều có xác suất ngang nhau ở đây), và sử dụng quy luật nào đó để rút ra các cá thể tiếp theo.\nHình 5: Systematic Clustering\nNhư ví dụ ở trên, chúng ta xắp xếp các nhân vật áo vàng, xanh, đỏ ngẫu nhiên tuỳ ý theo sự lựa chọn của người ta. Quy luật là cứ 4 người sẽ lấy người cuối. Ấn nút ngẫu nhiên \u0026hellip; ta được số 3. Vậy là cá thể đầu tiên là nhân vật ở vị trí số 3, tiếp theo sẽ là nhân vật ở vị trí 7, 11, 15,19, 5, \u0026hellip;\nMulti-Stage Sampling Phương pháp này là sự kết hợp của một hoặc nhiều phương pháp được mô tả ở trên.\nQuần thể được chia thành nhiều cụm (cluster) và mỗi cụm được chia vào từng nhóm con (subgrop - strata) dựa trên sự tương đồng =\u0026gt; chúng ta được một tập các cụm con được gọi là stratum. Chúng ta sẽ lựa nhọn một hoặc một vài strata trong stratum. Quá trình này sẽ được lặp đi lặp lại đến khi không còn cụm nào có thể phân chia được nữa.\nVí dụ, các quốc gia có thể được phân chia thành từng bang, thành phố, thành thị, nông thôn. Và tất cả các khu vực có cùng ký tự đầu có thể được gom lại thành với nhau tạo thành một strata.\nHình 6: Multi-Stage Sampling\nLấy mẫu phi ngẫu nhiên Những kỹ thuật nằm trong nhóm này không sử dụng hàm ngẫu nhiên. Kỹ thuật này phụ thuộc vào khả năng hiểu biết của các nhà nghiên cứu (researcher) trên tập quần thể họ đang có để chọn lựa cá thể cho tập mẫu. Kết quả của việc lấy mẫu có thể bị lệch.\nMột số phương pháp thuộc nhóm này là:\n  Convenience Sampling\n  Purposive Sampling\n  Quota Sampling\n  Referral /Snowball Sampling\n  Convenience Sampling Các cá thể được chọn dựa trên tính khả dụng của dữ liệu. Phương pháp này được sử dụng khi tính khả dụng của dữ liệu là hiếm và tốn kém. Do vậy, chúng ta sẽ lựa chọn mẫu dựa trên sự tiện lợi.\nVí dụ, Các nhà nghiên cứu thường hay sử dụng phương pháp này trong các giai đoạn đầu của các nghiên cứu khảo sát, vì nó dễ dàng, nhanh chóng và cho ra kết quả nhanh.\nPurposive Sampling Phương pháp lấy mẫu này dựa trên mục đích của nghiên cứu. Chỉ chọn ra những cá thể trong quần thể phù hợp nhất với mục đích nghiên cứu .\nVí dụ: Nếu chúng ta muốn hiểu được \u0026ldquo;suy nghĩ của những người quan tâm đến bằng thạc sỹ\u0026rdquo; thì tiêu chí lựa chọn cá thể là những người say yes trong câu hỏi \u0026ldquo;bạn có hứng thú với bậc thạc sỹ trong lĩnh vực \u0026hellip; không?\u0026rdquo;. Những người say \u0026ldquo;No\u0026rdquo; sẽ bị loại khỏi tập mẫu của chúng ta.\nQuota Sampling Phương pháp lấy mẫu này phụ thuộc vào một số tiêu chuẩn thiết lập từ trước. Tỷ lệ của các nhóm cá thể trong tập mẫu phải giống hết trong tập quần thể. Các cá thể được chọn cho đến khi chúng đạt đúng tỷ lệ của một loại dữ liệu.\nVí dụ: Giả sử chúng ta biết rằng trên trái đất này có 6 tỷ người, và 45% trong số đó là nam giới và 55% là nữ giới. Vậy thì chúng ta sẽ lấy mẫu làm sao cho tập mẫu chúng ta cũng phản ánh số đó, nghĩa là trong tập mẫu có 1000 người thì 45% trong số 1000 người đó phải là nam và 55% trong số 1000 người đó là nữ.\nReferral /Snowball Sampling Kỹ thuật này được sử dụng khi chúng ta không biết gì về tập quần thể hoặc tập quần thể hiếm. Lúc đó chúng ta sẽ tìm ra cá thể đầu tiên trong quần thể, rồi nhờ cá thể đầu tiên đó gợi ý các cá thể tiếp theo với điều kiện thoả nhu cẫu lấy mẫu của nghiên cứu. Cứ tiếp tục như vậy thì kích thước của tập mẫu sẽ tăng lên theo cấp nhân như kích thước quả quả cầu tuyết, nên kỹ thuật này còn có tên gọi khác là Snowball Sampling.\nHình 7: Ví dụ về Snowball Sampling\nVí dụ: Trong tình huống, ngữ cảnh là bạn muốn làm 1 bài khảo sát về những người bị nhiễm HIV, những người này thường có khuynh hướng không cởi mở ở mức độ công cộng và khó cho chúng ta tiếp cận để thu thập thông tin trực tiếp từ họ.\nNhóm khảo sát sẽ tiến hành liên hệ 1 người nào đó mà họ biết hoặc người nào đó xung phong làm cầu nối với các người bị nhiễm và thu thập thông tin từ họ (những người bị nhiễn tin tưởng người được xung phong hơn nhóm khảo sát. Vì nhóm khảo sát là người lạ).\nHi vọng sau bài viết này, các bạn có thêm nhiều ý tưởng hơn nữa về việc lấy mẫu và các cách để lấy mẫu trong ứng dụng thực tế.\nBài viết được lược dịch và một số hình ảnh được lấy từ nguồn https://towardsdatascience.com/sampling-techniques-a4e34111d808\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.\n","date":"May 4, 2019","img":"","permalink":"/blog/2019-05-04-sampling-method/","series":null,"tags":["machine learning","deep learning","sampleing","Probability Sampling","non-probability sampling"],"title":"Các Kỹ Thuật Lấy Mẫu"},{"categories":null,"content":"1. Giới thiệu về PredictionIO PredictionIO là một \u0026ldquo;open source Machine Learning Server built on top of a state-of-the-art open source stack\u0026rdquo; giúp cho các developers và các data scientists tạo ra các engine dự đoán trong học máy. PredictionIO giúp chúng ta\n  Xây dựng và triển khai các ứng dụng, dịch vụ một cách nhanh chóng bằng cách tuỳ chỉnh lại các template đã sẵn có.\n  Trả lời các câu truy vấn động trong thời gian thực.\n  huấn luyện và so sánh/đánh giá nhiều mô hình khác nhau dễ dàng.\n  Hợp nhất hoá dữ liệu từ nhiều nền tảng khác nhau hoặc trong thời gian thực để thực hiện phân tích dự đoán.\n  Hỗ trợ các thư viện máy học và xử lý dữ liệu như Spark MLLib và OpenNLP\n  Tự xây dựng, triển khai, customize một mô hình machine learning\n  2. Cơ chế hoạt động của PredictionIO PredictionIO bao gồm các thành phần sau:\n  PredictionIO platform: là nền tảng open source được apache xây dựng sẵn giúp chúng ta triển khai, xây dựng, đánh giá các mô hình máy học.\n  Event Server: là nơi giúp chúng ta chuẩn hoá các sự kiện từ nhiều nguồn khác nhau\n  Template Gallery: là nơi chúng ta download các engine template máy học về. PredictionIO hỗ trợ cho chúng ta rất nhiều template mẫu khác nhau. Chúng ta sẽ lần lượt tìm hiểu và implement ở các bài viết tiếp theo.\n  Event Server PredictionIO Event Server chịu trách nhiệu thu thập dữ liệu từ các ứng dụng của bạn. Bạn có thể nhìn kỹ hơn ở hình bên dưới, các ứng dụng web, mobile app \u0026hellip; khi người dùng tương tác sẽ phát sinh các sự kiện (Event Data), ví dụ sự kiện người dùng thêm 1 đơn hàng vào giỏ hàng, người dùng xem sản phẩn A, người dùng xem sản phẩm C sau khi xem sản phẩm A\u0026hellip; Event Server sẽ ghi nhận lại đống dữ liệu này, chuẩn hoá lại. PredictionIO engine sau đó sẽ xây dựng mô hình dự đoán dựa trên các dữ liệu chúng ta thu thập được. Sau khi bạn có được mô hình tối ưu, chúng ta sẽ deploy các predict webservice, lắng nghe các truy vấn từ các ứng dụng và trả về kết quả trong thời gian thực.\nHình 1: Event server trong predictionio\nEvent Server sẽ thu thập dữ liệu của bạn trong thời gian thực hoặc theo chu kỳ. Sau đó, nó sẽ chuẩn hoá dữ liệu hỗn độn của bạn từ nhiều nguồn khác nhau thành một dạng chuẩn chung. Event Server chủ yếu phục vụ hai mục đính chính:\n  Cung cấp dữ liệu cho các engine để huấn luyện và đánh giá\n  Cung cấp dữ liệu dạng chuẩn để data analysis\n  Cũng giống như một database server, Event Server có thể được sử dụng để phục vụ cho nhiều ứng dụng khác nhau. Dữ liệu được phân tách cho các ứng dụng bằng \u0026ldquo;app_name\u0026rdquo; duy nhất. Cái này sẽ nói lại lúc xây dựng ứng dụng ở bên dưới.\nKhi một Event Server được triển khai, bạn có thể gửi dữ liệu cho một \u0026lsquo;app_name\u0026rsquo; cụ thể nào đó, app-name được định danh bằng access key. Dữ liệu được gửi đến Event Server sử dụng EventAPI sử dụng giao thức http (tham khảo thêm ở https://predictionio.apache.org/datacollection/eventapi/) hoặc sử dụng các PredictionIO SDK. Tham khảo thêm các SDK ở https://predictionio.apache.org/sdk/.\nTrong một số trường hợp, bạn muốn engine đọc dữ liệu từ một datastore nào đó thay vì Event Server. Bạn có thể thực hiện thông qua hướng dẫn ở https://predictionio.apache.org/start/customize/\nEngine Engine là nơi chịu trách nhiệu đưa ra các quyết định. Nó gồm một hoặc nhiều thuật toán học máy học khác nhau. Các Engine sẽ huấn luyện dữ liệu và xây dựng các mô hình dự đoán. Sau đó sẽ phát triển thành các webservice. Các webservice sẽ nhận các truy vấn từ ứng dụng, dự đoán và trả về kết quả cho ứng dụng.\nPredictionIO\u0026rsquo;s cung cấp cho chúng ta rất nhiều các template khác nhau đáp ứng gần như là đẩy đủ các mô hình máy học mà chúng ta cần. Bạn có thể dễ dàng tạo một mô hình máy học từ các template. Các thành phần của một template dược đặt tên là Data Source, Data Preparator, Algorithm(s), Serving, các bạn có thể dễ dàng customize lại tuỳ thuộc nhu cầu của bạn.\n3. Cài đặt PredictionIO trên môi trường Ubuntu Trong thời đại docker, các bạn có thể cài đặt PredictionIO dựa vào các docker được xây dựng sẵn đầy rẫy trên mạng, chúng giúp bạn đỡ tốn công sức hơn. Tuy nhiên, trong bài viết này, mình sẽ cài đặt từng thành phần PredictiIO trên ubuntu, không sử dụng docker.\nDownload và build Apache Prediction IO Chúng ta sẽ download Prediction IO từ trang github chính chủ. Phiên bản hiện tại là 0.14.0. Các bạn có thể lưu dữ liệu ở đâu tuỳ ý các bạn. Mình lưu ở thư mục /data/pio. Và trong suốt bài viết này, mình sẽ lưu các thứ liên quan trong thư mục /data/pio. Các bạn có cài đặt theo hướng dẫn của mình thì nhớ sửa lại cho đúng đường dẫn của các bạn. Chúng ta sẽ clone nguồn từ trang github predictionio. và sẽ switch qua branch release. Đây là branch chính thành phẩm, các branch khác đang trong giai đoạn phát triển nên có thể build không được. Lúc các bạn làm có thể nó đã phát triển lên bản 15, 16 hoặc 1.0 gì đó rồi. Các bạn cứ tự tin sử dụng phiên bản mới nhất.\n1git clone https://github.com/apache/predictionio.git 2git checkout release/0.14.0 Biên dịch Prediction IO Sau khi tải về bộ nguồn của Prediction IO, chúng ta sẽ tiền hành biên dịch. Quá trình biên dịch sẽ xảy ra khá lâu, các bạn kiên nhẫn chờ đợi\n1cd predictionio 2./make-distribution.sh Kết thúc quá trình biên dịch, các bạn sẽ thấy dòng chữ\n1PredictionIO binary distribution created at PredictionIO-0.14.0.tar.gz Vậy là chúng ta đã thành công. Việc tiếp theo là giải nén file PredictionIO-0.14.0.tar.gz để sử dụng\n1tar xvzf PredictionIO-0.14.0.tar.gz -C /data/pio Nhắc lại 1 lần nữa là do thời điểm hiện tại mình viết bài viết này, PredictionIO mới release bản 0.14.0 nên file tập tin sẽ là PredictionIO-0.14.0.tar.gz. Các bạn nhớ giải nén đúng với tên file ứng với phiên bản PredictionIO tương ứng nhé.\nDownload và giải nén các Dependencies Mình sẽ sử dụng Spark, ElasticSearch, Hbase và zookeeper, nên mình download hết về. Mình có thói quen sử dụng phiên bản mới nhất. Nên mình lên trang chủ và lấy link download mới nhất của chúng thôi. Tất cả các Dependencies mình dùng đều được bỏ vào trong thư mục vendors\n12cd PredictionIO-0.14.0 3mkdir vendors 4cd vendors 5wget https://archive.apache.org/dist/spark/spark-2.4.2/spark-2.4.2-bin-hadoop2.7.tgz 67wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.9.tar.gz 89wget https://www.apache.org/dyn/closer.lua/hbase/2.1.4/hbase-2.1.4-bin.tar.gz 1011wget https://www-us.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz 1213tar xvzf spark-2.4.2-bin-hadoop2.7.tgz 1415tar xvzf elasticsearch-5.6.9.tar.gz 1617tar xvzf hbase-2.1.4-bin.tar.gz 1819tar xvzf zookeeper-3.4.14/zookeeper-3.4.14.tar.gz Cấu hình chương trình Cấu hình dependency Chúng ta sẽ cấu hình một chút để PredictionIO nhận ra các dependency của mình và cấu hình các dependency\nĐầu tiên, chúng ta sẽ chỉnh sửa file hbase-site.xml của HBase\n1nano /data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4/conf/hbase-site.xml Thay đoạn\n1\u0026lt;configuration\u0026gt; 2\u0026lt;/configuration\u0026gt; bằng đoạn\n1\u0026lt;configuration\u0026gt; 2\u0026lt;property\u0026gt; 3\u0026lt;name\u0026gt;hbase.rootdir\u0026lt;/name\u0026gt; 4\u0026lt;value\u0026gt;file:///data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4\u0026lt;/value\u0026gt; 5\u0026lt;/property\u0026gt; 6\u0026lt;property\u0026gt; 7\u0026lt;name\u0026gt;hbase.zookeeper.property.dataDir\u0026lt;/name\u0026gt; 8\u0026lt;value\u0026gt;/data/pio/PredictionIO-0.14.0/vendors/zookeeper-3.4.14\u0026lt;/value\u0026gt; 9\u0026lt;/property\u0026gt; 10\u0026lt;/configuration\u0026gt; Tiếp theo, chúng ta sẽ add đường dẫn java cho hbase\n1nano /data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4/conf/hbase-env.sh Thêm đoạn\n1export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre/ các bạn hãy thay đường dẫn java tương ứng với đường dẫn trong máy bạn. Nếu chưa có java thì các bạn hãy cài vào, nếu các bạn đã cài java mà không biết nó nằm ở đâu, các bạn có thể gọi lệnh bên dưới để xem đường dẫn\n1update-alternatives --config java Để chắc chắn rằng trong máy của bạn có cài java bạn hãy gọi lện java -version\nVí dụ trong máy mình\n1$java -version 2openjdk version \u0026#34;1.8.0_191\u0026#34; 3OpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-2ubuntu0.16.04.1-b12) 4OpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode) Các bạn cố gắng sử dụng phiên bản java mới nhất. Nó sẽ tương thích tốt hơn với phiên bản mới nhất của HBase, hoặc đọc phiên bản java đề nghị trong trang chủ HBase. Tránh trường hợp sử dụng phiên bản java quá cũ HBase không hỗ trợ.\nCấu hình Prediction IO Chỉnh sửa file pio-env.sh.\n12nano /data/pio/PredictionIO-0.14.0/conf/pio-env.sh Mặc định PredictionIO sử dụng PosgresSQl làm event server. Mình không dùng nó mà thay thế bằng HBASE và ELASTICSEARCH.\nMột số thay đổi mình sẽ liệt kê bên dưới\n1SPARK_HOME=$PIO_HOME/vendors/spark-2.3.2-bin-hadoop2.7 23HBASE_CONF_DIR=$PIO_HOME/vendors/hbase-2.1.4/conf 45PIO_STORAGE_REPOSITORIES_METADATA_NAME=pio_meta 6PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH 78PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=pio_event 9PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE 1011PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_model 12PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS 1314#Comment các dòng này lại, do không dùng postgres 15# PIO_STORAGE_SOURCES_PGSQL_PASSWORD accordingly 16# PIO_STORAGE_SOURCES_PGSQL_TYPE=jdbc 17# PIO_STORAGE_SOURCES_PGSQL_URL=jdbc:postgresql://localhost/pio 18# PIO_STORAGE_SOURCES_PGSQL_USERNAME=pio 19# PIO_STORAGE_SOURCES_PGSQL_PASSWORD=pio 2021PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=$PIO_HOME/vendors/elasticsearch-5.6.9 22PIO_STORAGE_SOURCES_HBASE_HOME=$PIO_HOME/vendors/hbase-2.1.4 4.Khởi chạy hệ thống Chúng ta sẽ add path của PredictIO vào biến môi trường để sử dụng cho các lần sau\n12nano ~/.bashrc 3erport PATH=/data/pio/PredictionIO-0.14.0/bin:$PATH Hoặc có thể add path trong mỗi session\n1PATH=$PATH:/data/pio/PredictionIO-0.14.0/bin; export PATH Tiếp theo, chúng ta sẽ cấp quyền cho thư mục PredictionIO\n1sudo chmod -R 775 /data/pio Nếu không cấp quyền write cho thư mục thì PredictionIO không thể write log file được.\nChạy PredictionIO Server bằng cách gọi câu lệnh\n1pio-start-all Kết quả\n1Stopping PredictionIO Event Server... 2Stopping HBase... 3stopping hbase............. 4Stopping Elasticsearch... 5tgdd@U1604:/data/pio/PredictionIO-0.14.0/bin$ pio-start-all 6Starting Elasticsearch... 7Starting HBase... 8running master, logging to /data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4/bin/../logs/hbase-tgdd-master-U1604.out 9Waiting 10 seconds for Storage Repositories to fully initialize... 10Starting PredictionIO Event Server... Để kiểm tra hệ thống khi start có lỗi lầm gì không, chúng ta sử dụng lệnh\n1pio status Kết quả\n1[INFO] [Management$] Inspecting PredictionIO... 2[INFO] [Management$] PredictionIO 0.14.0 is installed at /data/pio/PredictionIO-0.14.0 3[INFO] [Management$] Inspecting Apache Spark... 4[INFO] [Management$] Apache Spark is installed at /data/spark-2.3.2-bin-hadoop2.7 5[INFO] [Management$] Apache Spark 2.3.2 detected (meets minimum requirement of 2.0.2) 6[INFO] [Management$] Inspecting storage backend connections... 7[INFO] [Storage$] Verifying Meta Data Backend (Source: ELASTICSEARCH)... 8[INFO] [Storage$] Verifying Model Data Backend (Source: LOCALFS)... 9[INFO] [Storage$] Verifying Event Data Backend (Source: HBASE)... 10[INFO] [Storage$] Test writing to Event Store (App Id 0)... 11[INFO] [HBLEvents] The table pio_event:events_0 doesn\u0026#39;t exist yet. Creating now... 12[INFO] [HBLEvents] Removing table pio_event:events_0... 13[INFO] [Management$] Your system is all ready to go. Bạn thấy dòng chữ [INFO] [Management$] Your system is all ready to go. thì yên tâm, hệ thống đã chạy thành công.\nĐể stop hệ thống, các bạn gọi lệnh\n1pio-stop-all Kết quả khi stop\n1Stopping PredictionIO Event Server... 2Stopping HBase... 3stopping hbase............. 4Stopping Elasticsearch... Vậy là chúng ta đã tiến hành cài đặt thành công PredictionIO Server rồi. Hẹn gặp bạn ở bài thứ hai, cài đặt các template cho PredictionIO và tiến hành dự đoán.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.\n","date":"May 3, 2019","img":"","permalink":"/blog/2019-05-04-setup-predictio/","series":null,"tags":["machine learning","deep learning","PredictionIO","forecast","dự đoán"],"title":"PredictionIO Phần 1 - Hướng Dẫn Cài Đặt"},{"categories":null,"content":"1. Tạo chương trình đầu tiên bằng PredictionIO Đầu tiên, các bạn hãy tạo thư mục template ở đâu đó. Mình sẽ tạo ở trong thư mục /data/pio. Đường dẫn của mình sẽ là /data/pio/template\n1mdkir /data/pio/template Tiếp theo, chúng ta sẽ clone templte trên github về, các bạn thực hiện lệnh sau\n1git clone https://github.com/apache/predictionio-template-recommender.git 2cd predictionio-template-recommender Tiếp theo, chúng ta sẽ tạo một app đầu tiên, mình đặt tên là ourrecommendation, các bạn thích đặt tên gì thì đặt nha.\n1pio app new ourrecommendation Để liệt kê danh sách app đang có trong hệ thống, các bạn dùng lệnh\n1pio app list Kết quả trong máy mình tại thời điểm viết bài là\n1[INFO] [Pio$] Name | ID | Access Key | Allowed Event(s) 2[INFO] [Pio$] ourrecommendation | 1 | Z93rJZ7Xq2pXiQwVC6B5nRK6jRykcfyMI5huOijKbdDJeUeKEnVT-ph5nabptIX1 | (all) 3[INFO] [Pio$] Finished listing 1 app(s). Mình mới tạo app đầu tiên tên là ourrecommendation nên chỉ có 1 app trong hệ thống. Sau này sẽ có nhiều hơn. À, sau khi tạo app, thì hệ thống sẽ generate tự động cho app với một Access Key, ví dụ access key của app ourrecommendateion của mình là Z93rJZ7Xq2pXiQwVC6B5nRK6jRykcfyMI5huOijKbdDJeUeKEnVT-ph5nabptIX1. Các bạn sẽ có access key khác với access key của mình, nên đừng copy của mình về làm gì hết :).\nSau khi khởi tạo app xong, chúng ta sẽ import data vào hệ thống. Ở đây, mình sẽ download dữ liệu mẫu từ nguồn https://gist.githubusercontent.com/vaghawan/0a5fb8ddb85e03631dd500d7c8f0677d/raw/17487437dd8269588d9dd1ac859b129a43842ba5/data-sample.json. Sau khi download về các bạn import dữ liệu vào hệ thống bằng lệnh\n1pio import — appid 1 — input data-sample.json Với appod 1 là id của ourrecommendation chúng ta vừa mới tạo. Nếu quên appid, các bạn có thể xem lại bằng lệnh pio app list.\nSau khi import thành công, chúng ta sẽ thay đổi giá trị của trường appname trong file engine.json thành tên của app mình, là ourrecommendation\n1nano engine.json 23{ 4\u0026#34;id\u0026#34;: \u0026#34;default\u0026#34;, 5\u0026#34;description\u0026#34;: \u0026#34;Default settings\u0026#34;, 6\u0026#34;engineFactory\u0026#34;: \u0026#34;org.example.recommendation.RecommendationEngine\u0026#34;, 7\u0026#34;datasource\u0026#34;: { 8\u0026#34;params\u0026#34; : { 9\u0026#34;appName\u0026#34;: \u0026#34;ourrecommendation\u0026#34; 10} 11}, 12\u0026#34;algorithms\u0026#34;: [ 13{ 14\u0026#34;name\u0026#34;: \u0026#34;als\u0026#34;, 15\u0026#34;params\u0026#34;: { 16\u0026#34;rank\u0026#34;: 10, 17\u0026#34;numIterations\u0026#34;: 20, 18\u0026#34;lambda\u0026#34;: 0.01, 19\u0026#34;seed\u0026#34;: 3 20} 21} 22] 23} Một lưu ý quang trọng là giá trị \u0026ldquo;org.example.recommendation.RecommendationEngine\u0026rdquo; trong \u0026ldquo;engineFactory\u0026rdquo; là của hệ thống. Và bạn đừng sửa, thay đổi chúng. Nói chung là ngoài giá trị của \u0026ldquo;appName\u0026rdquo; ra, bạn không nên thay đổi bất kỳ thức gì khác trong file engine.json.\nSau khi import file thành công. Chúng ta sẽ build app. Lệnh build có tác dụng kiểm tra lại hệ thống đã được cấu hình đúng và đủ chưa.\n1pio build Nếu build thành công, chúng ta sẽ thấy dòng chữ này.\n12[INFO] [Engine$] Build finished successfully. 3[INFO] [Pio$] Your engine is ready for training. Sau khi build thành công, chúng ta sẽ tiến hành huấn luyện mô hình\n1pio build Và chờ đợi dòng này xuất hiện\n12[INFO] [CoreWorkflow$] Training completed successfully. Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.\n","date":"May 3, 2019","img":"","permalink":"/blog/2019-05-07-predictio-mini-demo1/","series":null,"tags":["machine learning","deep learning","PredictionIO","forecast","dự đoán"],"title":"PredictionIO Phần 2 - Cài Đặt Chương Trình Demo"},{"categories":null,"content":"Ở bài trước mình đã trình bày định nghĩa và một số ứng dụng của Máy học (Machine Learning – ML), phân biệt ML với Trí tuệ nhân tạo (Artificial Intelligence – AI) cũng như mối quan hệ giữa AI, ML và Big Data. Từ bài viết này trở đi mình sẽ tập trung viết về ML, các thuật toán, cách sử dụng công cụ kèm theo một vài demo nhỏ giúp bạn đọc dễ hình dung và áp dụng. Để mở đầu cho chuỗi bài viết sắp tới, hôm nay mình sẽ trình bày cách phân nhóm các thuật toán ML.\nVới đa số mọi người, trước khi bắt đầu giải quyết một vấn đề nào đó, việc đầu tiên là chúng ta sẽ tìm hiểu xem liệu có ai đã gặp vấn đề này hoặc vấn đề tương tự như vậy hay không và cách họ giải quyết thế nào. Sau khi nắm được thông tin khái quát, công việc kế tiếp là chọn lựa và điều chỉnh giải pháp sao cho phù hợp với vấn đề của bản thân. Trong trường hợp vấn đề còn quá mới mẻ thì chúng ta mới phải bắt tay làm từ đầu, điều này hầu như rất hiếm, đặc biệt là trong thời đại công nghệ này, khi mà chỉ bằng một cú nhấp chuột, hàng ngàn thông tin, tư liệu về đề tài chúng ta quan tâm sẽ xuất hiện. Cũng giống như thế, ML hiện đã được nghiên cứu rộng khắp, rất nhiều công trình khoa học, thuật toán được cho ra đời. Với người mới bắt đầu mà nói thì chúng ta chưa cần phải làm gì cả ngoài việc nắm được các thuật toán cơ bản, đặc điểm của chúng để khi đối diện với một bài toán cụ thể trong thực tế chúng ta có thể biết được mình nên lựa chọn thuật toán nào cho phù hợp đã là điều rất tốt rồi.\nMặc dù có rất nhiều thuật toán học nhưng dựa vào phương thức học (learning style) hoặc sự tương đồng (similarity) về hình thức hay chức năng mà chúng có thể được gom thành từng nhóm. Sau đây mình sẽ trình bày tổng quan cả hai cách phân nhóm thuật toán học này.\n1.\tPhân nhóm dựa trên phương thức học Xét theo phương thức học, các thuật toán ML được chia làm bốn nhóm, bao gồm “Học có giám sát” (Supervised Learning), “Học không giám sát” (Unsupervised Learning), “Học bán giám sát” (hay học kết hợp - Semi-supervised Learning) và “Học tăng cường” (Reinforcement Learning).\na.\tHọc có giám sát Học có giám sát hay còn gọi là học có thầy là thuật toán dự đoán nhãn (label)/đầu ra (output) của một dữ liệu mới dựa trên tập dữ liệu huấn luyện mà trong đó mỗi mẫu dữ liệu đều đã được gán nhãn như minh hoạ ở Hình 1. Khi đó, thông qua một quá trình huấn luyện, một mô hình sẽ được xây dựng để cho ra các dự đoán và khi các dự đoán bị sai thì mô hình này sẽ được tinh chỉnh lại. Việc huấn luyện sẽ tiếp tục cho đến khi mô hình đạt được mức độ chính xác mong muốn trên dữ liệu huấn luyện. Điều này cũng giống như khi chúng ta đi học trên lớp, ta biết câu trả lời chính xác từ giáo viên (tập dữ liệu có nhãn) và từ đó ta sẽ sửa chữa nếu làm sai. Học có giám sát là nhóm phổ biến nhất trong các thuật toán ML.\nHình 1: Supervised Learning Algorithms\nMột cách toán học, học có giám sát là khi chúng ra có một tập hợp biến đầu vào $ X={x_1,x_2,…,x_N} $ và một tập hợp nhãn tương ứng $ Y={y_1,y_2,…,y_N} $, trong đó $ x_i$, $y_i $ là các vector. Các cặp dữ liệu biết trước $( x_i, y_i ) \\in X \\times Y $ được gọi là tập dữ liệu huấn luyện (training data). Từ tập dữ liệu huấn luyện này, chúng ta cần tạo ra một hàm số ánh xạ mỗi phần tử từ tập X sang một phần tử (xấp xỉ) tương ứng của tập Y:\n$$ y_i \\approx f(x_i), \\forall i=1, 2, …, N $$\nMục đích là xấp xỉ hàm số $f$ thật tốt để khi có một dữ liệu x mới, chúng ta có thể tính được nhãn tương ứng của nó $y=f(x)$.\nVí dụ: Trong nhận dạng chữ số viết tay, ta có ảnh của hàng nghìn trường hợp ứng với mỗi chữ số được viết bởi nhiều người khác nhau. Ta đưa các bức ảnh này vào một thuật toán học và chỉ cho nó biết “mỗi bức ảnh tương ứng với chữ số nào”. Sau khi thuật toán tạo ra một mô hình, tức là một hàm số nhận đầu vào là một bức ảnh và cho ra kết quả là một chữ số. Khi nhận được một bức ảnh mới mà mô hình “chưa từng gặp qua” và nó sẽ dự đoán xem bức ảnh đó tương ứng với chữ số nào.\nHình 2: Ảnh minh hoạ cho tập dữ liệu chữ số viết tay - MNIST\nĐối với những ai sử dụng mạng xã hội Facebook thì khá quen thuộc với tính năng phát hiện khuôn mặt trong một bức ảnh, bản chất của thuật toán dò tìm các khuôn mặt này là một thuật toán học có giám sát với tập huấn luyện là vô số ảnh đã được gán nhãn là mặt người hay không phải mặt người.\nCác thuật toán học có giám sát còn được phân ra thành hai loại chính là phân lớp (Classification) và hồi quy (Regression).\nPhân lớp Một bài toán được gọi là phân lớp nếu các nhãn của dữ liệu đầu vào được chia thành một số hữu hạn lớp (miền giá trị là rời rạc). Chẳng hạn như tính năng xác định xem một email có phải là spam hay không của Gmail; xác định xem hình ảnh của con vật là chó hay mèo. Hoặc ví dụ nhận dạng ký số viết tay ở trên cũng thuộc bài toán phân lớp, bao gồm mười lớp ứng với các số từ 0 đến 9. Tương tự cho ví dụ nhận dạng khuôn mặt với hai lớp là phải và không phải khuôn mặt, …\nHồi quy Một bài toán được xem là hồi quy nếu nhãn không được chia thành các nhóm mà là một giá trị thực cụ thể (miền giá trị là liên tục). Hầu hết các bài toán dự báo (giá cổ phiếu, giá nhà, …) thường được xếp vào bài toán hồi quy. Ví như, nếu một căn nhà rộng 150 m^2, có 7 phòng và cách trung tâm thành phố 10 km sẽ có giá là bao nhiêu? Lúc này kết quả dự đoán sẽ là một số thực.\nNếu như phát hiện khuôn mặt là bài toán phân lớp thì dự đoán tuổi là bài toán hồi quy. Tuy nhiên dự đoán tuổi cũng có thể coi là phân lớp nếu ta cho tuổi là một số nguyên dương N và khi đó ta sẽ có N lớp khác nhau tính từ 1. Một số thuật toán nổi tiếng thuộc về nhóm học có giám sát như:\n  Phân lớp: k-Nearest Neighbors, mạng nơron nhân tạo, SVM, …\n  Hồi quy: Linear Regression, Logistic Regression, …\n  b. Học không giám sát Trái với Supervised learning, học không giám sát hay học không thầy là thuật toán dự đoán nhãn của một dữ liệu mới dựa trên tập dữ liệu huấn luyện mà trong đó tất cả các mẫu dữ liệu đều chưa được gán nhãn hay nói cách khác là ta không biết câu trả lời chính xác cho mỗi dữ liệu đầu vào như minh hoạ ở Hình 3. Điều này cũng giống như khi ta học mà không có thầy cô, sẽ không ai cho ta biết đáp án đúng là gì.\nHình 3: Unsupervised Learning Algorithms\nKhi đó, mục tiêu của thuật toán unsupervised learning không phải là tìm đầu ra chính xác mà sẽ hướng tới việc tìm ra cấu trúc hoặc sự liên hệ trong dữ liệu để thực hiện một công việc nào đó, ví như gom cụm (clustering) hoặc giảm số chiều của dữ liệu (dimension reduction) để thuận tiện trong việc lưu trữ và tính toán.\nCác bài toán Unsupervised learning tiếp tục được chia nhỏ thành hai loại là phân cụm (Clustering) và luật kết hợp (Association Rule).\nPhân cụm Một bài toán phân cụm / phân nhóm toàn bộ dữ liệu X thành các nhóm/cụm nhỏ dựa trên sự liên quan giữa các dữ liệu trong mỗi nhóm. Chẳng hạn như phân nhóm khách hàng dựa vào độ tuổi, giới tính. Điều này cũng giống như việc ta đưa cho một đứa trẻ rất nhiều mảnh ghép với các hình dạng và màu sắc khác nhau, có thể là tam giác, vuông, tròn với màu xanh, đỏ, tím, vàng, sau đó yêu cầu trẻ phân chúng thành từng nhóm. Mặc dù ta không dạy trẻ mảnh nào tương ứng với hình nào hoặc màu nào, nhưng nhiều khả năng trẻ vẫn có thể phân loại các mảnh ghép theo màu sắc hoặc hình dạng.\nLuật kết hợp Là bài toán mà khi chúng ta muốn khám phá ra một quy luật dựa trên nhiều dữ liệu cho trước. Ví như những khách hàng mua mặt hàng này sẽ mua thêm mặt hàng kia; hoặc khan giả xem phim này sẽ có xu hướng thích xem phim kia, dựa vào đó ta có thể xây dựng những hệ thống gợi ý khách hàng (Recommendation System) nhằm thúc đẩy nhu cầu mua sắm hoặc xem phim\u0026hellip;.\nMột số thuật toán thuộc nhóm học không giám sát như Apriori (Association Rule), k-Means (Clustering), …\nc.\tHọc bán giám sát Là bài toán mà khi tập dữ liệu đầu vào X là hỗn hợp các mẫu có nhãn và không có nhãn, trong đó số lượng có nhãn chỉ chiếm một phần nhỏ như minh hoạ ở Hình 4.\nPhần lớn các bài toán thực tế của ML thuộc nhóm này vì việc thu thập dữ liệu có nhãn tốn rất nhiều thời gian và có chi phí cao. Rất nhiều loại dữ liệu thậm chí cần phải có chuyên gia mới gán nhãn được, chẳng hạn như ảnh y học hoặc các cặp câu song ngữ. Ngược lại, dữ liệu chưa có nhãn có thể được thu thập với chi phí thấp từ internet.\nHình 4: Semi-supervised Learning Algorithms\nVới bài toán này, mô hình phải tìm hiểu các cấu trúc để tổ chức dữ liệu cũng như đưa ra dự đoán. Vì đặc điểm trung gian nên ta có thể sử dụng unsupervised learning để khám phá và tìm hiểu cấu trúc trong dữ liệu đầu vào, đồng thời sử dụng supervised learning để dự đoán cho dữ liệu không được gán nhãn. Sau đó đưa dữ liệu vừa dự đoán trở lại làm dữ liệu huấn luyện cho supervised learning và sử dụng mô hình sau khi huấn luyện để đưa ra dự đoán về dữ liệu mới.\nMột số thuật toán học tăng cường như: Self Training, Generative models, S3VMs, Graph-Based Algorithms, Multiview Algorithms, …\nd.\tHọc tăng cường Học tăng tường hay học củng cố là bài toán giúp cho một hệ thống tự động xác định hành vi dựa trên hoàn cảnh để đạt được lợi ích cao nhất. Hiện tại, reinforcement learning chủ yếu được áp dụng vào Lý Thuyết Trò Chơi (Game Theory), các thuật toán cần xác định nước đi tiếp theo để đạt được điểm số cao nhất. Hình 5 là một ví dụ đơn giản sử dụng học tăng cường.\nHình 5: Minh hoạ cho học tăng cường được áp dụng trong lý thuyết trò chơi.\nAlphaGo - một phần mềm chơi cờ vây trên máy tính được xây dựng bởi Google DeepMind hay chương trình dạy máy tính chơi game Mario là những ứng dụng sử dụng học tăng cường.\nCờ vậy được xem là trò chơi có độ phức tạp cực kỳ cao với tổng số nước đi là xấp xỉ 1076110761, so với cờ vua là 1012010120, vì vậy thuật toán phải chọn ra một nước đi tối ưu trong số hàng tỉ tỉ lựa chọn. Về cơ bản, AlphaGo bao gồm các thuật toán thuộc cả Supervised learning và Reinforcement learning. Trong phần Supervised learning, dữ liệu từ các ván cờ do con người chơi với nhau được đưa vào để huấn luyện. Tuy nhiên, mục tiêu cuối cùng của AlphaGo không phải là chơi như con người mà phải thắng được con người. Vì vậy, sau khi học xong các ván cờ của con người, AlphaGo tự chơi với chính nó thông qua hàng triệu ván cờ để tìm ra các nước đi mới tối ưu hơn. Thuật toán trong phần tự chơi này được xếp vào loại Reinforcement learning.\nĐơn giản hơn cờ vây, tại một thời điểm cụ thể, người chơi game Mario chỉ cần bấm một số lượng nhỏ các nút (di chuyển, nhảy, bắn đạn) hoặc không cần bấm nút nào ứng với một chướng ngại vật cố định ở một vị trí cố định. Khi đó thuật toán trong ứng dụng dạy máy tính chơi game Mario sẽ nhận đầu vào là sơ đồ của màn hình tại thời điểm hiện hành, nhiệm vụ của thuật toán là tìm ra tổ hợp phím nên được bấm ứng với đầu vào đó. Việc huấn luyện này được dựa trên điểm số cho việc di chuyển được bao xa với thời gian bao lâu trong game, càng xa và càng nhanh thì điểm thưởng đạt được càng cao, tất nhiên điểm thưởng này không phải là điểm của trò chơi mà là điểm do chính người lập trình tạo ra. Thông qua huấn luyện, thuật toán sẽ tìm ra một cách tối ưu để tối đa số điểm trên, qua đó đạt được mục đích cuối cùng là cứu công chúa.\nCó nhiều cách khác nhau để thuật toán có thể mô hình hóa một vấn đề dựa trên sự tương tác của nó với dữ liệu đầu vào. Phân loại hoặc cách tổ chức thuật toán học máy này rất hữu ích vì nó buộc chúng ta phải suy nghĩ về vai trò của dữ liệu đầu vào và quy trình chuẩn bị mô hình và chọn một thuật toán phù hợp nhất cho vấn đề của chúng ta để có kết quả tốt nhất.\n2.\tPhân nhóm dựa trên sự tương đồng Dựa vào sự tương đồng về chức năng hay cách thức hoạt động mà các thuật toán sẽ được gom nhóm với nhau. Sau đây là danh sách các nhóm và các thuật toán theo từng nhóm.\na.\tCác thuật toán hồi quy (Regression Algorithms) Hồi quy là quá trình tìm mối quan hệ phụ thuộc của một biến (được gọi là biến phụ thuộc hay biến được giải thích, biến được dự báo, biến được hồi quy, biến phản ứng, biến nội sinh) vào một hoặc nhiều biến khác (được gọi là biến độc lập, biến giải thích, biến dự báo, biến hồi quy, biến tác nhân hay biến kiểm soát, biến ngoại sinh) nhằm mục đích ước lượng hoặc tiên đoán giá trị kỳ vọng của biến phụ thuộc khi biết trước giá trị của biến độc lập. Hình 6 tượng trưng cho ý tưởng của các thuật toán hồi quy.\nVí dụ như, dự đoán rằng nếu tăng lãi suất tiền gửi thì sẽ huy động được lượng tiền gửi nhiều hơn, khi đó ngân hàng A cần biết mối quan hệ giữa lượng tiền gửi và lãi suất tiền gửi, cụ thể hơn họ muốn biết khi tăng lãi suất thêm 0.1% thì lượng tiền gửi sẽ tăng trung bình là bao nhiêu.\nCác thuật toán hồi quy phổ biến nhất là:\n  Linear Regression\n  Logistic Regression\n  Locally Estimated Scatterplot Smoothing (LOESS)\n  Multivariate Adaptive Regression Splines (MARS)\n  Ordinary Least Squares Regression (OLSR)\n  Stepwise Regression\n  Hình 6: Regression Algorithms\nb.\tThuật toán dựa trên mẫu (Instance-based Algorithms) Mô hình học tập dựa trên mẫu hay thực thể là bài toán ra quyết định dựa vào các trường hợp hoặc các mẫu dữ liệu huấn luyện được coi là quan trọng hay bắt buộc đối với mô hình.\nNhóm thuật toán này thường xây dựng cơ sở dữ liệu về dữ liệu mẫu và so sánh dữ liệu mới với cơ sở dữ liệu bằng cách sử dụng thước đo tương tự để tìm kết quả phù hợp nhất và đưa ra dự đoán. Khi đó trọng tâm được đặt vào đại diện của các thể hiện được lưu trữ như minh hoạ ở Hình 7.\nHình 7: Instance-based Algorithms\nCác thuật toán dựa trên thực thể phổ biến nhất là:\n  k-Nearest Neighbor (kNN – k láng giềng gần nhất)\n  Learning Vector Quantization (LVQ)\n  Locally Weighted Learning (LWL)\n  Self-Organizing Map (SOM)\n  c.\tThuật toán chuẩn hoá (Regularization Algorithms) Các thuật toán chuẩn hoá ra đời từ sự mở rộng các phương pháp đã có (điển hình là các phương pháp hồi quy) bằng cách xử phạt các mô hình dựa trên mức độ phức tạp của chúng. Việc ưu tiên các mô hình đơn giản hơn cũng tốt hơn trong việc khái quát hóa. Hình 8 tượng trưng cho ý tưởng của thuật toán chuẩn hoá.\nHình 8: Regularization Algorithms\nCác thuật toán chính quy phổ biến nhất là:\n  Elastic Net\n  Least Absolute Shrinkage and Selection Operator (LASSO)\n  Least-Angle Regression (LARS)\n  Ridge Regression\n  d.\tThuật toán cây quyết định (Decision Tree Algorithms) Đây là phương pháp xây dựng mô hình ra quyết định dựa trên các giá trị thực của những thuộc tính trong dữ liệu. Sự quyết định được rẽ nhánh trong cấu trúc cây cho đến khi quyết định dự đoán được đưa ra cho một mẫu nhất định như minh hoạ ở Hình 9. Phương pháp này được sử dụng trong việc huấn luyện dữ liệu cho bài toán phân lớp và hồi quy. Vì sự nhanh chóng, chính xác nên phương pháp này rất được ưa chuộng trong ML.\nHình 9: Decision Tree Algorithms\nCác thuật toán cây quyết định phổ biến nhất bao gồm:\n  Chi-squared Automatic Interaction Detection (CHAID)\n  Classification và Regression Tree – CART\n  Conditional Decision Trees\n  C4.5 và C5.0\n  Decision Stump\n  Iterative Dichotomiser 3 (ID3)\n  M5\n  e.\tThuật toán Bayes (Bayesian Algorithms) Đây là nhóm các thuật toán áp dụng Định lý Bayes cho bài toán phân loại và hồi quy.\nHình 10: Bayesian Algorithms\nCác thuật toán phổ biến nhất là:\n  Averaged One-Dependence Estimators (AODE)\n  Bayesian Belief Network (BBN)\n  Bayesian Network (BN)\n  Gaussian Naive Bayes\n  Multinomial Naive Bayes\n  Naive Bayes\n  f.\tThuật toán phân cụm (Clustering Algorithms) Tất cả các phương pháp đều sử dụng các cấu trúc vốn có trong dữ liệu để tổ chức tốt nhất dữ liệu thành các nhóm có mức độ phổ biến tối đa dựa vào trọng tâm (centroid) và thứ bậc (hierarchal) như thể hiện ở Hình 11.\nHình 11: Clustering Algorithms\nCác thuật toán phân cụm phổ biến nhất là:\n  Expectation Maximisation (EM – cực đại hoá kỳ vọng)\n  Hierarchical Clustering\n  k-Means\n  k-Medians\n  g.\tCác thuật toán luật kết hợp (Association Rule Learning Algorithms) Đây là những thuật toán sẽ rút trích ra các quy tắc giải thích tốt nhất mối quan hệ giữa các biến trong dữ liệu. Các quy tắc này có thể giúp khám phá ra các tính chất quan trọng và hữu ích trong các tập dữ liệu lớn và cao chiều trong thương mại cùng các lĩnh vực khác. Hình 12 minh hoạ cho ý tưởng của thuật toán luật kết hợp.\nHình 12: Association Rule Learning Algorithms\nCác thuật toán luật kết hợp phổ biến nhất là:\n  Apriori algorithm\n  Eclat algorithm\n  FP-Growth algorithm\n  h.\tThuật toán mạng nơron nhân tạo (Artificial Neural Network Algorithms) Mạng nơron nhân tạo là các mô hình được lấy cảm hứng từ cấu trúc và chức năng của mạng lưới thần kinh sinh học. Hình 13 minh hoạ cho một mạng truyền thẳng. Nhóm thuật toán này có thể được sử dụng cho bài toán phân lớp và hồi quy với rất nhiều biến thể khác nhau cho hầu hết các vấn đề. Tuy nhiên, trong bài viết này mình chỉ trình bày các thuật toán cổ điển và phổ biến nhất:\n  Back-Propagation (mạng lan truyền ngược)\n  Perceptron (Mạng lan truyền thẳng)\n  Multi-layer perceptron (Mạng truyền thẳng đa lớp)\n  Hopfield Network\n  Radial Basis Function Network (RBFN)\n  Hình 13: Artificial Neural Network Algorithms\ni.\tThuật toán học sâu (Deep Learning Algorithms) Thực chất Deep Learning là một bản cập nhật hiện đại cho Artificial Neural Networks nhằm khai thác khả năng tính toán của máy tính, tuy nhiên vì sự phát triển lớn mạnh của chúng nên mình tách ra thành một nhóm riêng.\nDeep Learning quan tâm đến việc xây dựng các mạng thần kinh lớn hơn, phức tạp hơn nhiều, và làm sao để khai thác hiệu quả các bộ dữ liệu lớn chứa rất ít dữ liệu đã được gán nhãn. Hình 14 minh hoạ cho ý tưởng của Deep learning.\nHình 14: Deep Learning Algorithms\nCác thuật toán học sâu phổ biến nhất là:\n  Convolutional Neural Network (CNN)\n  Deep Belief Networks (DBN)\n  Deep Boltzmann Machine (DBM)\n  Stacked Auto-Encoders\n  j.\tNhóm thuật toán Giảm chiều dữ liệu (Dimensionality Reduction Algorithms) Giống như các phương pháp phân cụm, giảm không gian tìm kiếm và khai thác cấu trúc vốn có trong dữ liệu nhưng theo cách không giám sát hoặc để tóm tắt hay mô tả dữ liệu sử dụng ít thông tin hơn là mục tiêu của nhóm phương pháp này. Hình 15 minh hoạ cho việc giảm chiều dữ liệu.\nĐiều này có thể hữu ích để trực quan hóa dữ liệu hoặc đơn giản hóa dữ liệu mà sau đó có thể được sử dụng trong phương pháp học có giám sát. Nhiều trong số các phương pháp này có thể được điều chỉnh để sử dụng trong phân lớp và hồi quy.\nHình 15: Dimensional Reduction Algorithms\nCác thuật toán Giảm chiều dữ liệu phổ biến như:\n  Flexible Discriminant Analysis (FDA)\n  Linear Discriminant Analysis (LDA)\n  Mixture Discriminant Analysis (MDA)\n  Multidimensional Scaling (MDS)\n  Partial Least Squares Regression (PLSR)\n  Principal Component Analysis (PCA)\n  Principal Component Regression (PCR)\n  Projection Pursuit\n  Quadratic Discriminant Analysis (QDA)\n  Sammon Mapping\n  k.\tThuật toán tập hợp (Ensemble Algorithms) Ensemble methods là những phương pháp kết hợp các mô hình yếu hơn được huấn luyện độc lập và phần dự đoán của chúng sẽ được kết hợp theo một cách nào đó để đưa ra dự đoán tổng thể như minh họa ở Hình 16.\nNhóm thuật toán này khá mạnh và được nghiên cứu nhiều, đặc biệt là về cách để kết hợp các mô hình với nhau.\nHình 16: Ensemble Algorithms\nMột số thuật toán phổ biến như:\n  AdaBoost\n  Boosting\n  Bootstrapped Aggregation (Bagging)\n  Gradient Boosting Machines (GBM)\n  Gradient Boosted Regression Trees (GBRT)\n  Random Forest\n  Stacked Generalization (blending)\n  l.\tCác thuật toán khác Còn rất nhiều các thuật toán khác không được liệt kê ở đây, chẳng hạn như Support Vector Machines (SVM), mình đang phân vân rằng liệu thuật toán này nên được đưa vào nhóm nào đó hay đứng một mình. Nếu dựa vào danh sách các biến thể và mức độ phát triển thì SVM có thể được tách thành một nhóm riêng – nhóm thuật toán sử dụng véctơ hỗ trợ.\nThêm vào đó, các thuật toán được hình thành từ các nhiệm vụ đặc biệt, hoăc các thuật toán từ những nhánh con đặc biệt của ML cũng không được liệt kê vào các nhóm, chẳng hạn như:\n  Feature selection algorithms\n  Algorithm accuracy evaluation\n  Performance measures\n  Có dịp mình sẽ bổ sung hoặc đề cập đến những thuật toán này ở một bài viết khác.\nMặc dù rất hữu ích (dựa vào nhóm, người dùng sẽ dễ dàng nhớ được bản chất của thuật toán) nhưng phương pháp phân nhóm này chưa hoàn hảo ở điểm có những thuật toán có thể phù hợp với nhiều danh mục như Learning Vector Quantization, vừa là phương pháp lấy cảm hứng từ mạng thần kinh (neural network), vừa là phương pháp dựa trên cá thể (instance-based). Hoặc là thuật toán có cùng tên mô tả bài toán và nhóm thuật toán như Hồi quy (Regression) và Phân cụm (Clustering). Đối với những trường hợp này ta có thể giải quyết bằng cách liệt kê các thuật toán hai lần hoặc bằng cách chọn nhóm một cách chủ quan. Để tránh trùng lặp các thuật toán và giữ cho mọi thứ đơn giản thì có lẽ chọn nhóm theo cách chủ quan sẽ phù hợp hơn.\nĐể giúp các bạn dễ nhớ cũng như tổng kết cho phần này mình đã vẽ một sơ đồ các thuật toán phân theo nhóm và sắp xếp theo alphabet, các bạn có thể xem thểm ở Hình 17 bên dưới.\nHình 17: Sơ đồ phân nhóm thuật toán theo sự tương đồng\nHy vọng bài viết này sẽ mang lại hữu ích cho bạn đọc, nhất là giúp bạn có dược cái nhìn tổng quan về những gì hiện có và một số ý tưởng về cách liên kết các thuật toán với nhau.\nDanh sách các nhóm và thuật toán được liệt kê trong bài viết chỉ đảm bảo được yếu tố phổ biến tuy nhiên sẽ không đầy đủ. Vậy nên nếu bạn biết thêm thuật toán hoặc nhóm nào chưa được liệt kê ở đây hoặc kể cả cách phân nhóm thuật toán khác, cũng như sau khi đọc mà các bạn có bất kỳ góp ý, câu hỏi giúp cải thiện bài viết tốt hơn, các bạn có thể để lại bình luận nhằm chia sẻ cùng mình và những bạn đọc khác nhé.\nTài liệu tham khảo: A Tour of Machine Learning Algorithms by Jason Brownlee in Understand Machine Learning Algorithms\nSemi-Supervised Learning Tutorial by Xiaojin Zhu\nhttps://en.wikipedia.org/wiki/Outline_of_machine_learning#Machine_learning_algorithms\nTop 10 algorithms in data mining by Xindong Wu · Vipin Kumar · J. Ross Quinlan · Joydeep Ghosh · Qiang Yang · Hiroshi Motoda · Geoffrey J. McLachlan · Angus Ng · Bing Liu · Philip S. Yu · Zhi-Hua Zhou · Michael Steinbach · David J. Hand · Dan Steinberg.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.\n","date":"Apr 19, 2019","img":"","permalink":"/blog/2019-04-19-deep-learning-view/","series":null,"tags":["machine learning","deep learning","học có giám sát","học không giám sát","học tăng cường"],"title":"Phân Nhóm Các Thuật Toán Học Máy"},{"categories":null,"content":"Lời mở đầu Ở trong bài viết này, chúng ta sẽ sử dụng tập dữ liệu là tập dữ liệu ở ở link https://www.kaggle.com/alxmamaev/flowers-recognition. Tập dữ liệu này bao gồm 4242 hình cảnh của 5 loại hoa hồng (rose), hoa mặt trời (sunflower), hoa bồ công anh (dandelion), hoa cúc (daisy) và hoa tulip. Nhóm tác giả đã thu thập dữ liệu dựa trên các trang web flicr, google images, yandex. Tập hình ảnh được chia thành 5 lớp, mỗi lớp có khoảng 800 hình, có kích thước xấp xỉ 320x320 pixel. Các hình ảnh có kích thước không đồng nhất với nhau.\nThực hiện Dữ liệu sau khi giản nén có dạng\n1data_dir/classname1/*.* 2data_dir/classname2/*.* 3... Cấu trúc lưu trũ như này đúng với mô hình của mình nên chúng ta cần nên chúng ta không thay đổi gì về câu trúc nữa, tiến hành viết code\nĐầu tiên, chúng ta sẽ load dataset lên và tranform nó để đưa vào huấn luyện.\n1import sys 2import os 3from collections import defaultdict 4import numpy as np 5import scipy.misc 678def preprocess_input(x0): 9x = x0 / 255. 10x -= 0.5 11x *= 2. 12return x 131415def reverse_preprocess_input(x0): 16x = x0 / 2.0 17x += 0.5 18x *= 255. 19return x 202122def dataset(base_dir, n): 23print(\u0026#34;base dir: \u0026#34;+base_dir) 24print(\u0026#34;n: \u0026#34;+str(n)) 25n = int(n) 26d = defaultdict(list) 27for root, subdirs, files in os.walk(base_dir): 28for filename in files: 29file_path = os.path.join(root, filename) 30assert file_path.startswith(base_dir) 3132suffix = file_path[len(base_dir):] 3334suffix = suffix.lstrip(\u0026#34;/\u0026#34;) 35suffix = suffix.lstrip(\u0026#34;\\\\\u0026#34;) 36if(suffix.find(\u0026#39;/\u0026#39;)\u0026gt;-1): #linux 37label = suffix.split(\u0026#34;/\u0026#34;)[0] 38else: #window 39label = suffix.split(\u0026#34;\\\\\u0026#34;)[0] 40d[label].append(file_path) 41print(\u0026#34;walk directory complete\u0026#34;) 42tags = sorted(d.keys()) 4344processed_image_count = 0 45useful_image_count = 0 4647X = [] 48y = [] 4950for class_index, class_name in enumerate(tags): 51filenames = d[class_name] 52for filename in filenames: 53processed_image_count += 1 54if processed_image_count%100 ==0: 55print(class_name+\u0026#34;\\tprocess: \u0026#34;+str(processed_image_count)+\u0026#34;\\t\u0026#34;+str(len(d[class_name]))) 56img = scipy.misc.imread(filename) 57height, width, chan = img.shape 58assert chan == 3 59aspect_ratio = float(max((height, width))) / min((height, width)) 60if aspect_ratio \u0026gt; 2: 61continue 62# We pick the largest center square. 63centery = height // 2 64centerx = width // 2 65radius = min((centerx, centery)) 66img = img[centery-radius:centery+radius, centerx-radius:centerx+radius] 67img = scipy.misc.imresize(img, size=(n, n), interp=\u0026#39;bilinear\u0026#39;) 68X.append(img) 69y.append(class_index) 70useful_image_count += 1 71print(\u0026#34;processed %d, used %d\u0026#34; % (processed_image_count, useful_image_count)) 7273X = np.array(X).astype(np.float32) 74#X = X.transpose((0, 3, 1, 2)) 75X = preprocess_input(X) 76y = np.array(y) 7778perm = np.random.permutation(len(y)) 79X = X[perm] 80y = y[perm] 8182print(\u0026#34;classes:\u0026#34;,end=\u0026#34; \u0026#34;) 83for class_index, class_name in enumerate(tags): 84print(class_name, sum(y==class_index),end=\u0026#34; \u0026#34;) 85print(\u0026#34;X shape: \u0026#34;,X.shape) 8687return X, y, tags Đoạn code trên khá đơn giản và dễ hiểu. Lưu ý ở đây là với những bức ảnh có tỷ lệ width và height \u0026gt; 2 thì mình sẽ loại chúng ra khỏi tập dữ liệu.\nTiếp theo, chúng ta sẽ xây dựng mô hình dựa trên mô hình Resnet50 có sẵn của kares, do sử dụng pretrain model, nên n-1 lớp trước đó sẽ không được huấn luyện và chúng ta sẽ sử dụng dụng các weight có sẵn đã được huấn luyện trên tập ImageNet rút đặc trưng cho mô hình. Chúng ta chỉ cần thêm một lớp full connected và softmax để phân lớp các loại hoa, công việc của chúng ta hiện tại là tìm ra trọng số của lớp full connected cuối cùng (thay vì huấn luyện lại hết toàn bộ mô hình).\n12# create the base pre-trained model 3def build_model(nb_classes): 4base_model = ResNet50(weights=\u0026#39;imagenet\u0026#39;, include_top=False) 56# add a global spatial average pooling layer 7x = base_model.output 8x = GlobalAveragePooling2D()(x) 9# let\u0026#39;s add a fully-connected layer 10x = Dense(1024, activation=\u0026#39;relu\u0026#39;)(x) 11# and a logistic layer 12predictions = Dense(nb_classes, activation=\u0026#39;softmax\u0026#39;)(x) 1314# this is the model we will train 15model = Model(inputs=base_model.input, outputs=predictions) 1617# first: train only the top layers (which were randomly initialized) 18# i.e. freeze all convolutional ResNet50 layers 19for layer in base_model.layers: 20layer.trainable = False 2122return model 23Visualize một chút xíu về kiến trúc inceptionV3 mình đang dùng.\n1__________________________________________________________________________________________________ 2Layer (type) Output Shape Param # Connected to 3================================================================================================== 4input_1 (InputLayer) (None, None, None, 3 0 5__________________________________________________________________________________________________ 6conv1_pad (ZeroPadding2D) (None, None, None, 3 0 input_1[0][0] 7__________________________________________________________________________________________________ 8conv1 (Conv2D) (None, None, None, 6 9472 conv1_pad[0][0] 9__________________________________________________________________________________________________ 10bn_conv1 (BatchNormalization) (None, None, None, 6 256 conv1[0][0] 11__________________________________________________________________________________________________ 12activation_1 (Activation) (None, None, None, 6 0 bn_conv1[0][0] 13__________________________________________________________________________________________________ 14pool1_pad (ZeroPadding2D) (None, None, None, 6 0 activation_1[0][0] 15__________________________________________________________________________________________________ 16max_pooling2d_1 (MaxPooling2D) (None, None, None, 6 0 pool1_pad[0][0] 17__________________________________________________________________________________________________ 18res2a_branch2a (Conv2D) (None, None, None, 6 4160 max_pooling2d_1[0][0] 19__________________________________________________________________________________________________ 20bn2a_branch2a (BatchNormalizati (None, None, None, 6 256 res2a_branch2a[0][0] 21__________________________________________________________________________________________________ 22activation_2 (Activation) (None, None, None, 6 0 bn2a_branch2a[0][0] 23__________________________________________________________________________________________________ 24res2a_branch2b (Conv2D) (None, None, None, 6 36928 activation_2[0][0] 25__________________________________________________________________________________________________ 26bn2a_branch2b (BatchNormalizati (None, None, None, 6 256 res2a_branch2b[0][0] 27__________________________________________________________________________________________________ 28activation_3 (Activation) (None, None, None, 6 0 bn2a_branch2b[0][0] 29__________________________________________________________________________________________________ 30res2a_branch2c (Conv2D) (None, None, None, 2 16640 activation_3[0][0] 31__________________________________________________________________________________________________ 32res2a_branch1 (Conv2D) (None, None, None, 2 16640 max_pooling2d_1[0][0] 33__________________________________________________________________________________________________ 34bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024 res2a_branch2c[0][0] 35__________________________________________________________________________________________________ 36bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024 res2a_branch1[0][0] 37__________________________________________________________________________________________________ 38add_1 (Add) (None, None, None, 2 0 bn2a_branch2c[0][0] 39bn2a_branch1[0][0] 40__________________________________________________________________________________________________ 41activation_4 (Activation) (None, None, None, 2 0 add_1[0][0] 42__________________________________________________________________________________________________ 43res2b_branch2a (Conv2D) (None, None, None, 6 16448 activation_4[0][0] 44__________________________________________________________________________________________________ 45bn2b_branch2a (BatchNormalizati (None, None, None, 6 256 res2b_branch2a[0][0] 46__________________________________________________________________________________________________ 47activation_5 (Activation) (None, None, None, 6 0 bn2b_branch2a[0][0] 48__________________________________________________________________________________________________ 49res2b_branch2b (Conv2D) (None, None, None, 6 36928 activation_5[0][0] 50__________________________________________________________________________________________________ 51bn2b_branch2b (BatchNormalizati (None, None, None, 6 256 res2b_branch2b[0][0] 52__________________________________________________________________________________________________ 53activation_6 (Activation) (None, None, None, 6 0 bn2b_branch2b[0][0] 54__________________________________________________________________________________________________ 55res2b_branch2c (Conv2D) (None, None, None, 2 16640 activation_6[0][0] 56__________________________________________________________________________________________________ 57bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024 res2b_branch2c[0][0] 58__________________________________________________________________________________________________ 59add_2 (Add) (None, None, None, 2 0 bn2b_branch2c[0][0] 60activation_4[0][0] 61__________________________________________________________________________________________________ 62activation_7 (Activation) (None, None, None, 2 0 add_2[0][0] 63__________________________________________________________________________________________________ 64res2c_branch2a (Conv2D) (None, None, None, 6 16448 activation_7[0][0] 65__________________________________________________________________________________________________ 66bn2c_branch2a (BatchNormalizati (None, None, None, 6 256 res2c_branch2a[0][0] 67__________________________________________________________________________________________________ 68activation_8 (Activation) (None, None, None, 6 0 bn2c_branch2a[0][0] 69__________________________________________________________________________________________________ 70res2c_branch2b (Conv2D) (None, None, None, 6 36928 activation_8[0][0] 71__________________________________________________________________________________________________ 72bn2c_branch2b (BatchNormalizati (None, None, None, 6 256 res2c_branch2b[0][0] 73__________________________________________________________________________________________________ 74activation_9 (Activation) (None, None, None, 6 0 bn2c_branch2b[0][0] 75__________________________________________________________________________________________________ 76res2c_branch2c (Conv2D) (None, None, None, 2 16640 activation_9[0][0] 77__________________________________________________________________________________________________ 78bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024 res2c_branch2c[0][0] 79__________________________________________________________________________________________________ 80add_3 (Add) (None, None, None, 2 0 bn2c_branch2c[0][0] 81activation_7[0][0] 82__________________________________________________________________________________________________ 83activation_10 (Activation) (None, None, None, 2 0 add_3[0][0] 84__________________________________________________________________________________________________ 85res3a_branch2a (Conv2D) (None, None, None, 1 32896 activation_10[0][0] 86__________________________________________________________________________________________________ 87bn3a_branch2a (BatchNormalizati (None, None, None, 1 512 res3a_branch2a[0][0] 88__________________________________________________________________________________________________ 89activation_11 (Activation) (None, None, None, 1 0 bn3a_branch2a[0][0] 90__________________________________________________________________________________________________ 91res3a_branch2b (Conv2D) (None, None, None, 1 147584 activation_11[0][0] 92__________________________________________________________________________________________________ 93bn3a_branch2b (BatchNormalizati (None, None, None, 1 512 res3a_branch2b[0][0] 94__________________________________________________________________________________________________ 95activation_12 (Activation) (None, None, None, 1 0 bn3a_branch2b[0][0] 96__________________________________________________________________________________________________ 97res3a_branch2c (Conv2D) (None, None, None, 5 66048 activation_12[0][0] 98__________________________________________________________________________________________________ 99res3a_branch1 (Conv2D) (None, None, None, 5 131584 activation_10[0][0] 100__________________________________________________________________________________________________ 101bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048 res3a_branch2c[0][0] 102__________________________________________________________________________________________________ 103bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048 res3a_branch1[0][0] 104__________________________________________________________________________________________________ 105add_4 (Add) (None, None, None, 5 0 bn3a_branch2c[0][0] 106bn3a_branch1[0][0] 107__________________________________________________________________________________________________ 108activation_13 (Activation) (None, None, None, 5 0 add_4[0][0] 109__________________________________________________________________________________________________ 110res3b_branch2a (Conv2D) (None, None, None, 1 65664 activation_13[0][0] 111__________________________________________________________________________________________________ 112bn3b_branch2a (BatchNormalizati (None, None, None, 1 512 res3b_branch2a[0][0] 113__________________________________________________________________________________________________ 114activation_14 (Activation) (None, None, None, 1 0 bn3b_branch2a[0][0] 115__________________________________________________________________________________________________ 116res3b_branch2b (Conv2D) (None, None, None, 1 147584 activation_14[0][0] 117__________________________________________________________________________________________________ 118bn3b_branch2b (BatchNormalizati (None, None, None, 1 512 res3b_branch2b[0][0] 119__________________________________________________________________________________________________ 120activation_15 (Activation) (None, None, None, 1 0 bn3b_branch2b[0][0] 121__________________________________________________________________________________________________ 122res3b_branch2c (Conv2D) (None, None, None, 5 66048 activation_15[0][0] 123__________________________________________________________________________________________________ 124bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048 res3b_branch2c[0][0] 125__________________________________________________________________________________________________ 126add_5 (Add) (None, None, None, 5 0 bn3b_branch2c[0][0] 127activation_13[0][0] 128__________________________________________________________________________________________________ 129activation_16 (Activation) (None, None, None, 5 0 add_5[0][0] 130__________________________________________________________________________________________________ 131res3c_branch2a (Conv2D) (None, None, None, 1 65664 activation_16[0][0] 132__________________________________________________________________________________________________ 133bn3c_branch2a (BatchNormalizati (None, None, None, 1 512 res3c_branch2a[0][0] 134__________________________________________________________________________________________________ 135activation_17 (Activation) (None, None, None, 1 0 bn3c_branch2a[0][0] 136__________________________________________________________________________________________________ 137res3c_branch2b (Conv2D) (None, None, None, 1 147584 activation_17[0][0] 138__________________________________________________________________________________________________ 139bn3c_branch2b (BatchNormalizati (None, None, None, 1 512 res3c_branch2b[0][0] 140__________________________________________________________________________________________________ 141activation_18 (Activation) (None, None, None, 1 0 bn3c_branch2b[0][0] 142__________________________________________________________________________________________________ 143res3c_branch2c (Conv2D) (None, None, None, 5 66048 activation_18[0][0] 144__________________________________________________________________________________________________ 145bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048 res3c_branch2c[0][0] 146__________________________________________________________________________________________________ 147add_6 (Add) (None, None, None, 5 0 bn3c_branch2c[0][0] 148activation_16[0][0] 149__________________________________________________________________________________________________ 150activation_19 (Activation) (None, None, None, 5 0 add_6[0][0] 151__________________________________________________________________________________________________ 152res3d_branch2a (Conv2D) (None, None, None, 1 65664 activation_19[0][0] 153__________________________________________________________________________________________________ 154bn3d_branch2a (BatchNormalizati (None, None, None, 1 512 res3d_branch2a[0][0] 155__________________________________________________________________________________________________ 156activation_20 (Activation) (None, None, None, 1 0 bn3d_branch2a[0][0] 157__________________________________________________________________________________________________ 158res3d_branch2b (Conv2D) (None, None, None, 1 147584 activation_20[0][0] 159__________________________________________________________________________________________________ 160bn3d_branch2b (BatchNormalizati (None, None, None, 1 512 res3d_branch2b[0][0] 161__________________________________________________________________________________________________ 162activation_21 (Activation) (None, None, None, 1 0 bn3d_branch2b[0][0] 163__________________________________________________________________________________________________ 164res3d_branch2c (Conv2D) (None, None, None, 5 66048 activation_21[0][0] 165__________________________________________________________________________________________________ 166bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048 res3d_branch2c[0][0] 167__________________________________________________________________________________________________ 168add_7 (Add) (None, None, None, 5 0 bn3d_branch2c[0][0] 169activation_19[0][0] 170__________________________________________________________________________________________________ 171activation_22 (Activation) (None, None, None, 5 0 add_7[0][0] 172__________________________________________________________________________________________________ 173res4a_branch2a (Conv2D) (None, None, None, 2 131328 activation_22[0][0] 174__________________________________________________________________________________________________ 175bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024 res4a_branch2a[0][0] 176__________________________________________________________________________________________________ 177activation_23 (Activation) (None, None, None, 2 0 bn4a_branch2a[0][0] 178__________________________________________________________________________________________________ 179res4a_branch2b (Conv2D) (None, None, None, 2 590080 activation_23[0][0] 180__________________________________________________________________________________________________ 181bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024 res4a_branch2b[0][0] 182__________________________________________________________________________________________________ 183activation_24 (Activation) (None, None, None, 2 0 bn4a_branch2b[0][0] 184__________________________________________________________________________________________________ 185res4a_branch2c (Conv2D) (None, None, None, 1 263168 activation_24[0][0] 186__________________________________________________________________________________________________ 187res4a_branch1 (Conv2D) (None, None, None, 1 525312 activation_22[0][0] 188__________________________________________________________________________________________________ 189bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096 res4a_branch2c[0][0] 190__________________________________________________________________________________________________ 191bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096 res4a_branch1[0][0] 192__________________________________________________________________________________________________ 193add_8 (Add) (None, None, None, 1 0 bn4a_branch2c[0][0] 194bn4a_branch1[0][0] 195__________________________________________________________________________________________________ 196activation_25 (Activation) (None, None, None, 1 0 add_8[0][0] 197__________________________________________________________________________________________________ 198res4b_branch2a (Conv2D) (None, None, None, 2 262400 activation_25[0][0] 199__________________________________________________________________________________________________ 200bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024 res4b_branch2a[0][0] 201__________________________________________________________________________________________________ 202activation_26 (Activation) (None, None, None, 2 0 bn4b_branch2a[0][0] 203__________________________________________________________________________________________________ 204res4b_branch2b (Conv2D) (None, None, None, 2 590080 activation_26[0][0] 205__________________________________________________________________________________________________ 206bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024 res4b_branch2b[0][0] 207__________________________________________________________________________________________________ 208activation_27 (Activation) (None, None, None, 2 0 bn4b_branch2b[0][0] 209__________________________________________________________________________________________________ 210res4b_branch2c (Conv2D) (None, None, None, 1 263168 activation_27[0][0] 211__________________________________________________________________________________________________ 212bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096 res4b_branch2c[0][0] 213__________________________________________________________________________________________________ 214add_9 (Add) (None, None, None, 1 0 bn4b_branch2c[0][0] 215activation_25[0][0] 216__________________________________________________________________________________________________ 217activation_28 (Activation) (None, None, None, 1 0 add_9[0][0] 218__________________________________________________________________________________________________ 219res4c_branch2a (Conv2D) (None, None, None, 2 262400 activation_28[0][0] 220__________________________________________________________________________________________________ 221bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024 res4c_branch2a[0][0] 222__________________________________________________________________________________________________ 223activation_29 (Activation) (None, None, None, 2 0 bn4c_branch2a[0][0] 224__________________________________________________________________________________________________ 225res4c_branch2b (Conv2D) (None, None, None, 2 590080 activation_29[0][0] 226__________________________________________________________________________________________________ 227bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024 res4c_branch2b[0][0] 228__________________________________________________________________________________________________ 229activation_30 (Activation) (None, None, None, 2 0 bn4c_branch2b[0][0] 230__________________________________________________________________________________________________ 231res4c_branch2c (Conv2D) (None, None, None, 1 263168 activation_30[0][0] 232__________________________________________________________________________________________________ 233bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096 res4c_branch2c[0][0] 234__________________________________________________________________________________________________ 235add_10 (Add) (None, None, None, 1 0 bn4c_branch2c[0][0] 236activation_28[0][0] 237__________________________________________________________________________________________________ 238activation_31 (Activation) (None, None, None, 1 0 add_10[0][0] 239__________________________________________________________________________________________________ 240res4d_branch2a (Conv2D) (None, None, None, 2 262400 activation_31[0][0] 241__________________________________________________________________________________________________ 242bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024 res4d_branch2a[0][0] 243__________________________________________________________________________________________________ 244activation_32 (Activation) (None, None, None, 2 0 bn4d_branch2a[0][0] 245__________________________________________________________________________________________________ 246res4d_branch2b (Conv2D) (None, None, None, 2 590080 activation_32[0][0] 247__________________________________________________________________________________________________ 248bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024 res4d_branch2b[0][0] 249__________________________________________________________________________________________________ 250activation_33 (Activation) (None, None, None, 2 0 bn4d_branch2b[0][0] 251__________________________________________________________________________________________________ 252res4d_branch2c (Conv2D) (None, None, None, 1 263168 activation_33[0][0] 253__________________________________________________________________________________________________ 254bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096 res4d_branch2c[0][0] 255__________________________________________________________________________________________________ 256add_11 (Add) (None, None, None, 1 0 bn4d_branch2c[0][0] 257activation_31[0][0] 258__________________________________________________________________________________________________ 259activation_34 (Activation) (None, None, None, 1 0 add_11[0][0] 260__________________________________________________________________________________________________ 261res4e_branch2a (Conv2D) (None, None, None, 2 262400 activation_34[0][0] 262__________________________________________________________________________________________________ 263bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024 res4e_branch2a[0][0] 264__________________________________________________________________________________________________ 265activation_35 (Activation) (None, None, None, 2 0 bn4e_branch2a[0][0] 266__________________________________________________________________________________________________ 267res4e_branch2b (Conv2D) (None, None, None, 2 590080 activation_35[0][0] 268__________________________________________________________________________________________________ 269bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024 res4e_branch2b[0][0] 270__________________________________________________________________________________________________ 271activation_36 (Activation) (None, None, None, 2 0 bn4e_branch2b[0][0] 272__________________________________________________________________________________________________ 273res4e_branch2c (Conv2D) (None, None, None, 1 263168 activation_36[0][0] 274__________________________________________________________________________________________________ 275bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096 res4e_branch2c[0][0] 276__________________________________________________________________________________________________ 277add_12 (Add) (None, None, None, 1 0 bn4e_branch2c[0][0] 278activation_34[0][0] 279__________________________________________________________________________________________________ 280activation_37 (Activation) (None, None, None, 1 0 add_12[0][0] 281__________________________________________________________________________________________________ 282res4f_branch2a (Conv2D) (None, None, None, 2 262400 activation_37[0][0] 283__________________________________________________________________________________________________ 284bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024 res4f_branch2a[0][0] 285__________________________________________________________________________________________________ 286activation_38 (Activation) (None, None, None, 2 0 bn4f_branch2a[0][0] 287__________________________________________________________________________________________________ 288res4f_branch2b (Conv2D) (None, None, None, 2 590080 activation_38[0][0] 289__________________________________________________________________________________________________ 290bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024 res4f_branch2b[0][0] 291__________________________________________________________________________________________________ 292activation_39 (Activation) (None, None, None, 2 0 bn4f_branch2b[0][0] 293__________________________________________________________________________________________________ 294res4f_branch2c (Conv2D) (None, None, None, 1 263168 activation_39[0][0] 295__________________________________________________________________________________________________ 296bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096 res4f_branch2c[0][0] 297__________________________________________________________________________________________________ 298add_13 (Add) (None, None, None, 1 0 bn4f_branch2c[0][0] 299activation_37[0][0] 300__________________________________________________________________________________________________ 301activation_40 (Activation) (None, None, None, 1 0 add_13[0][0] 302__________________________________________________________________________________________________ 303res5a_branch2a (Conv2D) (None, None, None, 5 524800 activation_40[0][0] 304__________________________________________________________________________________________________ 305bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048 res5a_branch2a[0][0] 306__________________________________________________________________________________________________ 307activation_41 (Activation) (None, None, None, 5 0 bn5a_branch2a[0][0] 308__________________________________________________________________________________________________ 309res5a_branch2b (Conv2D) (None, None, None, 5 2359808 activation_41[0][0] 310__________________________________________________________________________________________________ 311bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048 res5a_branch2b[0][0] 312__________________________________________________________________________________________________ 313activation_42 (Activation) (None, None, None, 5 0 bn5a_branch2b[0][0] 314__________________________________________________________________________________________________ 315res5a_branch2c (Conv2D) (None, None, None, 2 1050624 activation_42[0][0] 316__________________________________________________________________________________________________ 317res5a_branch1 (Conv2D) (None, None, None, 2 2099200 activation_40[0][0] 318__________________________________________________________________________________________________ 319bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192 res5a_branch2c[0][0] 320__________________________________________________________________________________________________ 321bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192 res5a_branch1[0][0] 322__________________________________________________________________________________________________ 323add_14 (Add) (None, None, None, 2 0 bn5a_branch2c[0][0] 324bn5a_branch1[0][0] 325__________________________________________________________________________________________________ 326activation_43 (Activation) (None, None, None, 2 0 add_14[0][0] 327__________________________________________________________________________________________________ 328res5b_branch2a (Conv2D) (None, None, None, 5 1049088 activation_43[0][0] 329__________________________________________________________________________________________________ 330bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048 res5b_branch2a[0][0] 331__________________________________________________________________________________________________ 332activation_44 (Activation) (None, None, None, 5 0 bn5b_branch2a[0][0] 333__________________________________________________________________________________________________ 334res5b_branch2b (Conv2D) (None, None, None, 5 2359808 activation_44[0][0] 335__________________________________________________________________________________________________ 336bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048 res5b_branch2b[0][0] 337__________________________________________________________________________________________________ 338activation_45 (Activation) (None, None, None, 5 0 bn5b_branch2b[0][0] 339__________________________________________________________________________________________________ 340res5b_branch2c (Conv2D) (None, None, None, 2 1050624 activation_45[0][0] 341__________________________________________________________________________________________________ 342bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192 res5b_branch2c[0][0] 343__________________________________________________________________________________________________ 344add_15 (Add) (None, None, None, 2 0 bn5b_branch2c[0][0] 345activation_43[0][0] 346__________________________________________________________________________________________________ 347activation_46 (Activation) (None, None, None, 2 0 add_15[0][0] 348__________________________________________________________________________________________________ 349res5c_branch2a (Conv2D) (None, None, None, 5 1049088 activation_46[0][0] 350__________________________________________________________________________________________________ 351bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048 res5c_branch2a[0][0] 352__________________________________________________________________________________________________ 353activation_47 (Activation) (None, None, None, 5 0 bn5c_branch2a[0][0] 354__________________________________________________________________________________________________ 355res5c_branch2b (Conv2D) (None, None, None, 5 2359808 activation_47[0][0] 356__________________________________________________________________________________________________ 357bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048 res5c_branch2b[0][0] 358__________________________________________________________________________________________________ 359activation_48 (Activation) (None, None, None, 5 0 bn5c_branch2b[0][0] 360__________________________________________________________________________________________________ 361res5c_branch2c (Conv2D) (None, None, None, 2 1050624 activation_48[0][0] 362__________________________________________________________________________________________________ 363bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192 res5c_branch2c[0][0] 364__________________________________________________________________________________________________ 365add_16 (Add) (None, None, None, 2 0 bn5c_branch2c[0][0] 366activation_46[0][0] 367__________________________________________________________________________________________________ 368activation_49 (Activation) (None, None, None, 2 0 add_16[0][0] 369__________________________________________________________________________________________________ 370global_average_pooling2d_1 (Glo (None, 2048) 0 activation_49[0][0] 371__________________________________________________________________________________________________ 372dense_1 (Dense) (None, 1024) 2098176 global_average_pooling2d_1[0][0] 373__________________________________________________________________________________________________ 374dense_2 (Dense) (None, 5) 5125 dense_1[0][0] 375================================================================================================== 376Total params: 25,691,013 377Trainable params: 2,103,301 378Non-trainable params: 23,587,712 379__________________________________________________________________________________________________ Phần train lại sẽ có khoảng hơn 2 triệu tham số, phần layer ở trước đó không train là khoảng 23 triệu tham số.\nChia tập dữ liệu ra thành 5 phần, 4 phần làm tập train, 1 phần làm tập validation.\n1X, y, tags = dataset.dataset(data_directory, n) 2nb_classes = len(tags) 345sample_count = len(y) 6train_size = sample_count * 4 // 5 7X_train = X[:train_size] 8y_train = y[:train_size] 9Y_train = np_utils.to_categorical(y_train, nb_classes) 10X_test = X[train_size:] 11y_test = y[train_size:] 12Y_test = np_utils.to_categorical(y_test, nb_classes) chúng ta tiến hành thực hiện ImageDataGenerator để có được nhiều dữ liệu mẫu hơn và chống overfit, trong keras đã có sẵn hàm\n1datagen = ImageDataGenerator( 2featurewise_center=False, 3samplewise_center=False, 4featurewise_std_normalization=False, 5samplewise_std_normalization=False, 6zca_whitening=False, 7rotation_range=45, 8width_shift_range=0.25, 9height_shift_range=0.25, 10horizontal_flip=True, 11vertical_flip=False, 12channel_shift_range=0.5, 13zoom_range=[0.5, 1.5], 14brightness_range=[0.5, 1.5], 15fill_mode=\u0026#39;reflect\u0026#39;) 1617datagen.fit(X_train) Cuối cùng, chúng ta sẽ xây dựng mô hình và tiến hành huấn luyện, lưu mô hình. Quá trình này tốn hơi nhiều thời gian.\n12model = net.build_model(nb_classes) 3model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;, metrics=[\u0026#34;accuracy\u0026#34;]) 45# train the model on the new data for a few epochs 67print(\u0026#34;training the newly added dense layers\u0026#34;) 89samples_per_epoch = X_train.shape[0]//batch_size*batch_size 10steps_per_epoch = samples_per_epoch//batch_size 11validation_steps = X_test.shape[0]//batch_size*batch_size 1213model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True), 14samples_per_epoch=samples_per_epoch, 15epochs=nb_epoch, 16steps_per_epoch = steps_per_epoch, 17validation_data=datagen.flow(X_test, Y_test, batch_size=batch_size), 18validation_steps=validation_steps, 19) 202122net.save(model, tags, model_file_prefix) Thử download một vài hình ảnh trên mạng về rồi test thử xem sao\n![Hình ảnh] (flower-classifition_demo.jpg)\nKết quả khá tốt phải không các bạn.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Apr 15, 2019","img":"","permalink":"/blog/2019-04-15-phan-loai-hoa/","series":null,"tags":["Machine learning","Deeplearning","hoa hồng","hoa mặt trời","hoa bồ công anh","hoa cúc","hoa tulip"],"title":"Phân Loại Hoa Sử Dụng Pretrain Model"},{"categories":null,"content":"Nghiên cứu dữ liệu Trong thực tế, Walmart đã chạy các chương trình khuyến mãi trong các ngày lễ lớn trong năm. Có 4 ngày lễ lớn đó là Siêu cúp bóng bầu dục Mỹ (Super Bowl - tổ chức vào chủ nhật đầu tiên của tháng Hai. Đây là một sự kiện thể thao lớn và ngày tổ chức Super Bowl được người Mỹ coi là ngày lễ quốc gia của Hoa Kỳ (theo wiki https://vi.wikipedia.org/wiki/Super_Bowl)), ngày lễ lao động (Labor Day - ngày một tháng 5), lễ tạ ơn (Thanksgiving, ngày lễ tạ ơn ở Mỹ được tổ chức vào ngày thứ Năm lần thứ tư của tháng 11, còn ở Canada ngày lễ tạ ơn được tổ chức vào ngày thứ hai lần thứ hai của tháng 10, theo wiki https://en.wikipedia.org/wiki/Thanksgiving), lễ giáng sinh (Christmas ngày 24 và 25 tháng 12 theo wiki https://en.wikipedia.org/wiki/Christmas ). Những tuần có chứa những ngày lễ lớn này được đánh trọng số gấp 5 lần những tuần khác. Chúng ta phải xây dựng mô hình để mô hình hoá các tác động của việc giảm giá trong các tuần lễ này khi không có dữ liệu lịch sử đầy đủ.\nTập dữ liệu được cung cấp bao gồm:\nTập train: chứa dữ liệu số bán từ 05-02-2010 đến 01-11-2012. Các trường dữ liệu là: store number - mã cửa hàng, Dept number - mã sản phẩm, Date - Tuần, Weekly_Sales - số bán, IsHoliday - Nếu tuần đó có chứa các holidate thì đánh 1 ngược lại đánh 0.\nTập test: Chứa dữ liệu test, có các cột thuộc tính như tập train\nTập features: Chứa thông tin thêm về của hàng, bao gồm store - mã cửa hàng, Date - ngày, Temperature - Nhiệt độ, Fuel_Price - giá dầu (ở mỹ, mỗi khu vực khác nhau sẽ có giá nhiên liệu khác nhau), MarkDown1, MarkDown2,\u0026hellip; , MarkDown5 - một chỉ số gì đó mà tác giả không cung cấp định nghĩa cho chúng ta, CPI - chỉ số giá tiêu dùng, Unemployment - tình trạng thất nghiệp, IsHoliday - Tuần có chứa ngày nghỉ.\nPhân tích dữ liệu Mình sẽ import một số thư viện cần thiết\n1import pandas as pd 2import numpy as np 34#Do some statistics 5from scipy.misc import imread 6from scipy import sparse 7import scipy.stats as ss 8import math 910#Nice graphing tools 11import matplotlib 12import matplotlib.pyplot as plt 13import seaborn as sns Đọc các file data lên, merge các file lại với nhau\n123train = pd.read_csv(\u0026#39;data/train.csv\u0026#39;) 4test = pd.read_csv(\u0026#39;data/test.csv\u0026#39;) 5feature = pd.read_csv(\u0026#39;data/features.csv\u0026#39;) 67train = train.merge(feature, how=\u0026#39;left\u0026#39;, on=[\u0026#39;Store\u0026#39;,\u0026#39;Date\u0026#39;]) 8test = test.merge(feature, how=\u0026#39;left\u0026#39;, on=[\u0026#39;Store\u0026#39;,\u0026#39;Date\u0026#39;]) 91011# Merge in store info 12stores = pd.read_csv(\u0026#34;data/stores.csv\u0026#34;) 13train = train.merge(stores, how=\u0026#39;left\u0026#39;, on=\u0026#39;Store\u0026#39;) 14test = test.merge(stores, how=\u0026#39;left\u0026#39;, on=\u0026#39;Store\u0026#39;) 15print(train.head()) Kết quả\n1Store Dept Date Weekly_Sales IsHoliday_x Temperature Fuel_Price MarkDown1 MarkDown2 MarkDown3 MarkDown4 MarkDown5 CPI Unemployment IsHoliday_y Type Size Split 20 1 1 2010-02-05 24924.50 False 42.31 2.572 NaN NaN NaN NaN NaN 211.096358 8.106 False A 151315 Train 31 1 1 2010-02-12 46039.49 True 38.51 2.548 NaN NaN NaN NaN NaN 211.242170 8.106 True A 151315 Train 42 1 1 2010-02-19 41595.55 False 39.93 2.514 NaN NaN NaN NaN NaN 211.289143 8.106 False A 151315 Train 53 1 1 2010-02-26 19403.54 False 46.63 2.561 NaN NaN NaN NaN NaN 211.319643 8.106 False A 151315 Train 64 1 1 2010-03-05 21827.90 False 46.50 2.625 NaN NaN NaN NaN NaN 211.350143 8.106 False A 151315 Train Mới có 5 dòng đầu tiên mà thấy các chỉ số markdown Nan rồi.\nChúng ta tiến hành một số phân tích dữ liệu. À, Mình sẽ merge dữ liệu train và test lại rồi phân tích thống kê\n1df = pd.concat([train,test],axis=0) # Join train and test 23print(df.describe()) Kết quả\n1CPI Dept Fuel_Price MarkDown1 MarkDown2 MarkDown3 MarkDown4 MarkDown5 Size Store Temperature Unemployment Weekly_Sales 2count 498472.000000 536634.000000 536634.000000 265596.000000 197685.000000 242326.000000 237143.000000 266496.000000 536634.00000 536634.000000 536634.000000 498472.000000 421570.000000 3mean 172.090481 44.277301 3.408310 7438.004144 3509.274827 1857.913525 3371.556866 4324.021158 136678.55096 22.208621 58.771762 7.791888 15981.258123 4std 39.542149 30.527358 0.430861 9411.341379 8992.047197 11616.143274 6872.281734 13549.262124 61007.71180 12.790580 18.678716 1.865076 22711.183519 5min 126.064000 1.000000 2.472000 -2781.450000 -265.760000 -179.260000 0.220000 -185.170000 34875.00000 1.000000 -7.290000 3.684000 -4988.940000 625% 132.521867 18.000000 3.041000 2114.640000 72.500000 7.220000 336.240000 1570.112500 93638.00000 11.000000 45.250000 6.623000 2079.650000 750% 182.442420 37.000000 3.523000 5126.540000 385.310000 40.760000 1239.040000 2870.910000 140167.00000 22.000000 60.060000 7.795000 7612.030000 875% 213.748126 74.000000 3.744000 9303.850000 2392.390000 174.260000 3397.080000 5012.220000 202505.00000 33.000000 73.230000 8.549000 20205.852500 9max 228.976456 99.000000 4.468000 103184.980000 104519.540000 149483.310000 67474.850000 771448.100000 219622.00000 45.000000 101.950000 14.313000 693099.360000 Phân tích một chút:\nBỏ qua cột Dept và Store vì nó là mã sản phẩm và mã của hàng, người ta thích đặt số bao nhiêu thì đặt.\nCác chỉ số MarkDown có độ lệch chuẩn khá cao.\nNhiệt độ min là -7.29, max là 101.95, trung bình là 58, nên không thể là độ C được, có thể là độ F\nXem thử hệ số tương quan giữa các column như thế nào\n1sns.set(style=\u0026#34;white\u0026#34;) 23# Compute the correlation matrix 4corr = df.corr() 56# Generate a mask for the upper triangle 7mask = np.zeros_like(corr, dtype=np.bool) 8mask[np.triu_indices_from(mask)] = True 910# Set up the matplotlib figure 11f, ax = plt.subplots(figsize=(11, 9)) 1213# Generate a custom diverging colormap 14cmap = sns.diverging_palette(220, 10, as_cmap=True) 1516# Draw the heatmap with the mask and correct aspect ratio 17sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, 18square=True, linewidths=.5, cbar_kws={\u0026#34;shrink\u0026#34;: .5}) 1920plt.show() Hệ số tương quan giữa các cột trong dữ liệu\nPhân tích một chút, chúng ta thấy rằng MarkDown5 hầu như không có liên quan gì đến các column còn lại. Hệ số trải từ -0.3 đến 0.3 chứng tỏ mổi quan hệ giữa các cột là khá lỏng lẻo. Chỉ số giá tiêu dùng tương quan tỷ lệ nghịch với tình trạng thất nghiệp (hợp lý không nhỉ). Kích thước cửa hàng càng bự thì bán càng nhiều (ok hiển nhiên), sản phẩm có mã càng lớn thì bán càng nhiều (? có lẽ là sản phẩm mới, người mỹ thích mua sản phẩm mới chăng). Và một vấn đề quan trọng là giá nhiên liệu, isHoliday, nhiệt độ không có mối tương quan với weekly sales. Chỉ số CPI và tình trạng thất nghiệp cũng ảnh hưởng không lớn với weekly sales.\nThử plot lên hình ảnh về số lượng bán và kích thước cửa hàng xem sao\n1plt.scatter( df[\u0026#39;Size\u0026#39;],df[\u0026#39;Weekly_Sales\u0026#39;]) 2plt.show() Tương quan giữa số bán và kích thước cửa hàng\nNhìn vào hình trên, chúng ta thấy rằng cửa hàng có kích thước nhỏ số bán cũng không tăng đột biến khi gặp ngày lễ, cửa hàng kích thước siêu bự có tỷ lệ đột biến thấp, cửa hàng trung trung có đột biến, ở khúc size 125000 và số bán là 700000. Chúng ta hãy xem những ngày có số bán lớn rơi vào ngày nào. Dựa vào bảng desription ở phía trên đã phân tích, trung bình của số bán là 15981 và lệch chuẩn là 22711, cộng lại là 15981 + 22711 = 38692, nhìn trên đô thị thì phần đột biến khá lớn. Max là 700000, min là 0 (cái này nhìn hình, không phải số thực tế ở bảng mô tả), mình sẽ lấy ra những ngày có số bán lớn hơn 350000 (vượt qua ngưỡng trung bình + độ lệch chuẩn rất nhều -\u0026gt; ngoại lệ là đây) xem những ngày đó là ngày gì\n12print(df.loc[df[\u0026#39;Weekly_Sales\u0026#39;] \u0026gt;350000].head(10)) In ra top 10 thằng đầu tiên\n12CPI Date Dept Fuel_Price IsHoliday_x IsHoliday_y MarkDown1 MarkDown2 MarkDown3 MarkDown4 MarkDown5 Size Split Store Temperature Type Unemployment Weekly_Sales 337201 126.669267 2010-11-26 72 2.752 True True NaN NaN NaN NaN NaN 205863 Train 4 48.08 A 7.127 381072.11 437253 129.836400 2011-11-25 72 3.225 True True 561.45 137.88 83340.33 44.04 9239.23 205863 Train 4 47.96 A 5.143 385051.04 588428 126.983581 2010-12-24 7 3.236 False False NaN NaN NaN NaN NaN 126512 Train 10 57.06 B 9.003 406988.63 695373 126.669267 2010-11-26 72 3.162 True True NaN NaN NaN NaN NaN 126512 Train 10 55.33 B 9.003 693099.36 795377 126.983581 2010-12-24 72 3.236 False False NaN NaN NaN NaN NaN 126512 Train 10 57.06 B 9.003 404245.03 895425 129.836400 2011-11-25 72 3.760 True True 174.72 329.00 141630.61 79.00 1009.98 126512 Train 10 60.68 B 7.874 630999.19 9115222 126.669267 2010-11-26 72 3.162 True True NaN NaN NaN NaN NaN 112238 Train 12 47.66 B 14.313 359995.60 10115274 129.836400 2011-11-25 72 3.622 True True 5391.83 8.00 63143.29 49.27 2115.67 112238 Train 12 53.25 B 12.890 360140.66 11128984 182.544590 2010-12-24 7 3.141 False False NaN NaN NaN NaN NaN 200898 Train 14 30.59 A 8.724 356867.25 12135665 182.783277 2010-11-26 72 3.039 True True NaN NaN NaN NaN NaN 200898 Train 14 46.15 A 8.724 474330.10 Nhìn vào bảng trên, chúng ta thấy rằng 10 ngày đầu tiên tập trung chủ yếu ở tháng 11 và tháng 12, tháng 12 là 24-25 tháng 12 -\u0026gt; ngày noel, còn tháng 11 là 25-26 tháng 11 (ngày gì vậy ta, trong mô tả không thấy) Tra lịch thì ngày 25 tháng 11 năm 2011 trúng thứ sáu, tra trên mạng một thông tin khá quan trong là \u0026ldquo;Black Friday sẽ rơi vào khoảng ngày 23-29 tháng 11\u0026rdquo; -\u0026gt; không nghi ngờ gì nữa có thể là ngày này đây. Thử tra tiếp ngày 26 tháng 11 năm 2010, cũng là thứ sáu luôn -\u0026gt; ngày black friday và ngày noel có sức mua điên cuồng quá.\nMình dùng một kỹ thuật nhỏ là giảm dần số bán, để ra số bán tối thiểu mà ngày black friday và ngày nodel vẫn còn giữ vị trí thống trị. Kỹ thuật khá đơn giản thôi, từ giá trị 350000, mỗi lần mình sẽ giảm đi 10000, và đếm số lần xuất hiện của các ngày, nếu có ngày nào đó nằm ngoài tuần chứa black friday và nodel thì mình dừng. Sau một hồi tìm kiếm và số bán đã xuất hiện, đó là 290000\n1print(df.loc[df[\u0026#39;Weekly_Sales\u0026#39;] \u0026gt;290000,\u0026#34;Date\u0026#34;].value_counts()) 12010-11-26 16 22011-11-25 14 32010-12-24 8 42011-12-23 3 52010-02-05 1 Làm sạch dữ liệu Xử lý missing values Một vấn đề khá quan trọng là trong tập dữ liệu này missing value khá nhiều, thử đếm số lượng null trong data cho ta biết được rằng\n1CPI 38162 2Date 0 3Dept 0 4Fuel_Price 0 5IsHoliday_x 0 6IsHoliday_y 0 7MarkDown1 271038 8MarkDown2 338949 9MarkDown3 294308 10MarkDown4 299491 11MarkDown5 270138 12Size 0 13Split 0 14Store 0 15Temperature 0 16Type 0 17Unemployment 38162 18Weekly_Sales 115064 Các giá trị MarkDown bị null khá nhiều, cách đơn giản nhất là set 0 cho tất cả các giá trị null ( Mình lưu log lại những index null của các markdown).\n1df = df.assign(md1_present = df[\u0026#39;MarkDown1\u0026#39;]notnull()) 2df = df.assign(md2_present = df[\u0026#39;MarkDown2\u0026#39;]notnull()) 3df = df.assign(md3_present = df[\u0026#39;MarkDown3\u0026#39;]notnull()) 4df = df.assign(md4_present = df[\u0026#39;MarkDown4\u0026#39;]notnull()) 5df = df.assign(md5_present = df[\u0026#39;MarkDown5\u0026#39;].notnull()) 67df.fillna(0, inplace=True) Tạo đặc trưng Đặc trưng holiday\n1df[\u0026#39;IsHoliday\u0026#39;] = \u0026#39;IsHoliday_\u0026#39; + df[\u0026#39;IsHoliday_x\u0026#39;].map(str) 2holiday_dummies = pd.get_dummies(df[\u0026#39;IsHoliday\u0026#39;]) Đặc trưng ngày tháng\nRút trích tháng\n1df[\u0026#39;DateType\u0026#39;] = [datetime.strptime(date, \u0026#39;%Y-%m-%d\u0026#39;).date() for date in df[\u0026#39;Date\u0026#39;].astype(str).values.tolist()] 2df[\u0026#39;Month\u0026#39;] = [date.month for date in df[\u0026#39;DateType\u0026#39;]] 3df[\u0026#39;Month\u0026#39;] = \u0026#39;Month_\u0026#39; + df[\u0026#39;Month\u0026#39;].map(str) 4Month_dummies = pd.get_dummies(df[\u0026#39;Month\u0026#39;] ) Rút trích ngày trước giáng sinh và black friday\n1df[\u0026#39;Black_Friday\u0026#39;] = np.where((df[\u0026#39;DateType\u0026#39;]==datetime(2010, 11, 26).date()) | (df[\u0026#39;DateType\u0026#39;]==datetime(2011, 11, 25).date()), \u0026#39;yes\u0026#39;, \u0026#39;no\u0026#39;) 2df[\u0026#39;Pre_christmas\u0026#39;] = np.where((df[\u0026#39;DateType\u0026#39;]==datetime(2010, 12, 23).date()) | (df[\u0026#39;DateType\u0026#39;]==datetime(2010, 12, 24).date()) | (df[\u0026#39;DateType\u0026#39;]==datetime(2011, 12, 23).date()) | (df[\u0026#39;DateType\u0026#39;]==datetime(2011, 12, 24).date()), \u0026#39;yes\u0026#39;, \u0026#39;no\u0026#39;) 3df[\u0026#39;Black_Friday\u0026#39;] = \u0026#39;Black_Friday_\u0026#39; + df[\u0026#39;Black_Friday\u0026#39;].map(str) 4df[\u0026#39;Pre_christmas\u0026#39;] = \u0026#39;Pre_christmas_\u0026#39; + df[\u0026#39;Pre_christmas\u0026#39;].map(str) 5Black_Friday_dummies = pd.get_dummies(df[\u0026#39;Black_Friday\u0026#39;] ) 6Pre_christmas_dummies = pd.get_dummies(df[\u0026#39;Pre_christmas\u0026#39;] ) Thêm các đặc trưng vào trong dữ liệu\n12df = pd.concat([df,holiday_dummies,Pre_christmas_dummies,Black_Friday_dummies],axis=1) Thêm đặc trưng trung vị của từng loại cửa hàng vào từng tháng, do một số của hàng sẽ bị NA ở cột số bán ở một thời điểm nào đó, nên chúng ta replace số bán là 0 có vẻ không hợp lý lắm. Mình chọn cách là thay thế bằng trung bình của số bán trong tháng của cửa hàng cùng loại. Nhưng trước tiên thì tính trung bình số bán của từng loại cửa hàng cái đã.\n12medians = pd.DataFrame({\u0026#39;Median Sales\u0026#39; :df.loc[df[\u0026#39;Split\u0026#39;]==\u0026#39;Train\u0026#39;].groupby(by=[\u0026#39;Type\u0026#39;,\u0026#39;Dept\u0026#39;,\u0026#39;Store\u0026#39;,\u0026#39;Month\u0026#39;,\u0026#39;IsHoliday\u0026#39;])[\u0026#39;Weekly_Sales\u0026#39;].median()}).reset_index() 3print(medians.head()) Kết quả\n1Type Dept Store Month IsHoliday Median Sales 20 Type_A Dept_1 Store_1 Month_1 IsHoliday_False 17350.585 31 Type_A Dept_1 Store_1 Month_10 IsHoliday_False 23388.030 42 Type_A Dept_1 Store_1 Month_11 IsHoliday_False 19551.115 53 Type_A Dept_1 Store_1 Month_11 IsHoliday_True 19865.770 64 Type_A Dept_1 Store_1 Month_12 IsHoliday_False 39109.390 thêm dữ liệu vào trong data chính, loại bỏ NA và tạo key cho mỗi dòng để dễ dàng truy xuất\n1df = df.merge(medians, how = \u0026#39;outer\u0026#39;, on = [\u0026#39;Type\u0026#39;,\u0026#39;Dept\u0026#39;,\u0026#39;Store\u0026#39;,\u0026#39;Month\u0026#39;,\u0026#39;IsHoliday\u0026#39;]) 23# Fill NA 4df[\u0026#39;Median Sales\u0026#39;].fillna(df[\u0026#39;Median Sales\u0026#39;].loc[df[\u0026#39;Split\u0026#39;]==\u0026#39;Train\u0026#39;].median(), inplace=True) 56# Create a key for easy access 78df[\u0026#39;Key\u0026#39;] = df[\u0026#39;Type\u0026#39;].map(str)+df[\u0026#39;Dept\u0026#39;].map(str)+df[\u0026#39;Store\u0026#39;].map(str)+df[\u0026#39;Date\u0026#39;].map(str)+df[\u0026#39;IsHoliday\u0026#39;].map(str) Chúng ta sẽ dự đoán số bán của tuần kế tiếp dựa vào kết quả số bán của tuần hiện tại, nên trong dữ liệu sẽ lưu trên ngày của tuần trước đó để dễ truy xuất. Vì 1 tuần có 7 ngày, chúng ta sẽ lưu giá trị là ngày ở cột hiện tại - 7\n1df[\u0026#39;DateLagged\u0026#39;] = df[\u0026#39;DateType\u0026#39;]- timedelta(days=7) Và giờ đây, chúng ta sẽ lặp qua toàn bộ các dòng trên tập dữ liệu, kiểm tra xem có dòng nào số bán nan hông, nếu có thì sẽ thay bằng trung bình đã tính ở trên. Ở đây mình tạo một sorted dataset để truy xuất cho nhanh\n12#Make a sorted dataframe. This will allow us to find lagged variables much faster! 3sorted_df = df.sort_values([\u0026#39;Store\u0026#39;, \u0026#39;Dept\u0026#39;,\u0026#39;DateType\u0026#39;], ascending=[1, 1,1]) 4sorted_df = sorted_df.reset_index(drop=True) # Reinitialize the row indices for the loop to work 56sorted_df[\u0026#39;LaggedSales\u0026#39;] = np.nan # Initialize column 7sorted_df[\u0026#39;LaggedAvailable\u0026#39;] = np.nan # Initialize column 8last=df.loc[0] # intialize last row for first iteration. Doesn\u0026#39;t really matter what it is 9row_len = sorted_df.shape[0] 10for index, row in sorted_df.iterrows(): 11lag_date = row[\u0026#34;DateLagged\u0026#34;] 12# Check if it matches by comparing last weeks value to the compared date  13# And if weekly sales aren\u0026#39;t 0 14if((last[\u0026#39;DateType\u0026#39;]== lag_date) \u0026amp; (last[\u0026#39;Weekly_Sales\u0026#39;]\u0026gt;0)): 15sorted_df.set_value(index, \u0026#39;LaggedSales\u0026#39;,last[\u0026#39;Weekly_Sales\u0026#39;]) 16sorted_df.set_value(index, \u0026#39;LaggedAvailable\u0026#39;,1) 17else: 18sorted_df.set_value(index, \u0026#39;LaggedSales\u0026#39;,row[\u0026#39;Median Sales\u0026#39;]) # Fill with median 19sorted_df.set_value(index, \u0026#39;LaggedAvailable\u0026#39;,0) 2021last = row #Remember last row for speed 22if(index%int(row_len/10)==0): #See progress by printing every 10% interval 23print(str(int(index*100/row_len))+\u0026#39;% loaded\u0026#39;) 2425print(sorted_df[[\u0026#39;Dept\u0026#39;, \u0026#39;Store\u0026#39;,\u0026#39;DateType\u0026#39;,\u0026#39;LaggedSales\u0026#39;,\u0026#39;Weekly_Sales\u0026#39;,\u0026#39;Median Sales\u0026#39;]].head()) 19% loaded 219% loaded 329% loaded 439% loaded 549% loaded 659% loaded 769% loaded 879% loaded 989% loaded 1099% loaded 11Dept Store DateType LaggedSales Weekly_Sales Median Sales 120 Dept_1 Store_1 2010-02-05 23510.49 24924.50 23510.49 131 Dept_1 Store_1 2010-02-12 24924.50 46039.49 37887.17 142 Dept_1 Store_1 2010-02-19 46039.49 41595.55 23510.49 153 Dept_1 Store_1 2010-02-26 41595.55 19403.54 23510.49 164 Dept_1 Store_1 2010-03-05 19403.54 21827.90 21280.40 Công việc đơn giản tiếp theo là merge dữ liệu vào data chính và tính độ lệch giữa 2 tuần bán\n1# Merge by store and department 2df = df.merge(sorted_df[[\u0026#39;Dept\u0026#39;, \u0026#39;Store\u0026#39;,\u0026#39;DateType\u0026#39;,\u0026#39;LaggedSales\u0026#39;,\u0026#39;LaggedAvailable\u0026#39;]], how = \u0026#39;inner\u0026#39;, on = [\u0026#39;Dept\u0026#39;, \u0026#39;Store\u0026#39;,\u0026#39;DateType\u0026#39;]) 3df[\u0026#39;Sales_dif\u0026#39;] = df[\u0026#39;Median Sales\u0026#39;] - df[\u0026#39;LaggedSales\u0026#39;] Và bây giờ , thay vì ta ước lượng weekly sales, chúng ta sẽ ước lượng độ lệch giữa week sales và median sales (đây là một cách trong những cách để tính điểm dừng của dữ liệu time series)\n1df[\u0026#39;Difference\u0026#39;] = df[\u0026#39;Median Sales\u0026#39;] - df[\u0026#39;Weekly_Sales\u0026#39;] Huấn luyện mô hình Lựa chọn các đặc trưng huấn luyện\n1selector = [ 2#\u0026#39;Month\u0026#39;, 3\u0026#39;CPI\u0026#39;, 4\u0026#39;Fuel_Price\u0026#39;, 5\u0026#39;MarkDown1\u0026#39;, 6\u0026#39;MarkDown2\u0026#39;, 7\u0026#39;MarkDown3\u0026#39;, 8\u0026#39;MarkDown4\u0026#39;, 9\u0026#39;MarkDown5\u0026#39;, 10\u0026#39;Size\u0026#39;, 11\u0026#39;Temperature\u0026#39;, 12\u0026#39;Unemployment\u0026#39;, 13141516\u0026#39;md1_present\u0026#39;, 17\u0026#39;md2_present\u0026#39;, 18\u0026#39;md3_present\u0026#39;, 19\u0026#39;md4_present\u0026#39;, 20\u0026#39;md5_present\u0026#39;, 2122\u0026#39;IsHoliday_False\u0026#39;, 23\u0026#39;IsHoliday_True\u0026#39;, 24\u0026#39;Pre_christmas_no\u0026#39;, 25\u0026#39;Pre_christmas_yes\u0026#39;, 26\u0026#39;Black_Friday_no\u0026#39;, 27\u0026#39;Black_Friday_yes\u0026#39;, 28\u0026#39;LaggedSales\u0026#39;, 29\u0026#39;Sales_dif\u0026#39;, 30\u0026#39;LaggedAvailable\u0026#39; 31] Tách dữ liệu train và test riêng ra\n12train = df.loc[df[\u0026#39;Split\u0026#39;]==\u0026#39;Train\u0026#39;] 3test = df.loc[df[\u0026#39;Split\u0026#39;]==\u0026#39;Test\u0026#39;] Lấy ngẫu nhiên 20% dữ liệu ở tập train để validation\n1# Set seed for reproducability  2np.random.seed(42) 3X_train, X_val, y_train, y_val = train_test_split(train[selector], train[\u0026#39;Difference\u0026#39;], test_size=0.2, random_state=42) Huấn luyện bằng neural network sử dụng lstm\n12adam_regularized = Sequential() 34# First hidden layer now regularized 5model.add(Dense(32,activation=\u0026#39;relu\u0026#39;, 6input_dim=X_train.shape[1], 7kernel_regularizer = regularizers.l2(0.01))) 89# Second hidden layer now regularized 10adam_regularized.add(Dense(16,activation=\u0026#39;relu\u0026#39;, 11kernel_regularizer = regularizers.l2(0.01))) 1213# Output layer stayed sigmoid 14adam_regularized.add(Dense(1,activation=\u0026#39;linear\u0026#39;)) 1516# Setup adam optimizer 17adam_optimizer=keras.optimizers.Adam(lr=0.01, 18beta_1=0.9, 19beta_2=0.999, 20epsilon=1e-08) 2122# Compile the model 23adam_regularized.compile(optimizer=adam_optimizer, 24loss=\u0026#39;mean_absolute_error\u0026#39;, 25metrics=[\u0026#39;acc\u0026#39;]) 2627# Train 28history=adam_regularized.fit(X_train, y_train, # Train on training set 29epochs=10, # We will train over 1,000 epochs 30batch_size=2048, # Batch size  31verbose=0) # Suppress Keras output 32print(\u0026#39;eval\u0026#39;,model.evaluate(x=X_val,y=y_val)) 3334# Plot network 35plt.plot(history.history[\u0026#39;loss\u0026#39;], label=\u0026#39;Adam Regularized\u0026#39;) 36plt.xlabel(\u0026#39;Epochs\u0026#39;) 37plt.ylabel(\u0026#39;loss\u0026#39;) 38plt.legend() 39plt.show() 1eval: [1457.0501796214685, 0.002312783168124545] Độ lỗi trên tập train\nĐộ lỗi trên tập train giảm xuống đến gần 1450 thì đừng hẳn, không thể giảm được nữa\nGiá trị độ lệch trên tập evaluation là 1457.0501796214685\nThử huấn luyện bằng random forest\n1regr = RandomForestRegressor(n_estimators=20, criterion=\u0026#39;mse\u0026#39;, max_depth=None, 2min_samples_split=2, min_samples_leaf=1, 3min_weight_fraction_leaf=0.0, max_features=\u0026#39;auto\u0026#39;, 4max_leaf_nodes=None, min_impurity_decrease=0.0, 5min_impurity_split=None, bootstrap=True, 6oob_score=False, n_jobs=1, random_state=None, 7verbose=2, warm_start=False) 89#Train on data 10regr.fit(X_train, y_train.ravel()) 11y_pred_random = regr.predict(X_val) 1213y_val = y_val.to_frame() 1415# Transform forest predictions to observe direction of change 16direction_true1= y_val.values 17direction_predict = y_pred_random 1819y_val[\u0026#39;Predicted\u0026#39;] = y_pred_random 20df_out = pd.merge(train,y_val[[\u0026#39;Predicted\u0026#39;]],how = \u0026#39;left\u0026#39;,left_index = True, right_index = True,suffixes=[\u0026#39;_True\u0026#39;,\u0026#39;_Pred\u0026#39;]) 21df_out = df_out[~pd.isnull(df_out[\u0026#39;Predicted\u0026#39;])] 2223df_out[\u0026#39;prediction\u0026#39;] = df_out[\u0026#39;Median Sales\u0026#39;]-df_out[\u0026#39;Predicted\u0026#39;] 2425print(\u0026#34;Medians: \u0026#34;+str(sum(abs(df_out[\u0026#39;Difference\u0026#39;]))/df_out.shape[0])) 26print(\u0026#34;Random Forest: \u0026#34;+str(sum(abs(df_out[\u0026#39;Weekly_Sales\u0026#39;]-df_out[\u0026#39;prediction\u0026#39;]))/df_out.shape[0])) Kết quả\n129% loaded 319% loaded 429% loaded 539% loaded 649% loaded 759% loaded 869% loaded 979% loaded 1089% loaded 1199% loaded 12Dept Store DateType LaggedSales Weekly_Sales Median Sales 130 Dept_1 Store_1 2010-02-05 23510.49 24924.50 23510.49 141 Dept_1 Store_1 2010-02-12 24924.50 46039.49 37887.17 152 Dept_1 Store_1 2010-02-19 46039.49 41595.55 23510.49 163 Dept_1 Store_1 2010-02-26 41595.55 19403.54 23510.49 174 Dept_1 Store_1 2010-03-05 19403.54 21827.90 21280.40 18[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers. 19building tree 1 of 20 20[Parallel(n_jobs=1)]: Done 1 out of 1 | elapsed: 6.5s remaining: 0.0s 21building tree 2 of 20 22building tree 3 of 20 23building tree 4 of 20 24building tree 5 of 20 25building tree 6 of 20 26building tree 7 of 20 27building tree 8 of 20 28building tree 9 of 20 29building tree 10 of 20 30building tree 11 of 20 31building tree 12 of 20 32building tree 13 of 20 33building tree 14 of 20 34building tree 15 of 20 35building tree 16 of 20 36building tree 17 of 20 37building tree 18 of 20 38building tree 19 of 20 39building tree 20 of 20 40[Parallel(n_jobs=1)]: Done 20 out of 20 | elapsed: 2.2min finished 41[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers. 42[Parallel(n_jobs=1)]: Done 1 out of 1 | elapsed: 0.0s remaining: 0.0s 43[Parallel(n_jobs=1)]: Done 20 out of 20 | elapsed: 1.1s finished 44Medians: 1545.7406070759525 45Random Forest: 1356.4670052620745 Trung bình lệch của random forest là 1356, giá trị này nhỏ hơn so với giá trị output của lstm trả về.\nThử huấn luyện bằng XGBoost\n12param_dist = { \u0026#39;max_depth\u0026#39;:5} 34model = XGBRegressor(**param_dist) 56#Train on data 7model.fit(X_train, y_train.ravel()) 8y_pred_random = model.predict(X_val) 910y_val = y_val.to_frame() 1112# Transform forest predictions to observe direction of change 13direction_true1= y_val.values 14direction_predict = y_pred_random 1516y_val[\u0026#39;Predicted\u0026#39;] = y_pred_random 17df_out = pd.merge(train,y_val[[\u0026#39;Predicted\u0026#39;]],how = \u0026#39;left\u0026#39;,left_index = True, right_index = True,suffixes=[\u0026#39;_True\u0026#39;,\u0026#39;_Pred\u0026#39;]) 18df_out = df_out[~pd.isnull(df_out[\u0026#39;Predicted\u0026#39;])] 1920df_out[\u0026#39;prediction\u0026#39;] = df_out[\u0026#39;Median Sales\u0026#39;]-df_out[\u0026#39;Predicted\u0026#39;] 2122print(\u0026#34;Medians: \u0026#34;+str(sum(abs(df_out[\u0026#39;Difference\u0026#39;]))/df_out.shape[0])) 23print(\u0026#34;XGB Regressor: \u0026#34;+str(sum(abs(df_out[\u0026#39;Weekly_Sales\u0026#39;]-df_out[\u0026#39;prediction\u0026#39;]))/df_out.shape[0])) Kết quả\n12Medians: 1545.7406070759525 3XGB Regressor: 1354.1976755192593 Kết quả cũng gần như bằng Random forest :).\nGiờ mình sẽ dùng random forest để tạo file submission\n123rf_model = RandomForestRegressor(n_estimators=80, criterion=\u0026#39;mse\u0026#39;, max_depth=None, 4min_samples_split=2, min_samples_leaf=1, 5min_weight_fraction_leaf=0.0, max_features=\u0026#39;auto\u0026#39;, 6max_leaf_nodes=None, min_impurity_decrease=0.0, 7min_impurity_split=None, bootstrap=True, 8oob_score=False, n_jobs=1, random_state=None, 9verbose=0, warm_start=False) 1011#Train on data 12rf_model.fit(train[selector], train[\u0026#39;Difference\u0026#39;]) 13final_y_prediction = rf_model.predict(test[selector]) 1415testfile = pd.concat([test.reset_index(drop=True), pd.DataFrame(final_y_prediction)], axis=1) 16testfile[\u0026#39;prediction\u0026#39;] = testfile[\u0026#39;Median Sales\u0026#39;]-testfile[0] 1718submission = pd.DataFrame({\u0026#39;id\u0026#39;:pd.Series([\u0026#39;\u0026#39;.join(list(filter(str.isdigit, x))) for x in testfile[\u0026#39;Store\u0026#39;]]).map(str) + \u0026#39;_\u0026#39; + 19pd.Series([\u0026#39;\u0026#39;.join(list(filter(str.isdigit, x))) for x in testfile[\u0026#39;Dept\u0026#39;]]).map(str) + \u0026#39;_\u0026#39; + 20testfile[\u0026#39;Date\u0026#39;].map(str), 21\u0026#39;Weekly_Sales\u0026#39;:testfile[\u0026#39;prediction\u0026#39;]}) 2223submission.to_csv(\u0026#39;submission.csv\u0026#39;,index=False) Sau khi submit mô hình, mình đạt được kết quả là 4455.96312 trên private board, và 4419.17292 trên publish board. Đây là một kết quả khá tệ (đứng hạng khoảng top 300). Sau khi mình nhìn lại mô hình thì phát hiện một số vấn đề.\nCác đặc trưng trong file features.csv nó không có mối tương quan gì hết với số bán như phân tích ở trên -\u0026gt; mình mạnh dạng bỏ luôn file features.csv, không quan tâm đến nó nữa, tập trung vào file chính.\nBỏ mấy cái lag luôn, thử forecast chính vào cái số bán luôn xem sao\nVới cửa hàng nào thì xây dựng mô hình cho cửa hàng và sản phẩm đó, không xây dựng một mô hình tổng quát áp dụng cho toàn cửa hàng. với những cửa hàng không có trong tập train hoặc những sản phẩm mà cửa hàng đó chưa bán trước đây (nói chung là không có trong tập train) thì mới áp dụng mô hình của toàn cửa hàng cho nó.\nKết quả là mình đạt được 2736 trên private board và 2657.40087 trên publish board (top 30), kết quả trên vẫn làm cho mình chưa hài lòng lắm.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Apr 15, 2019","img":"","permalink":"/blog/2019-04-17-walmart-store-sales-forecasting/","series":null,"tags":["walmart","forecast","dự đoán"],"title":"Dự Đoán Doanh Số Bán Của Các Cửa Hàng Walmart"},{"categories":null,"content":"Thực hiện Đây là một bài toán tiếp cận bằng Deep Learning, nên việc thu thập nhiều dữ liệu có ý nghĩa rất quang trọng trong việc đóng góp vào độ chính xác của mô hình. Ở đây, chúng ta sẽ download tập dữ liệu ảnh của http://places2.csail.mit.edu/download.html và sử dụng mạng UNet để huấn luyện mô hình.\nThu thập hình ảnh và tiền xử lý Dữ liệu sẽ được download tại địa chỉ http://data.csail.mit.edu/places/places365/train_256_places365challenge.tar. Tập trên có kích thước 108 GB. Đây là tập ảnh thuộc hệ màu RGB. Chúng ta sẽ chuyển tập ảnh trên về hệ màu grayscale làm ảnh gốc cho quá trình huấn luyện. Có một mẹo nhỏ cho chúng ta rút ngắn quá trình huấn luyện nhưng vẫn đảm bảo được độ chính xác của mô hình là ngoài kênh màu RGB mà chúng ta hay xài, trên thế giới còn có kênh màu HSV, trong đó nếu chúng ta chuyển một ảnh ở kênh màu RGB về hệ màu HSV, và bỏ đi các giá trị H, S, chỉ giữ lại giá trị V, thì chất lượng ảnh xám của nó gần như là tương đương với ảnh grayscale sử dụng công thức \u0026ldquo;thần thánh\u0026rdquo; mà chúng ta được học ở môn xử lý ảnh grayscale =0.30*R + 0.59*G + 0.11*B\nVì vậy, thay vì việc input là giá trị xám của ảnh, output là giá trị của các kênh màu RGB, chúng ta sẽ chuyển đổi bài toán lại là input là giá trị xám, output là giá trị H và S.\nMô hình mạng Unet\nMạng UNet là một mạng neural network được dùng khá phổ biến trong các cuộc thi phân đoạn ảnh, độ chính xác của nó so với các thuật toán khác là vượt trội hoàn toàn. Ở đây, chúng ta có 2 hướng tiếp cận, một là build một mạng Unet và random init weight rồi huấn luyện nó, cách thứ hai là build mạng unet sử dụng pretrain model rồi huấn luyện. Bởi vì đặc trưng của các pretrain model hoạt động khá tốt và được huấn luyện trên tập dataset lớn, nên mình sẻ sử dụng nó ở bài viết này. Song song đó, mình sẽ cung cấp một giải pháp kèm theo sử để sử dụng mạng mà không dùng pretrain model.\nÚ tưởng chính của mạng UNet tựa tựa như auto-encoder, từ ảnh gốc ban đầu, chúng sẽ được nén thông tin lại qua các phép biến đổi Conv2D (như các chú thích màu sắc của mũi tên trong hình trên), sau đó sẽ được \u0026ldquo;giải nén\u0026rdquo; về lại ảnh gốc ban đầu. Việc huấn luyện coi như là hoàn tất 100% nếu ảnh gốc với ảnh giải nén là là giống nhau hoàn toàn.\nBài viết sẽ được cập nhật\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Apr 14, 2019","img":"","permalink":"/blog/2019-04-16-colorfull-grayscale-to-color/","series":null,"tags":["machine learning","deep learning","neural network","amazone","thế giới di động","mwg"],"title":"Thử Làm Ứng Dụng Tô Màu Ảnh Xám Thành Ảnh Màu Sử Dụng Tensorflow"},{"categories":null,"content":"Trong cuốn The West Wing Script Book của Aaron Sorkin, ông ấy đã có một câu như thế này \u0026ldquo;There (is) order and even great beauty in what looks like total chaos. If we look closely enough at the randomness around us, patterns will start to emerge.\u0026rdquo;. Mình xin phép không dịch câu nói trên ra, bởi vì mình dịch khá tệ, và câu nói này khá nổi tiếng (đã được trích dẫn khá nhiều trên các bài viết của các bloger khác). Nhưng câu nói đó khá phù hợp với môi trường chứng khoán, nơi mà mọi thứ đều không rõ ràng và khá \u0026ldquo;hỗn loạn\u0026rdquo;.\nDự đoán chuỗi thời gian Giá cổ phiếu trên thị trường chứng khoán thường được quy vào bài toán là time series. Các công ty đầu tư hoặc các nhà nghiên cứu, các nhà đầu tư hiện nay thường sử dụng phương pháp stochastic hoặc các cải tiến của phương pháp stochastic (ví dụ mô hình ARIMA, RegARIMA,\u0026hellip;) để đưa ra các dự đoán hợp lý phù hợp với các giá trị quá khứ. Mục tiêu cuối cùng là tìm ra một mô hình khả dĩ nhất để phản ánh quy luật của thị trường và sử dụng nó để sinh ra lợi nhuận (trở nên giàu có hơn :)).\nCác thuộc tính của time series Một trong các thuộc tính của chuỗi thời gian là tính dừng (stationary). Một chuỗi time series được gọi là có tính dừng nếu các thuộc tính có ý nghĩa thống kê của nó (ví dụ như là trung bình, độ lệch chuẩn) không đổi theo thời gian. Ở đây, chúng ta luận bàn nho nhỏ một chút vì sao tính dừng rất quang trọng trong chuỗi thời gian.\nTrước hết, hầu hết các mô hình về time series hiện tại được xây dựng trên một giả định tính dừng của chuỗi thời gian. Có nghĩa là nếu chuỗi thời gian ở trong quá khứ có một hành vi nào đó, thì khả năng cao là nó sẽ lặp lại trong tương lai. Ngoài ra, các lý thuyết liên quan đến tính dừng của chuỗi time series đã được các nhà nghiên cứu khai thác một cách triệt để và dễ ràng implement hơn là các lý thuyết về non-stationary trong time series.\nTính dừng được định nghĩa bằng các tiêu chí rõ ràng và nghiêm ngặt. Tuy nhiên, trong bài toán thực tế, chúng ta có thể giả định rằng một chuỗi time series được coi là có tính dừng nếu các thuộc tính thống kê không đổi theo thời gian, nghĩa là:\n Giá trị trung bình không thay đổi. Nếu giá trị trung bình thay đổi, chuỗi thời gian sẽ có khuynh hướng đi lên hoặc đi xuống. Hình ảnh bên dưới, mô tả trực quan một chuỗi thời gian có tính dừng (trung bình không thay đổi), và một chuỗi thời gian không có tính dừng (trung bình thay đổi).   Giá trị phương sai không thay đổi. Thuộc tính này còn được gọi là đồng đẳng (homoscedasticity). Hình bên dưới mô tả một chuỗi có phương sai thay đổi (không có tính dừng) và một chuỗi có phương sai bất biến (có tính dừng).   Tính tự tương tự không phụ thuộc vào thời gian  Vì sao chúng ta lại quan tâm đến tính dừng của dữ liệu Chúng ta quan tâm đến tính dừng của dữ liệu, đơn giản là bởi vì nếu dữ liệu không có tính dừng, chúng ta không thể xây dựng mô hình chuỗi thời gian (như đã nói ở trên, các nghiên cứu hiện nay đều dựa trên một cơ sở là dữ liệu có tính dừng). Trong trường hợp bạn có trong tay dữ liệu thuộc dạng time series, và một tiêu chí nào đó trong 3 tiêu chí mình đã liệu kê ở trên bị vi phạm, suy ra là dữ liệu của bạn không có tính dừng. Bạn phải chuyển đổi dữ liệu bạn đang có để cho nó có tính dừng. May mắn rằng cũng có nhiều nghiên cứu thực hiện việc này, ví dụ như \u0026ldquo;khử xu hướng (detrending)\u0026rdquo;, khử sai biệt (differencing)\u0026hellip;\nNếu bạn mới chỉ bắt đầu phân tích chuỗi thời gian, bạn sẽ thấy việc làm trên khá là stupid. Lý thuyết tốt nhất hiện nay cho chuỗi thời gian là chia nhỏ nó ra thành các thành phần như là xu hướng (linear trend), mùa vụ (seasonal), chu kỳ, và yếu tố ngẫu nhiên. Dự đoán cho từng phần một, sau đó lấy tổng chúng lại.\nĐối với những ai đã quen thuộc với biến đổi Fourier, thì sẽ dễ dàng \u0026ldquo;cảm\u0026rdquo; hơn cái mình vừa nói ở trên.\nCách xác định tính dừng của dữ liệu Khá khó để xác định một biểu đồ chuỗi time series có tính dừng hay không (quan sát biểu đồ bằng mắt). Cho nên chúng ta sẽ sử dụng kiểm định Dickey-Fuller. Đây là một kiểm định thống kê để kiểm tra xem chuỗi dữ liệu có tính dừng hay không. Với giả thuyết null là chuỗi time series là một chuỗi không có tính dừng. Nếu giá trị nhỏ hơn một ngưỡng p-value nào đó (thường là 0.05), chúng ta có quyền bác bỏ giả định null, và nói rằng chuỗi thời gian đang có là có tính dừng. Ở bài viết này, mình không đề cập đến mô hình kiểm định - vốn được học trong môn xác xuất thống kê. Các bạn có nhu cầu tìm hiểu thì có thể search trên google hoặc là xem lại sách xác suất thống kê.\nPhương pháp dự đoán chuỗi thời gian cơ bản Phương pháp cơ bản nhất, đơn giản nhất, và để áp dụng nhất dược sử dụng để dự đoán chuỗi thời gian là moving average. Mô hình này thực hiện tính trung bình của t giá trị cuối cùng làm giá trị dự đoán của điểm tiếp theo. Ví dụ như để dự đoán giá chứng khoán của ngày thứ 2 của tuần tiếp theo, chúng ta sẽ lấy trung bình giá đóng của của 5 ngày trước đó (giá từ thứ hai đến thứ sáu tuần này).\nĐến đây, các bạn đã có một số hiểu biết về time series. Một mô hình khá nổi tiếng là ARIMA đã được sử dụng nhiều để phân tích và dự báo. Cách thực hiện của mô hình trên được trình bày tóm gọn trong hình mô tả bên dưới.\nPhương pháp dự đoán dựa vào mạng neural network Thực tế, có rất nhiều mạng neural network đã được áp dụng để dự đoán mô hình chứng khoán. Các bạn có thể tìm đọc lại các bài viết trước đây của mình về sử dụng LSTM trong dự báo chứng khoán. Mô hình chứng khoán bằng mạng neural network nói chung phải đối mặt với một vấn đề khá \u0026ldquo;xương xẩu\u0026rdquo; là xử lý nhiễu và vanishing gradients. Trong đó, việc xử lý vanishing gradients là quan trọng nhất. Bản chất của mạng neural network là tối ưu hoá hàm lan truyền ngược bằng cách sử dụng đạo hàm giữa các lớp layer để chúng \u0026lsquo;học\u0026rsquo;. Trải qua nhiều layer, giá trị của đạo hàm sẽ càng ngày nhỏ dần vào xấp xỉ bằng 0. Giả sử chúng ta có một mô hình có 100 lớp hidden layer, chúng ta nhân 100 lần số 0.1 với nhau và boom, giá trị cuối cùng chung ta nhận được là 0, nghĩa là chúng ta chẳng học được cái gì cả.\nMay mắn thay, tới thời điểm hiện tại, chúng ta có 3 cách để xử lý vấn đề trên:\n  Clipping gradients\n  LSTM (Long Short Term Memory) hoặc GRU (Gate Recurrent Units)\n  Echo states RNNs\n  Kỹ thuật clipping gradients sử dụng một mẹo là khi giá trị đạo hàm quá lớn hoặc quá nhỏ, chúng ta sẽ không lấy đạo hàm nữa. Kỹ thuật này thoạt nhìn có vẻ hay, nhưng nó không thể ngăn chúng ta mất mát thông tin và đây là một ý tưởng khá tệ.\nRNN (LSTM hoặc GRU) là một kỹ thuật khác là điều chỉnh các kết nối theo một vài quy luật nhất định, ví dụ output của layer tầng 1 có thể là input của layer tầng 10, chứ không nhất thiết là input của layer tầng 2 như cách thông thường. Kỹ thuật này khá tốt về mặt lý thuyết. Tuy nhiên, có một vấn đề khá lớn khi sử dụng là chúng ta phải tính toán kỹ các kết nối để đảm bảo hệ thống hoạt động ổn đinh. Mô hình được xây dựng trên kỹ thuật này khá bự, làm cho thuật toán chạy chậm. Ngoài ra, tính hội tụ của thuật toán không được đảm bảo. Mô hình LSTM đơn giản mình có để ở hình bên dưới.\nMạng echo states network, là một mô hình mới được nghiên cứu gần đây, bản chất nó là một mảng recurrent neural network với các hidden layer liên kết \u0026ldquo;lỏng lẻo\u0026rdquo; với nhau. Lớp này được gọi là \u0026lsquo;reservoir\u0026rsquo; (như hình mô tả bên dưới).\nTrong mô hình mạng echo state network, chúng ta chỉ cần huấn luyện lại trọng số của lớp output, việc này giúp chúng ta rút ngắn thời gian huấn luyện mô hình, và tăng tốc qusa trình training.\nSử dụng mạng Echo State Networks Về nguyên lý hoạt động của mô hình này, mình sẽ không đề cập ở đây. Chủ đề về mạng Echo State Networks mình sẽ nghiên cứu kỹ lưỡng và đề cập ở trong bài viết sắp tới. Mục tiêu của bài viết này là sử dụng mô hình Echo State Networks trong bài toán time series.\nDự doán chuỗi time series Trước tiên, chúng ta sẽ import một số thư viện cần thiết, thư viện ESN đã có sẵn tại đường dẫn pyESN, các bạn download về rồi dùng\n123import numpy as np 4import pandas as pd 5import seaborn as sns 6from matplotlib import pyplot as plt 7import warnings 8warnings.filterwarnings(\u0026#39;ignore\u0026#39;) 910# This is the library for the Reservoir Computing got it by: https://github.com/cknd/pyESN 11from pyESN import ESN Tiếp theo chúng ta sẽ đọc file\n12data = open(\u0026#34;amazon.txt\u0026#34;).read().split() 3data = np.array(data).astype(\u0026#39;float64\u0026#39;) Chúng ta sẽ xây dựng một mô hình ESN đơn giản\n12n_reservoir= 500 3sparsity=0.2 4rand_seed=23 5spectral_radius = 1.2 6noise = .0005 789esn = ESN(n_inputs = 1, 10n_outputs = 1, 11n_reservoir = n_reservoir, 12sparsity=sparsity, 13random_state=rand_seed, 14spectral_radius = spectral_radius, 15noise=noise) 1617``` 1819Để đơn giản, mình sẽ tạo mô hình với dữ liệu tào lao như sau:input là một vector toàn số 1, output là các điểm dữ liệu của mình. Cho mô hình ESN học với số lượng phần tử là 1500, sau đó sẽ dự đoán 10 điểm dữ liệu tiếp theo. Với bước nhảy là 10, lặp 10 lần. Sau quá trình lặp, mình thu được 100 điểm dự đoán 202122```python 23trainlen = 1500 24future = 10 25futureTotal=100 26pred_tot=np.zeros(futureTotal) 2728for i in range(0,futureTotal,future): 29pred_training = esn.fit(np.ones(trainlen),data[i:trainlen+i]) # dữ liệu từ ngày i đến ngày i + trainlen 30prediction = esn.predict(np.ones(future)) 31pred_tot[i:i+future] = prediction[:,0] # dự đoán cho ngày i+ trainlen + 1 đến ngày i + trainlen + future 323334``` 3536Vẽ mô hình cùi mía của mình mới làm lên để xem dữ liệu dự đoán và dữ liệu thực tế chênh lệch như thế nào 3738```python 39plt.figure(figsize=(16,8)) 40plt.plot(range(1000,trainlen+futureTotal),data[1000:trainlen+futureTotal],\u0026#39;b\u0026#39;,label=\u0026#34;Data\u0026#34;, alpha=0.3) 41#plt.plot(range(0,trainlen),pred_training,\u0026#39;.g\u0026#39;, alpha=0.3) 42plt.plot(range(trainlen,trainlen+futureTotal),pred_tot,\u0026#39;k\u0026#39;, alpha=0.8, label=\u0026#39;Free Running ESN\u0026#39;) 4344lo,hi = plt.ylim() 45plt.plot([trainlen,trainlen],[lo+np.spacing(1),hi-np.spacing(1)],\u0026#39;k:\u0026#39;, linewidth=4) 4647plt.title(r\u0026#39;Ground Truth and Echo State Network Output\u0026#39;, fontsize=25) 48plt.xlabel(r\u0026#39;Time (Days)\u0026#39;, fontsize=20,labelpad=10) 49plt.ylabel(r\u0026#39;Price ($)\u0026#39;, fontsize=20,labelpad=10) 50plt.legend(fontsize=\u0026#39;xx-large\u0026#39;, loc=\u0026#39;best\u0026#39;) 51sns.despine() 52plt.show() Độ phức tạp của mô hình là khá nhỏ khi so với mô hình RNN. Lý do là về bản chất, chúng ta chỉ huấn luyện trên trọng số của output layer, nó là một hàm tuyến tính. Do vậy, độ phức tạp tính toán chỉ giống như là việc tính một hàm hồi quy tuyến tính. Trong thực tế, độ phức tạp tính toán sẽ là O(N) với N là ố lượng hidden unit trong reservoir.\nTối ưu hoá các tham số Hyper parameters Ở phần trước, chúng ta set đại các tham số spectral_radius = 1.2 và noise = .0005. Trong thực tế, chúng ta phải tìm các siêu tham số này bằng cách tìm ra mô hình trả về MSE là nhỏ nhất.\nSử dụng kỹ thuật Grid Search với ngưỡng spectrum_radius nằm trong đoạn [0.5, 1.5] và noise nằm trong đoạn noise [0.0001, 0.01], chú ý là các bạn có thể search ở đoạn lớn hơn. Kết quả thu được:\n1def MSE(yhat, y): 2return np.sqrt(np.mean((yhat.flatten() - y)**2)) 34n_reservoir= 500 5sparsity = 0.2 6rand_seed = 23 7radius_set = [0.9, 1, 1.1] 8noise_set = [ 0.001, 0.004, 0.006] 910radius_set = [0.5, 0.7, 0.9, 1, 1.1,1.3,1.5] 11noise_set = [ 0.0001, 0.0003,0.0007, 0.001, 0.003, 0.005, 0.007,0.01] 12131415radius_set_size = len(radius_set) 16noise_set_size = len(noise_set) 1718trainlen = 1500 19future = 2 20futureTotal= 100 2122loss = np.zeros([radius_set_size, noise_set_size]) 2324for l in range(radius_set_size): 25rho = radius_set[l] 26for j in range(noise_set_size): 27noise = noise_set[j] 2829pred_tot=np.zeros(futureTotal) 3031esn = ESN(n_inputs = 1, 32n_outputs = 1, 33n_reservoir = n_reservoir, 34sparsity=sparsity, 35random_state=rand_seed, 36spectral_radius = rho, 37noise=noise) 3839for i in range(0,futureTotal,future): 40pred_training = esn.fit(np.ones(trainlen),data[i:trainlen+i]) 41prediction = esn.predict(np.ones(future)) 42pred_tot[i:i+future] = prediction[:,0] 4344loss[l, j] = MSE(pred_tot, data[trainlen:trainlen+futureTotal]) 45print(\u0026#39;rho = \u0026#39;, radius_set[l], \u0026#39;, noise = \u0026#39;, noise_set[j], \u0026#39;, MSE = \u0026#39;, loss[l][j] ) 46Kết quả\n12(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 20.367056799629353) 3(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 22.44956008062169) 4(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 24.574909979223666) 5(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 25.862558649155638) 6(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 29.882933676750657) 7(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 32.63942614291128) 8(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 36.441245548726) 9(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 44.77637915282457) 10(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 19.560517902720054) 11(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 20.12742795009036) 12(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 20.81801427735713) 13(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 21.26142619965559) 14(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 23.270880660885513) 15(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 26.061347331527354) 16(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 30.298361979419834) 17(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 39.17074955771047) 18(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 18.612970860501118) 19(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 18.681815816990774) 20(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 18.835785386862582) 21(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.982346096338105) 22(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 20.81632098844061) 23(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 24.60968377490799) 24(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 30.231007189936882) 25(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 41.28587340583505) 26(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 18.23852181110818) 27(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 18.27010615150326) 28(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 18.36078059388596) 29(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.47920006882226) 30(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 20.613227951906246) 31(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 25.153712109142973) 32(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 31.700838835741898) 33(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 44.23736750779224) 34(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 17.981571756431556) 35(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 18.009398312163942) 36(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 18.09054736889828) 37(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.218795249276663) 38(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 20.82610561349463) 39(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 26.272452530336505) 40(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 33.91532767431614) 41(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 48.22002405965967) 42(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 17.72839068197909) 43(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 17.799908079894703) 44(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 17.92917208443474) 45(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.143905288756557) 46(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 22.20343747458126) 47(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 30.05977704513729) 48(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 40.56654468067572) 49(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 59.43231026660687) 50(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 17.627409489404897) 51(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 17.835052829116567) 52(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 18.100099619981393) 53(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.481406587483956) 54(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 24.887601182697498) 55(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 36.34166374510305) 56(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 50.99612645577753) 57(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 75.94229622771246) Kết quả thu được là giá trị MSE tốt nhất là spectrum radius = 1.5 và nnoise = 0.0001\nThử dự đoán giá cổ phiếu của tập đoàn thế giới di động (Mã cổ phiếu MWG) xem sao\nỞ hình trên, mình không tiến hành grid search mà lấy lại các hyper parameters cũ để huấn luyện mô hình. Kết quả như hình trên mình thấy cũng khá tốt rồi, nên mình không tiến hành grid search lại để tìm kết quả tốt hơn.\nDựa vào kết quả chúng ta thu được, có thể nói rằng mô hình ESN dự đoán khá tốt dữ liệu thuộc dạng time series với độ hỗn loạn cao. Đây là một kết luận nhỏ của mình dựa vào bằng chứng trên việc mình test trên tập dữ liệu ngẫu nhiên mà mình có.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Apr 4, 2019","img":"","permalink":"/blog/2019-04-04-predicting-stock-prices-with-echo-state-networks/","series":null,"tags":["machine learning","deep learning","neural network","amazone","thế giới di động","mwg"],"title":"Dự Đoán Giá Cổ Phiếu Bằng Mô Hình Mạng Echo State Networks"},{"categories":null,"content":"Bạn huấn luyện một hình mất hơn 12 tiếng đồng hồ. Mọi thứ khá ổn: loss function giảm. Nhưng khi bạn mang mô hình ra predict thì điều tồi tệ nhất xảy ra: Tất cả trả về đều là 0, không có cái nào nhận dạng chính xác cả. \u0026ldquo;Điều gì đã xảy ra, bạn đã làm gì sai?\u0026rdquo;. Bạn hỏi máy tính, nó không trả lời bạn. Bạn đập bàn, đập ghế trong cơn tức giận và chẳng giải quyết được điều gì cả.\nCó rất nhiều nguyên nhân gây ra vấn đề này. Việc cần làm của các bạn là phải tìm ra chính xác nguyên nhân và \u0026ldquo;sửa\u0026rdquo; nó, sau đó tốn hơn 12 tiếng đồng hồ để huấn luyện lại :), rồi lại sửa \u0026hellip;\nHướng dẫn ban đầu Nếu bạn gặp tình trạng như phần mô tả ở trên, bạn hãy thực hiện các bước mình mô tả bên dưới thử xem vấn đề của bạn là gì?\n  Bắt đầu huấn luyện mô hình bằng một mô hình đơn giản mà bạn biết chắc rằng nó hoạt động tốt với tập dữ liệu bạn đang có. Ví dụ, trong bài toán object detection, hãy sử dụng mô hình VGG. Và bạn hãy cố gắng sửa dụng standard loss nếu có thể.\n  Bỏ qua những thứ râu ria như là regularization hoặc data augmentation. Hãy tập trung vào xây dựng một mô hình cho một kết quả khả quan cái đã, sau đó mới cải tiến bằng các thứ râu ria trên sau.\n  Nếu bạn finetuning một mô hình, bạn hãy kiểm tra thật kỹ quá trình tiền xử lý dữ liệu. Chắc chắn rằng quá trình tiền xử lý của bạn giống y chang quá trình tiền xử lý của mô hình gốc.\n  Chắc chắn 100% rằng giá trị đầu vào là đúng.\n  Bắt đầu bằng một tập sample nhỏ (từ 2 đến 20 mẫu). Huấn luyện nó đến khi bị overfit và bổ sung thêm mẫu huấn luyện sau khi mô hình của bạn bị overfit.\n  Bổ sung thên các yếu tố râu ria như augmentation/regularization, custom loss functions, thử với một mô hình phức tạp hơn.\n  Nếu những cách trên vẫn không thành công. Mô hình vẫn trả về giá trị zero. Bạn có thể mắc phải một số lỗi được liệt kê bên dưới.\nKiểm tra rằng dữ liệu của bạn đưa vào mạng neural netwok thật sự có ý nghĩa và đúng. Ví dụ, hãy đảm bảo rằng bạn không nhầm lẫn / swap giá trị giữa width và height của hình ảnh, hoặc một lý do nào đó bạn đưa vào một zero image, hoặc bạn chỉ huấn luyện duy nhất một batch (ví dụ dữ liệu bạn lớn, chia làm 10 batch, và code nhầm sao đó chỉ đưa input là batch số 1 vào).\nMột trường hợp nữa là khi input và output của bạn chẳng có mối liên hệ gì với nhau, và không cách nào nhận biết rằng nó phụ thuộc nhau bởi vì bản chất của dữ liệu là như vậy, hoặc input của bạn đang có chưa đủ chứng cứ để suy ra output. Một ví dụ của trường hợp này là giá chứng khoáng.\nKiểm tra kỹ dữ liệu train để đảm bảo không có đánh nhãn sai\nKiểm tra xem dữ liệu có bị mất cân bằng không. Hãy sử dụng các kỹ thuật để cân bằng lại dữ liệu.\nĐảm bảo rằng trong 1 batch chứa dữ liệu của nhiều hơn 1 nhãn. Hãy xáo trộn ngẫu nhiên dữ liệu để tránh lỗi này.\nBài báo https://arxiv.org/abs/1609.04836 chỉ ra rằng khi bạn huấn luyện mô hình với batch size lớn có thể làm giảm tính tổng quát của mô hình.\nKhoá học CS231 đã chỉ ra một lỗi khá phổ biến: \u0026ldquo;Bất kỳ một quá trình tiền xử lý nào cũng phải thực hiện trên tập train, và sau đó áp dụng vào tập validation,test\u0026rdquo;. Ví dụ, chúng ta tính trung bình trên toàn bộ dữ liệu, rồi sau đó chia tập dữ liệu thành train, test, predict là không đúng. Hành động đúng là chia tập dữ liệu thành train, test, vali trước, sau đó tính giá trị trung bình trên từng kênh màu trên tập train, rồi mới lấy giá trị trung bình đó áp cho tập test và tập validate.\nMột vấn đề khác có thể là \u0026ldquo;Look for correct loss at chance performance\u0026rdquo;:\nVí dụ, với tập dữ liệu CIFAR-10 sử dụng softmax classifier, ở lần đầu tiên, giá trị loss mong đợi của chúng ta là 2.303, bởi vì có 1 thằng đúng, 10 thằng sai, xác suất là 1/10 = 0.1. softmax loss là -ln(0.1) = 2.302.\nVới dữ liệu CIFAR-10 dùng SVM, ở lần lặp đầu tiên, giá trị loss chúng ta kỳ vọng là 9 (với mỗi lớp sai, giá trị margin sẽ là 1).\nNếu các giá trị trả ra không giống như mong đợi, vấn đề xảy ra là do giá trị init không đúng.\nMột vấn đề nữa là khi tăng giá trị regularization thì cũng đồng thời tăng giá trị loss. =\u0026gt; Nếu loss không tăng =\u0026gt; có vấn đề.\nBài viết được lược dịch từ https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607?fbclid=IwAR1Qj6jJW87oKi_LR7xWMDOMZDTx8xwLZEhCCMuvOw63ztwdD1MknZVjm_Q\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Apr 2, 2019","img":"","permalink":"/blog/2019-04-02-37-reason-neural-network-not-working/","series":null,"tags":["machine learning","deep learning","neural network"],"title":"Các Lý Do Mạng Neural Network Không Hoạt Động Không Chính Xác"},{"categories":null,"content":"Trong vài năm trở lại đây (khoảng từ 2013) truyền thông trong và ngoài nước có khá nhiều bài viết giật tít về “Cách mạng công nghiệp lần thứ tư” hay “Thời đại công nghiệp 4.0”. Cùng với các cụm từ này, “Trí tuệ nhân tạo”, “Máy học”, “Dữ liệu lớn” lại được nhắc đến với tần suất cao hơn. Vậy thì những thuật ngữ này có ý nghĩa gì và giữa chúng có mối liên hệ nào với nhau hay không? Trong bài viết này, chúng ta sẽ cùng tìm hiểu.\nTrí tuệ nhân tạo Năm 2016, trong “Trận thách đấu của Google DeepMind” được tổ chức tại Hàn Quốc, AlphaGo (một phần mềm chơi cờ vây trên máy tính được xây dựng bởi Google DeepMind) đã dành chiến thắng 4/5 ván trước Lee Sedol (người từng 18 lần vô địch giải cờ vây thế giới) là sự kiện quan trọng khiến con người có thể tin tưởng vào tương lai và sức mạnh của trí tuệ nhân tạo.\nSau khi trận đấu kết thúc, chính phủ Hàn Quốc công bố rằng họ sẽ đầu từ 863 triệu USD (khoảng 1 nghìn tỷ won) vào nghiên cứu trí tuệ nhân tạo trong vòng vài năm tiếp theo.\nTính tới nay, lượng dữ liệu các trận đấu cờ vây được nhận vào giúp AlphaGO có kinh nghiệm tương đương với 80 năm chơi cờ vây liên tục. Một con số đáng ngạc nhiên và ngưỡng mộ.\nNhư vậy trí tuệ nhân tạo là gì?\nTrí tuệ nhân tạo (AI - Artificial Intelligence) là một nhánh nghiên cứu trong lĩnh vực khoa học máy tính và từ lâu đã được rất nhiều các nhà nghiên cứu quan tâm. Thuật ngữ AI được đặt bởi nhà khoa học máy tính người Mỹ - John McCarthy vào năm 1956 tại Hội nghị Dartmouth. Cho đến thời điểm hiện tại thì có khá nhiều những phát biểu khác nhau về AI bởi các chuyên gia, chẳng hạn như:\n  AI là khoa học nghiên cứu giúp tạo ra máy tính có khả năng suy nghĩ, đầy trí tuệ như tên của chính nó (Haugeland, 1985).\n  AI là khoa học nghiên cứu các hoạt động trí não thông qua các mô hình tính toán (Chaniaka và McDemott, 1985).\n  AI là khoa học nghiên cứu cách để máy tính có thể thực hiện được những công việc mà con người làm tốt hơn máy (Rich và Knight, 1991).\n  AI là khoa học nghiên cứu các mô hình máy tính có thể nhận thức, lập luận và hành động (Winston, 1992).\n  AI là khoa học nghiên cứu các hành vi thông minh mô phỏng các vật thể nhân tạo (Nilsson, 1998)\n  AI là khoa học nghiên cứu các hành vi thông minh nhằm giải quyết các vấn đề được đặt ra đối với các chương trình máy tính (Học viện Kỹ thuật Quân sự).\n  Như vậy, từ những định nghĩa trên chúng ta có thể rút ra định nghĩa tổng quát rằng trí tuệ nhân tạo hay trí thông minh nhân tạo là trí tuệ được biểu diễn bởi bất kỳ một hệ thống nhân tạo nào. Hệ thống đó sẽ mô phỏng các quá trình hoạt động trí tuệ của con người, bao gồm quá trình học tập, lập luận và tự sửa lỗi. Do đó, trí thông minh nhân tạo liên quan đến cách hành xử, sự học hỏi và khả năng thích ứng thông minh của máy móc nói chung và máy tính nói riêng.\nCách đây vài năm, đối với phần đông chúng ta – những người không nghiên cứu chuyên sâu về AI sẽ cho rằng AI là một phương thức để nhân bản con người bằng máy móc và được ứng dụng trong chế tạo robot. Tuy nhiên AI hiện tại không phải chỉ là những con robot mà nó có thể biểu hiện dưới bất cứ hình dạng nào, thậm chí vô hình vô dạng, nhằm cung cấp lời giải cho các vấn đề của cuộc sống thực tế trên hầu hết các lĩnh vực, chẳng hạn như:\n  Trong lĩnh vực chăm sóc sức khỏe: AI góp phần cải thiện tình trạng sức khỏe bệnh nhân, và giúp giảm chi phí điều trị. Một trong những hệ thống công nghệ chăm sóc sức khỏe tốt nhất phải kể đến là IBM Watson, được mệnh danh là “Bác sĩ biết tuốt” khi mà hệ thống này có khả năng hiểu được các ngôn ngữ tự nhiên và có khả năng phản hồi các câu hỏi được yêu cầu hoặc cho phép bệnh nhân tra cứu thông tin về tinh hình sức khoẻ của mình. IBM Watson có thể lướt duyệt cùng lúc hàng triệu hồ sơ bệnh án để cung cấp cho các bác sĩ những lựa chọn điều trị dựa trên bằng chứng chỉ trong vòng vài giây nhờ khả năng tổng hợp dữ liệu khổng lồ và tốc độ xử lý mạnh mẽ. “Bác sĩ biết tuốt” khai thác dữ liệu bệnh nhân và các nguồn dữ liệu sẵn có khác nhằm tạo ra giả thuyết và từ đó xậy dựng một lược đồ điểm tin cậy giúp “Bác sĩ thật” đưa ra quyết định điều trị cuối cùng. Ngoài ra, ứng dụng AI nổi bậc khác trong lĩnh vực này cần phải kể đến là chatbot - chương trình máy tính trực tuyến để trả lời các câu hỏi và hỗ trợ khách hàng, sắp xếp các cuộc hẹn hoặc trợ giúp bệnh nhân thông qua quá trình thanh toán và các trợ lý y tế ảo cung cấp phản hồi y tế cơ bản.\n  Trong lĩnh vực kinh doanh: Các tác vụ mà con người thực hiện lặp đi lặp lại giờ đây đã được tự động hoá quy trình bằng robot. Các thuật toán Machine Learning được tích hợp trên các nền tảng phân tích và CRM (Customer Relationship Management - quản lý quan hệ khách hàng) để khám phá các thông tin về cách phục vụ khách hàng tốt hơn. Chatbots được tích hợp trên các trang web nhằm cung cấp dịch vụ ngay lập tức cho khách hàng. Một số hệ thống trợ lý ảo nổi tiếng giúp sắp xếp, nhắc cuộc họp, tìm kiếm thông tin như Google Assistant, Alexa, Siri. Hiện nay các hệ thống này đã bắt đầu được tích hợp vào trong các thiết bị gia dụng như máy giặt, tủ lạnh, lò vi sóng, … giúp người sử dụng có thể điều khiển thiết bị bằng câu lệnh thoại.\n  Trong lĩnh vực giáo dục: Công nghệ thực tế ảo làm thay đổi cách dạy và học. Sinh viên có thể đeo kính VR và có cảm giác như đang ngồi trong lớp nghe giảng bài hay nhập vai để chứng kiến những trận đánh giả lập, ngắm nhìn di tích, điều này giúp mang lại cảm xúc và ghi nhớ sâu sắc nội dung học. Hoặc khi đào tạo nghề phi công, học viên đeo kính sẽ thấy phía trước là cabin và học lái máy bay như thật để thực hành giúp giảm thiểu rủi ro trong quá trình bay thật.\n  Trong lĩnh vực tài chính: AI áp dụng cho các ứng dụng tài chính cá nhân như Mint hay Turbo Tax giúp tăng cường các định chế tài chính.\n  Trong lĩnh vực pháp luật: Quá trình khám phá, chọn lọc thông qua các tài liệu trong luật pháp thường áp đảo đối với con người. Tự động hóa quá trình này giúp tiết kiệm thời gian và quá trình làm việc hiệu quả hơn. Các trợ lý ảo giúp trả lời các câu hỏi đã được lập trình sẵn.\n  Trong lĩnh vực sản xuất: Đây là lĩnh vực đi đầu trong việc kết hợp robot vào luồng công việc. Robot công nghiệp được sử dụng để thực hiện các nhiệm vụ đơn lẻ và đã được tách ra khỏi con người. Xe tự động lái Tesla là một ứng dụng điển hình trong lĩnh vực này.\n  Trong lĩnh vực bảo mật thông tin: rất nhiều hệ thống nhận diện và bảo mật thông minh được xây dựng, phải kể đến như FaceID - bảo mật thông qua nhận diện khuôn mặt của Apple, Facebook với khả nhận diện khuôn mặt để gợi ý tag. Bên cạnh các nước phương Tây thì Trung Quốc hiện đang là quốc gia đi đầu trong việc sử dụng AI để nhận diện và quản lý công dân.\n  Từ những ứng dụng trên ta có thể thấy rằng nói đến AI là nói về não bộ chứ không phải là nói về một cơ thể, là phần mềm chứ không phải là phần cứng.\nDữ liệu lớn Một cách tổng quát thì dữ liệu là thông tin dưới dạng ký hiệu, chữ viết, chữ số, hình ảnh, âm thanh hoặc dạng tương tự. Từ thế kỷ thứ 3 trước CN, Thư viện Alexandria được coi là nơi chứa đựng toàn bộ kiến thức của loài người. Ngày nay, tổng lượng dữ liệu trên toàn thế giới đủ để chia đều cho mỗi đầu người một lượng nhiều gấp 320 lần lượng dữ liệu mà các sử gia tin rằng Thư viện Alexandria từng lưu trữ – ước tính vào khoảng 120 exabyte. Các nhà thống kê cho rằng, nếu tất cả những dữ liệu này được ghi vào đĩa CD và xếp chồng chúng lên nhau thì sẽ có tới 5 chồng đĩa mà mỗi chồng đều có độ cao bằng khoảng cách từ Trái Đất đến Mặt Trăng.\nSự bùng nổ dữ liệu này chỉ mới xuất hiện gần đây. Cách đây không lâu, vào năm 2000, chỉ một phần tư lượng dữ liệu lưu trữ trên toàn thế giới ở dạng kỹ thuật số, ba phần tư còn lại được người ta lưu trên giấy tờ, phim, và các phương tiện analog khác. Nhưng do lượng dữ liệu kỹ thuật số bùng nổ quá nhanh – cứ 3 năm lại tăng gấp đôi, làm cho tỉ lệ này nhanh chóng đảo ngược. Hiện nay, chỉ dưới 2% tổng lượng dữ liệu chưa được chuyển sang lưu trữ ở dạng kỹ thuật số.\nDưới đây là một vài ví dụ nhỏ minh hoạ cho sự dùng nổ của dữ liệu hiện nay:\nTheo Forbes, lượng dữ liệu mà người dùng tạo ra mỗi ngày là 2.5 tỷ tỷ bytes, một con số rất đáng kinh ngạc và dự đoán con số này sẽ tiếp tục bùng nổ nữa cùng với sự phát triển của Internet vạn vật (IoT – Internet of thing), khi mà hệ thống các thiết bị thông minh được kết nối và tương tác với nhau cũng như tương tác với người dùng, đồng thời thu thập dữ liệu. Dự báo có khoảng 200 tỷ thiết bị như thế vào năm 2020. Giả sử chỉ xét đến thiết bị tìm kiếm bằng giọng nói, hiện tại:\n  Có 33 triệu thiết bị qua giọng nói đang lưu thông.\n  8 triệu người dùng điều khiển giọng nói mỗi tháng.\n  Các câu lệnh tìm kiếm bằng giọng nói trên Google trong năm 2016 tăng 35 lần so với năm 2008.\n  Theo thống kê, hiện nay có hơn 7 tỷ người sử dụng internet. Trung bình Google xử lý hơn 40.000 tìm kiếm mỗi giây (tức khoảng 3.5 tỷ tìm kiếm mỗi ngày, nếu tính cả những cổ máy tìm kiếm khác ngoại trừ Google thì con số này lên tới 5 tỷ lượt/ngày, 100 tỷ lượt/tháng) và những con số này sẽ tiếp tục tăng lên theo từng giây.\nRất đông người yêu thích các phương tiện truyền thông xã hội và dĩ nhiên việc sử dụng chúng cũng sẽ tạo ra dữ liệu. Theo báo cáo Data Never Sleép 5.0 của Domo, trên các phương tiện truyền thông cứ mỗi một phút sẽ có (nguồn http://www.internetlivestats.com/google-search-statistics/):\n  527.760 bức ảnh được chia sẻ bởi người sử dụng Snapchat .\n  456.000 tweet được gửi lên Twitter.\n  46.740 bức ảnh được đăng bởi người dùng Instagram.\n  Hơn 120 người có công việc ổn định tham gia LinkedIn.\n  Với khoảng 2 tỷ người dùng, Facebook vẫn là mạng xã hội lớn nhất hành tinh và dưới đây là các số liệu liên quan đến Facebook (nguồn http://newsroom.fb.com/company-info/):\n  Hơn 900 triệu người thật sự sử dụng Facebook mỗi ngày, 82.8% trong số đó ở ngoài Mỹ và Canada.\n  307 triệu / 2 tỷ là người Châu Âu.\n  Cứ mỗi giây lại có 5 tài khoản mới được tạo ra.\n  510.000 bình luận được đăng tải và 293.000 trạng thái được cập nhật mỗi phút.\n  Hơn 300 triệu bức ảnh được tải lên mỗi ngày.\n  15.000 ảnh GIF được gửi thông qua Facebook Messenger.\n  Cũng thuộc sở hữu của Facebook, Instagram cũng có những con số ấn tượng:\n  600 triệu người dùng.\n  400 triệu người hoạt động mỗi ngày.\n  100 triệu người sử dụng tính năng Stories mỗi ngày.\n  Liên quan đến số lượng người dùng và dữ liệu chúng ta không thể không nhắc đến Youtube khi mà cứ mỗi một phút sẽ có khoảng 300 giờ video được đăng tải trên Youtube (nguồn https://www.youtube.com/yt/about/press/).\nTrong thời đại công nghệ, việc thông qua các trang web hẹn hò để tìm nửa còn lại không còn là điều xa lạ. Với hơn 20 tỷ lượt kết đôi, Tinder xứng đáng là nhịp cầu công nghệ thành công bậc nhất hiện tại. Cứ mỗi phút trôi qua Tinder có khoảng 990.000 lượt vuốt và hơn 26 triệu lượt hẹn hò mỗi ngày.\nNgoài việc liên kết, trao đổi với nhau qua mạng xã hội, trong công việc mọi người thường sử dụng email, skype để thư từ, liên lạc. Tính đến năm 2019 có khoảng 9 tỷ người sử dụng email và dưới đây là một vài con số thống kê các sự kiện xảy ra trong một phút:\n  Người dùng gửi đi 16 triệu văn bản.\n  156 triệu email được gửi đi với khoảng 16 triệu văn bản.\n  103.447.520 thư rác được gửi đi.\n  154.200 cuộc gọi Skype.\n  Không còn quá khó khăn trong việc lưu giữ các khoảnh khắc, ngày nay khi mà bất cứ ai cũng có thể sở hữu một chiếc điện thoại thông minh (smartphone) và ai cũng là nhiếp ảnh gia, cứ như thế có hàng nghìn tỷ bức ảnh được cho ra đời và lưu trữ trên điện thoại.\nThông qua những ví dụ vừa nêu có thể chúng ta sẽ nghĩ rằng dữ liệu lớn thuần tuý chỉ là vấn đề về kích cỡ, và nếu điều này là đúng thì dữ liệu bao nhiêu được cho là “lớn”?\nĐể trả lời câu hỏi này ta quay lại một chút về lịch sử của thuật ngữ “Big Data”. Không giống với AI và ML, Big Data không phải là một ngành khoa học chính thống mà chỉ là một thuật ngữ truyền thông mới xuất hiện trong vài năm trở lại đây. Nó không khác gì thuật ngữ “kỷ nguyên phần mềm” hay “cách mạng công nghiệp”. Mặc dù thuật ngữ này mới xuất hiện nhưng khối lượng dữ liệu tích tụ kể từ khi mạng Internet xuất hiện vào cuối thế kỷ trước cũng không phải là nhỏ từ ví dụ về thư viện Alexandria. Vậy thì câu hỏi đặt ra là tại sao với khối lượng khổng lồ như thế mà thời đó vẫn không gọi là Big Data? Câu trả lời là mặc dù được bao quanh bởi dữ liệu khổng lồ nhưng ở thời điểm đó con người không biết làm gì với chúng ngoài lưu trữ và sao chép. Cho đến khi các nhà khoa học nhận ra rằng trong đống dữ liệu này đang ẩn chứa một khối lượng tri thức khổng lồ. Những tri thức ấy có thể giúp ta hiểu thêm về con người và xã hội. Chẳng hạn như từ danh sách các bộ phim yêu thích của một cá nhân, chúng ta có thể rút ra được sở thích xem phem của người đó và gợi ý những bộ phim cùng thể loại. Hoặc từ danh sách tìm kiếm của cộng đồng mạng chúng ta sẽ biết được vấn đề nóng hổi nhất đang được quan tâm và sẽ tập trung đăng tải nhiều tin tức hơn về vấn đề đó, …\nNhư vậy, bùng nổ thông tin không phải là lý do duy nhất dẫn đến sự ra đời của cụm từ Big Data mà Big Data chỉ thực sự bắt đầu khi chúng ta hiểu được giá trị của thông tin ẩn chứa trong dữ liệu và có đủ tài nguyên cũng như công nghệ để có thể khai tác chúng trên quy mô lớn. Và không có gì ngạc nhiên khi Máy học chính là thành phần mấu chốt của công nghệ đó.\nMáy học và mối quan hệ với Trí tuệ nhân tạo cùng Dữ liệu lớn Để máy tính có khả năng suy nghĩ và trí tuệ như con người thì đòi hỏi máy tính phải có khả năng “học” mà không cần phải lập trình để thực hiện các tác vụ cụ thể đó. Về phía các nhà nghiên cứu AI, họ muốn xem thử liệu máy tính có thể học dữ liệu như thế nào? Từ đó thuật ngữ Máy học hay Học máy (ML – Machine Learning) được hình thành. Mặc dù không có nhiều định nghĩa như AI nhưng ML lại có 2 định nghĩa khá tường minh như sau:\n  Máy học là ngành học cung cấp cho máy tính khả năng học hỏi mà không cần được lập trình một cách rõ ràng (Arthur Samuel, 1959).\n  Theo Giáo sư Tom Mitchell – Carnegie Mellon University: Máy học là 1 chương trình máy tính được nói là học hỏi từ kinh nghiệm E từ các tác vụ T và với độ đo hiệu suất P nếu hiệu suất của nó áp dụng trên tác vụ T và được đo lường bởi độ đo P tăng từ kinh nghiệm E.\n  Một vài ví dụ minh hoạ cho định nghĩa của Tom Mitchell:\n•\tVí dụ 1: Giả sử như ta muốn máy tính xác định một tin nhắn có phải là SPAM hay không thì:\n  Tác vụ T: Xác định 1 tin nhắn có phải SPAM hay không?\n  Kinh nghiệm E: Xem lại những tin nhắn được đánh dấu là SPAM xem có những đặc tính gì để có thể xác định nó là SPAM.\n  Độ đo P: Là phần trăm số tin nhắn SPAM được phân loại đúng.\n  •\tVí dụ 2: Chương trình nhận dạng chữ số viết tay (bao gồm các chữ số từ 0 đến 9)\n  Tác vụ T: nhận dạng được ảnh chứa ký tự số.\n  Kinh nghiệm E: Đặc trưng để phân loại ký tự số từ tập dữ liệu số cho trước.\n  Độ đo P: Độ chính xác của quá trình nhận dạng.\n  Mối quan hệ giữa ML với AI và Big Data Trong phần 1 và phần 2 chúng ta luôn thấy sự xuất hiện của ML, đây là lý do vì sao mình không tách riêng mối quan hệ giữa các khái niệm này ra một phần riêng mà để chung trong nội dung của ML. Vậy thì mối liên hệ đó là gì?\nMột cách hàn lâm thì AI là ngành khoa học được sinh ra với mục tiêu là làm cho máy tính có được trí thông minh như con người. Mục tiêu này vẫn khá mơ hồ vì không phải ai cũng đồng ý với một định nghĩa thống nhất về trí thông minh. Các nhà khoa học phải định nghĩa một số mục tiêu cụ thể hơn, một trong số đó là việc làm cho máy tính lừa được Turing Test. Turing Test được tạo ra bởi Alan Turing (1912 – 1954), người được xem là cha để của ngành khoa học máy tính hiện đại, nhằm phân biệt xem người đối diện có phả là người hay không.\nNhư vậy, AI thể hiện một của mục tiêu con người, trong khi ML là một phương tiện được kỳ vọng sẽ giúp con người đạt được mục tiêu đó. Và trên thực tế thì ML đã mang nhân loại đi rất xa trên quãng đường chinh phục AI. Dù có mối quan hệ chặc chẽ với nhau nhưng chúng không hẳn là trùng khớp vì môt bên là mục tiêu (AI), một bên là phương tiện (ML). Chinh phục AI mặc dù vẫn là mục đích tối thượng của ML, nhưng hiện tại ML tập trung vào những mục tiêu ngắn hạn hơn như làm cho máy tính có khả năng nhận thức cơ bản của con người như nghe, nhìn, hiểu được ngôn ngữ, giải toán, lập trình, …, các khả năng này ứng với các lĩnh vực cụ thể trong AI như:\n  Thị giác máy tính (computer vision): mục tiêu của lĩnh vực này là làm cho máy tính có thể nhìn như con người. Những ứng dụng quan trọng có thể kể đến trong lĩnh vực này như là nhận dạng chữ/ chứ số viết tay, nhận dạng khuôn mặt, dáng đi, cử chỉ, phân loại loài hoa, nhãn hiệu, phát hiện đồ vât, …. Từ tập hình ảnh ban đầu, các thuật toán ML sẽ tiến hành xử lý, phân tích để rút ra các đặc trưng chính giúp nhận dạng đối tượng hoặc phân biệt các đối tượng với nhau.\n  Xử lý Ngôn ngữ tự nhiên (Natural Language Processing – NLP): Mục tiêu là giúp cho máy tính có thể hiểu như con người. Dịch máy là một trong những ứng dụng điển hình của NLP, dịch nội dung của một đoạn văn bản từ ngôn ngữ này sang ngôn ngữ khác (Google Translate). Xuất phát từ “Từ điển” hoặc tập các cặp câu song ngữ, tập luật ngữ pháp của mỗi ngôn ngữ được tạo bởi người có chuyên môn về những ngôn ngữ đó, các thuật toán máy học sẽ tiến hành phân tích để tách câu, tách từ, xác định từ loại, phân tích cú pháp để từ đó lấy ra ngữ nghĩa phù hợp rồi ghép lại với nhau và cho ra nội dung ở ngôn ngữ tương ứng. Ngoài ra, tóm tắt văn bản dựa vào các từ khoá của từng lĩnh vực cũng là một bài toán ML rất được quan tâm trong vài năm trở lại đây, khi mà mỗi ngày lượng tin tức cần phải đọc là quá nhiều.\n  Xử lý tiếng nói (Speech Language Processing): nhằm làm cho máy tính có thể nghe được như người. Tổng hộp tiếng nói (text to speech) để đọc sách cho người khiếm thị, tạo sub cho các video (speech to text) để hỗ trợ cho người khiếm thính hoặc hỗ trợ cho việc học ngôn ngữ; nhận dạng giọng nói (speech recognition) giúp phát hiện tội phạm là một số ứng dụng điển hình trong lĩnh vực này.\n  Thay vì cố gắng “dạy” máy tính cách làm một việc gì đó, chẳng hạn như lái xe hơi, điều mà các chuyên gia AI cần làm là cung cấp “đủ” dữ liệu cho một máy tính để nó có thể tính ra xác suất của tất cả mọi thứ mà người ta muốn tính toán, ví như xác suất người đi đường gặp đèn giao thông màu xanh, màu đỏ, màu vàng, … thì chuẩn xác hơn.\nDo đó, nhiệm vụ thực sự của ML trong AI là “học” mà thực chất của việc học này là rút trích thông tin hữu ích cho từng bài toán trong “tập dữ liệu” cho trước. Lúc này mối quan hệ giữa ML và Big Data sẽ được bộc lộ, đó là nếu khối lượng dữ liệu của Big Data càng gia tăng thì ML sẽ phát triển hơn, có khả năng rút trích được nhiều thông tin giá trị hơn hay dự đoán chính xác hơn, ngược lại thì giá trị của Big Data phụ thuộc vào khả năng khai thác tri thức từ dữ liệu của ML, vì nó sẽ thực sự là Big Data khi khối lượng dữ liệu đó mang lại thông tin hữu ích.\nViệc sử dụng những khối lượng thông tin theo cách này đòi hỏi chúng ta phải có sự thay đổi trong cách tiếp cận dữ liệu. Một là thu thập và sử dụng thật nhiều dữ liệu thay vì chấp nhận lấy những mẫu thống kê với số lượng nhỏ như các nhà thống kê vẫn làm từ hơn một thế kỷ nay. Hai là không nhất thiết phải kén chọn sàng lọc ra dữ liệu sạch, vì kinh nghiệm thực tiễn cho thấy rằng một chút sai lệch trong thông tin vẫn có thể chấp nhận được, và việc sử dụng một lượng khổng lồ những dữ liệu ô hợp đem lại nhiều ích lợi hơn là dữ liệu tuy chính xác nhưng dung lượng quá ít. Ba là trong nhiều trường hợp, chúng ta không nhất thiết phải cố tìm ra nguyên nhân đằng sau các hiện tượng.Ví dụ, không cần phải cố tìm hiểu chính xác vì sao một cỗ máy bị hỏng, thay vào đó các nhà nghiên cứu có thể thu thập và phân tích thật nhiều dữ liệu về chúng cùng tất cả mọi thứ liên quan, từ đó rút ra quy luật làm cơ sở dự đoán các sự vật, sự việc trong tương lai.\nDưới đây là một số tài liệu mình đã sử dụng để tham khảo trong qua trình viết bài:\nIntroduction to Machine Learning of Alex Smola and S.V.N. Vishwanathan.\nArtificial Intelligence (third edition) of The McGraw-Hill Companies, write by Elaine Rich, Kevin Knight and Shivashankar B Nair.\nhttps://i4iam.files.wordpress.com/2013/08/artificial-intelligence-by-rich-and-knight.pdf\nhttps://en.wikipedia.org/wiki/Artificial_intelligence\nhttps://searchenterpriseai.techtarget.com/definition/AI-Artificial-Intelligence\nhttp://vienthongke.vn/tin-tuc/43-tin-tuc/2176-thoi-dai-cua-du-lieu-lon-big-data\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở những bài viết tiếp theo.\n","date":"Apr 2, 2019","img":"","permalink":"/blog/2019-04-02-deep-learning-view/","series":null,"tags":["machine learning","deep learning"],"title":"Trí Tuệ Nhân Tạo, Máy Học, Dữ Liệu Lớn"},{"categories":null,"content":"Bắt đầu Đầu tiên, chúng ta sẽ download tập dataset balloon tại https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip, giải nén và bỏ trong thư mục datasets. Tiếp đó, các bạn donwload file balloon.py và visualize.py về. File đầu tiên hỗ trợ chúng ta đọc dữ liệu của dataset balloon và file thứ hai hỗ trợ visualize hình ảnh một cách trực quan. Cả hai file mình đều lấy mã nguồn của Matterport trên https://github.com/matterport/Mask_RCNN/ Tiến hành import các thư viện cần thiết về.\n1import os 2import sys 3import itertools 4import math 5import logging 6import json 7import re 8import random 9from collections import OrderedDict 10import numpy as np 11import matplotlib 12import matplotlib.pyplot as plt 13import matplotlib.patches as patches 14import matplotlib.lines as lines 15from matplotlib.patches import Polygon 161718import balloon 19import utils 20import visualize 2122config = balloon.BalloonConfig() 23BALLOON_DIR = \u0026#34;datasets/balloon\u0026#34; Thông tin của tập train bao gồm\n1dataset = balloon.BalloonDataset() 2dataset.load_balloon(BALLOON_DIR, \u0026#34;train\u0026#34;) 34# Must call before using the dataset 5dataset.prepare() 67print(\u0026#34;Image Count: {}\u0026#34;.format(len(dataset.image_ids))) 8print(\u0026#34;Class Count: {}\u0026#34;.format(dataset.num_classes)) 9for i, info in enumerate(dataset.class_info): 10print(\u0026#34;{:3}. {:50}\u0026#34;.format(i, info[\u0026#39;name\u0026#39;])) 1Image Count: 61 2Class Count: 2 30. BG 41. balloon Vậy là có tổng cộng 61 hình train. Dữ liệu được đánh làm 2 nhãn, một nhãn là background, một nhãn là balloon.\nVisualize dữ liệu Chúng ta sẽ load một vài hình lên xem người ta đã mask dữ liệu như thế nào. Ở đây, với mỗi hình ảnh, mình sẽ load 1 hình gốc và 4 hình của 4 quả bóng tương ứng trong hình, nếu trong hình có nhiều hơn 4 quả bóng thì chỉ vẽ 4 quả bóng đầu tiên\n123n_col = 5 45# Load and display random samples 6fig, axs = plt.subplots(nrows=4, ncols=n_col, figsize=(9.3, 6),subplot_kw={\u0026#39;xticks\u0026#39;: [], \u0026#39;yticks\u0026#39;: []}) 7fig.subplots_adjust(left=0.03, right=0.97, hspace=0.3, wspace=0.05) 8image_ids = np.random.choice(dataset.image_ids, 4) 9# for image_id in image_ids: 10# for ax, image_id in zip(axs.flat, image_ids): 1112for index in range(0,4): 13image_id = image_ids[index] 1415image = dataset.load_image(image_id) 16mask, class_ids = dataset.load_mask(image_id) 17print(mask.shape) 18print(len(class_ids)) 1920axs.flat[index*n_col].imshow(image) 21axs.flat[index*n_col].set_title(\u0026#39;img\u0026#39;) 2223for sub_index in range(0,len(class_ids)): 24if sub_index \u0026gt;= n_col: 25break 26axs.flat[index*n_col +1 + sub_index].imshow(mask[:,:,sub_index]) 27axs.flat[index*n_col + 1+sub_index].set_title(str(dataset.class_names[class_ids[sub_index]])) 282930plt.tight_layout() 31plt.show() Các bạn có thể sử dụng hàm display_top_masks của tác giả Mask R-CNN để xem thử, hàm của họ hơi khác của mình một chút.\n12image_ids = np.random.choice(dataset.image_ids, 4) 3for image_id in image_ids: 4image = dataset.load_image(image_id) 5mask, class_ids = dataset.load_mask(image_id) 6visualize.display_top_masks(image, mask, class_ids, dataset.class_names) Bounding Boxes Chúng ta có 2 cách để lấy Bounding Boxes của các hình. Một là lấy trực tiếp từ tập dataset (đối với những dataset có lưu bounding box), hai là rút trích bounding box từ các toạ độ mask. Chúng ta nên thực hiện cách hai, lý do là chúng ta sẽ dùng các kỹ thuật Data Generator để sinh nhiều ảnh hơn cung cấp cho thuật toán train. Lúc này, việc tính lại bounding box sẽ dễ dàng hơn.\n12# Load random image and mask. 3image_id = random.choice(dataset.image_ids) 4image = dataset.load_image(image_id) 5mask, class_ids = dataset.load_mask(image_id) 67# Compute Bounding box 8bbox = utils.extract_bboxes(mask) 910# Display image and additional stats 11print(\u0026#34;image_id \u0026#34;, image_id, dataset.image_reference(image_id)) 1213# Display image and instances 14visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names) Resize Images Các ảnh trong tập train có các kích thước khác nhau. Các bạn có thể xem các hình ở trên, có ảnh có kích thước này, có ảnh có kích thước kia. Chúng ta sẽ resize chúng về cùng một kích thước (ví dụ 1024x1024) để làm đầu vào cho tập huấn luyện. Và chúng ta sẽ sử dụng zero padding để lấp đầy những khoảng trống của những ảnh không đủ kích thước.\n1234# Load random image and mask. 5image_id = np.random.choice(dataset.image_ids, 1)[0] 6image = dataset.load_image(image_id) 7mask, class_ids = dataset.load_mask(image_id) 8original_shape = image.shape 9# Resize 10image, window, scale, padding, _ = utils.resize_image( 11image, 12min_dim=config.IMAGE_MIN_DIM, 13max_dim=config.IMAGE_MAX_DIM, 14mode=config.IMAGE_RESIZE_MODE) 15mask = utils.resize_mask(mask, scale, padding) 16# Compute Bounding box 17bbox = utils.extract_bboxes(mask) 1819# Display image and additional stats 20print(\u0026#34;image_id: \u0026#34;, image_id, dataset.image_reference(image_id)) 21print(\u0026#34;Original shape: \u0026#34;, original_shape) 22print(\u0026#34;Resize shape: \u0026#34;, image.shape) 23# Display image and instances 24visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names) Kết quả\n1image_id: 9 datasets/balloon\\train\\15290896925_884ab33fd3_k.jpg 2Original shape: (1356, 2048, 3) 3Resize shape: (1024, 1024, 3) Lưu ý một điều là ở đây, mình sử dụng random image, nên nếu các bạn chạy lại câu lệnh như mình thì kết quả ra phần nhiều sẽ khác mình. Tuy nhiên, Resize shape luôn là (1024, 1024, 3).\nMini Masks Một vấn đề khá nghiêm trọng ở đây là chúng ta cần khá nhiều bộ nhớ để lưu các masks. Numpy sử dụng 1 byte để lưu 1 giá trị bit. Do đó, với kích thước ảnh là 1024x1024, chúng ta cần 1MB bộ nhớ ram để lưu trữ. Nếu chúng ta có tập dataset tầm 1000 bức ảnh thì cần đến 1GB bộ nhớ, khá là lớn. Ngoài việc tốn bộ nhớ lữu trữ, chúng còn làm chậm tốc độ huấn luyện mô hình nữa.\nĐể cải tiến, chúng ta có thể sử dụng một trong hai cách sau:\n Cách thứ nhất: Thay vì lưu toàn bộ mask của toàn bức ảnh, chúng ta chỉ lưu những pixel của mask trong bounding box. Với việc sử dụng cách này, chúng ta sẽ tiết kiệm kha khá bộ nhớ chính. Cách thứ hai: Chúng ta có thể resize mask về một kích thước chuẩn nào đó, ví dụ 48x48 pixel. Với những mask có kích thước lớn hơn 48x48, chúng sẽ bị mất thông tin.  Mình không thích cách thứ hai cho lắm. Tuy nhiên, theo lý giải của nhóm tác giả Mask R-CNN, thì hầu hết việc gán các đường biên (object annotations) thường không chính xác cho lắm (thừa hoặc thiếu một vài chỗ), cho nên, việc mất mát thông tin với lượng nhỏ này hầu như là không đáng kể.\nĐể đánh giá hiệu quả của hàm mask resizing, chúng ta sẽ chạy đoạn code bên dưới và xem ảnh kết quả. Đoạn code trên mình sử dụng 2 hàm compose_image_meta và load_image_gt của tác giả ở đường dẫn https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/model.py. Mình có modify lại hàm load_image_gt một chút để hợp với ý mình hơn.\n1############################################################ 2# Data Formatting 3############################################################ 45def compose_image_meta(image_id, original_image_shape, image_shape, 6window, scale, active_class_ids): 7\u0026#34;\u0026#34;\u0026#34;Takes attributes of an image and puts them in one 1D array. 8image_id: An int ID of the image. Useful for debugging. 9original_image_shape: [H, W, C] before resizing or padding. 10image_shape: [H, W, C] after resizing and padding 11window: (y1, x1, y2, x2) in pixels. The area of the image where the real 12image is (excluding the padding) 13scale: The scaling factor applied to the original image (float32) 14active_class_ids: List of class_ids available in the dataset from which 15the image came. Useful if training on images from multiple datasets 16where not all classes are present in all datasets. 17\u0026#34;\u0026#34;\u0026#34; 18meta = np.array( 19[image_id] + # size=1 20list(original_image_shape) + # size=3 21list(image_shape) + # size=3 22list(window) + # size=4 (y1, x1, y2, x2) in image cooredinates 23[scale] + # size=1 24list(active_class_ids) # size=num_classes 25) 26return meta 272829def load_image_gt(dataset, config, image_id, augment=False, augmentation=None, 30use_mini_mask=False): 31\u0026#34;\u0026#34;\u0026#34;Load and return ground truth data for an image (image, mask, bounding boxes). 32augment: (deprecated. Use augmentation instead). If true, apply random 33image augmentation. Currently, only horizontal flipping is offered. 34augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation. 35For example, passing imgaug.augmenters.Fliplr(0.5) flips images 36right/left 50% of the time. 37use_mini_mask: If False, returns full-size masks that are the same height 38and width as the original image. These can be big, for example 391024x1024x100 (for 100 instances). Mini masks are smaller, typically, 40224x224 and are generated by extracting the bounding box of the 41object and resizing it to MINI_MASK_SHAPE. 42Returns: 43image: [height, width, 3] 44shape: the original shape of the image before resizing and cropping. 45class_ids: [instance_count] Integer class IDs 46bbox: [instance_count, (y1, x1, y2, x2)] 47mask: [height, width, instance_count]. The height and width are those 48of the image unless use_mini_mask is True, in which case they are 49defined in MINI_MASK_SHAPE. 50\u0026#34;\u0026#34;\u0026#34; 51# Load image and mask 52image = dataset.load_image(image_id) 53mask, class_ids = dataset.load_mask(image_id) 54original_shape = image.shape 55image, window, scale, padding, crop = utils.resize_image( 56image, 57min_dim=config.IMAGE_MIN_DIM, 58min_scale=config.IMAGE_MIN_SCALE, 59max_dim=config.IMAGE_MAX_DIM, 60mode=config.IMAGE_RESIZE_MODE) 61mask = utils.resize_mask(mask, scale, padding, crop) 6263# Random horizontal flips. 64# TODO: will be removed in a future update in favor of augmentation 65if augment: 66logging.warning(\u0026#34;\u0026#39;augment\u0026#39; is deprecated. Use \u0026#39;augmentation\u0026#39; instead.\u0026#34;) 67if random.randint(0, 1): 68image = np.fliplr(image) 69mask = np.fliplr(mask) 7071# Augmentation 72# This requires the imgaug lib (https://github.com/aleju/imgaug) 73if augmentation: 74import imgaug 7576# Augmenters that are safe to apply to masks 77# Some, such as Affine, have settings that make them unsafe, so always 78# test your augmentation on masks 79MASK_AUGMENTERS = [\u0026#34;Sequential\u0026#34;, \u0026#34;SomeOf\u0026#34;, \u0026#34;OneOf\u0026#34;, \u0026#34;Sometimes\u0026#34;, 80\u0026#34;Fliplr\u0026#34;, \u0026#34;Flipud\u0026#34;, \u0026#34;CropAndPad\u0026#34;, 81\u0026#34;Affine\u0026#34;, \u0026#34;PiecewiseAffine\u0026#34;] 8283def hook(images, augmenter, parents, default): 84\u0026#34;\u0026#34;\u0026#34;Determines which augmenters to apply to masks.\u0026#34;\u0026#34;\u0026#34; 85return augmenter.__class__.__name__ in MASK_AUGMENTERS 8687# Store shapes before augmentation to compare 88image_shape = image.shape 89mask_shape = mask.shape 90# Make augmenters deterministic to apply similarly to images and masks 91det = augmentation.to_deterministic() 92image = det.augment_image(image) 93# Change mask to np.uint8 because imgaug doesn\u0026#39;t support np.bool 94mask = det.augment_image(mask.astype(np.uint8), 95hooks=imgaug.HooksImages(activator=hook)) 96# Verify that shapes didn\u0026#39;t change 97assert image.shape == image_shape, \u0026#34;Augmentation shouldn\u0026#39;t change image size\u0026#34; 98assert mask.shape == mask_shape, \u0026#34;Augmentation shouldn\u0026#39;t change mask size\u0026#34; 99# Change mask back to bool 100mask = mask.astype(np.bool) 101102# Note that some boxes might be all zeros if the corresponding mask got cropped out. 103# and here is to filter them out 104_idx = np.sum(mask, axis=(0, 1)) \u0026gt; 0 105mask = mask[:, :, _idx] 106class_ids = class_ids[_idx] 107# Bounding boxes. Note that some boxes might be all zeros 108# if the corresponding mask got cropped out. 109# bbox: [num_instances, (y1, x1, y2, x2)] 110bbox = utils.extract_bboxes(mask) 111112# Active classes 113# Different datasets have different classes, so track the 114# classes supported in the dataset of this image. 115active_class_ids = np.zeros([dataset.num_classes], dtype=np.int32) 116source_class_ids = dataset.source_class_ids[dataset.image_info[image_id][\u0026#34;source\u0026#34;]] 117active_class_ids[source_class_ids] = 1 118119# Resize masks to smaller size to reduce memory usage 120if use_mini_mask: 121if USE_MINI_MASK_SHAPE: 122mask = utils.minimize_mask(bbox, mask, MINI_MASK_SHAPE) 123else: 124mask = utils.minimize_mask(bbox, mask, mask.shape[:2]) 125126# Image meta data 127image_meta = compose_image_meta(image_id, original_shape, image.shape, 128window, scale, active_class_ids) 129130return image, image_meta, class_ids, bbox, mask 131132133image_id = np.random.choice(dataset.image_ids, 1)[0] 134image, image_meta, class_ids, bbox, mask = load_image_gt( 135dataset, config, image_id, use_mini_mask=False) 136137138visualize.display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 5))]) 139140image, image_meta, class_ids, bbox, mask = load_image_gt( 141dataset, config, image_id, use_mini_mask=True) 142143144visualize.display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 5))]) 145146USE_MINI_MASK_SHAPE = True 147148image, image_meta, class_ids, bbox, mask = load_image_gt( 149dataset, config, image_id, use_mini_mask=True) 150151152visualize.display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 5))]) 153154mask = utils.expand_mask(bbox, mask, image.shape) 155visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names) Với ảnh ở line 1 là ảnh gốc ban đầu và các full mask của bức ảnh, ảnh ở line 2 là chỉ lấy mask của bounding box, ảnh ở line 3 là lấy mask ở bounding box và scale ảnh (do scale ảnh nên ở line 3 các bạn sẽ thấy mask có hình răng cưa, khác với các mask line 2). Line 4 là ảnh ở line 3 được revert back lại hình gốc ban đầu. Các bạn có để ý thấy rằng nó sẽ bị răng cưa ở biên cạnh chứ không được smooth như ảnh gốc. Nếu chúng ta không làm object annotations kỹ, thì object cũng sẽ bị răng cưa như trên.\nAnchors Thứ tự của các anchor thật sự rất quan trọng. Trong quá trình train, thứ tự của các anchor như thế nào thì trong quá trình test, validation, prediction phải dùng y hệt vậy.\nTrong mạng FPN, các anchor phải được xắp xếp theo cách mà chúng ta có thể dễ dàng liên kết với giá trị output\n  Xắp xếp các anchor theo thứ tự các lớp của pyramid. Tất cả các anchor của level đầu tiên, tiếp theo là các anchor của các lớp thứ hai, lớp thư ba\u0026hellip; Việc xắp xếp theo cách này sẽ giúp chúng ta dễ dàng phân tách các lớp anchor và dễ hiểu theo lẽ tự nhiên.\n  Trong mỗi level, xắp xếp các anchor trong mỗi level bằng thứ tự xử lý của các feature map. Thông thường, một convolution layer sẽ dịch chuyển trên feature map bắt đầu từ vị trí trái - trên (top - left) đi xuống phải dưới (từ trái qua phải, xuống hàng rồi lại từ trái qua phải).\n  Trên mỗi cell của feature map, chúng ta sẽ xắp xếp các anchor theo các ratios.\n  Anchor Stride:\n12backbone_shapes = modellib.compute_backbone_shapes(config, config.IMAGE_SHAPE) 3anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES, 4config.RPN_ANCHOR_RATIOS, 5backbone_shapes, 6config.BACKBONE_STRIDES, 7config.RPN_ANCHOR_STRIDE) 89# Print summary of anchors 10num_levels = len(backbone_shapes) 11anchors_per_cell = len(config.RPN_ANCHOR_RATIOS) 12print(\u0026#34;Total anchors: \u0026#34;, anchors.shape[0]) 13print(\u0026#34;ANCHOR Scales: \u0026#34;, config.RPN_ANCHOR_SCALES) 14print(\u0026#34;BACKBONE STRIDE: \u0026#34;, config.BACKBONE_STRIDES) 15print(\u0026#34;ratios: \u0026#34;, config.RPN_ANCHOR_RATIOS) 16print(\u0026#34;Anchors per Cell: \u0026#34;, anchors_per_cell) 17# print(\u0026#34;Anchors stride: \u0026#34;, config.RPN_ANCHOR_STRIDE) 18print(\u0026#34;Levels: \u0026#34;, num_levels) 19anchors_per_level = [] 20for l in range(num_levels): 21num_cells = backbone_shapes[l][0] * backbone_shapes[l][1] 22print(\u0026#34;backbone_shapes in level \u0026#34;,l,\u0026#39; \u0026#39;,backbone_shapes[l][0],\u0026#39;x\u0026#39;,backbone_shapes[l][1]) 23print(\u0026#34;num_cells in level \u0026#34;,l,\u0026#39; \u0026#39;,num_cells) 24anchors_per_level.append(anchors_per_cell * num_cells // config.RPN_ANCHOR_STRIDE**2) 25print(\u0026#34;Anchors in Level {}: {}\u0026#34;.format(l, anchors_per_level[l])) 1Total anchors: 261888 2ANCHOR Scales: (32, 64, 128, 256, 512) 3BACKBONE STRIDE: [4, 8, 16, 32, 64] 4ratios: [0.5, 1, 2] 5Anchors per Cell: 3 6Levels: 5 7backbone_shapes in level 0 256 x 256 8num_cells in level 0 65536 9Anchors in Level 0: 196608 10backbone_shapes in level 1 128 x 128 11num_cells in level 1 16384 12Anchors in Level 1: 49152 13backbone_shapes in level 2 64 x 64 14num_cells in level 2 4096 15Anchors in Level 2: 12288 16backbone_shapes in level 3 32 x 32 17num_cells in level 3 1024 18Anchors in Level 3: 3072 19backbone_shapes in level 4 16 x 16 20num_cells in level 4 256 21Anchors in Level 4: 768 Trong kiến trức FPN, feature map tại một số layer đầu tiên là những feature map có độ phân giải lớn. Ví dụ, nếu bức ảnh đầu vào có kích thước là 1024x1024 pixel, và kích thước của mỗi anchor lớp đầu tiên là 32x32 pixel (giá trị đầu tiên của RPN_ANCHOR_SCALES (32, 64, 128, 256, 512)) và bước nhảy (STRIDE) của lớp đầu tiên là 4 (giá trị đầu tiên của BACKBONE_STRIDES ([4, 8, 16, 32, 64])). Từ những dữ kiện này, ta có thể suy ra được là sẽ sinh ra backbone cell có kích thước 256x256 pixel =\u0026gt; 256x256 = 65536 anchor. Với mỗi backbone cell, chúng ta thực hiện phép scale với 3 tỷ lệ khác nhau là [0.5, 1, 2], vậy chúng ta có tổng cộng là 65536x3 = 196608 anchor (xấp xỉ 200k anchor). Để ý một điều là kích thước của một anchor là 32x32 pixel, và bước nhảy là 4, cho nên chúng ta sẽ bị chống lấn (overlap) 28 pixel của anchor 1 và anchor 2 ngay sau nó.\nMột điều thú vị là, nếu ta tăng bước nhảy lên gấp 2 lần, ví dụ từ 4 pixel lấy một anchor lên 8 pixel lấy một anchor, thì số lượng anchor giảm đi đến 4 lần (196608 anchor ở level 0 so với 49152 anchor ở level 1).\nThử vẽ tất cả các anchor của tất cả các level ở điểm giữa một bức ảnh bức kỳ lên, mỗi một level sẽ dùng một màu khác nhau, chúng ta được một hình như bên dưới.\n1## Visualize anchors of one cell at the center of the feature map of a specific level 23# Load and draw random image 4image_id = np.random.choice(dataset.image_ids, 1)[0] 5image, image_meta, _, _, _ = modellib.load_image_gt(dataset, config, image_id) 6fig, ax = plt.subplots(1, figsize=(10, 10)) 7ax.imshow(image) 8levels = len(backbone_shapes) 910kn_color =np.array( [(255,0,0),(0,255,0),(0,0,255),(128,0,0),(0,128,0),(0,0,128)])/255. 1112for level in range(levels): 13# colors = visualize.random_colors(levels) 14colors = kn_color 15# Compute the index of the anchors at the center of the image 16level_start = sum(anchors_per_level[:level]) # sum of anchors of previous levels 17level_anchors = anchors[level_start:level_start+anchors_per_level[level]] 18print(\u0026#34;Level {}. Anchors: {:6}Feature map Shape: {}\u0026#34;.format(level, level_anchors.shape[0], 19backbone_shapes[level])) 20center_cell = backbone_shapes[level] // 2 21center_cell_index = (center_cell[0] * backbone_shapes[level][1] + center_cell[1]) 22level_center = center_cell_index * anchors_per_cell 23center_anchor = anchors_per_cell * ( 24(center_cell[0] * backbone_shapes[level][1] / config.RPN_ANCHOR_STRIDE**2) \\ 25+ center_cell[1] / config.RPN_ANCHOR_STRIDE) 26level_center = int(center_anchor) 2728# Draw anchors. Brightness show the order in the array, dark to bright. 29for i, rect in enumerate(level_anchors[level_center:level_center+anchors_per_cell]): 30y1, x1, y2, x2 = rect 31p = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, facecolor=\u0026#39;none\u0026#39;, 32edgecolor=np.array(colors[level]) / anchors_per_cell) 33print(i) 34ax.add_patch(p) 353637plt.show() Nhìn ảnh trên,các bạn phần nào đó mường tượng ra các anchor sẽ như thế nào rồi phải không.\nPrediction Để tiến hành detect vị trí quả bóng và mask của quả bóng, chúng ta download một ảnh small party nhỏ trên internet về và kiểm chứng.\n12import os 34import tensorflow as tf 56import cv2 78DEVICE = \u0026#34;/cpu:0\u0026#34; 9ROOT_DIR = os.path.abspath(\u0026#34;../../\u0026#34;) 10MODEL_DIR = os.path.join(ROOT_DIR, \u0026#34;logs\u0026#34;) 11# Create model in inference mode 1213class InferenceConfig(config.__class__): 14# Run detection on one image at a time 15GPU_COUNT = 1 16IMAGES_PER_GPU = 1 1718config = InferenceConfig() 19config.display() 2021with tf.device(DEVICE): 22model = modellib.MaskRCNN(mode=\u0026#34;inference\u0026#34;, model_dir=MODEL_DIR, 23config=config) 242526weights_path = \u0026#34;mask_rcnn_balloon.h5\u0026#34; 2728# Load weights 29print(\u0026#34;Loading weights \u0026#34;, weights_path) 30# model.load_weights(weights_path, by_name=True) 3132imgpath = \u0026#34;datasets\\\\balloon\\\\test\\\\t1.png\u0026#34; 33# imgpath = \u0026#34;datasets/balloon/val/14898532020_ba6199dd22_k.jpg\u0026#34; 3435image = cv2.imread(imgpath) 3637image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) 38394041ds_name = [\u0026#39;BG\u0026#39;, \u0026#39;balloon\u0026#39;] 424344results = model.detect([image], verbose=1) 4546def get_ax(rows=1, cols=1, size=16): 47\u0026#34;\u0026#34;\u0026#34;Return a Matplotlib Axes array to be used in 48all visualizations in the notebook. Provide a 49central point to control graph sizes. 5051Adjust the size attribute to control how big to render images 52\u0026#34;\u0026#34;\u0026#34; 53_, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows)) 54return ax 55# Display results 56ax = get_ax(1) 57r = results[0] 58visualize.display_instances(image, r[\u0026#39;rois\u0026#39;], r[\u0026#39;masks\u0026#39;], r[\u0026#39;class_ids\u0026#39;], 59dataset.class_names, r[\u0026#39;scores\u0026#39;], ax=ax, 60title=\u0026#34;Predictions\u0026#34;) 61plt.show() Kết quả nhận dạng khá chính xác phải không các bạn.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Mar 25, 2019","img":"","permalink":"/blog/2019-03-25-mask-rcnn-balloon/","series":null,"tags":["machine learning","deep learning","Mask R-CNN","balloon","bóng bay"],"title":"Tìm Hiểu Mask R-CNN Và Ví Dụ Phân Vùng Quả Bóng Bay Sử Dụng Deep Learning"},{"categories":null,"content":"Thêm dấu tiếng việt là một trong những bài toán khá hay trong xử lý ngôn ngữ tự nhiên. Ở đây, mình đã tiến hành thu thập dữ liệu bài báo của nhiều nguồn khác nhau như zing.vn, vnexpress, kenh14.vn \u0026hellip; làm kho ngữ liệu và xây dựng mô hình.\nĐể tiến hành thực nghiệm, mình sẽ lấy một số đoạn văn mẫu ở trang tin tức của thế giới di động (https.www.thegioididong.com) (mình không crawl nội dung tin tức ở trang này làm dữ liệu học).\nỞ bài viết link https://www.thegioididong.com/tin-tuc/3-ngay-cuoi-tuan-mua-laptop-online-tang-them-pmh-den-400k-tra-gop-0--1151334, mình lấy đoạn mở đầu \u0026ldquo;Từ ngày 15/3 đến 17/3, nhiều mẫu laptop tại Thế Giới Di Động sẽ được ưu đãi mạnh, tặng phiếu mua hàng đến 400 ngàn đồng, trả góp 0% và nhiều quà tặng hấp dẫn khác khi mua theo hình thức ONLINE. Nếu đang có nhu cầu mua laptop, bạn hãy nhanh chóng xem qua danh sách sản phẩm dưới đây nhé.\u0026rdquo;, bỏ dấu của câu đi, thì mình được câu\n\u0026ldquo;Tu ngay 15/3 den 17/3, nhieu mau laptop tai The Gioi Di Dong se duoc uu dai manh, tang phieu mua hang den 400 ngan dong, tra gop 0% va nhieu qua tang hap dan khac khi mua theo hinh thuc ONLINE. Neu dang co nhu cau mua laptop, ban hay nhanh chong xem qua danh sach san pham duoi day nhe.\u0026rdquo;\nSử dụng mô hình mình đã huấn luyện, thu được kết quả như sau:\n\u0026ldquo;Từ ngày 15/3 đến 17/3 m t m, nhiều mẫu laptoP tạI thế giỚi di động sẽ được ưu đãi mạnh, tang phiếu mua hàng đến 400 ngàn đồng, trả góp 0 r% và nhiều quà tặng hấp dẫn khác khi mua theo hìNH THỨc Onfine. nếu đang có nhu cầu mua laptop, bạn hãy nhanh chóng xem qua danh sách sản phẩm dưới\u0026rdquo;\nKết quả khá khả quan phải không các bạn, còn một số lỗi nhỏ ở phần nhận dạng ký tự hoa nữa. Mình sẽ fix lại ở các bài viết sau.\nMình thí nghiệm tiếp với phần đầu bài viết https://www.thegioididong.com/tin-tuc/apple-ban-ra-thi-truong-35-trieu-cap-tai-nghe-airpods-nam-2018-1155181. Đoạn \u0026ldquo;Hôm nay, báo cáo của Counterpoint Research cho thấy, trong năm 2018 Apple đã bán được khoảng 35 triệu cặp tai nghe không dây AirPods. Theo hãng phân tích này, AirPods hiện là tai nghe không dây phổ biến nhất.\u0026rdquo;, bỏ dấu tiếng việt là thu được \u0026ldquo;Hom nay, bao cao cua Counterpoint Research cho thay, trong nam 2018 Apple da ban duoc khoang 35 trieu cap tai nghe khong day AirPods. Theo hang phan tich nay, AirPods hien la tai nghe khong day pho bien nhat.\u0026rdquo;\nKết quả của mô hình: \u0026ldquo;Hôm nay, bạo cáo của Coorteenria eEeeroa c ttt, trong năm 2018 apple đã bán được khoảng 35 triệu cặp tại nghe không đầy aitcoDs. theo Hàng phân tích này, airxoDs Hiện là tai nghe không dạy phổ biến nhất.\u0026rdquo;\nMô hình của mình cho lặp 50 lần. Mình tiến hành thí nghiệm và publish mô hình ở lần lặp thứ 10.\nMã nguồn file predict\n1from keras.models import load_model 2model = load_model(\u0026#39;a_best_weight.h5\u0026#39;) 34from collections import Counter 56import numpy as np 78import utils 9import string 10import re 1112alphabet = set(\u0026#39;\\x00_\u0026#39; + string.ascii_lowercase + string.digits + \u0026#39;\u0026#39;.join(utils.ACCENTED_TO_BASE_CHAR_MAP.keys())) 1314print(\u0026#34;alphabet\u0026#34;,alphabet) 15codec = utils.CharacterCodec(alphabet, utils.MAXLEN) 1617def guess(ngram): 18text = \u0026#39; \u0026#39;.join(ngram) 19text += \u0026#39;\\x00\u0026#39; * (utils.MAXLEN - len(text)) 20if utils.INVERT: 21text = text[::-1] 22preds = model.predict_classes(np.array([codec.encode(text)]), verbose=0) 23rtext = codec.decode(preds[0], calc_argmax=False).strip(\u0026#39;\\x00\u0026#39;) 24if len(rtext)\u0026gt;0: 25index = rtext.find(\u0026#39;\\x00\u0026#39;) 26if index\u0026gt;-1: 27rtext = rtext[:index] 28return rtext 293031def add_accent(text): 32# lowercase the input text as we train the model on lowercase text only 33# but we keep the map of uppercase characters to restore cases in output 34is_uppercase_map = [c.isupper() for c in text] 35text = utils.remove_accent(text.lower()) 3637outputs = [] 38words_or_symbols_list = re.findall(\u0026#39;\\w[\\w ]*|\\W+\u0026#39;, text) 3940# print(words_or_symbols_list) 4142for words_or_symbols in words_or_symbols_list: 43if utils.is_words(words_or_symbols): 44outputs.append(_add_accent(words_or_symbols)) 45else: 46outputs.append(words_or_symbols) 47# print(outputs) 48output_text = \u0026#39;\u0026#39;.join(outputs) 4950# restore uppercase characters 51output_text = \u0026#39;\u0026#39;.join(c.upper() if is_upper else c 52for c, is_upper in zip(output_text, is_uppercase_map)) 53return output_text 5455def _add_accent(phrase): 56grams = list(utils.gen_ngram(phrase.lower(), n=utils.NGRAM, pad_words=utils.PAD_WORDS_INPUT)) 5758guessed_grams = list(guess(gram) for gram in grams) 59# print(\u0026#34;phrase\u0026#34;,phrase,\u0026#39;grams\u0026#39;,grams,\u0026#39;guessed_grams\u0026#39;,guessed_grams) 60candidates = [Counter() for _ in range(len(guessed_grams) + utils.NGRAM - 1)] 61for idx, gram in enumerate(guessed_grams): 62for wid, word in enumerate(re.split(\u0026#39; +\u0026#39;, gram)): 63candidates[idx + wid].update([word]) 64output = \u0026#39; \u0026#39;.join(c.most_common(1)[0][0] for c in candidates if c) 65return output.strip(\u0026#39;\\x00\u0026#39;) 66676869# print(add_accent(\u0026#39;do,\u0026#39;)) 70# print(add_accent(\u0026#39;7.3 inch,\u0026#39;)) 71# print(add_accent(\u0026#39;Truoc do, tren san khau su kien SDC 2018, giam doc cao cap mang marketing san pham di dong cua Samsung, ong Justin Denison da cam tren tay nguyen mau cua thiet bi nay. Ve co ban, no chang khac gi mot chiec may tinh bang 7.3 inch, duoc cau thanh tu nhieu lop phu khac nhau nhu polyme, lop man chong soc, lop phan cuc voi do mong gan mot nua so voi the he truoc, lop kinh linh hoat va mot tam lung da nang co the bien thanh man hinh. Tat ca se duoc ket dinh bang mot loai keo cuc ben, cho phep chiec may nay co the gap lai hang tram ngan lan ma khong bi hu hong.\u0026#39;)) 72# print(add_accent(\u0026#39;man hinh. Tat ca se duoc ket dinh bang mot loai keo cuc ben, cho phep chiec may nay co the gap lai hang tram ngan lan ma khong bi hu hong.\u0026#39;)) 73print(add_accent(\u0026#39;Hom nay, bao cao cua Counterpoint Research cho thay, trong nam 2018 Apple da ban duoc khoang 35 trieu cap tai nghe khong day AirPods. Theo hang phan tich nay, AirPods hien la tai nghe khong day pho bien nhat.\u0026#39;)) Mã nguồn file utils\n1import re 2import string 3import time 4from contextlib import contextmanager 5import numpy as np 6789# maximum string length to train and predict 10# this is set based on our ngram length break down below 11MAXLEN = 32 1213# minimum string length to consider 14MINLEN = 3 1516# how many words per ngram to consider in our model 17NGRAM = 5 1819# inverting the input generally help with accuracy 20INVERT = True 2122# mini batch size 23BATCH_SIZE = 128 2425# number of phrases set apart from training set to validate our model 26VALIDATION_SIZE = 100000 2728# using g2.2xl GPU is ~5x faster than a Macbook Pro Core i5 CPU 29HAS_GPU = True 3031PAD_WORDS_INPUT = True 3233### Ánh xạ từ không dấu sang có dấu 3435ACCENTED_CHARS = { 36\u0026#39;a\u0026#39;: u\u0026#39;a á à ả ã ạ â ấ ầ ẩ ẫ ậ ă ắ ằ ẳ ẵ ặ\u0026#39;, 37\u0026#39;o\u0026#39;: u\u0026#39;o ó ò ỏ õ ọ ô ố ồ ổ ỗ ộ ơ ớ ờ ở ỡ ợ\u0026#39;, 38\u0026#39;e\u0026#39;: u\u0026#39;e é è ẻ ẽ ẹ ê ế ề ể ễ ệ\u0026#39;, 39\u0026#39;u\u0026#39;: u\u0026#39;u ú ù ủ ũ ụ ư ứ ừ ử ữ ự\u0026#39;, 40\u0026#39;i\u0026#39;: u\u0026#39;i í ì ỉ ĩ ị\u0026#39;, 41\u0026#39;y\u0026#39;: u\u0026#39;y ý ỳ ỷ ỹ ỵ\u0026#39;, 42\u0026#39;d\u0026#39;: u\u0026#39;d đ\u0026#39;, 43} 4445### Ánh xạ từ có dấu sang không dấu 46ACCENTED_TO_BASE_CHAR_MAP = {} 47for c, variants in ACCENTED_CHARS.items(): 48for v in variants.split(\u0026#39; \u0026#39;): 49ACCENTED_TO_BASE_CHAR_MAP[v] = c 5051# \\x00 ký tự padding 5253### Những ký tự cơ bản, bao gồm ký tự padding, các chữ cái và các chữ số 54BASE_ALPHABET = set(\u0026#39;\\x00_\u0026#39; + string.ascii_lowercase + string.digits) 5556### Bộ ký tự bao gồm những ký tự cơ bản và những ký tự có dấu 57ALPHABET = BASE_ALPHABET.union(set(\u0026#39;\u0026#39;.join(ACCENTED_TO_BASE_CHAR_MAP.keys()))) 585960def is_words(text): 61return re.fullmatch(\u0026#39;\\w[\\w ]*\u0026#39;, text) 6263# Hàm bỏ dấu khỏi một câu 64def remove_accent(text): 65\u0026#34;\u0026#34;\u0026#34; remove accent from text \u0026#34;\u0026#34;\u0026#34; 66return u\u0026#39;\u0026#39;.join(ACCENTED_TO_BASE_CHAR_MAP.get(char, char) for char in text) 6768#hàm thêm padding vào một câu 69def pad(phrase, maxlen): 70\u0026#34;\u0026#34;\u0026#34; right pad given string with \\x00to exact \u0026#34;maxlen\u0026#34; length \u0026#34;\u0026#34;\u0026#34; 71return phrase + u\u0026#39;\\x00\u0026#39; * (maxlen - len(phrase)) 727374def gen_ngram(words, n=3, pad_words=True): 75\u0026#34;\u0026#34;\u0026#34; gen n-grams from given phrase or list of words \u0026#34;\u0026#34;\u0026#34; 76if isinstance(words, str): 77words = re.split(\u0026#39;\\s+\u0026#39;, words.strip()) 7879if len(words) \u0026lt; n: 80if pad_words: 81words += [\u0026#39;\\x00\u0026#39;] * (n - len(words)) 82yield tuple(words) 83else: 84for i in range(len(words) - n + 1): 85yield tuple(words[i: i + n]) 8687def extract_phrases(text): 88\u0026#34;\u0026#34;\u0026#34; extract phrases, i.e. group of continuous words, from text \u0026#34;\u0026#34;\u0026#34; 89return re.findall(r\u0026#39;\\w[\\w ]+\u0026#39;, text, re.UNICODE) 909192@contextmanager 93def timing(label): 94begin = time.monotonic() 95print(label, end=\u0026#39;\u0026#39;, flush=True) 96try: 97yield 98finally: 99duration = time.monotonic() - begin 100print(\u0026#39;: took {:.2f}s\u0026#39;.format(duration)) 101102class CharacterCodec(object): 103def __init__(self, alphabet, maxlen): 104self.alphabet = list(sorted(set(alphabet))) 105self.index_alphabet = dict((c, i) for i, c in enumerate(self.alphabet)) 106self.maxlen = maxlen 107108def encode(self, C, maxlen=None): 109maxlen = maxlen if maxlen else self.maxlen 110X = np.zeros((maxlen, len(self.alphabet))) 111for i, c in enumerate(C[:maxlen]): 112X[i, self.index_alphabet[c]] = 1 113return X 114115def try_encode(self, C, maxlen=None): 116try: 117return self.encode(C, maxlen) 118except KeyError: 119return None 120121def decode(self, X, calc_argmax=True): 122if calc_argmax: 123X = X.argmax(axis=-1) 124return \u0026#39;\u0026#39;.join(self.alphabet[x] for x in X) link donwnload mô hình ở lần lặp thứ 10 ở https://github.com/AlexBlack2202/alexmodel/blob/master/a_best_weight.h5?raw=true\nÀ, kết quả của câu nói phần mở đầu là \u0026ldquo;mẹ nói rằng em rất đậm đang\u0026rdquo;. Hi hi, may quá.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Mar 16, 2019","img":"","permalink":"/blog/2019-03-16-vietnamese-accent/","series":null,"tags":["machine learning","nlp","thêm dấu tiếng việt"],"title":"Thêm Dấu Tiếng Việt Cho Câu Không Dấu"},{"categories":null,"content":"Thông tin đang được cập nhật.\n","date":"Feb 28, 2019","img":"","permalink":"/about/","series":null,"tags":null,"title":"About"},{"categories":null,"content":"ĐIỀU KHOẢN SỬ DỤNG Thỏa thuận sử dụng và bảo mật này (sau đây gọi là “Thỏa thuận”) được lập ra bởi và giữa bạn (“bạn”) và Công ty Cổ phần công nghệ ePi (“ePi” hoặc “chúng tôi”) về việc sử dụng bất kỳ hay tất cả các loại dịch vụ (“Dịch vụ”) của Baomoi.com (“Baomoi”) của bạn. Bằng việc sử dụng Dịch vụ, bạn đồng ý chịu ràng buộc bởi những điều khoản và điều kiện này.\nDịch vụ được thiết kế để giúp bạn tiếp cận thông tin tin tức được liên kết từ các trang không do ePi sở hữu hoặc quản lý. Cụ thể, Dịch vụ cung cấp những mô tả ngắn gọn về các bài báo để giúp bạn xác định nội dung chính của bài báo mà bạn quan tâm. Khi bạn lựa chọn một bài báo, bạn sẽ được kết nối tới website chứa bài báo đó (sau đây gọi là “website được kết nối”).\nThuật ngữ “bạn” để chỉ tất cả các cá nhân và/hoặc các tổ chức truy cập vào Baomoi vì bất kỳ lý do nào.\nI. Thỏa thuận sử dụng I.1. Quyền gắn với Dịch vụ. ePi sở hữu và duy trì mọi quyền lợi sở hữu trí tuệ đối với Dịch vụ của mình nhưng ePi không tuyên bố là mình có quyền sở hữu trí tuệ đối với các bài báo tại các website được kết nối. Các quyền sở hữu trí tuệ này thuộc về các website được kết nối.\nePi cũng không chịu trách nhiệm về các thông tin, dịch vụ và nội dung của những website được kết nối. Bạn là người chịu hoàn toàn trách nhiệm trong việc sử dụng, khai thác, cung cấp thông tin cá nhân, v.v\u0026hellip; cho các website này.\nI.2. Sử dụng và chấm dứt sử dụng Dịch vụ. Bạn chỉ có thể sử dụng nội dung của Dịch vụ cho mục đích cá nhân của riêng bạn (cụ thể là không dùng cho mục đích thương mại) và không được sao chép, thay đổi, sửa đổi, tạo ra các tác phẩm phái sinh hoặc thể hiện một cách công khai bất kỳ nội dung nào của Dịch vụ. Chẳng hạn, bạn không được sử dụng Dịch vụ để bán một sản phẩm hay dịch vụ; hay sử dụng Dịch vụ để tăng số lượt truy cập tới trang web của bạn vì mục đích thương mại; hay sử dụng các kết quả từ Dịch vụ rồi định dạng lại và thể hiện công khai chúng, hay sử dụng các công cụ hoặc tài liệu khác để theo dõi hay sao chép bất kỳ nội dung nào từ Dịch vụ. Nếu bạn không chắc liệu dự định sử dụng Dịch vụ của bạn có được phép hay không, xin vui lòng liên hệ với chúng tôi.\nePi sẽ không chịu trách nhiệm đối với việc gián đoạn, ngừng hoạt động, mất hoặc sai lệch dữ liệu từ những hành động tấn công của cá nhân hay tổ chức nào khác, cũng như về các sự cố kỹ thuật trong khi cung cấp Dịch vụ. ePi cũng không chịu trách nhiệm về các tổn thất phát sinh từ việc sử dụng Dịch vụ hoặc từ sự tương tác giữa bạn với những người dùng khác.\nePi có quyền đơn phương đình chỉ hoặc chấm dứt Dịch vụ hoặc sự truy cập của bạn tới Dịch vụ.\nII. Thỏa thuận bảo mật II.1. Những thông tin mà chúng tôi thu thập Khi bạn đăng ký làm thành viên, bạn cần cung cấp cho chúng tôi một số thông tin cá nhân, ví dụ như họ tên, địa chỉ email và các thông tin khác do bạn cung cấp. Chúng tôi có thể kết hợp thông tin cá nhân do bạn cung cấp với các thông tin khác ngoài Dịch vụ hoặc từ các bên thứ ba để phân tích các nội dung mà bạn quan tâm.\nMỗi khi bạn truy cập Dịch vụ, hệ thống của Baomoi sẽ sử dụng cookies và các kỹ thuật khác để lưu lại những hoạt động của bạn trên Baomoi. Server của Baomoi cũng sẽ tự động ghi lại thông tin khi bạn truy cập trang này và sử dụng các Dịch vụ bao gồm nhưng không giới hạn URL, địa chỉ IP, loại trình duyệt, ngôn ngữ, ngày giờ truy cập hoặc sử dụng Dịch vụ.\nII.2. Sử dụng thông tin Chúng tôi sử dụng thông tin cá nhân của bạn để nâng cao chất lượng của Dịch vụ, để gửi tới bạn các thông báo về dịch vụ mới của Baomoi hoặc dịch vụ của bên thứ ba mà chúng tôi tin rằng sẽ hữu ích với bạn.\nChúng tôi có thể sử dụng thông tin cá nhân của bạn trong việc điều tra, nghiên cứu hoặc phân tích để vận hành và nâng cấp các kỹ thuật của Baomoi và Dịch vụ.\nChúng tôi có thể sử dụng thông tin cá nhân của bạn để xác định xem liệu bạn có thể quan tâm đến các sản phẩm hay dịch vụ của bên thứ ba nào không.\nVề nguyên tắc, chúng tôi không cung cấp cho bên thứ ba thông tin cá nhân của bạn trừ các trường hợp sau:\nBạn đồng ý để chúng tôi cung cấp thông tin cá nhân của bạn cho bên thứ ba; và/hoặc Chúng tôi cho rằng việc cung cấp thông tin cá nhân của bạn cho bên thứ ba là cần thiết, ví dụ nhằm tuân theo các yêu cầu pháp lý, ngăn chặn tội phạm hoặc bảo vệ an ninh quốc gia, hay bảo vệ an toàn cá nhân của những người sử dụng hoặc công chúng, v.v\u0026hellip;; và/hoặc Bên thứ ba là đối tượng mua lại toàn bộ hay phần lớn pháp nhân sở hữu Baomoi và Dịch vụ; và/hoặc Thông tin cá nhân là thông tin vô danh về khách ghé thăm Baomoi. Chúng tôi có thể chia sẻ loại thông tin này cho bên thứ ba để họ có thể tìm hiểu về các loại khách tới thăm Baomoi và cách họ sử dụng Dịch vụ. II.3. Sửa đổi hoặc xoá thông tin Bạn có thể truy cập thông tin cá nhân của mình và sử đổi thông tin này nếu chúng chưa đúng hoặc xoá bỏ các thông tin đó. Việc thay đổi và/hoặc xoá bỏ như trên có thể không thực hiện được vào một số thời điểm nhất định khi có sự bất ổn định của hệ thống Baomoi. Trong trường hợp này, chúng tôi sẽ nỗ lực để bạn có thể tiếp tục sửa chữa hoặc xoá bỏ thông tin cá nhân sớm nhất có thể nhưng chúng tôi không chịu trách nhiệm về bất cứ vấn đề hoặc thiệt hại nào có thể có do việc chậm trễ này gây ra.\nII.4. Bảo mật Mật khẩu truy cập tài khoản của tất cả các thành viên của Baomoi đều được ePi bảo vệ. Tuy nhiên, an ninh mạng không an toàn tuyệt đối, vì thế ePi không chịu trách nhiệm về những thiệt hại có thể xảy ra.\n","date":"Feb 28, 2019","img":"","permalink":"/privacy/","series":null,"tags":null,"title":"Privacy"},{"categories":null,"content":"ĐIỀU KHOẢN SỬ DỤNG Thỏa thuận sử dụng và bảo mật này (sau đây gọi là “Thỏa thuận”) được lập ra bởi và giữa bạn (“bạn”) và Công ty Cổ phần công nghệ ePi (“ePi” hoặc “chúng tôi”) về việc sử dụng bất kỳ hay tất cả các loại dịch vụ (“Dịch vụ”) của Baomoi.com (“Baomoi”) của bạn. Bằng việc sử dụng Dịch vụ, bạn đồng ý chịu ràng buộc bởi những điều khoản và điều kiện này.\nDịch vụ được thiết kế để giúp bạn tiếp cận thông tin tin tức được liên kết từ các trang không do ePi sở hữu hoặc quản lý. Cụ thể, Dịch vụ cung cấp những mô tả ngắn gọn về các bài báo để giúp bạn xác định nội dung chính của bài báo mà bạn quan tâm. Khi bạn lựa chọn một bài báo, bạn sẽ được kết nối tới website chứa bài báo đó (sau đây gọi là “website được kết nối”).\nThuật ngữ “bạn” để chỉ tất cả các cá nhân và/hoặc các tổ chức truy cập vào Baomoi vì bất kỳ lý do nào.\nI. Thỏa thuận sử dụng I.1. Quyền gắn với Dịch vụ. ePi sở hữu và duy trì mọi quyền lợi sở hữu trí tuệ đối với Dịch vụ của mình nhưng ePi không tuyên bố là mình có quyền sở hữu trí tuệ đối với các bài báo tại các website được kết nối. Các quyền sở hữu trí tuệ này thuộc về các website được kết nối.\nePi cũng không chịu trách nhiệm về các thông tin, dịch vụ và nội dung của những website được kết nối. Bạn là người chịu hoàn toàn trách nhiệm trong việc sử dụng, khai thác, cung cấp thông tin cá nhân, v.v\u0026hellip; cho các website này.\nI.2. Sử dụng và chấm dứt sử dụng Dịch vụ. Bạn chỉ có thể sử dụng nội dung của Dịch vụ cho mục đích cá nhân của riêng bạn (cụ thể là không dùng cho mục đích thương mại) và không được sao chép, thay đổi, sửa đổi, tạo ra các tác phẩm phái sinh hoặc thể hiện một cách công khai bất kỳ nội dung nào của Dịch vụ. Chẳng hạn, bạn không được sử dụng Dịch vụ để bán một sản phẩm hay dịch vụ; hay sử dụng Dịch vụ để tăng số lượt truy cập tới trang web của bạn vì mục đích thương mại; hay sử dụng các kết quả từ Dịch vụ rồi định dạng lại và thể hiện công khai chúng, hay sử dụng các công cụ hoặc tài liệu khác để theo dõi hay sao chép bất kỳ nội dung nào từ Dịch vụ. Nếu bạn không chắc liệu dự định sử dụng Dịch vụ của bạn có được phép hay không, xin vui lòng liên hệ với chúng tôi.\nePi sẽ không chịu trách nhiệm đối với việc gián đoạn, ngừng hoạt động, mất hoặc sai lệch dữ liệu từ những hành động tấn công của cá nhân hay tổ chức nào khác, cũng như về các sự cố kỹ thuật trong khi cung cấp Dịch vụ. ePi cũng không chịu trách nhiệm về các tổn thất phát sinh từ việc sử dụng Dịch vụ hoặc từ sự tương tác giữa bạn với những người dùng khác.\nePi có quyền đơn phương đình chỉ hoặc chấm dứt Dịch vụ hoặc sự truy cập của bạn tới Dịch vụ.\nII. Thỏa thuận bảo mật II.1. Những thông tin mà chúng tôi thu thập Khi bạn đăng ký làm thành viên, bạn cần cung cấp cho chúng tôi một số thông tin cá nhân, ví dụ như họ tên, địa chỉ email và các thông tin khác do bạn cung cấp. Chúng tôi có thể kết hợp thông tin cá nhân do bạn cung cấp với các thông tin khác ngoài Dịch vụ hoặc từ các bên thứ ba để phân tích các nội dung mà bạn quan tâm.\nMỗi khi bạn truy cập Dịch vụ, hệ thống của Baomoi sẽ sử dụng cookies và các kỹ thuật khác để lưu lại những hoạt động của bạn trên Baomoi. Server của Baomoi cũng sẽ tự động ghi lại thông tin khi bạn truy cập trang này và sử dụng các Dịch vụ bao gồm nhưng không giới hạn URL, địa chỉ IP, loại trình duyệt, ngôn ngữ, ngày giờ truy cập hoặc sử dụng Dịch vụ.\nII.2. Sử dụng thông tin Chúng tôi sử dụng thông tin cá nhân của bạn để nâng cao chất lượng của Dịch vụ, để gửi tới bạn các thông báo về dịch vụ mới của Baomoi hoặc dịch vụ của bên thứ ba mà chúng tôi tin rằng sẽ hữu ích với bạn.\nChúng tôi có thể sử dụng thông tin cá nhân của bạn trong việc điều tra, nghiên cứu hoặc phân tích để vận hành và nâng cấp các kỹ thuật của Baomoi và Dịch vụ.\nChúng tôi có thể sử dụng thông tin cá nhân của bạn để xác định xem liệu bạn có thể quan tâm đến các sản phẩm hay dịch vụ của bên thứ ba nào không.\nVề nguyên tắc, chúng tôi không cung cấp cho bên thứ ba thông tin cá nhân của bạn trừ các trường hợp sau:\nBạn đồng ý để chúng tôi cung cấp thông tin cá nhân của bạn cho bên thứ ba; và/hoặc Chúng tôi cho rằng việc cung cấp thông tin cá nhân của bạn cho bên thứ ba là cần thiết, ví dụ nhằm tuân theo các yêu cầu pháp lý, ngăn chặn tội phạm hoặc bảo vệ an ninh quốc gia, hay bảo vệ an toàn cá nhân của những người sử dụng hoặc công chúng, v.v\u0026hellip;; và/hoặc Bên thứ ba là đối tượng mua lại toàn bộ hay phần lớn pháp nhân sở hữu Baomoi và Dịch vụ; và/hoặc Thông tin cá nhân là thông tin vô danh về khách ghé thăm Baomoi. Chúng tôi có thể chia sẻ loại thông tin này cho bên thứ ba để họ có thể tìm hiểu về các loại khách tới thăm Baomoi và cách họ sử dụng Dịch vụ. II.3. Sửa đổi hoặc xoá thông tin Bạn có thể truy cập thông tin cá nhân của mình và sử đổi thông tin này nếu chúng chưa đúng hoặc xoá bỏ các thông tin đó. Việc thay đổi và/hoặc xoá bỏ như trên có thể không thực hiện được vào một số thời điểm nhất định khi có sự bất ổn định của hệ thống Baomoi. Trong trường hợp này, chúng tôi sẽ nỗ lực để bạn có thể tiếp tục sửa chữa hoặc xoá bỏ thông tin cá nhân sớm nhất có thể nhưng chúng tôi không chịu trách nhiệm về bất cứ vấn đề hoặc thiệt hại nào có thể có do việc chậm trễ này gây ra.\nII.4. Bảo mật Mật khẩu truy cập tài khoản của tất cả các thành viên của Baomoi đều được ePi bảo vệ. Tuy nhiên, an ninh mạng không an toàn tuyệt đối, vì thế ePi không chịu trách nhiệm về những thiệt hại có thể xảy ra.\n","date":"Feb 28, 2019","img":"","permalink":"/teamofservices/","series":null,"tags":null,"title":"Team of Services"},{"categories":null,"content":"Bài toán người giao hàng là gì Người giao hàng là bài toán cơ bản trong nhóm bài toán tối ưu. Bài toán được phát biểu như sau: Có một người giao hàng cần đi giao hàng tại n thành phố. Xuất phát từ một thành phố nào đó, đi qua các thành phố khác để giao hàng và trở về thành phố ban đầu. Mỗi thành phố chỉ đến một lần, khoảng cách từ một thành phố đến các thành phố khác là xác định được. Hãy tìm một chu trình (một đường đi khép kín thỏa mãn điều kiện trên) sao cho tổng độ dài các cạnh là nhỏ nhất.\nCó rất nhiều cách để giải bài toán này, các bạn đọc có thể search google để tìm thêm cách giải khác, ở đây, mình sẽ trình bày cách sử dụng thư viện mlrose của python để giải quyết bài toán trên.\nCài đặt chương trình và thực thi Chúng ta giả định rằng người giao hàng sẽ đi qua 5 thành phố, và mỗi thành phố sẽ có 2 giá trị x và y tương ứng với toạ độ của các thành phố đó trên bản đồ.\n1input = [ 2[9, 12], 3[24, 15], 4[12 ,30], 5[4 ,3], 6[13, 27], 7] Theo phần trước, chúng ta sẽ xây dựng 4 phần\nXây dựng vector state Đơn giản là một vector x có số lượng phần tử bằng số lượng thành phố mà người giao hàng sẽ viết thăm\nx = [x0,x1,2,x3,x4], trong đó, giá trị x1 là chỉ số của thành phố người giao hàng sẽ ghé đầu tiên, x0 là toạ độ thành phố bắt đầu\nXây dựng hàm fitness function Mục tiêu của bài toán là tìm đường đi ngăn nhất, nên chúng ta có thể dễ dàng xây dựng hàn fitness bằng cách tính khoảng cách euclide giữa các thành phố.\n12def fitness_fun(state): 3distance = 0 45for index in range(1, len(state)): 6dist = np.linalg.norm(input[state[index-1]]-input[state[index]]) 78distance = distance + dist 910dist = np.linalg.norm(input[state[0]]-input[state[len(state)-1]]) 11distance = distance + dist 1213return distance 1415fitness_cust = mlrose.CustomFitness(fitness_fun,\u0026#39;tsp\u0026#39;) Xác định loại bài toán Đây là bài toán rời rạc không lặp, nên ta sẽ sử dụng hàm TSPOpt, length = 5 do số lượng phần tử của state là 5, maximize=False do bài toán tìm đường đi ngắn nhất .\n1problem_fit = mlrose.TSPOpt(length = 5, fitness_fn = fitness_cust, 2maximize=False) Xác định thuật toán tối ưu Chúng ta vẫn tiếp tục sử dụng thuật toán simulated_annealing như trước xem kết quả như thế nào\n1#Define decay schedule 2schedule = mlrose.ExpDecay() 34# Define initial state 5init_state = np.array([0, 1, 2, 3, 4]) 67# Set random seed 8np.random.seed(1) 910# Solve problem using simulated annealing 11best_state, best_fitness = mlrose.simulated_annealing(problem, schedule = schedule, 12max_attempts = 10, max_iters = 500, 13init_state = init_state) 1415print(\u0026#39;The best state found is: \u0026#39;, best_state) 16print(\u0026#39;The fitness at the best state is: \u0026#39;, best_fitness) Kết quả\n1The best state found is: [1 4 2 0 3] 2The fitness at the best state is: 71.30882356753094 Đây là kết quả tối ưu của bài toán.\nThử thay bằng giải thuật di truyền GA, với tỷ lệ đột biến là 0.2\n1best_state, best_fitness = mlrose.genetic_alg(problem,mutation_prob = 0.2) 23print(\u0026#39;The best state found is: \u0026#39;, best_state) 4print(\u0026#39;The fitness at the best state is: \u0026#39;, best_fitness) Kết quả\n12The best state found is: [0 2 4 1 3] 3The fitness at the best state is: 71.30882356753094 Thử thay đổi tập dữ liệu input có nhiều số phần tử hơn\n1input =[(1, 1), (4, 2), (5, 2), (6, 4), (4, 4), (3, 6), (1, 5), (2, 3)] Kết quả\n1The best state found is: [3 4 5 6 7 0 1 2] 2The fitness at the best state is: 17.34261754766733 Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Feb 8, 2019","img":"","permalink":"/blog/2019-02-08-randomized-optimization-in-python-v1/","series":null,"tags":["chấm điểm công dân","china","China social credit system","credit system"],"title":"Tối Ưu Hoá Ngẫu Nhiên - Bài Toán Người Giao Hàng"},{"categories":null,"content":"Bài toán tối ưu hoá là gì Theo Russell and Norvig bài toán tối ưu hoá là bài toán mà \u0026ldquo;the aim is to find the best state according to an objective function\u0026rdquo; (mình xin phép để nguyên câu tiếng anh).\nTrong đó, state trong từ best state phụ thuộc vào ngữ cảnh của bài toán. Ví dục\n Trong ngữ cảnh là mạng neural network, state chính là các trọng số (weight), best state là tìm các trọng số tối ưu Trong bài toán 8 hậu, state là vị trí của các con hậu, best state là vị trí tốt nhất thoả yêu cầu, cũng chính là lời giải. Trong bài toán người giao hàng, state là các thành phố người giao hàng đi qua. Trong bài toán tô màu cho mỗi quốc gia trên bản đồ, state là màu được tô cho mỗi quốc gia  Nói đến đây, các bạn chắc cũng đã hiểu được khái niệm state là gì rồi. Điều quan trọng ở đây là chúng ta có thể biểu diễn state dưới dạng một con số, hoặc một mảng các giá trị số. (nghĩa là chúng ta phải chuyển đổi màu, thành phố, \u0026hellip; dưới dạng số) thì mới có thể tính toán được.\nTừ best trong chữ best state được biểu diễn bởi một hàm toán học (mà chúng ta quen thuộc với các từ như là objective funtion, fitness funtion, cost funtion, loss function , v.v). Cái mà chúng ta muốn là cực đại hoặc cực tiểu hoá nó (để có được kết quả tốt nhất). Hàm này nhận đầu vào là state array và trả về \u0026ldquo;fitness\u0026rdquo; value.\nCho nên, chúng ta có thể định nghĩa đơn giản bài toán tối ưu là việc tìm các giá trị tối ưu để cực đại/ cực tiểu hoá một hàm toán học.\nVí dụ Một ví dụ xàm xàm như sau\nTa có một (state) vector x = [x0,x1,x2,x3,x4] thuộc đoạn [0,1] một hàm f(x) = x0 + x1 + x2 + x3 + x4, tìm các giá trị x để f đạt cực đại.\nRõ ràng, bằng việc tính nhẩm, chúng ta biết được rằng giá trị cực đại của hàm trên là 5, và lời giải cho bài toán trên là x = [1,1,1,1,1].\nCòn theo toán học cấp 3, ta sẽ tính đạo hàm riêng phần của từng phần tử (cái này đơn giản, mình không nhắc lại), và cũng đạt được x = [1,1,1,1,1]\nTại sao lại dùng Randomized Optimization? Trong bài toán ở trên, chúng ta có thể dễ dàng nhẩm được giá trị tối ưu một cách nhanh chóng. Tuy nhiên, trong thực tế, bài toán sẽ khó hơn một chút, và có nhiều hàm chúng ta không thể dễ dàng tìm được giá trị đạo hàm một cách nhanh chóng được (tốn thời gian rất lâu để giải bài toán ). Lúc này, chúng ta sẽ dùng Randomized optimization.\nRandomized optimization sẽ bắt đầu tại một điểm ngẫu nhiên \u0026ldquo;best\u0026rdquo; state nào đó, sau đó sẽ sinh ngẫu nhiên một state khác (thường là láng giềng của \u0026ldquo;best\u0026rdquo; state hiện tại). Nếu state mới đạt giá trị finest tốt hơn \u0026ldquo;best\u0026rdquo; state hiện tại thì gán \u0026ldquo;best\u0026rdquo; state bằng state mới. Quá trình này lặp đi lặp lại cho đến khi không thể tìm được state mới này tốt hơn \u0026ldquo;best\u0026rdquo; state hiện tại.\nKhông có gì bảo đảm rằng randomized optimization sẽ tìm được lời giải tối ưu. Ví dụ như hình trên, thuật toán chỉ có thể dừng ở local maximin, rồi đứng yên ở đó. Tuy nhiên, nếu chúng ta thiết lập số lần lặp đủ lớn, thuật toán thông thường sẽ trả về kết quả tốt hơn.\nỞ đây, chúng ta có một sự đánh đổi trade-off giữa thời gian tìm ra lời giải tối ưu và chất lượng của lời giải.\nGiải bài toán tối ưu bằng thư viện mlrose Để giải bài toán tối ưu bằng thư viện mlrose, chúng ta sẽ phải định nghĩa 4 thứ:\n Định nghĩa state vector Định nghĩa hàm fitness function Xác định loại bài toán Chọn một thuật toán tối ưu hoá ngẫu nhiên để chạy.  Để đơn giản, chúng ta sẽ giải quyết bài toán 8 hậu bằng thư viện mlrose.\nBài toán 8 hậu Nhắc lại một chút về bài toán 8 hậu. Trong bàn cờ vua có kích thước 8x8, chúng ta phải chọn vị trí đặt 8 con hậu sao cho trên mỗi dòng, cột và đường chéo của một con hậu bất kỳ đang đứng không giáp mặt với con hậu khác.\nĐịnh nghĩa state Đây rõ ràng là bài toán tối ưu, và bước đầu tiên ta sẽ định nghĩa một vector trạng thái x = [x0, x1, x2, x3, x4, x5, x6, x7], quy ước toạ độ 0,0 là vị trí trái dưới. Giá trị của xi là vị trị cột của con hậu dòng i đang đứng.\nVí dụ, ở hình trên, ta có x = [6, 1, 7, 5, 0, 2, 3, 4], với x0 = 6 nghĩa là con hậu đang ở cột 0 dòng 6 (góc toạ độ chúng ta khảo sát là trái dưới)\nHình trên không phải là lời giải tối ưu cho bài toán, vì con hậu ở cột 5, cột 6 và cột 7 giáp mặt nhau theo đường chéo.\nĐịnh nghĩa fitness funtion Trong thư viện mlrose đã định nghĩa sẵn hàm fitness function cho một số bài toán đơn giản, ví dụ như trong bài toán 8 hậu vừa rồi. Tuy nhiên, chúng ta sẽ không sử dụng hàm có sẵn đó, mà sẽ tự viết một hàm fitness riêng. Có nhiều cách để định nghĩa hàm fitness khác nhau cho bài toán này. Ở đay, chúng ta sẽ xây dựng một hàm có input là vị trí của các con hậu output là một con số thông báo số lượng con hậu không giáp nhau. Nếu số lượng là 8 thì input chính là lời giải của bài toán.\n1# Define alternative N-Queens fitness function for maximization problem 2def queens_max(state): 34# Initialize counter 5fitness = 0 67# For all pairs of queens 8for i in range(len(state) - 1): 9for j in range(i + 1, len(state)): 1011# Check for horizontal, diagonal-up and diagonal-down attacks 12if (state[j] == state[i]) \\ 13or (state[j] == state[i] + (j - i)) \\ 14or (state[j] == state[i] - (j - i)): 1516# If no attacks, then increment counter 17fitness += 1 18break 192021return fitness 2223fitness_cust = mlrose.CustomFitness(queens_max) Xác định loại bài toán Thư viện mlrose cung cấp cho chúng ta các lớp để định nghĩa 3 loại bài toán tối ưu:\n  DiscreteOpt: Lớp này được sử dụng để giải các bài toán có giá trị trạng thái là rời rạc. Và tập các trạng thái sẽ được cung cấp trước. Mỗi phần tử trong state chỉ nhận một giá trị trong tập trạng thái. và mỗi phần tử trong tập trạng thái chỉ thuộc về một phần tử trong state.\n  ContinuousOpt: Lớp này được sử dụng để giải các bài toán có giá trị trạng thái là liên tục.\n  TSPOpt: Lớp này được dùng để giải các bài toán về travelling. Ví dụ bài toán người giao hàng. Bài toán này khác bài toán Discrete ở chỗ chúng ta sẽ phải tìm ra thứ tự tối ưu của các con số.\n  Bài toán 8 hậu được xếp vào dạng bài toán tối ưu rời rạc. Trong đó, mỗi phần tử trong state vector chỉ mang một con số từ 0 đến 7.\n12problem = mlrose.DiscreteOpt(length = 8, fitness_fn = fitness, 3maximize = False, max_val = 8) 4length chính là số lượng phần tử trong state vector ( chúng ta có 8 cột nên length = 8), max_val = 8 (đã nói ở trên, giá trị tối ưu là khi 8 con hậu không giáp mặt nhau). Do bài toán của mình là cực tiểu (lý do là fitness = 0 thì không có con hậu nào giáp mặt nhau, nên chúng ta set maximize = False)\nXác định thuật toán tối ưu Thư viện mlrose cung cấp cho chúng ta các thuật toán như leo đồi (hill climbing), leo đồi ngẫu nhiên (stochastic hill climbing),simulated annealing, thuật giải di truyền (genetic algorithm), MIMIC (Mutual-Information-Maximizing Input Clustering). Với dạng bài toán rời rạc và travelling, chúng ta có thể chọn bất kỳ thuật toán tối ưu nào. Với bài toán liên tục, thì thuật toán MIMIC không hỗ trợ.\nVí dụ, chúng ta sẽ sử dụng simulated annealing để mô phỏng hàm tối ưu, với trạng thái init là x = [1,2,3,4,5,6,7], lặp 1000 lần để tìm trạng thái tốt nhất. Có 10 lần thử. để tìm hàng xóm tốt nhất trong mỗi lần lặp.\n1# Define decay schedule 2schedule = mlrose.ExpDecay() 34# Define initial state 5init_state = np.array([0, 1, 2, 3, 4, 5, 6, 7]) 67# Set random seed 8np.random.seed(1) 910# Solve problem using simulated annealing 11best_state, best_fitness = mlrose.simulated_annealing(problem, schedule = schedule, 12max_attempts = 10, max_iters = 1000, 13init_state = init_state) 1415print(\u0026#39;The best state found is: \u0026#39;, best_state) 16print(\u0026#39;The fitness at the best state is: \u0026#39;, best_fitness) Kết quả\n1The best state found is: [0 7 6 4 7 1 3 5] 2The fitness at the best state is: 1.0 Do best state =1 , nên có 2 con hậu có thể nhìn thấy và tấn công nhau, Chúng ta sẽ thử thay dổi số max_attempts =10 thành max_attempts = 50 xem sao.\n12The best state found is: [2 0 6 4 7 1 3 5] 3The fitness at the best state is: 0.0 Thử thay bằng bài toán 12 hậu\n1import mlrose 23import numpy as np 45# Define alternative N-Queens fitness function for maximization problem 6def queens_max(state): 78# Initialize counter 9fitness = 0 1011# For all pairs of queens 12for i in range(len(state) - 1): 13for j in range(i + 1, len(state)): 1415# Check for horizontal, diagonal-up and diagonal-down attacks 16if (state[j] == state[i]) \\ 17or (state[j] == state[i] + (j - i)) \\ 18or (state[j] == state[i] - (j - i)): 1920# If no attacks, then increment counter 21fitness += 1 22break 232425return fitness 2627fitness_cust = mlrose.CustomFitness(queens_max) 2829problem = mlrose.DiscreteOpt(length = 12, fitness_fn = fitness_cust, maximize = False, max_val = 12) 303132# Define decay schedule 33schedule = mlrose.ExpDecay() 3435# Define initial state 36init_state = np.array([0, 1, 2, 3, 4, 5, 6, 7,8,9,10,11]) 3738# Set random seed 39np.random.seed(1) 4041# Solve problem using simulated annealing 42best_state, best_fitness = mlrose.simulated_annealing(problem, schedule = schedule, 43max_attempts = 100, max_iters = 5000, 44init_state = init_state) 4546print(\u0026#39;The best state found is: \u0026#39;, best_state) 47print(\u0026#39;The fitness at the best state is: \u0026#39;, best_fitness) 48`` 4950Kết quả 5152```python 53The best state found is: [ 8 10 3 6 0 9 1 5 2 11 7 4] 54The fitness at the best state is: 0.0 Tất nhiên, ở trên chỉ là 1 trong số các lời giải của bài toán trên, chúng ta còn có nhiều lời giải khác, do bài toán có nhiều nghiệm.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Feb 8, 2019","img":"","permalink":"/blog/2019-02-08-getting-started-with-randomized-optimization-in-python/","series":null,"tags":["tối ưu hóa ngẫu nhiên","mlrose"],"title":"Tối Ưu Hoá Ngẫu Nhiên"},{"categories":null,"content":"Chính quyền Trung Quốc đang xây dựng một hệ thống xếp hạng có tên là \u0026quot; Hệ thống tín dụng xã hội - social credit system\u0026quot;. Hệ thống được xây dựng nhằm mục đích theo dõi hành vi của công dân và xếp hạng tất cả các hành vi trên.\nTheo một tài liệu cho biết,\u0026ldquo;Hệ thống tín dụng xã hội\u0026rdquo;, lần đầu tiên được công bố vào năm 2014, nhằm mục đích củng cố ý tưởng rằng \u0026ldquo;giữ niềm tin là vinh quang và phá vỡ niềm tin là ô nhục\u0026rdquo;.\nHệ thống sẽ được vận hành hoàn toàn trên toàn quốc vào năm 2020, nhưng đã được thí điểm ở một số vùng trên đất nước, và mang lại kết quả khá khả quan.\nTại thời điểm hiện tại, hệ thống đang được điều hành bởi chính phủ, một số công ty tư nhân cũng được cấp phép tham gia xây dựng và phát triển hệ thống, như alibaba, tencent.\nGiống như điểm tín dụng tư nhân, điểm xã hội của một người có thể đi lên xuống tùy theo hành vi của họ. Cách thức tính điểm và các hành vi được cho là tốt/xấu hiện thời vẫn chưa được công bố. Nhưng các ví dụ về vi phạm đã bị trừ điểm bao gồm lái xe ẩu, hút thuốc trong khu vực cấm hút thuốc, mua quá nhiều trò chơi video và đăng tin tức giả lên mạng.\n1. Cấm bay máy bay hoặc đi tàu điện ngầm Chính phủ Trung Quốc đã bắt đầu trừng phạt người dân bằng cách hạn chế việc đi lại của họ.\nChín triệu người có điểm thấp đã bị chặn mua vé cho các chuyến bay nội địa, Channel News Asia đưa tin vào 16/Mar/2018 nguồn https://www.channelnewsasia.com/news/asia/china-bad-social-credit-barred-from-buying-train-plane-tickets-10050390.\nNgười dân cũng có thể bị giới hạn sử dụng các dịch vụ nâng cao, ví dụ ba triệu người không được mua vé hạng thương gia (trích cùng nguồn trên).\nHere\u0026#39;s a dystopian vision of the future: A real announcement I recorded on the Beijing-Shanghai bullet train. (I\u0026#39;ve subtitled it so you can watch in silence.) pic.twitter.com/ZoRWtdcSMy\n\u0026mdash; James O\u0026#39;Malley (@Psythor) October 29, 2018  video trên, được đăng bởi nhà báo James O\u0026rsquo;Malley, cho thấy một thông báo trên một chuyến tàu cao tốc từ Bắc Kinh đến Thượng Hải cảnh báo mọi người không nên có những hành vi sai trái - nếu không thì \u0026ldquo;hành vi của họ sẽ được ghi lại trong hệ thống thông tin tín dụng cá nhân\u0026rdquo;.\n2. Điều chỉnh tốc độ internet Theo nghiên cứu của Rachel Botsman (nguồn https://www.wired.co.uk/article/chinese-government-social-credit-score-privacy-invasion) chính quyền sẽ giới hạn tốc độ, băng thông của các dịch vụ internet, 3G, 4G, \u0026hellip; của những công dân có điểm tính dụng xã hội thấp.\nTrong nghiên cứu của tác giả, một số hành vi sẽ bị trừng phạt, bao gồm:\n Công dân có thanh toán hóa đơn đúng hạn hay không. Dành quá nhiều thời gian để chơi trò chơi video Lãng phí tiền mua hàng tào lao và đăng lên phương tiện truyền thông xã hội (dạng như tự sướng ở Việt Nam mình á). Truyền bá tin tức giả mạo, cụ thể là về các cuộc tấn công khủng bố hoặc an ninh sân bay.  3. Cấm bạn, hoặc con cái của bạn được học ở những trường tốt Theo Beijing News reported(nguồn http://www.bjnews.com.cn/news/2018/03/19/479533.html), 17 người đã từ chối thực hiện nghĩa vụ quân sự vào năm ngoái (2017) đã bị cấm đăng ký vào giáo dục đại học, nộp đơn vào trường trung học hoặc tiếp tục việc học tập của họ.\nTheo nguồn https://www.businessinsider.com/china-social-credit-affects-childs-university-enrolment-2018-7?r=UK, vào tháng 7/2018, một trường đại học ở Trung Quốc, đã cấm một sinh viên nhập học (dù anh ấy đã thi đậu), vì lý do là điểm tín dụng xã hội của bố anh ấy \u0026ldquo;xấu\u0026rdquo;.\n4. Không cho bạn có một công việc tốt Theo nguồn của Botsman, các cá nhân có điểm tín nhiệm thấp sẽ bị cấm làm quản lý ở các công ty nhà nước, các ngân hàng lớn.\nCác hành vi như gian lận thuế, tham ô, \u0026hellip; cũng ảnh hưởng đến điểm xã hội.\n5. Không được thuê những khách sạn tốt Theo Botsman, những người gian lận nghĩa vụ quân sự sẽ bị cấm thuê khách sạn tốt khi đi du lịch.\nNhững công dân có điểm tín dụng tốt sẽ được thuê khách sạn mà không cần phải đặt cọc, có thể kéo dài thời gian du lịch hơn.\n6. Cấm nuôi chó Thành phố Tế Nam đã bắt đầu thực thi một hệ thống tín dụng xã hội cho các chủ sở hữu chó vào năm 2017. Theo đó, chủ vật nuôi sẽ bị trừ điểm nếu nuôi chó mà không xích, không rọ mõm, hoặc để cho chó đi bậy nơi công cộng.\nNhững người bị zero điểm sẽ bị cấm nuôi chó, con vật sẽ bị tịch thu, người sở hữu phải làm bài kiểm tra. Nguồn http://uk.businessinsider.com/china-dog-owners-social-credit-score-2018-10\n7. Bị bêu tên trước công chúng Chính phủ đã và đang xây dựng một danh sách các cá nhân có điểm tín nhiệm xấu và sẵn sàng đăng tên kèm hình ảnh của họ trên các phương tiện thông tin đại chúng. Các công ty cũng được khuyến khích tham khảo các thông tin của công dân trong hệ thống trước khi thuê họ.\nĐược biết, toà án sẽ thông báo cho công dân về hành vi của họ trước khi tên của họ được đưa vào danh sách đen. Công dân có 10 ngày kháng cáo kể từ khi nhận được thông báo.\nNguồn https://www.hrw.org/news/2017/12/12/chinas-chilling-social-credit-blacklist, http://zxgk.court.gov.cn/\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Feb 7, 2019","img":"","permalink":"/blog/2019-02-07-china-social-creadit-system/","series":null,"tags":["chấm điểm công dân","china","China social credit system","credit system"],"title":"Hệ Thống Tín Dụng Xã Hội Của Trung Quốc - Những Ảnh Hưởng Khi Bạn Có Điểm Xã Hội Thấp"},{"categories":null,"content":"Mở đầu Việc xây dựng một mô hình machine learning chưa bao giờ thật sự dễ dàng. Rất nhiều bài báo chỉ \u0026ldquo;show hàng\u0026rdquo; những thứ cao siêu, những thứ chỉ nằm trong sự tưởng tượng của chính các nhà báo. Còn khi đọc các bài báo khoa học về machine learning, tác giả công bố cho chúng ta những mô hình rất tốt, giải quyết một domain nhỏ vấn đề của họ. Tuy nhiên, có một thứ họ không/ chưa công bố. Đó là cách thức họ lựa chọn số lượng note ẩn, số lượng layer trong mô hình neural network. Trong bài viết này, chúng ta sẽ xây dựng mô hình LSTM đơn giản để dự đoán giới tính khi biết tên một người, và thử tìm xem công thức để chọn ra tham số \u0026ldquo;đủ tốt\u0026rdquo; là như thế nào.\nChẩn bị dữ liệu Tập dữ liệu ở đây có khoảng 500000 tên kèm giới tính. Đầu tiên mình sẽ làm sạch dữ liệu bằng cách chỉ lấy giới tính là \u0026rsquo;m\u0026rsquo; và \u0026lsquo;f\u0026rsquo;, loại bỏ những tên quá ngắn (có ít hơn 3 ký tự)\n1filepath = \u0026#39;firstnames.csv\u0026#39; 2max_rows = 500000 # Reduction due to memory limitations 34df = (pd.read_csv(filepath, usecols=[\u0026#39;name\u0026#39;, \u0026#39;gender\u0026#39;],sep=\u0026#34;;\u0026#34;) 5.dropna(subset=[\u0026#39;name\u0026#39;, \u0026#39;gender\u0026#39;]) 6.assign(name = lambda x: x.name.str.strip()) 7.assign(gender = lambda x: x.gender.str.lower()) 8.head(max_rows)) 910df= df[df.gender.isin([\u0026#39;m\u0026#39;,\u0026#39;f\u0026#39;])] 1112# In the case of a middle name, we will simply use the first name only 13df[\u0026#39;name\u0026#39;] = df[\u0026#39;name\u0026#39;].apply(lambda x: str(x).split(\u0026#39; \u0026#39;, 1)[0]) 1415# Sometimes people only but the first letter of their name into the field, so we drop all name where len \u0026lt;3 16df.drop(df[df[\u0026#39;name\u0026#39;].str.len() \u0026lt; 3].index, inplace=True) Tiếp theo, chúng ta sử dụng một kỹ thuật khá cũ trong NLP là one-hot encoding. Mỗi ký tự được biểu diễn bởi một vector nhị phân. Ví dụ có 26 ký tự trong bảng chữ cái tiếng anh, vector đại diện cho chữ a là [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], ký tự b được biểu diễn là [0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], \u0026hellip; tương tự cho đến z.\nMột từ được encode là một tập các vector. Ví dụ chữ hello được biểu diễn là\n1[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #h, 2[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #e, 3[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #l, 4[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #l, 5[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #o] Đọc đến đây, chắc các bạn đã mườn tượng ra rằng một từ sẽ được encode như thế nào rồi phải không. Tiếp theo, chúng ta sẽ xây dựng hàm encode cho tập dữ liệu\n1# Define a mapping of chars to integers 2char_to_int = dict((c, i) for i, c in enumerate(accepted_chars)) 3int_to_char = dict((i, c) for i, c in enumerate(accepted_chars)) 45# Removes all non accepted characters 6def normalize(line): 7return [c.lower() for c in line if c.lower() in accepted_chars] 89# Returns a list of n lists with n = word_vec_length 10def name_encoding(name): 1112# Encode input data to int, e.g. a-\u0026gt;1, z-\u0026gt;26 13integer_encoded = [char_to_int[char] for i, char in enumerate(name) if i \u0026lt; word_vec_length] 1415# Start one-hot-encoding 16onehot_encoded = list() 1718for value in integer_encoded: 19# create a list of n zeros, where n is equal to the number of accepted characters 20letter = [0 for _ in range(char_vec_length)] 21letter[value] = 1 22onehot_encoded.append(letter) 2324# Fill up list to the max length. Lists need do have equal length to be able to convert it into an array 25for _ in range(word_vec_length - len(name)): 26onehot_encoded.append([0 for _ in range(char_vec_length)]) 2728return onehot_encoded 2930# Encode the output labels 31def lable_encoding(gender_series): 32labels = np.empty((0, 2)) 33for i in gender_series: 34if i == \u0026#39;m\u0026#39;: 35labels = np.append(labels, [[1,0]], axis=0) 36else: 37labels = np.append(labels, [[0,1]], axis=0) 38return labels Và tiến hành chia tập dữ liệu thành train, val, và test set\n12# Split dataset in 60% train, 20% test and 20% validation 3train, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))]) 45# Convert both the input names as well as the output lables into the discussed machine readable vector format 6train_x = np.asarray([np.asarray(name_encoding(normalize(name))) for name in train[predictor_col]]) 7train_y = lable_encoding(train.gender) 89validate_x = np.asarray([name_encoding(normalize(name)) for name in validate[predictor_col]]) 10validate_y = lable_encoding(validate.gender) 1112test_x = np.asarray([name_encoding(normalize(name)) for name in test[predictor_col]]) 13test_y = lable_encoding(test.gender) Vậy là chúng ta đã có chuẩn bị xong dữ liệu đầy đủ rồi đó. Bây giờ chúng ta xây dựng mô hình thôi.\nXây dựng mô hình Có rất nhiều cách để chọn tham số cho mô hình, ví dụ như ở https://stats.stackexchange.com/questions/95495/guideline-to-select-the-hyperparameters-in-deep-learning liệt kê ra 4 cách là Manual Search, Grid Search, Random Search, Bayesian Optimization. Tuy nhiên, những cách trên đều khá tốn thời gian và đòi hỏi người kỹ sư phải có am hiểu nhất định.\nỞ đây, chúng ta sử dụng một công thức được đưa ra trong link https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw/136542#136542, cụ thể\n$$ N_h = \\frac{N_s}{(\\alpha * (N_i + N_o))}$$\nTrong đó Ni là số lượng input neural, No là số lượng output neural, Ns là số lượng element trong tập dữ liệu train. alpha là một con số trade-off đại diện cho tỷ lệ thuộc đoạn [2-10].\nMột lưu ý ở đây là bạn có thể dựa vào công thức và số alpha mà ước lượng xem rằng bạn đã có đủ dữ liệu mẫu hay chưa. Một ví dụ đơn giản là giả sử bạn có 10,000 mẫu dữ liệu, input số từ 0 đến 9, output là 64, chọn alpha ở mức nhỏ nhất là 2, vậy theo công thức số neural ẩn là 10000/(26410) = 7.8 ~ 8. Nếu bạn tăng số alpha lên thì số hidden layer còn ít nữa. Điều trên chứng tỏ rằng số lượng mẫu của bạn chưa đủ, còn thiếu quá nhiều. Nếu bạn tăng gấp 100 lần số dữ liệu mẫu, thì con số có vẻ hợp lý hơn.\nTrong tập dữ liệu, mình có:\n1The input vector will have the shape {17} x {82} 2Train len: (21883, 17, 82) 36473 Tổng cộng N_s là 21883, Ni là 17, No là 82, chọn alpha là 2 thì mình có 21883/(21782) = 7.8 ~ 8. Một con số khá nhỏ, chứng tỏ dữ liệu của mình còn quá ít.\nĐối với tập dữ liệu nhỏ như thế này, mình thường sẽ áp dụng công thức sau:\n$$ N_h= \\beta* (N_i + N_o) $$\nVới beta là một con số thực thuộc nửa đoạn (0,1]. Thông thường sẽ là 2/3. Kết quả là số lượng neural của mình khoảng 929.333 node. Thông thường, mình sẽ chọn số neural là một con số là bội số của 2, ở đây 929 gần với 2^10 nhất, nên mình chọn số neural là 2^10.\nTóm lại, mình sẽ theo quy tắc\nNếu dữ liệu nhiều:\n$$ N_h = \\frac{N_s}{(\\alpha * (N_i + N_o))}$$\nNếu dữ liệu ít\n$$ N_h= \\frac{2}{3}* (N_i + N_o) $$\nLàm tròn lên bằng với bội số của 2 mũ gần nhất.\nMột lưu ý nhỏ là số lượng node càng nhiều thì tỷ lệ overfit càng cao, và thời gian huấn luyện càng lâu. Do đó, bạn nên trang bị máy có cấu hình kha khá một chút, tốt hơn hết là nên có GPU đi kèm. Ngoài ra, bạn nên chuẩn bị càng nhiều dữ liệu càng tốt. Một kinh nghiệm của mình rút ra trong quá trình làm Machine Learning là nếu không có nhiều dữ liệu, thì đừng cố thử áp dụng các phương pháp ML trên nó.\nMô hình mình xây dựng như sau:\n12hidden_nodes = 1024 345# Build the model 6print(\u0026#39;Build model...\u0026#39;) 7model = Sequential() 8model.add(LSTM(hidden_nodes, return_sequences=False, input_shape=(word_vec_length, char_vec_length))) 9model.add(Dropout(0.2)) 10model.add(Dense(units=output_labels)) 11model.add(Activation(\u0026#39;softmax\u0026#39;)) 12model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;acc\u0026#39;]) 1314batch_size=1000 15model.fit(train_x, train_y, batch_size=batch_size, epochs=50, validation_data=(validate_x, validate_y)) Do bài viết chỉ tập trung vào vấn đề lựa chọn số lượng node, nên mình sẽ bỏ qua những phần phụ như là early stoping, save each epochs \u0026hellip;, Các vấn đề trên ít nhiều mình đã đề cập ở các bài viết trước.\nKết quả của việc huấn luyện mô hình\n121883/21883 [==============================] - 34s 2ms/step - loss: 0.6602 - acc: 0.6171 - val_loss: 0.6276 - val_acc: 0.7199 2Epoch 2/50 321883/21883 [==============================] - 30s 1ms/step - loss: 0.5836 - acc: 0.7056 - val_loss: 0.5625 - val_acc: 0.7193 4Epoch 3/50 521883/21883 [==============================] - 30s 1ms/step - loss: 0.5531 - acc: 0.7353 - val_loss: 0.5506 - val_acc: 0.7389 6Epoch 4/50 721883/21883 [==============================] - 31s 1ms/step - loss: 0.5480 - acc: 0.7446 - val_loss: 0.5664 - val_acc: 0.7313 8Epoch 5/50 921883/21883 [==============================] - 30s 1ms/step - loss: 0.5406 - acc: 0.7420 - val_loss: 0.5247 - val_acc: 0.7613 10Epoch 6/50 1121883/21883 [==============================] - 30s 1ms/step - loss: 0.5077 - acc: 0.7686 - val_loss: 0.4918 - val_acc: 0.7790 12Epoch 7/50 1321883/21883 [==============================] - 30s 1ms/step - loss: 0.4825 - acc: 0.7837 - val_loss: 0.4939 - val_acc: 0.7740 14Epoch 8/50 1521883/21883 [==============================] - 31s 1ms/step - loss: 0.4611 - acc: 0.7887 - val_loss: 0.4407 - val_acc: 0.8037 16Epoch 9/50 1721883/21883 [==============================] - 30s 1ms/step - loss: 0.4421 - acc: 0.7987 - val_loss: 0.4657 - val_acc: 0.8005 18Epoch 10/50 1921883/21883 [==============================] - 30s 1ms/step - loss: 0.4293 - acc: 0.8055 - val_loss: 0.4183 - val_acc: 0.8141 20Epoch 11/50 2121883/21883 [==============================] - 31s 1ms/step - loss: 0.4129 - acc: 0.8128 - val_loss: 0.4171 - val_acc: 0.8212 22Epoch 12/50 2321883/21883 [==============================] - 30s 1ms/step - loss: 0.4153 - acc: 0.8141 - val_loss: 0.4031 - val_acc: 0.8188 24Epoch 13/50 2521883/21883 [==============================] - 30s 1ms/step - loss: 0.3978 - acc: 0.8191 - val_loss: 0.3918 - val_acc: 0.8280 26Epoch 14/50 2721883/21883 [==============================] - 30s 1ms/step - loss: 0.3910 - acc: 0.8268 - val_loss: 0.3831 - val_acc: 0.8276 28Epoch 15/50 2921883/21883 [==============================] - 30s 1ms/step - loss: 0.3848 - acc: 0.8272 - val_loss: 0.3772 - val_acc: 0.8314 30Epoch 16/50 3121883/21883 [==============================] - 30s 1ms/step - loss: 0.3751 - acc: 0.8354 - val_loss: 0.3737 - val_acc: 0.8363 32Epoch 17/50 3321883/21883 [==============================] - 30s 1ms/step - loss: 0.3708 - acc: 0.8345 - val_loss: 0.3717 - val_acc: 0.8374 34Epoch 18/50 3521883/21883 [==============================] - 31s 1ms/step - loss: 0.3688 - acc: 0.8375 - val_loss: 0.3768 - val_acc: 0.8330 36Epoch 19/50 3721883/21883 [==============================] - 30s 1ms/step - loss: 0.3704 - acc: 0.8375 - val_loss: 0.3621 - val_acc: 0.8392 38Epoch 20/50 3921883/21883 [==============================] - 31s 1ms/step - loss: 0.3608 - acc: 0.8444 - val_loss: 0.3656 - val_acc: 0.8422 40Epoch 21/50 4121883/21883 [==============================] - 31s 1ms/step - loss: 0.3548 - acc: 0.8459 - val_loss: 0.3670 - val_acc: 0.8417 42Epoch 22/50 4321883/21883 [==============================] - 30s 1ms/step - loss: 0.3521 - acc: 0.8452 - val_loss: 0.3555 - val_acc: 0.8462 44Epoch 23/50 4521883/21883 [==============================] - 30s 1ms/step - loss: 0.3432 - acc: 0.8504 - val_loss: 0.3591 - val_acc: 0.8402 46Epoch 24/50 4721883/21883 [==============================] - 31s 1ms/step - loss: 0.3415 - acc: 0.8524 - val_loss: 0.3471 - val_acc: 0.8470 48Epoch 25/50 4921883/21883 [==============================] - 30s 1ms/step - loss: 0.3355 - acc: 0.8555 - val_loss: 0.3577 - val_acc: 0.8436 50Epoch 26/50 5121883/21883 [==============================] - 30s 1ms/step - loss: 0.3320 - acc: 0.8552 - val_loss: 0.3602 - val_acc: 0.8430 52Epoch 27/50 5321883/21883 [==============================] - 30s 1ms/step - loss: 0.3294 - acc: 0.8578 - val_loss: 0.3565 - val_acc: 0.8485 54Epoch 28/50 5521883/21883 [==============================] - 30s 1ms/step - loss: 0.3235 - acc: 0.8602 - val_loss: 0.3427 - val_acc: 0.8514 56Epoch 29/50 5721883/21883 [==============================] - 31s 1ms/step - loss: 0.3138 - acc: 0.8651 - val_loss: 0.3523 - val_acc: 0.8470 58Epoch 30/50 5921883/21883 [==============================] - 30s 1ms/step - loss: 0.3095 - acc: 0.8683 - val_loss: 0.3457 - val_acc: 0.8487 60Epoch 31/50 6121883/21883 [==============================] - 31s 1ms/step - loss: 0.3064 - acc: 0.8701 - val_loss: 0.3538 - val_acc: 0.8531 62Epoch 32/50 6321883/21883 [==============================] - 30s 1ms/step - loss: 0.2985 - acc: 0.8717 - val_loss: 0.3555 - val_acc: 0.8455 64Epoch 33/50 6521883/21883 [==============================] - 30s 1ms/step - loss: 0.2930 - acc: 0.8741 - val_loss: 0.3430 - val_acc: 0.8525 66Epoch 34/50 6721883/21883 [==============================] - 30s 1ms/step - loss: 0.2901 - acc: 0.8786 - val_loss: 0.3457 - val_acc: 0.8503 68Epoch 35/50 6921883/21883 [==============================] - 30s 1ms/step - loss: 0.2852 - acc: 0.8776 - val_loss: 0.3458 - val_acc: 0.8510 70Epoch 36/50 7121883/21883 [==============================] - 30s 1ms/step - loss: 0.2817 - acc: 0.8811 - val_loss: 0.3445 - val_acc: 0.8568 72Epoch 37/50 7321883/21883 [==============================] - 30s 1ms/step - loss: 0.2780 - acc: 0.8816 - val_loss: 0.3356 - val_acc: 0.8540 74Epoch 38/50 7521883/21883 [==============================] - 30s 1ms/step - loss: 0.2734 - acc: 0.8852 - val_loss: 0.3442 - val_acc: 0.8559 76Epoch 39/50 7721883/21883 [==============================] - 31s 1ms/step - loss: 0.2579 - acc: 0.8904 - val_loss: 0.3552 - val_acc: 0.8540 78Epoch 40/50 7921883/21883 [==============================] - 30s 1ms/step - loss: 0.2551 - acc: 0.8927 - val_loss: 0.3677 - val_acc: 0.8532 80Epoch 41/50 8121883/21883 [==============================] - 30s 1ms/step - loss: 0.2558 - acc: 0.8921 - val_loss: 0.3496 - val_acc: 0.8588 82Epoch 42/50 8321883/21883 [==============================] - 30s 1ms/step - loss: 0.2472 - acc: 0.8963 - val_loss: 0.3534 - val_acc: 0.8587 84Epoch 43/50 8521883/21883 [==============================] - 31s 1ms/step - loss: 0.2486 - acc: 0.8948 - val_loss: 0.3490 - val_acc: 0.8537 86Epoch 44/50 8721883/21883 [==============================] - 31s 1ms/step - loss: 0.2503 - acc: 0.8965 - val_loss: 0.3594 - val_acc: 0.8552 88Epoch 45/50 8921883/21883 [==============================] - 30s 1ms/step - loss: 0.2391 - acc: 0.8993 - val_loss: 0.3793 - val_acc: 0.8566 90Epoch 46/50 9121883/21883 [==============================] - 31s 1ms/step - loss: 0.2244 - acc: 0.9048 - val_loss: 0.3815 - val_acc: 0.8543 92Epoch 47/50 9321883/21883 [==============================] - 30s 1ms/step - loss: 0.2203 - acc: 0.9095 - val_loss: 0.3848 - val_acc: 0.8554 94Epoch 48/50 9521883/21883 [==============================] - 30s 1ms/step - loss: 0.2221 - acc: 0.9051 - val_loss: 0.3892 - val_acc: 0.8558 96Epoch 49/50 9721883/21883 [==============================] - 30s 1ms/step - loss: 0.2117 - acc: 0.9124 - val_loss: 0.3654 - val_acc: 0.8544 98Epoch 50/50 9921883/21883 [==============================] - 30s 1ms/step - loss: 0.2141 - acc: 0.9118 - val_loss: 0.3726 - val_acc: 0.8547 Độ chính xác trên tập train là hơn 90%, trên tập val là hơn 85%. Nhìn kỹ hơn vào những từ sai ta thấy rằng\n1name gender predicted_gender 26750 Chiaki f m 328599 Naheed f m 411448 Espiridión m f 5895 Akmaral f m 633778 Ros f m Có một sự nhập nhằng ở ngôn ngữ giữa tên nam và tên nữ ở những từ này. Có lẽ một tập dữ liệu với đầy đủ họ và tên sẽ cho ra một kết quả có độ chính xác cao hơn. Ví dụ, ở Việt Nam, tên Ngọc thì có thể đặt được cho cả Nam lẫn Nữ.\nMình sẽ cố gắng kiếm một bộ dataset tên tiếng việt và thực hiện việc xây dựng mô hình xác định giới tính thông qua tên người dựa vào mô hình LSTM.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Feb 6, 2019","img":"","permalink":"/blog/2019-02-06-choosing-the-right-hyperparameters-for-a-simple-lstm-using-keras/","series":null,"tags":["Machine learning","Deeplearning","python"],"title":"Lựa Chọn Siêu Tham Số Cho Mô Hình LSTM Đơn Giản Sử Dụng Keras"},{"categories":null,"content":"Mở đầu Bắt đầu bằng một class đơn giản như sau:\n1class DataItem(object): 2def __init__(self, name, age, address): 3self.name = name 4self.age = age 5self.address = address Bạn nghĩ một đối tượng của class trên sẽ chiếm bao nhiêu bộ nhớ. Chúng ta cùng tiến hành một vài thí nghiệm nho nhỏ bên dưới.\n1dx = DataItem(\u0026#34;Alex Black\u0026#34;, 42, \u0026#34;-\u0026#34;) 2print (\u0026#34;sys.getsizeof(dx):\u0026#34;, sys.getsizeof(dx)) 3\u0026gt;\u0026gt; sys.getsizeof(dx): 56 Kết quả ra là 56 bytes, khá hợp lý phải không các bạn. Thử với một ví dụ khác xem sao nhỉ.\n1dy = DataItem(\u0026#34;Alex Black\u0026#34;, 42, \u0026#34;I am working at MWG\u0026#34;) 2print (\u0026#34;sys.getsizeof(dy):\u0026#34;, sys.getsizeof(dy)) 3\u0026gt;\u0026gt; sys.getsizeof(dy): 56 Kết quả vẫn là 56 bytes. Có cái gì đó sai sai ở đây không nhỉ?\nChúng ta thực nghiệm một vài thí nghiệm khác để chứng thực.\n1print (sys.getsizeof(\u0026#34;\u0026#34;)) 2\u0026gt;\u0026gt; 49 3print (sys.getsizeof(\u0026#34;1\u0026#34;)) 4\u0026gt;\u0026gt; 50 5print (sys.getsizeof(1)) 6\u0026gt;\u0026gt; 28 7print (sys.getsizeof(dict())) 8\u0026gt;\u0026gt; 240 9print (sys.getsizeof({})) 10\u0026gt;\u0026gt; 240 11print (sys.getsizeof(list())) 12\u0026gt;\u0026gt; 64 13print (sys.getsizeof([])) 14\u0026gt;\u0026gt; 64 15print (sys.getsizeof(())) 16\u0026gt;\u0026gt; 48 Một điều cực kỳ bất ngờ đã xuất hiện ở đây. Một chuỗi rỗng chiếm đến tận 49 bytes, một dictionary rỗng, không chứa phần tử nào chiếm đến 240 bytes, và một list rỗng chiếm tới 64 bytes. Rõ ràng, python đã lưu một số thứ gì đó ngoài dữ liệu của mình.\nĐi sâu vào thử tìm hiểu những thứ \u0026rsquo;linh kiện\u0026rsquo; linh tinh mà python đã kèm theo cho chúng ta là gì nhé.\nĐầu tiên, chúng ta sẽ cần một hàm in ra những thứ mà python đã \u0026rsquo;nhúng\u0026rsquo; thêm vào class DataItem chúng ta khai báo ở trên.\n1def dump(obj): 2for attr in dir(obj): 3print(\u0026#34; obj.%s= %r\u0026#34; % (attr, getattr(obj, attr))) và dump biến dy ra thôi\n1dump(dy) 23obj.__class__ = \u0026lt;class \u0026#39;__main__.DataItem\u0026#39;\u0026gt; 4obj.__delattr__ = \u0026lt;method-wrapper \u0026#39;__delattr__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 5obj.__dict__ = {\u0026#39;name\u0026#39;: \u0026#39;Alex Black\u0026#39;, \u0026#39;age\u0026#39;: 42, \u0026#39;address\u0026#39;: \u0026#39;i am working at MWG\u0026#39;} 6obj.__dir__ = \u0026lt;built-in method __dir__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 7obj.__doc__ = None 8obj.__eq__ = \u0026lt;method-wrapper \u0026#39;__eq__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 9obj.__format__ = \u0026lt;built-in method __format__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 10obj.__ge__ = \u0026lt;method-wrapper \u0026#39;__ge__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 11obj.__getattribute__ = \u0026lt;method-wrapper \u0026#39;__getattribute__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 12obj.__gt__ = \u0026lt;method-wrapper \u0026#39;__gt__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 13obj.__hash__ = \u0026lt;method-wrapper \u0026#39;__hash__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 14obj.__init__ = \u0026lt;bound method DataItem.__init__ of \u0026lt;__main__.DataItem object at 0x000001A64A6DD0F0\u0026gt;\u0026gt; 15obj.__init_subclass__ = \u0026lt;built-in method __init_subclass__ of type object at 0x000001A64A5DE738\u0026gt; 16obj.__le__ = \u0026lt;method-wrapper \u0026#39;__le__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 17obj.__lt__ = \u0026lt;method-wrapper \u0026#39;__lt__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 18obj.__module__ = \u0026#39;__main__\u0026#39; 19obj.__ne__ = \u0026lt;method-wrapper \u0026#39;__ne__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 20obj.__new__ = \u0026lt;built-in method __new__ of type object at 0x000000005C2DC580\u0026gt; 21obj.__reduce__ = \u0026lt;built-in method __reduce__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 22obj.__reduce_ex__ = \u0026lt;built-in method __reduce_ex__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 23obj.__repr__ = \u0026lt;method-wrapper \u0026#39;__repr__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 24obj.__setattr__ = \u0026lt;method-wrapper \u0026#39;__setattr__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 25obj.__sizeof__ = \u0026lt;built-in method __sizeof__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 26obj.__str__ = \u0026lt;method-wrapper \u0026#39;__str__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 27obj.__subclasshook__ = \u0026lt;built-in method __subclasshook__ of type object at 0x000001A64A5DE738\u0026gt; 28obj.__weakref__ = None 29obj.address = \u0026#39;i am working at MWG\u0026#39; 30obj.age = 42 31obj.name = \u0026#39;Alex Black\u0026#39; Wow, có vẻ khá là đồ sộ nhỉ.\nTrên github, có một hàm có sẵn tính toán số lượng bộ nhớ mà object chiếm được dựa vào cách truy xuất trực tiếp từng trường dữ liệu của đối tượng và tính toán kích thước\n1import sys 23def get_size(obj, seen=None): 4\u0026#34;\u0026#34;\u0026#34;Recursively finds size of objects\u0026#34;\u0026#34;\u0026#34; 5size = sys.getsizeof(obj) 6if seen is None: 7seen = set() 8obj_id = id(obj) 9if obj_id in seen: 10return 0 11# Important mark as seen *before* entering recursion to gracefully handle 12# self-referential objects 13seen.add(obj_id) 14if isinstance(obj, dict): 15size += sum([get_size(v, seen) for v in obj.values()]) 16size += sum([get_size(k, seen) for k in obj.keys()]) 17elif hasattr(obj, \u0026#39;__dict__\u0026#39;): 18size += get_size(obj.__dict__, seen) 19elif hasattr(obj, \u0026#39;__iter__\u0026#39;) and not isinstance(obj, (str, bytes, bytearray)): 20size += sum([get_size(i, seen) for i in obj]) 21return size thử với 2 biến dx và dy của chúng ta xem sao\n1\u0026gt;\u0026gt;\u0026gt; print (\u0026#34;get_size(d1):\u0026#34;, get_size(dx)) 2get_size(d1): 466 3\u0026gt;\u0026gt;\u0026gt; print (\u0026#34;get_size(d1):\u0026#34;, get_size(dy)) 4get_size(d1): 484 Chúng tốn lần lượt là 466 và 484 bytes. Có vẻ đúng đó nhỉ.\nĐiều chúng ta quan tâm lúc này là có cách nào để giảm bộ nhớ tiêu thụ của một object hay không?\nGiảm bộ nhớ tiêu thụ của một đối tượng trong python Tất nhiên là sẽ có cách giảm. Python là một ngôn ngữ thông dịch, và nó cho phép chúng ta mở rộng lớp bất kể lúc nào bằng cách thêm một/ nhiều trường dữ liệu.\n1dz = DataItem(\u0026#34;Alex Black\u0026#34;, 42, \u0026#34;-\u0026#34;) 2dz.height = 1.80 3print ( get_size(dz)) 4\u0026gt;\u0026gt; 484 Chính vì lý do này, trình biên dịch sẽ tốn thêm một đống bộ nhớ tạm để chúng ta có thể dễ dàng mở rộng một lớp trong tương lai. Nếu chúng ta \u0026ldquo;ép buộc\u0026rdquo; trình biên dịch, nói rằng chúng ta chỉ có nhiêu đó trường, và bỏ phần dư thừa đi.\n1class DataItem(object): 2__slots__ = [\u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;, \u0026#39;address\u0026#39;] 3def __init__(self, name, age, address): 4self.name = name 5self.age = age 6self.address = address Và thử lại\n12dz = DataItem(\u0026#34;Alex Black\u0026#34;, 42, \u0026#34;i am working at MWG\u0026#34;) 3print (\u0026#34;sys.getsizeof(dz):\u0026#34;, get_size(dz)) 45\u0026gt;\u0026gt;sys.getsizeof(dz): 64 Các bạn thấy gì không, bộ nhớ tiêu thụ chỉ là \u0026ldquo;64 bytes\u0026rdquo;. Dung lượng đã giảm đi hơn \u0026ldquo;7 lần\u0026rdquo; so với model class ban đầu. Tuy nhiên, chúng ta sẽ không thể mở rộng class dễ dàng như xưa nữa.\n1\u0026gt;\u0026gt;\u0026gt; dz.height = 1.80 2Traceback (most recent call last): 3File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; 4AttributeError: \u0026#39;DataItem\u0026#39; object has no attribute \u0026#39;height\u0026#39; Thử tạo một đối tượng có 1000 phần tử và kiểm tra thử.\n1class DataItem(object): 2__slots__ = [\u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;, \u0026#39;address\u0026#39;] 3def __init__(self, name, age, address): 4self.name = name 5self.age = age 6self.address = address 789data = [] 1011tracemalloc.start() 12start =datetime.datetime.now() 13for p in range(100000): 14data.append(DataItem(\u0026#34;Alex\u0026#34;, 42, \u0026#34;middle of nowhere\u0026#34;)) 1516end =datetime.datetime.now() 17snapshot = tracemalloc.take_snapshot() 18top_stats = snapshot.statistics(\u0026#39;lineno\u0026#39;) 19total = sum(stat.size for stat in top_stats) 20print(\u0026#34;Total allocated size: %.1fMB\u0026#34; % (total / (1024*1024))) 21print(\u0026#34;Total execute time:\u0026#34;,(end-start).microseconds) 2223\u0026gt;\u0026gt; Total allocated size: 6.9 MB 24\u0026gt;\u0026gt; Total execute time: 232565 Bỏ dòng slots = [\u0026rsquo;name\u0026rsquo;, \u0026lsquo;age\u0026rsquo;, \u0026lsquo;address\u0026rsquo;] đi thử\n12class DataItem(object): 3def __init__(self, name, age, address): 4self.name = name 5self.age = age 6self.address = address 789data = [] 1011tracemalloc.start() 12start =datetime.datetime.now() 13for p in range(100000): 14data.append(DataItem(\u0026#34;Alex\u0026#34;, 42, \u0026#34;middle of nowhere\u0026#34;)) 15end =datetime.datetime.now() 16snapshot = tracemalloc.take_snapshot() 17top_stats = snapshot.statistics(\u0026#39;lineno\u0026#39;) 18total = sum(stat.size for stat in top_stats) 19print(\u0026#34;Total allocated size: %.1fMB\u0026#34; % (total / (1024*1024))) 20print(\u0026#34;Total execute time:\u0026#34;,(end-start).microseconds) 2122\u0026gt;\u0026gt; Total allocated size: 16.8 MB 23\u0026gt;\u0026gt; Total execute time: 240772 So sánh thử, chúng ta thấy rằng số lượng RAM giảm đi khá nhiều, thời gian thực thi khá tương đương nhau (có giảm một chút).\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Feb 6, 2019","img":"","permalink":"/blog/2019-02-06-how-to-reduce-memory-consumption-by-half-by-adding-just-one-line-of-code/","series":null,"tags":["Machine learning","Deeplearning","python"],"title":"Giảm Bộ Nhớ Sử Dụng Trong Python"},{"categories":null,"content":"Mở đầu Hiện nay, có rất nhiều thư viện do cộng đồng đóng góp và xây dựng. Ví dụ như biopython trong tin sinh học, pandas (data science), keras/tensorflow (machine learning), astropy ( cho thiên văn học - astronomy). Trước khi bắt đầu đọc bài viết này, bạn đên đọc \u0026ldquo;Python Tricks Book\u0026rdquo; của Dan Bader trước (https://dbader.org/products/python-tricks-book/). Trong sách, anh ấy đã chia sẻ một số lời khuyên và mẹo về các code python hiệu quả hơn.\nMẹo số 1: Sức mạnh của một dòng Khi bạn đọc một đoạn giải thuật với nhiều dòng code, có thể bạn sẽ bị quên thông tin những dòng trước đó đã viết gì, đặc biệt là trong những câu lệnh điều kiện. Ví dụ:\n12if alpha \u0026gt; 7: 3beta = 999 4elif alpha == 7: 5beta = 99 6else: 7beta =0 Chóng ta có thể viết đơn giản hơn chỉ với một dòng code như sau.\n1beta = 999 if alpha \u0026gt; 7 else 99 if alpha == 7 else 0 thật đơn giản phải không. Bạn chỉ cần nhìn đúng một dòng là nằm được nội dung ý nghĩa của đoạn code bạn cần. Một ví dụ khác về vòng lặp for.\n1lst = [1, 2, 3, 4] 2lst_double = [] 34for num in lst: 5lst_double.append(num * 2) Đoạn code trên có thể viết lại dưới dạng 1 dòng như sau.\n1lst_double = [num * 2 for num in lst] Tất nhiên, bạn không nên \u0026ldquo;lạm dụng\u0026rdquo; one line một cách thái quá, ví dụ\n1import pprint; pprint.pprint(zip((\u0026#39;Byte\u0026#39;, \u0026#39;KByte\u0026#39;, \u0026#39;MByte\u0026#39;, \u0026#39;GByte\u0026#39;, \u0026#39;TByte\u0026#39;), (1 \u0026lt;\u0026lt; 10*i for i in xrange(5)))) Trông nó có vẻ hơi \u0026ldquo;lố bịch\u0026rdquo; phải không.\nMẹo 2: Các thao tác nhanh trên chuỗi Python cung cấp cho chúng ta một số cách viết ngắn gọn giúp chúng ta có thể dể dàng thao tác trên chuỗi. Để reverse một chuỗi, chúng ta sử dụng toán tử ::-1\n12str = \u0026#39;i am alex\u0026#39; 3print(str[::-1]) 4\u0026gt;\u0026gt; xela ma i Mẹo trên cũng có thể sử dụng đối với list số nguyên.\nĐể nối các phần tử trong một list thành một chuỗi, chúng ta có thể dùng hàm join()\n12str1 = [\u0026#34;pig\u0026#34;, \u0026#34;year\u0026#34; , \u0026#34;2019\u0026#34;] 3str2 = \u0026#34;happy \u0026#34; 4str3 = \u0026#34;new \u0026#34; 567print( \u0026#39; \u0026#39;.join(str1)) 8\u0026gt;\u0026gt; pig year 2019 910print(str2+str3+\u0026#39; \u0026#39;.join(str1)) 11\u0026gt;\u0026gt; happy new year 2019 Thật tuyệt vời phải không các bạn.\nNgoài ra các bạn có thể sử dụng biếu thức chính quy để tìm kiếm chuỗi và pattern. Về biểu thức chính quy trong python, các bạn có thể tìm hiểu ở https://docs.python.org/3/library/re.html.\nMẹo số 3: Chuỗi lồng nhau Thử tưởng tượng rằng bạn có hàng tá các list, và sau một mớ các thao tác, kết quả của bạn là một list các list. Chúng ta sẽ sử dụng itertools - một thư viện được cung cấp sẵn trong python để giải quyết vấn đề này giúp chúng ta.\n12import itertools 3flatten = lambda x: list(itertools.chain.from_iterable(x)) 4s =[[\u0026#34;this\u0026#34;,\u0026#34;is\u0026#34;],[\u0026#34;the\u0026#34;,\u0026#34;year\u0026#34;], [\u0026#34;of\u0026#34;, \u0026#34;pig\u0026#34;], [\u0026#34;in\u0026#34;], [\u0026#34;Việt\u0026#34;, \u0026#34;Nam\u0026#34;]] 56print(\u0026#39; \u0026#39;,join(flatten(s))) 7\u0026gt;\u0026gt; this is the year of pig in Việt Nam Nếu bạn chạy dòng code trên bị lỗi, rất có thể là do terminal của bạn không hỗ trợ tiếng việt font unicode. Hãy chuyển qua font unicode trên terminal hoặc dùng terminal của ubuntu, bash (trên window 10).\nNgoài ra, itertools còn hỗ trợ rất nhiều hàm khác để giúp chúng ta thao tác trên chuỗi lồng dễ dàng hơn. Các bạn có thể tham khảo thêm ở https://docs.python.org/2/library/itertools.html.\nMẹo 4: Cấu trúc dữ liệu đơn giản. Chúng ta có thể xây dựng một cây đơn giản chỉ với một dòng mã lệnh:\n1def tree(): return defaultdict(tree) Một ví dụ đơn giản khác là hàm tạo số nguyên chỉ với 1 dòng code ngắn gọn\n1reduce( (lambda r,x: r-set(range(x**2,N,x)) if (x in r) else r), 2range(2,N), set(range(2,N))) Python có hỗ trợ nhiều thư viện rất mạnh trong việc giải quyết các vấn đề trong thế giới thực. Ví dụ thư viện Collections\n1from collections import Counter 2myList = [1,1,2,3,4,5,3,2,3,4,2,1,2,3] 3print(Counter(myList)) 4Counter({2: 4, 3: 4, 1: 3, 4: 2, 5: 1}) Một lưu ý nhỏ là các thư viện này chỉ nên sử dụng khi tập dữ liệu của bạn nhỏ, nếu tập dữ liệu lớn, ví dụ bạn cần đếm số lần xuất hiện của các từ trong tập văn bản với 100GB dữ liệu. Bạn hãy dùng cách khác, ví dụ hadoop, hoặc tăng bộ nhớ ram của bạn lên, ví dụ 1 Tb chẳng hạn :)\nMẹo 5: Xuất dữ liệu ra command line dễ dàng Để xuất dữ liệu của một list int ra command line, theo như mẹo ở trên, ta sẽ dùng hàm .join() và vòng lặp.\n```python` lst_row = [1,2,3,4,5] print(\u0026rsquo;,\u0026rsquo;.join([str(x) for x in lst_row]) 1,2,3,4,5\n12Cách đơn giản hơn chỉ với một dòng code (Ước gì mình biết cách này sớm hơn, hix). 34```python 5print(*lst_row, sep=\u0026#39;,\u0026#39;) 61,2,3,4,5 Một mẹo khác là trong một số trường hợp duyệt mảng, bạn cần lấy giá trị và chỉ số của mảng đó để làm một số thao tác khác\n12lst_arr = [\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;,\u0026#39;d\u0026#39;] 34int_index = 0 56for item in lst_arr: 7print(int_index, item) 8int_index = int_index + 1 910\u0026gt;\u0026gt; 0 a 111 b 122 c 133 d hoặc cách viết giống c/c++\n12for int_index in len(lst_arr): 3print(int_index, lst_arr[int_index]) 45\u0026gt;\u0026gt; 0 a 61 b 72 c 83 d Một cách khác là sử dụng hàm có sẵn enumerate của python\n1for int_index, item in enumerate(lst_arr): 2print(int_index, item) 34\u0026gt;\u0026gt; 0 a 51 b 62 c 73 d Có rất nhiều mẹo hay để đơn giản hoá việc xuất dữ liệu ra terminal. Hãy thông tin cho mình biết nếu bạn có nhiều mẹo hay khác cần chia sẻ nhé.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Feb 5, 2019","img":"","permalink":"/blog/2019-02-05-5-python-tricks-you-need-to-know-today/","series":null,"tags":["Machine learning","Deeplearning","python"],"title":"5 Mẹo Hay Sử Dụng Python"},{"categories":null,"content":"Đặt vấn đề DonorsChoose.org được thành lập vào năm 2000 bởi một giáo viên lịch sử tại Mỹ tên là Bronx và đã huy động được 685 triệu đô la cho các lớp học. 3/4 các giáo viên ở các trường công lập ở Hoa Kỳ đã sử dụng Donor để gửi các yêu cầu bài tập cho học sinh. Từ đó, Donor trở thành nền tảng giáo dục hàng đầu hỗ trợ cho các vấn đề giáo dục công cộng.\nĐến nay, hơn 3 triệu người dùng và đối tác đã đóng góp hơn 1,1 triệu dự án cho Donor. Nhưng các giáo viên vẫn phải tốn hàng tỷ đô tiền túi để chuẩn bị các dụng cụ học tập trên lớp (để truyền tải kiến thức cho học sinh).\nGiải pháp được đưa ra ở đây là xây dựng một chiến dịch gợi ý cho các nhà tại trợ.\nPhân tích dữ liệu Chúng ta có các file sau:\nFile Donations.csv. Với mỗi dự án (Project ID), sẽ có 1 hoặc nhiều nhà quyên góp (Donor ID) mỗi cặp (dự án - nhà quyên góp sẽ định dang bằng 1 mã chung (Donation ID) và có các cột thông tin liên quan đến việc quyên góp đó). File có xấp xỉ 4.67 triệu dòng (chính xác là 4687844 dòng) và 7 cột. (Project ID - Định danh dự án, Donation ID - Định danh khoảng đóng góp (tưởng tượng như khoá tự tăng của bảng này đó các bạn), Donor ID - Mã định danh người đóng góp, Donation Included Option - hỗ trợ website donoschoose 15% giá trị quyên góp, Donation Amount - Số tiền quyên góp, Donor Cart Sequence - Thứ tự của dự án trọng bảng danh sách quyên góp,Donation Received Date - Ngày giờ quyên góp).\nFile Donors.csv. File định danh người quyên góp. Chứa tổng cộng hơn 2 triệu dòng( chính xác là 2122640 dòng) File có kích thước 2122640 x 5 với các thông tin cột là Donor ID (khoá chính, không trùng), Donor City (tên thành phố nhà đầu tư đang sinh sống), Donor State (tiểu bang mà người quyên góp đang sống), Donor is teacher, Donor Zip (3 ký tự đầu của mã bưu điện nhà từ thiện).\nFile Teacher.csv. File có tổng cộng 402900 dòng với các cột TeachId, Teacher Prefix (Mr, Mrs, Ms), Teacher First Project Posted Date.\nFile Schools.csv. File có tổng cộng 72994 dòng với các cột là SchoolID, SchoolName (tên trường có thể trùng nhau), School Metro Type ( phân loại trường thuộc 1 trong 5 nhóm : suburnban - ngoại ô, rural - nông thôn, uban - thành thị, town - thị trấn, unknow), School Percentage Free Lunch ( Số nguyên, mô tả tỷ lệ phần trăm số học sinh đủ điều kiện ăn trưa miễn phí hoặc ăn trưa giảm phí. Dữ liệu thu được cung cấp bởi một đối tác thống kê độc lập là NCES. Nếu trường nào không có giá trị do NCES cung cấp, chúng ta sẽ lấy số phần trăm này là trung bình phần trăm của các trường cùng huyện), School State (Trường đang toạ lạc ở bang nào (vd cali, Florida, Virginia, \u0026hellip;)), School Zip (mã bưu chính), School City, School County\nFile Resources.csv. Với mỗi dự án, chúng ta cần các loại tài nguyên khác nhau. Các cột là Project ID (mã dự án), Resource Item Name (tên tài nguyên cần cho dự án đó vd project 000009891526c0ade7180f8423792063 cần \u0026lsquo;chair move and store cart\u0026rsquo;), Resource Quantity (số lượng tài nguyên cần, vd cần 1 cái ghế, 2 cái bảng v.v), Resource Unit Price (đơn giá cho 1 đơn vị tài nguyên, vd cái ghế giá 7 ngàn, cái bảng giá 10 ngàn, nếu 1 unit là ghế + bảng thì là 17 ngàn), Resource Vendor Name(nhà cung cấp, vd: Amazon Business, Woodwind and Brasswind).\nFile Projects.csv\nXây dựng chiến lược tiếp cận bài toán Hãy xem đây như là bài toán gợi ý. Và Donors chính là hệ thống cung cấp các sản phẩm. Ví dụ đơn giản là bạn có website nghe nhạc mp3.zing.vn, alice vào nghe một hoặc một vài bài nhạc. Chúng ta sẽ xây dựng một hệ gợi ý những bài nhạc tiếp theo alice nên nghe dựa vào những bài nhạc đã nghe trước đó của alice. Tương tự vậy, hệ thống Donor như là website mp3.zing, bài nhạc tương tự như các project đang có, người dùng tương tự như các nhà tự thiện. Một khi một nhà từ thiện đã quyên góp cho 1 hoặc 1 nhón các dự án, chúng ta sẽ lên kế hoạch và gợi ý cho khác hàng dự án tiếp theo khách hàng nên tìm hiểu kỹ để xét xem có nên donate hay không.\nDựa vào các chiến lược trên, chúng ta có 3 cách có thể tiếp cận vấn đề:\n Content-based filltering. Collaborative Filtering Hybrid methods  1. Tiền xử lý dữ liệu Trước khi bắt đầu xây dựng chương trình gợi ý, chúng ta cần phải load dữ liệu lên bộ nhớ chính và làm sạch dữ liệu.\nTrước tiên, chúng ta sẽ import các thư viện cần thiết. Nếu thiếu các thư viện nào, các bạn cứ pip install tên thư viện trong cmd/terminal là được\n12import numpy as np 3import scipy 4import pandas as pd 5import math 6import random 7import sklearn 8from nltk.corpus import stopwords 9from sklearn.model_selection import train_test_split 10from sklearn.feature_extraction.text import TfidfVectorizer 11from sklearn.metrics.pairwise import cosine_similarity 12from scipy.sparse.linalg import svds 13import matplotlib.pyplot as plt 14import os Tiếp theo, chúng ta sẽ load 3 file Projects.csv, Donations.csv, Donors.csv lên và merge donations với donors.\n1# Set up test mode to save some time 2test_mode = True 34# Read datasets 5projects = pd.read_csv(\u0026#39;../input/Projects.csv\u0026#39;) 6donations = pd.read_csv(\u0026#39;../input/Donations.csv\u0026#39;) 7donors = pd.read_csv(\u0026#39;../input/Donors.csv\u0026#39;) 89#this piece of code converts Project_ID which is a 32-bit Hex int digits 10-1010 10# create column \u0026#34;project_id\u0026#34; with sequential integers 11f=len(projects) 12projects[\u0026#39;project_id\u0026#39;] = np.nan 13g = list(range(10,f+10)) 14g = pd.Series(g) 15projects[\u0026#39;project_id\u0026#39;] = g.values 1617# Merge datasets 18donations = donations.merge(donors, on=\u0026#34;Donor ID\u0026#34;, how=\u0026#34;left\u0026#34;) 19df = donations.merge(projects,on=\u0026#34;Project ID\u0026#34;, how=\u0026#34;left\u0026#34;) 2021# only load a few lines in test mode 22if test_mode: 23df = df.head(10000) 2425donations_df = df Ở giai đoạn xây dựng code và debug, mình chỉ load 10000 dữ liệu lên để test thử (để đảm bảo rằng mình code đúng - bằng cách set test_mode = True). Khi chạy thật mình sẽ set lại test_mode = False.\nThực hiện một vài bước phân tích kỹ thuật đơn giản để nắm rõ hơn về dữ liệu.\nThử đo mối quan hệ giữa các dự án và các \u0026ldquo;mạnh thường quân\u0026rdquo;\n1# Deal with missing values 2donations[\u0026#34;Donation Amount\u0026#34;] = donations[\u0026#34;Donation Amount\u0026#34;].fillna(0) 34# Define event strength as the donated amount to a certain project 5donations_df[\u0026#39;eventStrength\u0026#39;] = donations_df[\u0026#39;Donation Amount\u0026#39;] 67def smooth_donor_preference(x): 8return math.log(1+x, 2) 910donations_full_df = donations_df \\ 11.groupby([\u0026#39;Donor ID\u0026#39;, \u0026#39;Project ID\u0026#39;])[\u0026#39;eventStrength\u0026#39;].sum() \\ 12.apply(smooth_donor_preference).reset_index() 1314# Update projects dataset 15project_cols = projects.columns 16projects = df[project_cols].drop_duplicates() 1718print(\u0026#39;# of projects: %d\u0026#39; % len(projects)) 19print(\u0026#39;# of unique user/project donations: %d\u0026#39; % len(donations_full_df)) 1# of projects: 1889 2# of unique user/project donations: 8648 Dựa vào kết quả trên tập test, chúng ta có thể đưa ra một vài nhận xét như sau:\n Hầu hết các mạnh thường quân chỉ donate cho 1 project (tỷ lệ 86,48%) Sẽ có trường hợp 1 mạnh thường quân sẽ donate cho nhiều dự án, và cũng có trường hợp 1 mạnh thường quân donate nhiều lần cho 1 dự án. Trường hợp này chiếm phần ít.  Để đánh giá mô hình, chúng ta sẽ chia tập dữ liệu thành 2 phần là train và test. Ở đây, chúng ta sẽ set tỷ lệ train/test là 20%.\n2. Xây dựng mô hình Content-Based Filtering Cách tiếp cận đầu tiên, chúng ta sẽ tìm những project gần giống với những project mà donor đã donated. Đơn giản nhất là với mỗi project, chúng ta sẽ định nghĩa các vector đặc trưng của chúng và đo độ giống nhau giữa hai vector đó. Vector đặc trưng chúng ta có thể xây dựng trên các thuộc tính như project type, project catefory, grade level, resource category, cost, school zip code, \u0026hellip; hoặc các bạn có thể từ các vector cơ bản do tập dữ liệu cung cấp bổ sung thêm các vector cấp cao hơn, ví dụ như là rút trích các feature từ tên project hoặc mô tả của project, loại bỏ stopwords \u0026hellip;\nỞ đây, chúng ta sẽ sử dụng kỹ thuật TF-IDF để rút trích thông tin đặc trưng của dự án dựa trên project tittle và description. Về TF-IDF, các bạn có thể đọc ở một bài viết nào đó của google, mình không tiện nhắc đến nó chi tiết ở bài viết này.\na. Xây dựng tập đặc trưng 12# Preprocessing of text data 3textfeats = [\u0026#34;Project Title\u0026#34;,\u0026#34;Project Essay\u0026#34;] 4for cols in textfeats: 5projects[cols] = projects[cols].astype(str) 6projects[cols] = projects[cols].astype(str).fillna(\u0026#39;\u0026#39;) # FILL NA 7projects[cols] = projects[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently 89text = projects[\u0026#34;Project Title\u0026#34;] + \u0026#39; \u0026#39; + projects[\u0026#34;Project Essay\u0026#34;] 10vectorizer = TfidfVectorizer(strip_accents=\u0026#39;unicode\u0026#39;, 11analyzer=\u0026#39;word\u0026#39;, 12lowercase=True, # Convert all uppercase to lowercase 13stop_words=\u0026#39;english\u0026#39;, # Remove commonly found english words (\u0026#39;it\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;the\u0026#39;) which do not typically contain much signal 14max_df = 0.9, # Only consider words that appear in fewer than max_df percent of all documents 15# max_features=5000 # Maximum features to be extracted  16) 17project_ids = projects[\u0026#39;Project ID\u0026#39;].tolist() 18tfidf_matrix = vectorizer.fit_transform(text) 19tfidf_feature_names = vectorizer.get_feature_names() 202122## build profile 2324def get_project_profile(project_id): 25idx = project_ids.index(project_id) 26project_profile = tfidf_matrix[idx:idx+1] 27return project_profile 2829def get_project_profiles(ids): 30project_profiles_list = [get_project_profile(x) for x in np.ravel([ids])] 31project_profiles = scipy.sparse.vstack(project_profiles_list) 32return project_profiles 3334def build_donors_profile(donor_id, donations_indexed_df): 35donations_donor_df = donations_indexed_df.loc[donor_id] 36donor_project_profiles = get_project_profiles(donations_donor_df[\u0026#39;Project ID\u0026#39;]) 37donor_project_strengths = np.array(donations_donor_df[\u0026#39;eventStrength\u0026#39;]).reshape(-1,1) 38#Weighted average of project profiles by the donations strength 39donor_project_strengths_weighted_avg = np.sum(donor_project_profiles.multiply(donor_project_strengths), axis=0) / (np.sum(donor_project_strengths)+1) 40donor_profile_norm = sklearn.preprocessing.normalize(donor_project_strengths_weighted_avg) 41return donor_profile_norm 4243from tqdm import tqdm 4445def build_donors_profiles(): 46donations_indexed_df = donations_full_df[donations_full_df[\u0026#39;Project ID\u0026#39;].isin(projects[\u0026#39;Project ID\u0026#39;])].set_index(\u0026#39;Donor ID\u0026#39;) 47donor_profiles = {} 48for donor_id in tqdm(donations_indexed_df.index.unique()): 49donor_profiles[donor_id] = build_donors_profile(donor_id, donations_indexed_df) 50return donor_profiles 5152donor_profiles = build_donors_profiles() 53print(\u0026#34;# of donors with profiles: %d\u0026#34; % len(donor_profiles)) 5455mydonor1 = \u0026#34;6d5b22d39e68c656071a842732c63a0c\u0026#34; 56mydonor2 = \u0026#34;0016b23800f7ea46424b3254f016007a\u0026#34; 57mydonor1_profile = pd.DataFrame(sorted(zip(tfidf_feature_names, 58donor_profiles[mydonor1].flatten().tolist()), 59key=lambda x: -x[1])[:10], 60columns=[\u0026#39;token\u0026#39;, \u0026#39;relevance\u0026#39;]) 61mydonor2_profile = pd.DataFrame(sorted(zip(tfidf_feature_names, 62donor_profiles[mydonor2].flatten().tolist()), 63key=lambda x: -x[1])[:10], 64columns=[\u0026#39;token\u0026#39;, \u0026#39;relevance\u0026#39;]) 6566print(\u0026#39;feature of user \u0026#39; + str(mydonor1)) 67print(mydonor1_profile) 6869print(\u0026#39;feature of user \u0026#39; + str(mydonor2)) 70print(mydonor2_profile) Mã nguồn ở trên cũng có chú thích đầy đủ, và đọc cũng dễ hiểu, nên mình không nói thêm gì nhiều. Mình tóm gọn một chút là chúng ta sẽ convert toàn bộ project tittle và description về dạng chữ thường, tách từ dựa vào khoảng trắng, loại bỏ những english stopwords. Sau đó xây dựng profile cho từng donor.\nKết quả\n1feature of user 6d5b22d39e68c656071a842732c63a0c 2token relevance 30 music 0.450057 41 auditorium 0.355256 52 cart 0.272809 63 chair 0.223861 74 equipment 0.211338 85 musicians 0.179244 96 time 0.172908 107 moving 0.137749 118 ohms 0.134065 129 prepare 0.131274 13feature of user 0016b23800f7ea46424b3254f016007a 14token relevance 150 pollinators 0.670222 161 plants 0.305398 172 module 0.223407 183 pollination 0.211870 194 seeds 0.180609 205 writing 0.166816 216 books 0.137455 227 reading 0.115003 238 weaved 0.111704 249 bees 0.101842 Nhìn kết quả trên, ta thấy rằng donor 1 có vẻ thích những thứ liên quan đến âm nhạc (music, auditorim), trong khi đó donor 2 thích những thứ liên quan đến trồng trọt (pollinators - thụ phấn, plants - cây cối)\nb. Xây dựng mô hình Việc xây dựng mô hình đến đây là khá đơn giản. Chúng ta chỉ việc tính khoảng cách cosin giữa vector cần dự đoán và toàn bộ vector có trong tập train rồi show top K prject có liên quan cao nhất\n123class ContentBasedRecommender: 45MODEL_NAME = \u0026#39;Content-Based\u0026#39; 67def __init__(self, projects_df=None): 8self.project_ids = project_ids 9self.projects_df = projects_df 1011def get_model_name(self): 12return self.MODEL_NAME 1314def _get_similar_projects_to_donor_profile(self, donor_id, topn=1000): 15#Computes the cosine similarity between the donor profile and all project profiles 16cosine_similarities = cosine_similarity(donor_profiles[donor_id], tfidf_matrix) 17#Gets the top similar projects 18similar_indices = cosine_similarities.argsort().flatten()[-topn:] 19#Sort the similar projects by similarity 20similar_projects = sorted([(project_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1]) 21return similar_projects 2223def recommend_projects(self, donor_id, projects_to_ignore=[], topn=10, verbose=False): 24similar_projects = self._get_similar_projects_to_donor_profile(donor_id) 25#Ignores projects the donor has already donated 26similar_projects_filtered = list(filter(lambda x: x[0] not in projects_to_ignore, similar_projects)) 2728recommendations_df = pd.DataFrame(similar_projects_filtered, columns=[\u0026#39;Project ID\u0026#39;, \u0026#39;recStrength\u0026#39;]).head(topn) 2930recommendations_df = recommendations_df.merge(self.projects_df, how = \u0026#39;left\u0026#39;, 31left_on = \u0026#39;Project ID\u0026#39;, 32right_on = \u0026#39;Project ID\u0026#39;)[[\u0026#39;recStrength\u0026#39;, \u0026#39;Project ID\u0026#39;, \u0026#39;Project Title\u0026#39;, \u0026#39;Project Essay\u0026#39;]] 333435return recommendations_df 363738cbr_model = ContentBasedRecommender(projects) 394041print(\u0026#39;recommend for user \u0026#39; + str(mydonor1)) 42print(cbr_model.recommend_projects(mydonor1)) 4344print(\u0026#39;recommend for user \u0026#39; + str(mydonor2)) 45print(cbr_model.recommend_projects(mydonor2)) Kết quả\n1recommend for user 6d5b22d39e68c656071a842732c63a0c 2recStrength ... Project Essay 30 1.000000 ... the music students in our classes perform freq... 41 0.390997 ... i have spent 12 years as an educator rebuildin... 52 0.338676 ... \u0026#34;music is what feelings sound like.\u0026#34; -g. cates... 63 0.331034 ... true music is created not by the teacher but b... 74 0.324355 ... every morning my first grade students come to ... 85 0.322923 ... in today\u0026#39;s fast paced environment, students ne... 96 0.315910 ... \u0026#34;music is a moral law. it gives soul to the u... 107 0.314845 ... i walk in the door so excited to get the stude... 118 0.310103 ... some students have never put their hands on a ... 129 0.297516 ... my students do not have money, but they do hav... 1314[10 rows x 4 columns] 15recommend for user 0016b23800f7ea46424b3254f016007a 16recStrength ... Project Essay 170 1.000000 ... my students are creative, curious, and excited... 181 0.211962 ... our school is a title 1 school. 100% of stude... 192 0.189111 ... my students are active and eager learners who ... 203 0.188095 ... being a small rural school we do a lot of trad... 214 0.173520 ... \u0026#34;science is a way of life...science is the pro... 225 0.159015 ... my second grade students love to come to schoo... 236 0.158071 ... i teach 28 fourth graders in a neighborhood sc... 247 0.150389 ... in my classroom we are working hard to become ... 258 0.144724 ... as a teacher in a diverse, low-income, high-po... 269 0.139937 ... have you ever been told you need to read, but ... 2728[10 rows x 4 columns] Mình dùng cmd nên bị giới hạn kết quả, các bạn có thể write log vào file hoặc dùng jupiter để show kết quả rõ hơn.\nỞ đây, chúng ta nhận thấy rằng các recommend cho donor 1 thường là những project liên quan tới âm nhạc (nhìn tập feature ta cũng có thể đoán được). Và recommend cho donor 2 là những thứ liên quan đến chủ đề làm vườn và reading.\n3. Collaborative Filtering Model Lý thuyết về Collaborative Filtering Model các bạn có thể xem ở các bài viết khác của mình hoặc tham khảo thêm trên mạng. Ở đây, mình sẽ sử dụng Singular Value Decomposition (SVD) để xây dựng ma trận đặc trưng.\na. Xây dựng ma trận donor - project Đầu tiên, chúng ta sẽ xây dựng ma trận mối quan hệ giữa donor và project. Nếu donor i có donated cho 1 project j thì dòng i cột j của ma trận sẽ được đánh dấu là 1, ngược lại là 0.\n1#### create matrix 2#Creating a sparse pivot table with donors in rows and projects in columns 3donors_projects_pivot_matrix_df = donations_full_df.pivot(index=\u0026#39;Donor ID\u0026#39;, 4columns=\u0026#39;Project ID\u0026#39;, 5values=\u0026#39;eventStrength\u0026#39;).fillna(0) 67# Transform the donor-project dataframe into a matrix 8donors_projects_pivot_matrix = donors_projects_pivot_matrix_df.as_matrix() 910# Get donor ids 11donors_ids = list(donors_projects_pivot_matrix_df.index) 1213print(donors_projects_pivot_matrix[:5]) # print first 5 row 12array([[ 0., 0., 0., ..., 0., 0., 0.], 3[ 0., 0., 0., ..., 0., 0., 0.], 4[ 0., 0., 0., ..., 0., 0., 0.], 5[ 0., 0., 0., ..., 0., 0., 0.], 6[ 0., 0., 0., ..., 0., 0., 0.]]) b. Singular Value Decomposition Sau khi có ma trận trên, ta có một nhận xét rằng nó rất thưa, số lượng 0 thì nhiều mà 1 thì ít. Sau khi áp dụng SVD, ma trận kết quả sẽ ít thưa hơn (có thể đạt được đến mức không còn thưa nữa).\n1# Performs matrix factorization of the original donor-project matrix 2# Here we set k = 20, which is the number of factors we are going to get 3# In the definition of SVD, an original matrix A is approxmated as a product A ≈ UΣV  4# where U and V have orthonormal columns, and Σ is non-negative diagonal. 5U, sigma, Vt = svds(donors_projects_pivot_matrix, k = 20) 6sigma = np.diag(sigma) 78# Reconstruct the matrix by multiplying its factors 9all_donor_predicted_ratings = np.dot(np.dot(U, sigma), Vt) 1011#Converting the reconstructed matrix back to a Pandas dataframe 12cf_preds_df = pd.DataFrame(all_donor_predicted_ratings, 13columns = donors_projects_pivot_matrix_df.columns, 14index=donors_ids).transpose() 1516print(cf_preds_df.head()) 10003aba06ccf49f8c44fc2dd3b582411 ... ffff088c35d3455779a30898d1327b76 2Project ID ... 34000009891526c0ade7180f8423792063 -3.423182e-34 ...-4.577244e-34 500000ce845c00cbf0686c992fc369df4 -3.061322e-36 ...-6.492305e-36 600002d44003ed46b066607c5455a999a 1.368936e-33 ...-2.239156e-32 700002eb25d60a09c318efbd0797bffb5 1.784576e-33 ...1.163684e-32 80000300773fe015f870914b42528541b 4.314216e-34 ...-4.666110e-34 910[5 rows x 8015 columns] c. Xây dựng Collaborative Filtering Model 123class CFRecommender: 45MODEL_NAME = \u0026#39;Collaborative Filtering\u0026#39; 67def __init__(self, cf_predictions_df, projects_df=None): 8self.cf_predictions_df = cf_predictions_df 9self.projects_df = projects_df 1011def get_model_name(self): 12return self.MODEL_NAME 1314def recommend_projects(self, donor_id, projects_to_ignore=[], topn=10): 15# Get and sort the donor\u0026#39;s predictions 16sorted_donor_predictions = self.cf_predictions_df[donor_id].sort_values(ascending=False) \\ 17.reset_index().rename(columns={donor_id: \u0026#39;recStrength\u0026#39;}) 1819# Recommend the highest predicted projects that the donor hasn\u0026#39;t donated to 20recommendations_df = sorted_donor_predictions[~sorted_donor_predictions[\u0026#39;Project ID\u0026#39;].isin(projects_to_ignore)] \\ 21.sort_values(\u0026#39;recStrength\u0026#39;, ascending = False) \\ 22.head(topn) 232425recommendations_df = recommendations_df.merge(self.projects_df, how = \u0026#39;left\u0026#39;, 26left_on = \u0026#39;Project ID\u0026#39;, 27right_on = \u0026#39;Project ID\u0026#39;)[[\u0026#39;recStrength\u0026#39;, \u0026#39;Project ID\u0026#39;, \u0026#39;Project Title\u0026#39;, \u0026#39;Project Essay\u0026#39;]] 282930return recommendations_df 3132cfr_model = CFRecommender(cf_preds_df, projects) 33print(cfr_model.recommend_projects(mydonor1)) 3435print(cfr_model.recommend_projects(mydonor2)) 1[5 rows x 8015 columns] 2recStrength ... Project Essay 30 3.015461e-17 ... Our students are some of the hardest working k... 41 2.237275e-17 ... As Service Learning Coordinators at our elemen... 52 2.188501e-17 ... We are trying to engage more students in scien... 63 1.768711e-17 ... We are a brand new charter school that has onl... 74 1.344489e-17 ... Sitting at a desk for a sustained period of ti... 85 9.957278e-18 ... Our students come from a Title I school in Jer... 96 6.932330e-18 ... In my school 50% of the students are socioecon... 107 8.589640e-19 ... Have you ever been told you need to read, but ... 118 6.698040e-19 ... \u0026#34;I cannot say good-bye to those whom I have gr... 129 5.733941e-19 ... I have students in class who are squinting and... 1314[10 rows x 4 columns] 15recStrength ... Project Essay 160 3.015461e-17 ... Our students are some of the hardest working k... 171 2.237275e-17 ... As Service Learning Coordinators at our elemen... 182 2.188501e-17 ... We are trying to engage more students in scien... 193 1.768711e-17 ... We are a brand new charter school that has onl... 204 1.344489e-17 ... Sitting at a desk for a sustained period of ti... 215 9.957278e-18 ... Our students come from a Title I school in Jer... 226 6.932330e-18 ... In my school 50% of the students are socioecon... 237 8.589640e-19 ... Have you ever been told you need to read, but ... 248 6.698040e-19 ... \u0026#34;I cannot say good-bye to those whom I have gr... 259 5.733941e-19 ... I have students in class who are squinting and... Kết quả trả về có vẻ không được đẹp như ở phương pháp trên. Ở đây, thuật toán dựa vào hành vi donated của những người khác có điểm tương đồng với user donor 1 và 2. Bởi vậy gợi ý những project sẽ khác những gợi ý ở phương pháp 1.\n4. Hybrid Method Phương pháp lai này kết hợp cả 2 hướng tiếp cận của hai phương pháp ở trên. Ở đây, chúng ta sẽ xây dựng một mô hình nhỏ, nhân điểm của content based và collaborative filtering lại với nhau, sau đó xếp hạng để được điểm hybrid. Đây là 1 cách đơn giản, các bạn có thể tìm đọc nhiều cách tiếp cận khác và ứng dụng vào bài toán.\n1class HybridRecommender: 23MODEL_NAME = \u0026#39;Hybrid\u0026#39; 45def __init__(self, cb_rec_model, cf_rec_model, projects_df): 6self.cb_rec_model = cb_rec_model 7self.cf_rec_model = cf_rec_model 8self.projects_df = projects_df 910def get_model_name(self): 11return self.MODEL_NAME 1213def recommend_projects(self, donor_id, projects_to_ignore=[], topn=10): 14#Getting the top-1000 Content-based filtering recommendations 15cb_recs_df = self.cb_rec_model.recommend_projects(donor_id, projects_to_ignore=projects_to_ignore, 16topn=1000).rename(columns={\u0026#39;recStrength\u0026#39;: \u0026#39;recStrengthCB\u0026#39;}) 1718#Getting the top-1000 Collaborative filtering recommendations 19cf_recs_df = self.cf_rec_model.recommend_projects(donor_id, projects_to_ignore=projects_to_ignore, 20topn=1000).rename(columns={\u0026#39;recStrength\u0026#39;: \u0026#39;recStrengthCF\u0026#39;}) 2122#Combining the results by Project ID 23recs_df = cb_recs_df.merge(cf_recs_df, 24how = \u0026#39;inner\u0026#39;, 25left_on = \u0026#39;Project ID\u0026#39;, 26right_on = \u0026#39;Project ID\u0026#39;) 2728#Computing a hybrid recommendation score based on CF and CB scores 29recs_df[\u0026#39;recStrengthHybrid\u0026#39;] = recs_df[\u0026#39;recStrengthCB\u0026#39;] * recs_df[\u0026#39;recStrengthCF\u0026#39;] 3031#Sorting recommendations by hybrid score 32recommendations_df = recs_df.sort_values(\u0026#39;recStrengthHybrid\u0026#39;, ascending=False).head(topn) 3334recommendations_df = recommendations_df.merge(self.projects_df, how = \u0026#39;left\u0026#39;, 35left_on = \u0026#39;Project ID\u0026#39;, 36right_on = \u0026#39;Project ID\u0026#39;)[[\u0026#39;recStrengthHybrid\u0026#39;, 37\u0026#39;Project ID\u0026#39;, \u0026#39;Project Title\u0026#39;, 38\u0026#39;Project Essay\u0026#39;]] 394041return recommendations_df 4243hybrid_model = HybridRecommender(cbr_model, cfr_model, projects) 444546print(hybrid_model.recommend_projects(mydonor1)) 4748print(hybrid_model.recommend_projects(mydonor2)) 1recStrengthHybrid ... Project Essay 20 1.574375e-18 ... we are trying to engage more students in scien... 31 1.221807e-18 ... in my school 50% of the students are socioecon... 42 1.214293e-18 ... our students are some of the hardest working k... 53 4.037232e-19 ... sitting at a desk for a sustained period of ti... 64 6.661794e-20 ... “music expresses that which cannot be put into... 75 4.872264e-20 ... i walk in the door so excited to get the stude... 86 4.410098e-20 ... i have spent 12 years as an educator rebuildin... 97 2.907349e-20 ... \u0026#34;music is what feelings sound like.\u0026#34; -g. cates... 108 2.121616e-20 ... \u0026#34;i cannot say good-bye to those whom i have gr... 119 1.353927e-20 ... our band program is one of the largest in our ... 1213[10 rows x 4 columns] 14recStrengthHybrid ... Project Essay 150 2.811124e-18 ... in this modern, digital age, i would like to u... 161 1.249967e-18 ... we are a brand new charter school that has onl... 172 6.055628e-19 ... my students are african american and hispanic.... 183 5.912367e-19 ... the a. community and its students are a very s... 194 2.541749e-19 ... do you want to go on an adventure and learn ab... 205 2.494812e-19 ... the average day in my class involves students ... 216 2.323313e-19 ... i teach ela (reading component) to self-contai... 227 1.271629e-19 ... hi there! do you want to help to instill a lif... 238 1.044990e-19 ... having writing utensils is essential for stude... 249 1.004780e-19 ... there\u0026#39;s no such thing as a kid who hates readi... 2526[10 rows x 4 columns] Kết quả trả ra tốt hơn nhiều so với cách 2, donor1 có music, donor2 có cây trồng và sách.\n5. Đánh giá mô hình Có rất nhiều cách khác nhau để đánh giá mô hình recommend system. Một trong các cách mình sử dụng ở đây là sử dụng độ đo top K accuracy. Độ đo này được tính như sau:\nVới mỗi user: Với mỗi item user đã pick trong test set Lấy mẫu 1000 item khác mà người dùng chưa bao giờ pick\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo. Cố lên.\n","date":"Dec 11, 2018","img":"","permalink":"/blog/2019-01-03-donor-project-matching-with-recommender-systems/","series":null,"tags":["Machine learning","Deeplearning","recommender system"],"title":"Hệ Thống Gợi Ý Khoá Học Cho Website DonorChoose.org"},{"categories":null,"content":"Lời mở đầu Việc huấn luyện một mô hình neural network khá đơn giản, chỉ việc download code mẫu về, quăng tập data của mình vào, rồi cho chạy, xong. Nhưng khó khăn ở đây là làm cách nào để nâng độ chính xác của mô hình lên. Ở bài viết này, chúng ta sẽ tìm hiểu một số cách giúp tăng độ chính xác của mô hình.\nKiểm tra dữ liệu   Thực chất, chúng ta phải hiểu rõ kỹ chúng ta đang có những gì trong tay, thì chúng ta mới dạy cho máy học đủ và đúng được. Các bạn hãy kiểm tra thật kỹ để đảm bảo rằng tập nhãn được gán chính xác, bouding box của đối tượng được vẽ không quá dư thừa, không có missing value, v.v. Một ví dụ nhỏ là tập MNIST, có nhiều hình bị nhập nhằng giữa những con số, chúng ta không thể phân biệt được chính xác hình đó là con số nào bằng mắt thường.\n  Tiếp theo, các bạn hãy quyết định xem rằng mình có nên sử dụng các pre-train model hay không.\n    Nếu tập dữ liệu của bạn gần giống với tập dữ liệu ImageNet, hãy dùng pre-train model. Có các mô hình đã được huấn luyện sẵn là VGG net, ResNet, DenseNet, Xception. Với các kiến trúc khác nhau như VGG(16 và 19 layer), ResNet (50, 101, 152 layer), DenseNet(201,169,121 layer). Ban đầu, đừng sử dụng các kiến trúc có số lượng nhiều (ResNet152, DenseNet201) bởi vì nó rất tốn chi phí tính toán. Chúng ta nên bắt đầu bởi các mô hình nhỏ như VGG16, ResNet50. Hãy chọn một mô hình mà bạn nghĩ là sẽ có kết quả tốt. Sau khi huấn luyện, nếu kết quả không được như ý muốn, hãy tăng số lớp lên (ví dụ ban đầu chọn Resnet50, sau đó nâng lên Resnet101, \u0026hellip;).\n  Nếu bạn có ít dữ liệu, bạn nãy \u0026ldquo;đóng băng\u0026rdquo; lại trọng số của pre-train model, chỉ huấn luyện phần phân lớp. Bạn cũng có thể thêm phần Dropout để tránh overfit.\n  Nếu tập dữ liệu của bạn không giống một tí nào so với taapk ImageNet, không nên dùng pre-train model.\n   Luôn luôn sử dụng lớp chuẩn hoá trong mô hình. Nếu bạn huấn luyện mô hình với batch-size lớn ( ví dụ lớn hơn 10), hãy sử dụng BatchNormalization Layer trong keras. Nếu bạn sử dụng batch-size nhỏ (ví dụ 1), thì hãy sử dụng InstanceNormalization. Hai layer này đã có sẵn trong Keras, trong các framework khác thì mình không rõ lắm. Có nhiều tác giả đã chỉ ra rằng sử dụng BatchNormalization sẽ cho kết quả tốt hơn nếu tăng batch-size và hiệu năng sẽ giảm khi batch-size nhỏ, và trong trường hợp batch-size nhỏ thì kết quả sẽ tốt hơn một tí khi sử dụng InstanceNormalization thay cho BatchNormalization. Ngoài ra, các bạn cũng có thể sử dụng GroupNormalization (mình chưa kiểm chứng GroupNormalization có làm tăng độ chính xác hay không).\n  Nếu bạn sử dụng concatenation layer để kết hợp các feature từ nhiều convolution layers (Li), và những Li trên rút trích thông tin từ cùng một input (F), thì bạn jay sử dụng SpatialDropout ngay sau concatenation layer trên (Xem hình bên dưới). Khi các convolution layer rút trích thông tin từ cùng một nguồn, các đặc trưng của chúng thường sẽ có mức tương quan với nhau rất lớn. SpatialDropout sẽ loại bỏ những đặc trưng có mức độ liên quan cao này và giúp bạn chống lại hiện tượng overfiting. Thông thường người ta chỉ sử dụng SpatialDropout ở các lớp gần input layer, và không sử dụng chúng ở các lớp cao bên trên.\n   Theo andrej Karpathy, để xác định khả năng lưu trữ thông tin của mô hình, hãy rút một phần nhỏ dữ liệu trong tập train của bạn đem đi huấn luyện. Nếu mô hình không overfit, chúng ta tăng số lượng node/layer lên. Nếu mô hình bị overfit, sử dụng các kỹ thuật như L1, L2, Dropout hoăc các kỹ thuật khác để chống lại việc overfit.\n  Các kỹ thuật chuẩn hoá thường sẽ ràng buộc hoặc tinh gọn các trọng số của mô hình. Nó cũng đồng thời giúp chúng ta chống lại việc gradient explosion (gradient mang giá trị lớn khi tính backpropagation) (lý do là các trọng số sẽ bị giới hạn trong đoạn nào đó, ví dụ L2 giới hạn căn bậc 2 tổng bình phương các trọng số =1 chẳng hạn). Ví dụ dưới sử dụng kares và giới hạn max của L2 là 2.\n  1from keras.constraints import max_norm 2# add to Dense layers 3model.add(Dense(64, kernel_constraint=max_norm(2.))) 4# or add to Conv layers 5model.add(Conv2D(64, kernel_constraint=max_norm(2.)))  Việc sử dụng mean subtraction đôi khi cho kết quả khá tệ, đặc biệt là khi sử dụng trong ảnh xám (grayscale image), hoặc các bài toán phân đoạn ảnh.\n  Luôn nhớ đến việc xáo trộn dữ liệu (nếu bạn có thể). Nếu được, hãy thực hiện xáo trộn dữ liệu trong quá trình huấn luyện. Việc xáo trộn ảnh sẽ giúp bạn cải thiện độ chính xác.\n  Nếu bài toán của bạn thuộc nhóm dense prediction (ví dụ phân đoạn ngữ nghĩa - semantic segmentation). Hãy sử dụng pre-train model là Dilated Residual Networks. Mô hình trên cực kỳ hiệu quả cho bài toán này.\n  Để xác định thông tin ngữ cảnh xung quanh các đối tượng, hãy sử dụng module multi-scale feature pooling. Module này sẽ giúp bạn tăng độ chính xác và thường được sử dụng trong bài toán phân đoạn ngữ nghĩa (semantic segmentation) hoặc bài toán phân đoạn nền (foreground segmentation).\n  Khi bạn tính độ lỗi hoặc độ chính xác, nếu có vùng nào không trả về nhãn, hoặc nhãn trả về không chắc chắn, hãy bỏ qua việc tính toán chúng đi. Hành động này sẽ giúp mô hình của bạn chắc chắn hơn khi đưa ra quyết định.\n  Sử dụng trọng số cho từng class trong quá trình training nếu dữ liệu của bạn có tính bất cân bằng cao. Hãy đặt trọng số lớn cho những lớp có ít dữ liệu, và trọng số nhỏ cho những lớp có nhiều dữ liệu. Trọng số của các lớp có thể được tính toán một cách dễ dàng bằng các sử dụng thư viện skearn trong python. Ngoài ra, bạn có thể sử dụng các kỹ thuật như OverSampling hoặc UnderSampling đối với tập dữ liệu nhỏ.\n  Chọn đúng hàm tối ưu. Có rất nhiều hàm tối ưu như Adam, Adagrad, Adadellta, RMSprop, \u0026hellip; Trong các paper người ta thường sử dụng tổ hợp SGD + momentun. Có hai vấn đề cần được xem xét ở đây: Một là nếu bạn muốn mô hình có độ hội tụ nhanh, hãy dùng Adam ( và có khả năng cao là mô hình sẽ bị kẹt ở điểm cực tiểu cục bộ -\u0026gt; không có tính tổng quát hoá cao). Hai là sử dujg SGD + momentun để tìm cực tiểu toàn cục, mô hình này phụ thuộc rất nhiều vào giá trị khởi tạo ban đầu và mô hình thường sẽ hội tụ rất chậm. (Xem hình bên dưới)\n   Thông thường, chúng ta sẽ chọn learning-rate là (1e-1, 1e-3, 1e-6). Nếu bạn sử dụng pre-train model, hãy sử dụng learning rate nhỏ hơn 1e-3 (ví dụ 1e-4). Nếu bạn không sử dụng pre-train model, hãy sử dụng learning-rate lớn hơn 1e-3. Bạn có thể grid search giá trị learning-rate và chọn ra mô hình cho kết quả tốt nhất. Bạn có thể sử dụng Learing Rate Schedulers giảm giá trịn learning rate trong quá trình huấn luyện mô hình.\n  Bên cạnh việc sử dụng Learing Rate Schedulers để giảm giá trị learning rate, bạn có thể sử dụng một kỹ thuật khác để giảm giá trị learning-rate. Ví dụ sau 5 epochs, độ lỗi trên tập validation không thay đổi, bạn giảm learning-rate đi 10 lần (vd từ 1e-3 thành 1e-4). Trong keras, bạn có thể dễ dàng implement công thức trên bằng việc sử dụng callbacs ReduceLROnPlateau.\n  1reduce = keras.callbacks.ReduceLROnPlateau(monitor=\u0026#39;val_loss\u0026#39;, factor=0.1, patience=5, mode=\u0026#39;auto\u0026#39;) 2early = keras.callbacks.EarlyStopping(monitor=\u0026#39;val_loss\u0026#39;, min_delta=1e-4, patience=10, mode=\u0026#39;auto\u0026#39;) 3model.fit(X, Y, callbacks=[reduce, early]) Ví dụ trên, chúng ta sẽ giảm learning-rate đi 10 lần khi độ lỗi trên tập validation không thay đổi qua 5 lần lặp liên tiếp, và sẽ dừng việc huấn luyện khi độ lỗi không giảm qua 10 lần lặp liên tiếp.\n Nếu bài toán của bạn thuộc nhóm dense prediction như phân đoạn ảnh, phân đoạn ngữ nghĩa, bạn nên sử dụng skip connection để chống lại việc các biên của đối tượng hoặc các thông tin đặc trưng hữu ích của đối tượng bị mất trong max-pooling hoặc strided convolution. Skip connection cũng giúp mô hình học features map từ feature space và image space dễ dàng hơn, và nó cũng giúp cho bạn giảm bị vanish gradient ( giá trị gradient nhỏ dần và gần xấp xỉ bằng 0, nên trọng số không thay đổi nhiều, dẫn đến không hội tụ).\n  Nên sử dụng data augmentation, như là horizontally flipping, rotating, zoom-croping\u0026hellip; để tăng dữ liệu của bạn lên. Việc có nhiều dữ liệu sẽ giúp mô hình có mức tổng quát hoá cao hơn.\n  Sử dụng Max-pooling trước Relu để giảm thiểu mức độ tính toán thay vì làm ngược lại. chúng ta biết rằng ReLU trả ra giá trị có ngưỡng cực tiểu là 0 do f(x)=max(0,x), và max-pooling tính max cho các đặc trưng f(x) = max(x1,x2,\u0026hellip;,xi). Nếu ta sử dụng Conv \u0026gt; ReLU \u0026gt; Max-pooling, ta sẽ tốn i lần tính ReLu, và 1 lần tính max. Nếu ta sử dụng Conv -\u0026gt; max-pooling \u0026gt; ReLU, ta tốn 1 lần tính max, 1 lần tính ReLU.\n  Nếu có thể, hãy thử sử dụng Depthwise Separable Convolution. Nó giúp mô hình giảm số lượng tham số so với các convolution khác, ngoài ra nó giúp mô hình chạy nhanh hơn.\n  Điều cuối cùng là đừng bao giờ từ bỏ. Hãy tin tưởng rằng bạn có thể làm được. Nếu bạn vẫn không thể đạt được độ chính xác như mong đợi, hãy điều chỉnh lại các tham số, kiến trúc mô hình, tập dữ liệu huấn luyện đến khi bạn đạt được mô hình với độ chính xác như bạn đề ra.\n  Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo. Cố lên.\n","date":"Dec 11, 2018","img":"","permalink":"/blog/2018-12-11-a-bunch-of-tips-and-tricks-for-training-deep-neural-networks/","series":null,"tags":["Machine learning","Deeplearning","object detector","single shot"],"title":"Một Số Mẹo Để Lựa Chọn Mô Hình Object Detection"},{"categories":null,"content":"Lời mở đầu Các thuật toán phát hiện đối tượng, như các thuật toán thuộc nhóm region proposal hoặc single shot đầu bắt đầu bởi những ý tưởng khác nhau, nhưng sau qua một vài quá trình cập nhật và nâng cấp cho đến thời điểm hiện tại, mô hình chung của chúng đã gần gần giống nhau hơn. Và hai thuật toán trên là hai thuật toán tiêu biểu cạnh tranh nhau danh hiệu thuật toán phát hiện đối tượng nhanh nhất và thuật toán nhận diện chính xác nhất. Trong bài viết này, chúng ta sẽ đề cập đến một số chiến lược lựa chọn mô hình cho bài toán object detector và một số benchmarks do team Google Research thực hiện.\nBox encoding và loss function Có rất nhiều hàm lỗi và box encoding được sử dụng trong các thuật toán phát hiện đối tượng. Ví dụ, SSD trả ra căn bậc hai của Width và height để giảm tỷ lệ độ lỗi.\nCác bạn có thể để ý kỹ hơn SSD phiên bản custom không sử dụng cặp toạ độ trái trên - phải dưới mà là cặp tâm - căn bậc hai của with, căn bậc hai của height. Một số thuật toán lại dùng log width, log height, một số lại dùng tâm là Wc/Wa, Wy/ha, với Wc và Wy là toạ độ tâm của đối tượng, wa và ha là chiều dài và rộng của anchor khớp nhất (matching anchor). Các bạn có thể tham khảo thêm ở https://arxiv.org/pdf/1611.10012.pdf.\nĐể huấn luyện mô hình tốt hơn, Các nhà nghiên cứu sử dụng các trọng số khác nhau cho các hàm lỗi, YOLO và một ví dụ minh hoạ.\nFeature extraction Trong thực tế, Feature extraction ảnh hưởng lớn trên 2 phần tradeoff là độ chính xác và tốc độ. Nhóm thuật toán ResNet và Inception đi theo tiêu chí là độ chính xác quan trọng hơn tốc độ (và quả thật nhóm thuật toán thuộc họ này có độ chính xác khá cao). MobileNet cung cấp cho chúng ta một mô hình khá nhỏ gọn, sử dụng SSD, mục tiêu của nhóm này là có thể xử lý được trên các thiết bị di động và thời gian xử lý là realtime.\nFeature extractor accuracy Nhìn vào hình trên, chúng ta có thể thấy rõ ràng rằng Faster R-CNN và R-FCN đều cho độ chính xác khá tốt trên feature extraction. Ngược lại SSD có kết quả khá tệ.\nNon-max suppression (nms) Sau khi thu được vị trí của các đối tượng, chúng ta sẽ merge lại các vị trí bị phát hiện trùng lắp. Các thuật toán thuộc nhóm single shot thường cho ra output overlap khá nhiều.\nData augmentation Ngày nay, hầu hết các thuật toán đều sử dụng Data augmentation. Việc augment data bằng cách cắt xét ảnh, quay ảnh một góc ngẫu nhiên nào đó, giúp cho tránh được overfit trong quá trình huấn luyện, do đó gián tiếp tăng độ chính xác của mô hình.\nFeature map strides Thuật toán thuộc nhóm single shot thường có tuỳ chọn layter feature map nào được sử dụng để nhận dạng đối tượng. Feature map có stride là 2 nếu chúng ta thực hiện giảm 2 lần độ phân giải. Feature map có độ phân giải thấp thường giữ lại những thông tin đặc trưng tốt của đối tượng và giúp cho detector thực hiện tốt hơn. Tuy nhiên, những đối tượng có kính thước nhỏ sẽ bị mất thông tin trầm trọng và khó để phát hiện ra chúng.\nSpeed v.s. accuracy Thật khó để trả lời rằng thuật toán nhận dạng đối tượng nào tốt hơn, mà câu trả lời phụ thuộc vào bài toán của bạn đang gặp. Nếu bài toán cần độ chính xác cao, hãy sử dụng ResNet hoặc Inception, nếu bạn cần chạy realtime và độ chính xác tạm chấp nhận, hãy sử dụng MobileNet hoặc YOLO. Không có (chưa có - ít nhất đến thời điểm hiện tại) có thuật toán nào đáp ứng cả 2 tiêu chí là vừa có độ chính xác cao, vừa chạy nhanh cả. Đó là một tradeoff giữa Speed và Accuracy.\nObject size Với những hình ảnh có kích thước lớn, SSD thực hiện rút trích đặc trưng rất tốt (nên nhớ rằng mô hình rút trích đặc trưng của SSD rất đơn giản). Với những hình ảnh dạng này, SSD có thể so sánh với các thuật toán khác khác về độ chính xác.\nVới nhưng hình ảnh có kích thước nhỏ, chúng ta không nên/không bao giờ xài SSD.\nNhìn hình ở trên, chúng ta thấy rõ độ chính xác của SSD và các thuật oán khác trên các tập dữ liệu có kích thước khác nhau. Và phụ thuộc vào kích thước dữ liệu của bạn để chọn ra mô hình tối ưu nhất.\nInput image resolution Nhìn hình trên các bạn cũng có thể nhìn thấy rõ. Ảnh có độ phân giải lớn giúp nhận dạng đối tượng tốt hơn rất nhiều so với ảnh có độ phân giải nhỏ. Khi giảm 2 lần độ phân giải trên mỗi chiều (từ 600x600 xuống còn 300x300), trung bình độ chính xác giảm 15.88% trong quá trình huấn luyện, và trung bình giảm 27.4% trong inference.\nNumber of proposals Số lượng proposal được sinh ra ảnh hưởng trực tiếp đến tốc độ của nhóm R-CNN. Ví dụ, Faster R-CNN có thể tăng tốc độ nhận dạng đối tượng gấp 3 lần nếu ta chỉ sử dụng 50 proposal thay vì 300 proposal. Độ chính xác chỉ giảm 4%\nHình trên, đường nét liền mô tả độ chính xác khi tăng số lượng proposal. Đường nét đứt thể hiện thời gian xử láy tăng khi tăng số lượng proposal.\nĐiểm danh danh lại các bước phát triển của object detection Các thuật toán object detection đã phát triển trong một khoảng thời gian dài. Ý tưởng đầu tiên, đơn giản nhất là chúng ta sẽ sử dụng cửa sổ trượt.\n12# Sliding windows 3for window in windows 4patch = get_patch(image, window) 5results = detector(patch) Để tăng tốc, chúng ta sẽ\n Giảm số lượng windows (R-CNN giảm còn khoảng 2000) Giảm các phép tính trong việc tìm ROI (Fast R-CNN sử dụng feature map thay vì toàn bộ image patchs).  1# Fast R-CNN 2feature_maps = process(image) 3ROIs = region_proposal(feature_maps) 4for ROI in ROIs 5patch = roi_pooling(feature_maps, ROI) 6results = detector2(patch) Việc tìm region_proposal cũng tốn khá nhiều thời gian. Faster R-CNN sử dụng một convolution network thay thế cho region proposal ở bước này (làm giảm thời gian từ 2.3s xuống còn 0.3 giây). Faster R-CNN cũng giới thiệu 1 khái nhiệm là anchor giúp cải thiện độ chính xác và việc huấn luyện trở nên dễ dàng hơn.\nR-FCN đưa ra một điều chỉnh nhỏ, là tiến hành tìm position và sensitive score map trên mỗi ROIS độc lập. Và tính trung bình xác suất xuất hiện đối tượng\n1# R-FCN 2feature_maps = process(image) 3ROIs = region_proposal(feature_maps) 4score_maps = compute_score_map(feature_maps) 5for ROI in ROIs 6V = pool(score_maps, ROI) 7class_scores = average(V) 8class_probabilities = softmax(class_scores) R-FCN chạy khá nhanh, nhưng độ chính xác thì thấp hơn một hút so với Faster R-CNN. Để ý kỹ đoạn mã giả ở trên, chúng ta phải trải qua 2 lần tính toán, một lần là tìm các ROIs, một lần là object detection. Thuật toán Single shot detector được đề xuất để sử dụng 1 lần tính toán.\n1feature_maps = process(image) 2results = detector3(feature_maps) # No more separate step for ROIs Thuật toán SSD và YOLO đều thuộc nhóm single shot detectors. Cả hai đều sử dụng convolution layer để rút trích đặc trưng và một convolution filter để đưa quyết định. Cả hai đều dùng feature map có độ phân giải thấp (low resolution feature map) để dò tìm đối tượng =\u0026gt; chỉ phát hiện được các đối tượng có kích thước lớn. Một cách tiếp cận là sử dụng các feature map có độ phân giải cao (higher resolution feature map). Nhưng độ chính xác sẽ giảm do thông tin đặc trưng của đối tượng quá hỗn loạn. FPN đưa ra ý tưởng sử dụng feature map trung gian merge giữa feature map high resolution và low resolution. Việc này giúp cho chúng ta vẫn giữ được thông tin đặc trưng hữu ích của đối tượng, đồng thời cũng giữ được thông tin của các đối tượng có kích thước nhỏ. Do đó, độ chính xác cũng tăng lên và phát hiện các đối tượng có các tỷ lệ khác nhau (different scale) tốt hơn.\nTrong quá trình huấn luyện, chúng ta sẽ nhận ra 1 vấn đề rằng backgroup sẽ chiếm 1 phần rất lớn trong bức ảnh. Hoặc một đối tượng nào đó có số mẫu nhiều hơn so với các đối tượng khác. Thuật toán Focal loss được sinh ra để giải quyết vấn đề này.\nLesson learned   Feature Pyramid Networks sử dụng các feature map nhiều thông tin hơn để cải thiện độ chính xác.\n  Sử dụng các mô hình như ResNet hoặc Inception ResNet nếu mô hình bạn cần độ chính xác và không quan tâm lắm về tốc độ.\n  Sử dụng các thuật toán thuộc nhóm Single shot detectors như MobileNet nếu bạn cần tốc độ tính toán và có thể chạy được trên mobilenet, yêu cầu về độ chính xác tạm chấp nhận được.\n  Sử dụng batch normaliation, nói chung là đều phải chuẩn hoá dữ liệu trước khi sử dụng.\n  Lựa chọn anchors cẩn thận (Cái này khá khó, đòi hỏi bạn phải am hiểu khá kỹ về dữ liệu, và nếu set nhầm thì sẽ đi tong).\n  Sử dụng data augmentation.\n  Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\nBài viết được lược dịch và tham khảo từ nguồn https://medium.com/@jonathan_hui/design-choices-lessons-learned-and-trends-for-object-detections-4f48b59ec5ff\n","date":"Dec 10, 2018","img":"","permalink":"/blog/2018-12-10-design-choices-lessons-learned-and-trends-for-object-detections/","series":null,"tags":["Machine learning","Deeplearning","object detector","single shot"],"title":"Lựa Chọn Mô Hình Object Detectors"},{"categories":null,"content":"Single Shot detectors Ở bài trước, chúng ta đã tìm hiểu về region proposal và ứng dụng của nó vào Faster R-CNN. Các thuật toán thuộc nhóm region proposal tuy cho kết quả có độ chính xác cao, nhưng chúng có một nhược điểm rất lớn là thời gian huấn luyện và đưa quyết định rất chậm. Faster R-CNN xử lý khoảng 7 FPS trên tập dữ liệu PASCAL VOC 2007. Một cách để tăng tốc quá trình tính toán là giảm số lượng tính toán trên mỗi ROI.\n1feature_maps = process(image) 2ROIs = region_proposal(feature_maps) 3for ROI in ROIs 4patch = roi_align(feature_maps, ROI) 5results = detector2(patch) # Giảm khối lượng tính toán ở đây Một ý tưởng khác, là chúng ta sẽ bỏ qua bước tìm region proposal, mà trực tiếp rút trích boundary boxes và classes trực tiếp từ feature map.\n1feature_maps = process(image) 2results = detector3(feature_maps) # Không cần tìm ROI Dựa trên ý tưởng sử dụng cửa sổ trượt. Chúng ta sẽ trượt trên feature máp để nhận diện các đối tượng. Với mỗi loại đối tượng khác nhau, chúng ta sửa dụng các cửa sổ trượt có kích thước khác nhau. Cách này thoạt đầu trông có vẻ khá tốt, nhưng điểm yếu của nó là đã sử dụng cửa sổ trượt làm final boundary box. Do đó, giả sử chúng ta có nhiều đối tượng, và mỗi đối tượng có kích thước khác nhau, chúng ta sẽ có rất nhiều cửa sổ trượt để bao phủ hết toàn bộ đối tượng.\nMột ý tưởng cải tiến là chúng ta sẽ định nghĩa trước các cửa sổ trượt, sau đó sẽ tiến hành dự đoán lớp và boundary box ( và Ý tưởng này, nhóm nghiên cứu phát triển thuật toán và đặt tên thuật toán là single shot detectors). Ý tưởng này tương tự như việc sử dụng anchors trong Faster R-CNN, nhưng single shot detectors thực hiện dự đoán boundary box và class đồng thời cùng nhau.\nVí dụ, giả sử chúng ta có một feature map 8x8 và chúng ta đưa ra k = 4 dự đoán. Vậy ta có tổng cộng 8x8x4 = 256 dự đoán.\nXét hình bên trên, ta có 4 anchors đã được định nghĩa trước ( màu xanh lá cây), và có 4 prediction( màu xanh nước biển) tương ứng với từng anchor trên.\nVới thuật toán Faster R-CNN, chúng ta sử dụng một convolution filter trả ra 5 kết quả dự đoán: 4 giá trị là toạ độ của boundary box, và giá trị còn lại là xác suất xuất hiện đối tượng. Tổng quát hơn, ta có input là D feature map 8x8, output là 8x8x5, số convolution filter trong Faster R-CNN là 3x3xDx8.\nVới single shot detector, input của ta cũng tương tự là 8x8xD, output là 8x8x (4 + C) ( với 4 tương ứng với 4 điểm boundary box, và C là số lượng lớp đối tượng), vậy ta cần một convolution filter là 3x3xDx(4+C)\nThuật toán Single shot detect chạy khá nhanh, nhưng độ chính xác của nó không cao lắm (không bằng region proposal). Thuật toán có vấn đề về việc nhận dạng các đối tượng có kích thước nhỏ. Ví dụ như hình bên dưới, chúng ta có tổng cộng 9 ông già noel, nhưng thuật toán chỉ nhận diện được có 5 ông.\nSSD SSD là mô hình single shot detector sử dụng mạng VGG16 để rút trích đặc trưng. Mô hình như hình bên dưới. Trong đó, những conv có màu xanh nước biển nhạt là những custom convolution layter (ta có thể thêm bớt bao nhiêu tuỳ thích). Convolutional filter layter (là cục màu xanh lá cây) có nhiệm vụ tổng hợp các thông tin lại để đưa quyết định.\nKhi sử dụng mô hình như hình ở trên, chúng ta thấy rằng các custom convolution layter có nhiệm vụ làm giảm chiều và giảm độ phân giải của bức ảnh. Cho nên, mô hình chỉ có khả năng nhận ra các đối tượng có kích thước lớn. Để giải quyết vấn đề này, chúng ta sẽ sử dụng các object detector khác nhau trên mỗi feature maps (xem output của mỗi custom convolution là một feature map).\nẢnh bên dưới là sơ đồ số chiều của các feature maps.\nSSD sử dụng các layter có kích thước giảm dần theo độ sâu để nhận dạng đối tượng. Nhìn vào hình vẽ sơ đồ bên dưới của SSD, chúng ra dễ dàng nhận thấy rằng độ phân giải giảm đáng kể qua mỗi layer và có lẽ (chắc chắn) sẽ bỏ sót những đối tượng có kích thước nhỏ ở những lớp có độ phân giải thấp. Nếu trong dự án thực tế của bạn có xảy ra vấn đề này, bạn nên tăng độ phân giải của ảnh đầu vào.\nYOLO YOLO cũng là một thuật toán sử dụng single shot detector để dò tìm vị trí của các đối tượng trong ảnh. YOLO sử dụng DarkNet để tạo các feature cho bức ảnh (SSD sử dụng VGG16). Mô hình của YOLLO như ảnh ở bên dưới.\nKhác với kiến trúc mạng SSD ở trên, YOLLO không sử dụng multiple scale feature map (SSD sử dụng các custom convolution layter, qua mỗi layter thì feature maps sẽ có kích thước giảm xuống - các output của custom convolution layer chính là các feature map chúng ta thu được). Thay vào đó, YOLLO sẽ làm phẳng hoá (flatten - vd ma trận 3x3 sẽ biến thành vector 1x9, ma trận 4x5 sẽ biến thành vector 1x20 \u0026hellip;, làm phẳng nghĩa là chúng ta sẽ không dùng bộ lọc nào hết, mà sử dụng các phép biến đổi, nên không làm thay đổi giá trị, chỉ làm thay đổi hình dạng) một phần output của convolution layer và kết hợp với convolution layer ở trong DarkNet tạo thành feature map (Xem hình ở trên sẽ rõ hơn). Ví dụ ở custom convolution layer chúng ta thu được output có kích thước 28x28x512, chúng ta sẽ flatten thành layter có kích thước 14x14x2048, kết hợp với 1 layter có kích thước 14x14x1024 ở trong darknet, chúng ta thu được feature maps có kích thước là 14x14x3072. Đem feature maps này đi đự đoán.\nYOLOv2 đã thêm vào rất nhiều các cải tiền để cải tăng mAP từ 63.4 trong mô hình đầu tiên (YOLOv1) lên 78.6. Các cải tiền bao gồm thêm batch norm, anchor boxes, hi-res classifier \u0026hellip; Các bạn có thể xem ở hình bên dưới. YOLO9000 có thể nhận dạng 9000 đối tượng khác nhau.\nYOLOv2 có thể nhận diện các đối tượng với ảnh đầu vào có độ phân giải bất kỳ. Với ảnh có độ phân giải thấp thì mô hình chạy khá nhanh, có FPS cao nhưng mAP lại thấp (tradeoff giữa FPS và mAP).\nYOLOv3 YOLOv3 sử dụng darknet với kiến trúc phức hơn để rút trích đặc trưng của bức ảnh. YOLOv3 thêm vào đặc trưng Pyramid để dò tìm các đối tượng có kích thước nhỏ.\nHình bên dưới so sánh tradeoff giữa thời gian thực thi và độ chính xác giữa các mô hình. Ta thấy rằng thời gian thực thi của YOLOv3 rất nhanh, cùng phân mức mAP 28.8, thời gian YOLOv3 thực thi chỉ tốn 22ms, trong khi đó SSD321 tốn đến 61ms - gấp 3 lần.\nFeature Pyramid Networks (FPN) Dò tìm các đối tượng có kích thước nhỏ là một vấn đề đáng được giải quyết để nâng cao độ chính xác. Và FPN là mô hình mạng được thiết kế ra dựa trên khái niệm pyramid để giải quyết vấn đề này.\nMô hình FPN kết hợp thông tin của mô hình theo hướng bottom-up kết hợp với top-down để dò tìm đối tượng (trong khi đó, các thuật toán khác chỉ thường sử dụng bottom-up). Khi chúng ta ở bottom và đi lên (up), độ phân giải sẽ giảm, nhưng giá trị ngữ nghĩa sẽ tăng lên. Xem hình mô phỏng bên dưới.\nSSD đưa ra quyết định dựa vào nhiều feature map. Nhưng layer ở bottom không được sử dụng để nhận dạng đối tượng. Vì những layter này có độ phân giải cao nhưng giá trị ngữ nghĩa của chúng lại không đủ cao (thấp) nên những nhà nghiên cứu bỏ chúng đi để tăng tốc độ xử lý. Các nhà nghiêng cứu biện minh rằng các layer ở bottom chưa đủ mức ý nghĩa cần thiết để nâng cao độ chính xác, thêm các layer đó vào sẽ không nâng độ chính xác cao thêm bao nhiêu và họ bỏ chúng đi để có tốc độ tốt hơn. Cho nên, SSD chỉ sử dụng các layer ở lớp trên , và do đó sẽ không nhận dạng được các đối tượng có kích thước nhỏ.\nTrong khi đó, FPN xây dựng thêm mô hình top-down, nhằm mục đích xây dựng các layer có độ phân giải cao từ các layer có ngữ nghĩa cao.\nTrong quá trình xây dựng lại các layer từ top xuống bottom, chúng ta sẽ gặp một vấn đề khá nghiêm trọng là bị mất mát thông tin của các đối tượng. Ví dụ một đối tượng nhỏ khi lên top sẽ không thấy nó, và từ top đi ngược lại sẽ không thể tái tạo lại đối tượng nhỏ đó. Để giải quyết vấn đề này, chúng ta sẽ tạo các kết nối (skip connection) giữa các reconstruction layter và các feature map để giúp quá trình detector dự đoán các vị trí của đối tượng thực hiện tốt hơn (hạn chế tốt nhất việc mất mát thông tin).\nThêm các skip connection giữa feature map và reconstruction layer\nĐồ hình bên dưới diễn ta chi tiết đường đi theo bottom-up và top-down. P2, P3, P4, P5 là các pyramid của các feature map.\nSo sánh Feature Pyramid Networks với Region Proposal Network FPN không phải là mô hình phát hiện đối tượng. Nó là mô hình phát hiện đặc trưng và được sử dụng trong phát hiện đối tượng. Các feature map từ P2 đến P5 trong hình bên dưới độc lập với nhau và các đặc trưng được sử dụng để phát hiện đối tượng.\nSử dụng Feature Pyramid Networks trong Fast R-CNN và Faster R-CNN Chúng ta hoàn toàn có thể sử dụng FPN trong Fast và Faster R-CNN. Chúng ta sẽ tạo ra các feature map sử dụng FPN, kết quả là ta thu được các puramid (feature map). Sau đó, chúng ta sẽ rút trích các ROIs trên các feature map đó. Dựa trên kích thước của các ROI, chúng ta sẽ chọn feature map nào tốt nhất để tạo các feature patches (các hình chữ nhật nhỏ). Các bạn có thể xem chi tiết ở hình bên dưới.\nFocal loss (RetinaNet) Trong thực tế, chúng ta sẽ gặp tình trạng tỷ lệ diện tích của các đối tượng trong ảnh nhỏ hơn nhiều so với phần background còn lại, ví dụ chúng ta cần nhận dạng một quả cam có kích thước 100x100 trong ảnh 1920x1080. Vì phần background quá lớn nên chúng sẽ là thành phần \u0026ldquo;thống trị\u0026rdquo; và làm sai lệch kết quả. SSD sử dụng phương pháp lấy mẫu tỷ lệ của object class và background class trong quá trình train (nên background sẽ không còn thống trị nữa).\nNgoài ra, chúng ta sẽ còn gặp tình trạng là số lượng tỷ lệ object trong ảnh không đều nhau, ví dụ trong tập huấn luyệt có 1000 quả cam và 10 quả táo.\nFocal loss (FL) được sinh ra để giải quyết tình trạng này. Để đi vào chi tiết hơn, chúng ta nhắc lại hàm lỗi cross entropy.\n$$ \\begin{equation} CE(p,y) = \\begin{cases} -\\log(p) \u0026amp; \\text{if y=1} \\\\\\\\ -\\log(1-p) \u0026amp; \\text{otherwise} \\end{cases} \\end{equation} $$\nTrong hàm trên thì y nhận giá trị 1 hoặc -1. Giá trị xác xuất nằm trong khoảng (0,1) là xác suất dự đoán cho lớp có y=1.\nĐể rõ ràng hơn, ta có thể viết lại hàm trên như sau:\n$$ \\begin{equation} p_t = \\begin{cases} p \u0026amp; \\text{if y=1} \\\\\\\\ 1-p \u0026amp; \\text{otherwise} \\end{cases} \\end{equation} $$\n$$ \\begin{equation} CE(p,y) = CE(p_t) = -\\log(p_t) \\end{equation} $$\nTa có nhận xét rằng đối với các trường hợp được phân loại tốt (có xác suất lớn hơn 0.6) thì hàm loss nhận gái trị với độ lớn lớn hơn 0. Và trong trường hợp dữ liệu có tỷ lệ lệch cao thì tổng các giá trị này sẽ cho ra kết quả loss với một con số rất lớn so với loss của các trường hợp khó phâm loại. Và nó ảnh hưởng đến quá trình huấn luyện.\nÝ tưởng chính của focal-lost là đối với các trường hợp được phân loại tốt ( xác suất lớn hơn 0.5) thì focal lost sẽ làm giảm giá trị cross-entropy của nó xuống nhỏ hơn so với thông thường. Do đó, ta sẽ thêm trọng số cho hàm cross-entropy để biến thành hàm focal lost.\n$$ FL(p_t) = -(1-p_t)^\\gamma\\log(p_t) $$\nVới nhân tử được thêm vào được gọi là modulating factor, gamma lớn hơn hoặc bằng 0 được gọi là tham số focusing.\nNhìn hình ở trên, ta thấy rằng khi gamma = 0 thì hàm focal lost chính là cross-entropy.\nĐặc điểm của hàm lost trên như sau:\nKhi mẫu bị phân loại sai, pt nhỏ, nhân tố modulating factor gần với 1 và hàm lost ít bị ảnh hưởng. Khi pt tiến gần tới 1 (mẫu phân loại tốt), moduling factor sẽ tiến gần tới 0 và hàm loss trong trường hợp này sẽ bị giảm trọng số xuống.\nTham số focusing sẽ điều chỉnh tỷ lệ các trường hợp được phân loại tốt được giảm trọng số. Khi gamma càng tăng thì ảnh hưởng của modulating factor cũng tăng. Trong các thí nghiệm cho thấy với gamma = 2 hì kết quả đạt được sẽ tốt nhất.\nHình bên dưới là đồ hình của RetinaNet được xây dựng dựa trên FPN và ResNet sử dung Focal loss.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\nBài viết được lược dịch và tham khảo từ nguồn https://medium.com/@jonathan_hui/what-do-we-learn-from-single-shot-object-detectors-ssd-yolo-fpn-focal-loss-3888677c5f4d\n","date":"Dec 6, 2018","img":"","permalink":"/blog/2018-12-06-what-do-we-learn-from-single-shot-object-detection/","series":null,"tags":["Machine learning","Deeplearning","object detector","single shot"],"title":"Tìm Hiểu Single Shot Object Detectors"},{"categories":null,"content":"Sliding-window detectors Bắt đầu từ năm 2012, sau khi mạng AlexNet giành giải nhất cuộc thi 2012 ILSVRC, mọi nghiên cứu về phân lớp dữ liệu đều sử dụng mạng CNN. Kể từ đó đến đây, CNN được coi như là thuật toán thống trị trên mọi publish paper về các bài toán phân lớp đối tượng. Trong khi đó, để nhận dạng 1 đối tượng trong ảnh, các đơn giản nhất là thiết lập một cửa sổ trượt có kích thước là window size trượt từ trái qua phải, từ trên xuống dưới, quét qua toàn bộ bức ảnh. Để phát hiện các đối tượng khác nhau ở các góc nhìn khác nhau, chúng ta sẽ sử dụng cửa sổ trượt có kích thước thay đổi và ảnh đầu vào có kích thước thay đổi.\nDựa vào windowsize, chúng ta có thể cắt tấm hình bự thành các tấm hình nhỏ, sau đó sẽ rescale các phần nhỏ của bức ảnh thành các bức ảnh có kích thước cố định.\nCác phần của bức ảnh sau đó sẽ được đem qua bộ phân lớp CNN để rút trích các đặc trưng, sau đó sử dụng một hàm phân lớp (như svm, logictic regression) để xác định lớp của bức hình và sử dụng linear regressor để tìm bao đóng của đối tượng.\nMã giả của mô hình\n1for window in windows 2patch = get_patch(image, window) 3results = detector(patch) Cách dễ dàng nhất để cải tiến hiệu năng của phương pháp này là giảm số lượng tấm hình nhỏ xuống (ví dụ tăng kích thước window size). Cách này còn được giang hồ gọi là brute force.\nSelective Search Thay vì hướng tiếp cận brute force ở trên, chúng ta sử dụng phương pháp region proposal để tạo các region of interest (ROIs) để phát hiện đối tượng. Selective search là một phương pháp nằm trong nhóm region proposal. Trong phương pháp selective search(SS), chúng ta bắt đầu bằng cách xem các pixel là mỗi nhóm, các lần lặp tiếp theo, chúng ta sẽ tính khoảng cách ngữ nghĩa (ví dụ như là màu sắc, cường độ ánh sáng) giữa các nhóm và gom các nhóm có khoảng cách gần nhau về chung 1 nhóm để tìm ra phân vùng có khả năng cao nhất chứa đối tượng (ưu tiên gom những nhóm nhỏ trước).\nNhư hình bên dưới, dòng đầu tiên, bức ảnh đâu tiên là ta có một vài nhóm nhỏ ở thời điểm X nào đó, ở hình thứ 2 là thực hiện gom nhớm theo cường độ màu sắc của hình số 1, và ở bước cuối cùng, ta thu được hình số 3. Những hình chữ nhật màu xanh ở dòng thứ 2 là những ROIS mô phỏng quá trình gom nhóm để tìm phân vùng có khả năng chứa đối tượng.\nselective search\nMạng R-CNN Mạng R-CNN sử dụng phương pháp region proposal để tạo ra khoảng 2000 ROIs. Các vùng sau đó sẽ được rescale theo một kích thước cố định nào đó và được đưa vào mô hình CNN có lớp cuối cùng kà một full conected layer để phân lớp đối tượng và để lọc ra boundary box (bao đóng) của đối tượng.\nMô phỏng việc sử dụng region proposal\nMô phỏng việc sử dụng region proposal của RCNN\nMã giả của mô hình\n1ROIs = region_proposal(image) 2for ROI in ROIs 3patch = get_patch(image, ROI) 4results = detector(patch) Với việc sử dụng ít tấm ảnh nhỏ hơn, và chất lượng của mỗi tấm ảnh nhỏ tốt hơn, Mạng R-CNN chạy nhanh hơn và có độ chính xác cao hơn so với mô hình sử dụng cửa sổ trượt.\nMạng Fast R-CNN Trong thực tế, các phân vùng của mạng R-CNN bị chồng lấp một phần / toàn bộ với các phân vùng khác. Do đó, việc huấn luyện và thực thi ( inference ) mạng R-CNN diễn ra khá chậm. Nếu chúng ta có 2000 proposal của mạng R-CNN, chúng ta phải thực hiện 2000 lần việc rút trích đặc trưng, một con số khác lớn.\nThay vì phải rút trích đặc trưng của mỗi proposal, chúng ta có thể dùng CNN rút trích đặc trưng của toàn bộ bức ảnh trước (được feature map), đồng thời rút trích các proposal, lấy các proposal tương ứng trên feature map, rescale và cuối cùng là phân lớp và tìm vị trí của object. Với việc không phải lặp lại 2000 lần việc rút trích đặc trưng, Fast R-CNN giảm thời gian xử lý một cách đáng kể.\nMô phỏngviệc sử dụng propoxal trên feature map và các bước tiếp theo của Fast R-CNN\nĐồ hình của Fast R-CNN\nMã giả của mô hình\n1feature_maps = process(image) 2ROIs = region_proposal(image) 3for ROI in ROIs 4patch = roi_pooling(feature_maps, ROI) 5results = detector2(patch) Với việc không phải lặp đi lặp lại quá trình tìm ra các proposal, tốc độ của thuật toán tăng lên kha khá. Trong thực nghiệm, mô hình Fast R-CNN chạy nhanh hơn gấp 10 lần so với R-CNN trong quá trình huấn luyện. Và nhanh hơn 150 lần trong inferencing.\nMột khác biệt lớn nhất của Fast R-CNN là toàn bộ network (feature extractior, classifier, boundary box regressor) có thể huấn luyện end-to end (nghĩa là từ đầu đến cuối) với 2 hàm độ lỗi (loss funtion) khác nhau cùng lúc (classification loss và localization loss). Điều này làm tăng độ chính xác của mô hình.\nROI Pooling Vì Fast R-CNN sử dụng full connected layter ở lớp cuối, nên đòi hỏi input của chúng phải có kích thước cố định, nên ta phải resize lại feature về 1 kích thước cố định (do 2000 proposal có kích thước không cố định). Ở đây, các tác giả sử dụng ROI pooling để resize. Thuật toán ở đây được sử dụng như sau:\nGiả sử đơn giản là chúng ta có một proposal có kích thước 5x7, và chúng ta cần resize về hình dạng 2x2. Chúng ta xem kỹ hình bên dưới.\nHình ảnh mô phỏng ROI pooling\nHình ở bên trái là feature map của chúng ta.\nHình số 2, vùng hình chữ nhật xanh là vùng proposal 5x7.\nVì chúng ta cần resize về vùng có kích thước 2x2 (4 phần), nên ta chia vùng proposal 5x7 thành 4 phần (5/2 =2 dư 3, vậy có 1 phần là 2, 1 phần là 3. Tương tự 7/2 = 3 dư 4, vậy có 1 phần 3, một phần 4. Cuối cùng ta có 4 hình chữ nhật có kích thước tương ứng là 2x3, 2x4, 3x3, 3x4) (Hình số 3).\nHình số 4, từ 4 phần của vùng số 3, ta sẽ lấy giá trị lớn nhất của mỗi vùng.\nVậy là ta thu được feature proposal có kích thước 2x2 rồi.\nFaster R-CNN Nhìn kỹ lại vào thuật toán F-CNN, chúng ta cần phải rút rích 2000 ROIs, và nó là nguyên nhân lớn gây nên sự chậm trể của mô hình\n1feature_maps = process(image) 2ROIs = region_proposal(image) # Expensive, slow 3for ROI in ROIs 4patch = roi_pooling(feature_maps, ROI) 5results = detector2(patch) Thuật toán Faster R-CNN sử dụng mô hình gần như tương tự Fast R-CNN, ngoài việc sử dụng thuật toán interal deep network thay cho selective search để tìm region proposal. Thuật toán mới chạy hiệu quả hơn khi tìm tất cả các ROIs trên mỗi bức ảnh với tốc độ 10ms/\nMô hình của Faster R-CNN\nĐồ hình của Faster R-CNN\nRegion proposal network Mạng region proposal sử dụng feature map làm input đầu vào (như hình trên đã mô phỏng). Mạng sử dụng 1 bộ lọc 3x3, sau đó là một mô hình CNN như ZF hoặc VGG hoặc ResNet ( mô hình càng phức tạp thì độ chính xác cao, nhưng bù lại thời gian tìm kiếm sẽ lâu hơn) để dự đoán boundary box và object score (để xét xem trong bodary box trên có chứa đối tượng hay không. Trong thực tế, mạng Faster R-CNN trả về 2 lớp, lớp thứ nhất là có chứa object, lớp thứ 2 là không chứa object ( ví dụ lớp màu nền - background, lớp abc gì gì đó)) .\nVí dụ Region proposal network\nMô hình Region proposal network sử dụng ZF network\nGiả sử tại 1 điểm nào đó trên feature map, RPN có k dự đoán, vậy là chúng ta có tổng cộng 4xk toạ độ điểm và 2xk điểm cho điểm đó. Nhìn ví dụ ở hình bên dưới.\nHình 1: ta có feature map với kích thước 8x8, vùng hình vuông được tô là filter đang xét có kích thước 3x3. Hình 2: Giả sử xét điểm có chấm xanh. Tại điểm đó, ta có k=3 sau khi chạy RPN, và ta được 3 hình chữ nhật như hình.\nTuy nhiên, tại mỗi điểm, ta chỉ cần 1 boundary box tốt nhất. Cách đơn giản nhất là chọn ngẫu nhiên 1 cái. Nhưng như vậy thì ngay từ đầu ta chọn k=1 luôn cho khoẻ, mắc công gì phải chọn k=3. Trong thực tế, Faster R-CNN không sử dụng phương pháp random select. Thay vào đó, thuật toán một reference boxs hay còn được gọi với tên là anchors và tìm mức độ liên quan của k boundary box với k reference boxs và chọn ra boundary box có độ liên quan lớn nhất.\nVí dụ anchors box\nCác anchors này được lựa chọn trước đó và được xem là config của mô hình. Faster R-CNN sử dụng 9 anchor boxs (tương ứng với k =3) với 3 box đầu tiên có tỷ lệ width, height khác nhau (ví dụ 2x3, 3x3, 3x2), tiếp đó sẽ scale các box trên với các tỷ lệ khác khau (ví dụ 1.5,3,7) để đạt được 9 anchor boxs.\nVì mỗi điểm sử dụng 9 anchors, nên ta có tổng cộng 2x9 score và 4x9 location (toạ độ)\nAnchor box có thể được goijlaf priors hoặc default boundary boxes trong mỗi bài báo khác nhau.\nHiệu năng của mô hình R-CNN Hình bên dưới mô tả benchmark của các mô hình dẫn xuất từ R-CNN, ta thấy Faster R-CNN có tốc độ tốt nhất.\nRegion-based Fully Convolutional Networks Giả sử chúng ta chỉ có toạ độ của mắt phải trong khuôn mặt, chúng ta có thể nội suy ra được vị trí của khuôn mặt. Vì ta biết rằng mắt phải nằm ở vị trí trái trái trong bức hình, và ta từ đó suy ra vị trí của các phần còn lại (xem hình).\nNếu chúng ta có thêm thông tin khác, ví như toạ độ của mắt trái, mũi, miệng, \u0026hellip; thì chúng ta có thể kết hợp chúng để tăng độ chính xác của phân vùng khuôn mặt.\nTrong Faster R-CNN, chúng ta phải tìm proposal sử dụng một mô hình CNN, với khoảng 2000 ROI, chúng ta sẽ tiêu tốn một khoảng thời gian khá lớn để tìm chúng.\n1feature_maps = process(image) 2ROIs = region_proposal(feature_maps) 3for ROI in ROIs 4patch = roi_pooling(feature_maps, ROI) 5class_scores, box = detector(patch) # Expensive, slow 6class_probabilities = softmax(class_scores) Trong khi đó, với Fast R-CNN, chúng ta chỉ cần phải tính max hoặc average, nên Fast R-CNN nhanh hơn Faster R-CNN ở đây.\n1feature_maps = process(image) 2ROIs = region_proposal(feature_maps) 3score_maps = compute_score_map(feature_maps) 4for ROI in ROIs 5V = region_roi_pool(score_maps, ROI) 6class_scores, box = average(V) # Much simpler, faster. 7class_probabilities = softmax(class_scores) Xét feature map M có kích thước 5x5, trong đó có chứa một hình vuông màu xanh, hình vuông xanh là đối tượng thực tế ta cần tìm.\nTa chia hình vuông thành phân vùng có kích thước 3x3 (hình 2). Sau đó, chúng ta tạo một feature mới để từ M để tìm ra góc trái trên của hình vuông (chỉ tìm góc trái trên) (hình 3). Feature map mới giống hình thứ 3, chỉ có ô được tô màu vàng ở vị trí [2,2] được bật.\nVới mỗi 9 phần của hình vuông, chúng ta có 9 feature map cho mỗi phần, nhận dạng 9 vùng tương ứng cho một đối tượng. Những feature map này được gọi là position sensitive score map, bởi vì chúng detect ra điểm (score) và sub region của một đối tượng (Xem hình bên dưới).\nXét ảnh bên dưới, giả sử vùng được tô gạch đỏ là proposal (hình 1). Chúng ta cũng chia nó thành những phân vùng con có kích thước 3x3 (hình 2). Và tìm xem mức độ giống nhau của mỗi vùng con của proposal và vùng con của feature map như thế nào. Kết quả sẽ được lưu vào một ma trận 3x3 như hình số 3.\nQuá trình ánh xạ điểm từ score maps và ROIS vào mảng vote_array được gọi là position sensitive ROI pool.\nSau khi tính toán hết các giá trị của position-sensitive ROI pool, chúng ta sẽ tính trung bình của vote_array để lấy điểm của lớp (class score).\nGiả sử mô hình chúng ta phải nhận dạng k lớp, do có thêm lớp background nên chúng ta có tổng cộng k+1 lớp. Với mỗi lớp chúng ta có 3x3 score map, suy ra chúng ta có tổng cộng là (k+1)x3x3 score maps, (k+1) điểm, và dùng softmax ta sẽ thu được xác suất của mỗi lớp.\nLuồng dữ liệu của mô hình\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\nBài viết được lược dịch và tham khảo từ nguồn https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9\n","date":"Dec 5, 2018","img":"","permalink":"/blog/2018-12-05-what-do-we-learn-from-object-detection-p1/","series":null,"tags":["Machine learning","Deeplearning","object detector","region base"],"title":"Tìm Hiểu Region Based Object Detectors"},{"categories":null,"content":"Lời mở đầu Instacart là một startup cung ứng đồ tạp hóa qua website và ứng dụng di động. Người dùng chỉ cần chọn đồ muốn mua tại các chuỗi bán lẻ và đặt đồ, Instacart sẽ đi mua và giao đến tận tay họ. Đến nay, Instacart hoạt động tại 15.000 cửa hàng tạp hoá tại 4.000 thành phố với khoảng 50.000 “trợ lý mua sắm”. Team data science của instacart đóng vai trò rất quan trọng trong việc cung cấp trải nghiệm người dùng trong việc sử dụng app để mua hàng. Hiện tại, họ đang sử dụng các dữ liệu của khách hàng để tạo nên mô hình dự đoán sản phẩm nào người dùng sẽ mua lại, sẽ mua thử lần đầu tiên, hoặc sẽ thêm vào giỏ hàng. Hiện họ đã publish khoảng 3 triệu đơn hàng của họ để các nhà khoa học dữ liệu khác sử dụng và nghiên cứu.\nDẫn nhập Phân tích dữ liệu Các bạn có thể download dữ liệu ở https://www.instacart.com/datasets/grocery-shopping-2017.\nCác file bao gồm:\nFile aisles.csv (134 dòng) có 2 cột là aisle_id,aisle\n1aisle_id,aisle 21,prepared soups salads 32,specialty cheeses 43,energy granola bars 5... File departments.csv (21 dòng) gồm 2 cột là department_id,department\n1department_id,department 21,frozen 32,other 43,bakery 5... File order_products__(prior|train).csv (trên 30 triệu dòng)\nTập này chứa danh sách sản phẩm được mua trong mỗi đơn hàng. File order_products__prior.csv chứa sản phẩm của đơn hàng trước đó của khách hàng. \u0026lsquo;reordered\u0026rsquo; nói rằng sản phẩm này trong đơn hàng hiện tại đã được mua ở đơn hàng trước đó. Vì vậy, sẽ có đơn hàng không được gán là \u0026lsquo;reordered\u0026rsquo; (chúng ta có thể gán nhãn là None hoặc cái gì đó cũng được để chỉ các sản phẩm này). \u0026lsquo;add_to_cart_order\u0026rsquo; là thứ tự của sp được thêm vào giỏ hàng.\n1order_id,product_id,add_to_cart_order,reordered 21,49302,1,1 31,11109,2,1 41,10246,3,0 5... File orders.csv (3.4 triệu dòng, 206k users): chứa thông tin của đơn hàng, trong đó, order_dow là ngày trong tuần, eval_set thuộc một trong 3 loại là prior, train, test. order_number là thứ tự của đơn hàng của user này.\n1order_id,user_id,eval_set,order_number,order_dow,order_hour_of_day,days_since_prior_order 22539329,1,prior,1,2,08, 32398795,1,prior,2,3,07,15.0 4473747,1,prior,3,3,12,21.0 5... File products.csv ((50k dòng) chứa thông tin sản phẩm:\n1product_id,product_name,aisle_id,department_id 21,Chocolate Sandwich Cookies,61,19 32,All-Seasons Salt,104,13 43,Robust Golden Unsweetened Oolong Tea,94,7 5... Với mỗi order_id trong tập test ở file orders.csv, chúng ta phải dự đoán các sản phẩm nào người dùng sẽ mua lại (\u0026ldquo;reorder\u0026rdquo;) thuộc đơn hàng đó. Nếu bạn dự đoán đó là đơn hàng không có sản phẩm nào được mua lại, thì ta sẽ điền vào giá trị \u0026lsquo;None\u0026rsquo;\nVí dụ về kết quả dự đoán:\n1order_id,products 217,1 2 334,None 4137,1 2 3 Thực hành Đầu tiên, ta sẽ import một số thư viện cơ bản để sử dụng, và load tất cả các file lên. Lưu ý một chút là ở đây, mình để tất cả các file trong thư mục data\n1import pandas as pd 2import numpy as np 3from collections import OrderedDict 45from sklearn.linear_model import LogisticRegression 6from sklearn.metrics import f1_score 78from sklearn import metrics, cross_validation 9from sklearn.metrics import f1_score 10from sklearn.preprocessing import MinMaxScaler 1112#Import the files 13aisles_df = pd.read_csv(\u0026#39;data/aisles.csv\u0026#39;) 14products_df = pd.read_csv(\u0026#39;data/products.csv\u0026#39;) 15orders_df = pd.read_csv(\u0026#39;data/orders.csv\u0026#39;) 16order_products_prior_df = pd.read_csv(\u0026#39;data/order_products__prior.csv\u0026#39;) 17departments_df = pd.read_csv(\u0026#39;data/departments.csv\u0026#39;) 18order_products_train_df = pd.read_csv(\u0026#39;data/order_products__train.csv\u0026#39;) Sau đó, mình sẽ merge đơn hàng vào chi tiết đơn hàng của tập train và tập prior\n1order_products_train_df = order_products_train_df.merge(orders_df.drop(\u0026#39;eval_set\u0026#39;, axis=1), on=\u0026#39;order_id\u0026#39;) 2order_products_prior_df = order_products_prior_df.merge(orders_df.drop(\u0026#39;eval_set\u0026#39;, axis=1), on=\u0026#39;order_id\u0026#39;) show ra 5 dòng đầu tiên của order_products_train_df\n1print(order_products_train_df.head()) 1order_id product_id add_to_cart_order reordered user_id order_number order_dow order_hour_of_day days_since_prior_order 20 1 49302 1 1 112108 4 4 10 9.0 31 1 11109 2 1 112108 4 4 10 9.0 42 1 10246 3 0 112108 4 4 10 9.0 53 1 49683 4 0 112108 4 4 10 9.0 64 1 43633 5 1 112108 4 4 10 9.0 78[5 rows x 9 columns] Tổng cộng mình có 9 cột, ý nghĩa các cột mình có giải thích ở trên rồi nha.\nTiếp theo, chúng ta tạo tập tập dữ liệu đếm số lượng sản phẩm của từng người mua\n1user_product_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;],as_index=False) 2.agg({\u0026#39;order_id\u0026#39;:\u0026#39;count\u0026#39;}) 3.rename(columns={\u0026#39;order_id\u0026#39;:\u0026#39;user_product_total_orders\u0026#39;})) 45train_ids = order_products_train_df[\u0026#39;user_id\u0026#39;].unique() 6df_X = user_product_df[user_product_df[\u0026#39;user_id\u0026#39;].isin(train_ids)] 7print(df_X.head()) 1product_id user_id user_product_total_orders 20 1 138 2 31 1 709 1 43 1 777 1 56 1 1052 2 69 1 1494 3 Ở đây, người 138 mua sản phẩm 1 2 lần, người 709 mua sản phẩm 1 1 lần, \u0026hellip; tương tự như vậy cho các user và product khác.\nBước tiếp theo, chúng ta sẽ liệt kê các sản phẩm người dùng đã mua:\n1train_carts = (order_products_train_df.groupby(\u0026#39;user_id\u0026#39;,as_index=False) 2.agg({\u0026#39;product_id\u0026#39;:(lambda x: set(x))}) 3.rename(columns={\u0026#39;product_id\u0026#39;:\u0026#39;latest_cart\u0026#39;})) print(train_carts.head())\n1user_id latest_cart 20 1 {196, 26405, 27845, 46149, 13032, 39657, 26088... 31 2 {24838, 11913, 45066, 31883, 48523, 38547, 248... 42 5 {40706, 21413, 20843, 48204, 21616, 19057, 201... 53 7 {17638, 29894, 47272, 45066, 13198, 37999, 408... 64 8 {27104, 15937, 5539, 41540, 31717, 48230, 2224... Mối tương quan giữa sản phẩm được add to card và sản phẩm được mua\n1df_X = df_X.merge(train_carts, on=\u0026#39;user_id\u0026#39;) 2df_X[\u0026#39;in_cart\u0026#39;] = (df_X.apply(lambda row: row[\u0026#39;product_id\u0026#39;] in row[\u0026#39;latest_cart\u0026#39;], axis=1).astype(int)) 34print(df_X.head()) 56print(df_X[\u0026#39;in_cart\u0026#39;].value_counts()) 1# df_X.head() 2product_id user_id user_product_total_orders latest_cart in_cart 30 1 138 2 {42475} 0 41 907 138 2 {42475} 0 52 1000 138 1 {42475} 0 63 3265 138 1 {42475} 0 74 4913 138 1 {42475} 0 89# df_X[\u0026#39;in_cart\u0026#39;].value_counts() 100 7645837 111 828824 12Name: in_cart, dtype: int64 Tỷ lệ khoảng 9.7%. Điều này nói lên rằng, người dùng trong 1 phiên mua hàng có thể add rất nhiều sản phẩm vào giỏ, nhưng chỉ khoảng 10% sản phẩm họ mua thật sự, hơn 90% sản phẩm còn lại sẽ bị remove trước khi nọ nhấn nút thanh toán.\nXây dựng tập đặc trưng Đặc trưng sản phẩm Với đặc trưng sản phẩm, chúng ta sẽ rút trích 2 đặc trưng đơn giản là tổng số lượng đơn hàng của một sản phẩm và trung bình số lượng đơn hàng có chứa sản phẩm.\n1prod_features = [\u0026#39;product_total_orders\u0026#39;,\u0026#39;product_avg_add_to_cart_order\u0026#39;] 23prod_features_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;],as_index=False) 4.agg(OrderedDict( 5[(\u0026#39;order_id\u0026#39;,\u0026#39;nunique\u0026#39;), 6(\u0026#39;add_to_cart_order\u0026#39;,\u0026#39;mean\u0026#39;)]))) 7prod_features_df.columns = [\u0026#39;product_id\u0026#39;] + prod_features 8print(prod_features_df.head()) 12product_id product_total_orders product_avg_add_to_cart_order 30 1 1852 5.801836 41 2 90 9.888889 52 3 277 6.415162 63 4 329 9.507599 74 5 15 6.466667 Add thêm đặc trưng sản phẩm vào trong tập huấn luyện\n12df_X = df_X.merge(prod_features_df, on=\u0026#39;product_id\u0026#39;) 34#note that dropping rows with NA product_avg_days_since_prior_order is likely a naive choice  5df_X = df_X.dropna() 6print(df_X.head()) 1product_id user_id ... product_total_orders product_avg_add_to_cart_order 20 1 138 ... 1852 5.801836 31 1 709 ... 1852 5.801836 42 1 777 ... 1852 5.801836 53 1 1052 ... 1852 5.801836 64 1 1494 ... 1852 5.801836 Đặc trưng người dùng Với người dùng, chúng sa sử dụng các đặc trưng là: Tổng số lượng đơn hàng, trung bình số sản phẩm trong 1 đơn hàng, tổng số lượng sản phẩm người dùng mua, Trung bình số ngày user sẽ mua đơn hàng tiếp theo\n1user_features = [\u0026#39;user_total_orders\u0026#39;,\u0026#39;user_avg_cartsize\u0026#39;,\u0026#39;user_total_products\u0026#39;,\u0026#39;user_avg_days_since_prior_order\u0026#39;] 23user_features_df = (order_products_prior_df.groupby([\u0026#39;user_id\u0026#39;],as_index=False) 4.agg(OrderedDict( 5[(\u0026#39;order_id\u0026#39;,[\u0026#39;nunique\u0026#39;, (lambda x: x.shape[0] / x.nunique())]), 6(\u0026#39;product_id\u0026#39;,\u0026#39;nunique\u0026#39;), 7(\u0026#39;days_since_prior_order\u0026#39;,\u0026#39;mean\u0026#39;)]))) 89user_features_df.columns = [\u0026#39;user_id\u0026#39;] + user_features 10print(user_features_df.head()) Và chúng ta merge tiếp đặc trưng user vào trong tập huấn luyện.\n12df_X = df_X.merge(user_features_df, on=\u0026#39;product_id\u0026#39;) 34#note that dropping rows with NA product_avg_days_since_prior_order is likely a naive choice  5df_X = df_X.dropna() Đặc trưng mối tương quan giữa người dùng và sản phẩm Ở đây, chúng ta sử dụng đặc trưng trung bình số sản phẩm của 1 người được thêm vào đơn hàng và tần suất 1 sản phẩm 1 user add vào đơn hàng.\n1user_prod_features = [\u0026#39;user_product_avg_add_to_cart_order\u0026#39;] 23user_prod_features_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;],as_index=False) \\ 4.agg(OrderedDict( 5[(\u0026#39;add_to_cart_order\u0026#39;,\u0026#39;mean\u0026#39;)]))) 67user_prod_features_df.columns = [\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;] + user_prod_features 8df_X = df_X.merge(user_prod_features_df,on=[\u0026#39;user_id\u0026#39;,\u0026#39;product_id\u0026#39;]) 9df_X[\u0026#39;user_product_order_freq\u0026#39;] = df_X[\u0026#39;user_product_total_orders\u0026#39;] / df_X[\u0026#39;user_total_orders\u0026#39;] Bổ sung thêm đặc trưng Ngoài các đặc trưng cơ bản ở trên, ta sẽ bổ sung thêm một số đặc trưng khác:\nĐặc trưng sản phẩm: bổ sung thêm 3 đặc trưng trung bình ngày trong tuần được đặt hàng (cột order_down), trung bình giờ đặt hàng (cột order_hour_of_day), trung bình ngày đặt hàng kể từ lần đặt trước đó (cột days_since_prior_order) theo sản phẩm.\n1prod_features = [\u0026#39;product_avg_order_dow\u0026#39;, \u0026#39;product_avg_order_hour_of_day\u0026#39;, \u0026#39;product_avg_days_since_prior_order\u0026#39;] 23prod_features_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;], as_index=False) 4.agg(OrderedDict( 5[(\u0026#39;order_dow\u0026#39;,\u0026#39;mean\u0026#39;), 6(\u0026#39;order_hour_of_day\u0026#39;, \u0026#39;mean\u0026#39;), 7(\u0026#39;days_since_prior_order\u0026#39;, \u0026#39;mean\u0026#39;)]))) 89prod_features_df.columns = [\u0026#39;product_id\u0026#39;] + prod_features 1011df_X = df_X.merge(prod_features_df, on=\u0026#39;product_id\u0026#39;) 12df_X = df_X.dropna() Đặc trưng người dùng: bổ sung thêm 2 cột đặc trung trung bình ngày trong tuần được đặt hàng (cột order_down) và trung bình giờ đặt hàng (cột order_hour_of_day) theo người dùng\n1user_features = [\u0026#39;user_avg_order_dow\u0026#39;,\u0026#39;user_avg_order_hour_of_day\u0026#39;] 23user_features_df = (order_products_prior_df.groupby([\u0026#39;user_id\u0026#39;],as_index=False) 4.agg(OrderedDict( 5[(\u0026#39;order_dow\u0026#39;,\u0026#39;mean\u0026#39;), 6(\u0026#39;order_hour_of_day\u0026#39;,\u0026#39;mean\u0026#39;)]))) 78user_features_df.columns = [\u0026#39;user_id\u0026#39;] + user_features 9df_X = df_X.merge(user_features_df, on=\u0026#39;user_id\u0026#39;) 10df_X = df_X.dropna() Đặc trung người dùng - sản phẩm: Bổ sung thêm đặc trưng tung bình trên cột order_down, order_hour_of_day, days_since_prior_order theo người dùng và sản phẩm\n12user_prod_features = [\u0026#39;user_product_avg_days_since_prior_order\u0026#39;, 3\u0026#39;user_product_avg_order_dow\u0026#39;, 4\u0026#39;user_product_avg_order_hour_of_day\u0026#39;] 56user_prod_features_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;],as_index=False) \\ 7.agg(OrderedDict( 8[(\u0026#39;days_since_prior_order\u0026#39;,\u0026#39;mean\u0026#39;), 9(\u0026#39;order_dow\u0026#39;,\u0026#39;mean\u0026#39;), 10(\u0026#39;order_hour_of_day\u0026#39;,\u0026#39;mean\u0026#39;)]))) 1112user_prod_features_df.columns = [\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;] + user_prod_features 1314df_X = df_X.merge(user_prod_features_df, on=[\u0026#39;user_id\u0026#39;, \u0026#39;product_id\u0026#39;]) 15df_X = df_X.dropna() Đặc trưng độ lệch: Tính độ lệch của của một số đặc trưng so với trung bình của chúng\n1#Create delta columns to compare how users perform against averages 2df_X[\u0026#39;product_total_orders_delta_per_user\u0026#39;] = df_X[\u0026#39;product_total_orders\u0026#39;] - df_X[\u0026#39;user_product_total_orders\u0026#39;] 34df_X[\u0026#39;product_avg_add_to_cart_order_delta_per_user\u0026#39;] = df_X[\u0026#39;product_avg_add_to_cart_order\u0026#39;] - \\ 5df_X[\u0026#39;user_product_avg_add_to_cart_order\u0026#39;] 67df_X[\u0026#39;product_avg_order_dow_per_user\u0026#39;] = df_X[\u0026#39;product_avg_order_dow\u0026#39;] - df_X[\u0026#39;user_product_avg_order_dow\u0026#39;] 89df_X[\u0026#39;product_avg_order_hour_of_day_per_user\u0026#39;] = df_X[\u0026#39;product_avg_order_hour_of_day\u0026#39;] - \\ 10df_X[\u0026#39;user_product_avg_order_hour_of_day\u0026#39;] 1112df_X[\u0026#39;product_avg_days_since_prior_order_per_user\u0026#39;] = df_X[\u0026#39;product_avg_days_since_prior_order\u0026#39;] - \\ 13df_X[\u0026#39;user_product_avg_days_since_prior_order\u0026#39;] Bổ sung thêm đặc trưng department name\n1f_departments_df = products_df.merge(departments_df, on = \u0026#39;department_id\u0026#39;) 2f_departments_df = f_departments_df[[\u0026#39;product_id\u0026#39;, \u0026#39;department\u0026#39;]] 34df_X = df_X.merge(f_departments_df, on = \u0026#39;product_id\u0026#39;) 5df_X = df_X.dropna() 6df_X = pd.concat([df_X, pd.get_dummies(df_X[\u0026#39;department\u0026#39;])], axis=1) 7del df_X[\u0026#39;department\u0026#39;] Chúng ta có tổng cộng 21 department name, vậy chúng ta thêm 21 cột, một cột tương ứng với một department name, ví dụ: alcohol,babies ,bakery, \u0026hellip; Sản phẩm thuộc department name thì sẽ được đánh số 1, không thuộc department name thì đánh số 0.\nHuấn luyện mô hình Chia tập dữ liệu thành 80/20 trong đó 80% là tập train, 20% là tập test. Sử dụng k-fold-cross_validation với k=10\n12np.random.seed(99) 3total_users = df_X[\u0026#39;user_id\u0026#39;].unique() 4test_users = np.random.choice(total_users, size=int(total_users.shape[0] * .20), replace=False) 5678test_user_sets = [] 9length = len(test_users) 10cv = 10 111213for x in range (0, cv): 14start = int(x/cv*length) 15finish = int((x+1)/cv*length) 16test_user_sets.append(test_users[start:finish]) 1718cv_f1_scores = [] 19cv_f1_scores_balanced = [] 20cv_f1_scores_10fit = [] 2122for test_user_set in test_user_sets: 23df_X_tr, df_X_te = df_X[~df_X[\u0026#39;user_id\u0026#39;].isin(test_user_set)], df_X[df_X[\u0026#39;user_id\u0026#39;].isin(test_user_set)] 2425y_tr, y_te = df_X_tr[\u0026#39;in_cart\u0026#39;], df_X_te[\u0026#39;in_cart\u0026#39;] 26X_tr, X_te = df_X_tr.drop([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;,\u0026#39;latest_cart\u0026#39;,\u0026#39;in_cart\u0026#39;],axis=1), \\ 27df_X_te.drop([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;,\u0026#39;latest_cart\u0026#39;,\u0026#39;in_cart\u0026#39;],axis=1), \\ 2829scaler = MinMaxScaler() 30X_tr = pd.DataFrame(scaler.fit_transform(X_tr), columns=X_tr.columns) 31X_te = pd.DataFrame(scaler.fit_transform(X_te), columns=X_te.columns) 3233lr = LogisticRegression(C=10000000) 34lr_balanced = LogisticRegression(class_weight=\u0026#39;balanced\u0026#39;, C=10000000) 35lr_10x = LogisticRegression(class_weight={1 : 6, 0 : 1}, C=10000000) 3637lr.fit(X_tr, y_tr) 38cv_f1_scores.append(f1_score(lr.predict(X_te), y_te)) 3940lr_balanced.fit(X_tr, y_tr) 41cv_f1_scores_balanced.append(f1_score(lr_balanced.predict(X_te), y_te)) 4243lr_10x.fit(X_tr, y_tr) 44cv_f1_scores_10fit.append(f1_score(lr_10x.predict(X_te), y_te)) 4546print(\u0026#34;cv_f1_scores: \u0026#34; +str( np.mean(cv_f1_scores))) 47print(\u0026#34;cv_f1_scores_balanced: \u0026#34;+str(np.mean(cv_f1_scores_balanced))) 48print(\u0026#34;cv_f1_scores_10fit: \u0026#34;+str(np.mean(cv_f1_scores_10fit))) 4950df_X_tr, df_X_te = df_X[~df_X[\u0026#39;user_id\u0026#39;].isin(test_users)], df_X[df_X[\u0026#39;user_id\u0026#39;].isin(test_users)] 5152y_tr, y_te = df_X_tr[\u0026#39;in_cart\u0026#39;], df_X_te[\u0026#39;in_cart\u0026#39;] 53X_tr, X_te = df_X_tr.drop([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;,\u0026#39;latest_cart\u0026#39;,\u0026#39;in_cart\u0026#39;],axis=1), \\ 54df_X_te.drop([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;,\u0026#39;latest_cart\u0026#39;,\u0026#39;in_cart\u0026#39;],axis=1), \\ 5556lr_10x = LogisticRegression(class_weight={1 : 6, 0 : 1}, C=10000000) 57lr_10x.fit(X_tr, y_tr) 58print(\u0026#34;F1 store all: \u0026#34;+str(f1_score(lr_10x.predict(X_te), y_te))) 1cv_f1_scores: 0.2026889989037295 2cv_f1_scores_balanced: 0.3816810646496983 3cv_f1_scores_10fit: 0.3899595078917494 45F1 store all: 0.3808374055616213 Thử in ra hệ số của hàm hồi quy\n1coefficients = pd.DataFrame(lr_10x.coef_, columns = X_tr.columns) 2coefficients = np.exp(coefficients) 3print(coefficients.T) 1user_product_total_orders 1.160475 2product_total_orders 1.077254 3product_avg_add_to_cart_order 0.915343 4user_total_orders 0.983272 5user_avg_cartsize 1.059655 6user_total_products 0.993839 7user_avg_days_since_prior_order 0.993513 8user_product_avg_add_to_cart_order 0.950418 9user_product_order_freq 1.051246 10product_avg_order_dow 0.994744 11product_avg_order_hour_of_day 1.010971 12product_avg_days_since_prior_order 0.994498 13user_avg_order_dow 0.997298 14user_avg_order_hour_of_day 1.012958 15user_product_avg_days_since_prior_order 1.003382 16user_product_avg_order_dow 0.994477 17user_product_avg_order_hour_of_day 1.003457 18product_total_orders_delta_per_user 0.928288 19product_avg_add_to_cart_order_delta_per_user 0.963095 20product_avg_order_dow_per_user 1.000268 21product_avg_order_hour_of_day_per_user 1.007489 22product_avg_days_since_prior_order_per_user 0.991147 23alcohol 0.998866 24babies 1.000313 25bakery 1.003098 26beverages 1.007733 27breakfast 1.000117 28bulk 0.999980 29canned goods 0.995017 30dairy eggs 1.018069 31deli 1.002720 32dry goods pasta 0.997379 33frozen 1.000752 34household 0.992164 35international 0.996822 36meat seafood 1.000340 37missing 1.001953 38other 0.999607 39pantry 0.972038 40personal care 0.992072 41pets 1.000466 42produce 1.017809 43snacks 1.004893 Thử show confusion matrix của dữ liệu:\n1from sklearn.metrics import confusion_matrix 2import seaborn as sns 3import matplotlib.pyplot as plt 4%matplotlib inline 5plt.style.use(\u0026#39;fivethirtyeight\u0026#39;) 67def plot_confusion_matrix(cm,title=\u0026#39;Confusion matrix\u0026#39;, cmap=plt.cm.Reds): 8plt.imshow(cm, interpolation=\u0026#39;nearest\u0026#39;,cmap=cmap) 9plt.title(title) 10plt.colorbar() 11plt.tight_layout() 12plt.ylabel(\u0026#39;True label\u0026#39;) 13plt.xlabel(\u0026#39;Predicted label\u0026#39;) 1415#y_tr=np.ravel(y_tr) 1617train_acc=lr_10x.score(X_tr, y_tr) 18test_acc=lr_10x.score(X_te, y_te) 19print(\u0026#34;Training Data Accuracy: %0.2f\u0026#34; %(train_acc)) 20print(\u0026#34;Test Data Accuracy: %0.2f\u0026#34; %(test_acc)) 2122y_true = y_te 23y_pred = lr_10x.predict(X_te) 242526conf = confusion_matrix(y_true, y_pred) 27print(conf) 2829print (\u0026#39;\\n\u0026#39;) 30print (\u0026#34;Precision: %0.2f\u0026#34; %(conf[1, 1] / (conf[1, 1] + conf[0, 1]))) 31print (\u0026#34;Recall: %0.2f\u0026#34;% (conf[1, 1] / (conf[1, 1] + conf[1, 0]))) 3233cm=confusion_matrix(y_true, y_pred, labels=[0, 1]) 3435plt.figure() 36plot_confusion_matrix(cm) Kết quả\n1Training Data Accuracy: 0.83 2Test Data Accuracy: 0.83 3[[1236979 190126] 4[ 78107 82493]] 567Precision: 0.30 8Recall: 0.51 Show đường cong ROC của dữ liệu\n12from sklearn.metrics import roc_curve, auc 34y_score = lr_10x.predict_proba(X_te)[:,1] 56fpr, tpr,_ = roc_curve(y_te, y_score) 7roc_auc = auc(fpr, tpr) 89plt.figure() 10# Plotting our Baseline.. 11plt.plot([0,1],[0,1], linestyle=\u0026#39;--\u0026#39;, color = \u0026#39;black\u0026#39;) 12plt.plot(fpr, tpr, color = \u0026#39;green\u0026#39;) 13plt.xlabel(\u0026#39;False Positive Rate\u0026#39;) 14plt.ylabel(\u0026#39;True Positive Rate\u0026#39;) 15plt.gca().set_aspect(\u0026#39;equal\u0026#39;, adjustable=\u0026#39;box\u0026#39;) Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Nov 13, 2018","img":"","permalink":"/blog/2018-11-13-instacart-market-basket-analysis/","series":null,"tags":["Machine learning","Deeplearning","instacart","Giỏ hàng","Đơn hàng"],"title":"Phân Tích Giỏ Hàng Của Website Instacart"},{"categories":null,"content":"Lời mở đầu Ở bài viết này, mình sẽ xây dựng mô hình hơn giản để áp dụng vào tập dữ liệu giá chứng khoáng. Mục tiêu của bài này là chúng ta sẽ dự đoán chỉ số S\u0026amp;P 500 sử dụng LSTM. Các bạn có nhu cầu tìm hiểu thêm về chỉ số sp 500 có thể đọc thêm ở https://vi.wikipedia.org/wiki/S%26P_500. Đây là một ứng dụng nhỏ, không có ý nghĩa nhiều ở thực tế do khi phân tích chứng khoán, ta còn xét thêm rất nhiều yếu tố phụ nữa. Mô hình này thực chất chỉ là một trong những mô hình chơi chơi.\nDẫn nhập Phân tích dữ liệu Các bạn có thể download dữ liệu ở https://github.com/AlexBlack2202/alexmodel/blob/master/GSPC.csv\nĐầu tiên, như thường lệ, chúng ta sẽ import các thư viện cần thiết để sử dụng.\n1import numpy as np # linear algebra 2import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) 34from subprocess import check_output 5from keras.layers.core import Dense, Activation, Dropout 6from keras.layers.recurrent import LSTM 7from keras.models import Sequential 8from sklearn.cross_validation import train_test_split 9import time #helper libraries 10from sklearn.preprocessing import MinMaxScaler 11import matplotlib.pyplot as plt 12from numpy import newaxis Đọc dữ liệu lên:\n12file_name =\u0026#39;GSPC.csv\u0026#39; 34prices_dataset = pd.read_csv(file_name, header=0) 56`` 78Xem kích thước của dữ liệu: 910```python 11print(prices_dataset.shape) 1(17114, 7) Kết quả là ta có 17114 ngàn dòng và 7 cột. Thử show 10 row đầu tiên của dữ liệu lên xem như thế nào.\n1print(prices_dataset.head()) 1Date Open High Low Close Adj Close Volume 20 1950-11-09 19.790001 19.790001 19.790001 19.790001 19.790001 1760000 31 1950-11-10 19.940001 19.940001 19.940001 19.940001 19.940001 1640000 42 1950-11-13 20.010000 20.010000 20.010000 20.010000 20.010000 1630000 53 1950-11-14 19.860001 19.860001 19.860001 19.860001 19.860001 1780000 64 1950-11-15 19.820000 19.820000 19.820000 19.820000 19.820000 1620000 Cột đầu tiên là ngày, sau đó là giá mở cửa, giá giao dịch cao nhất, giá giao dịch thấp nhât, giá đóng cử, giá đóng cửa đã điều chỉnh, khối lượng giao dịch.\nPlot đồ thị của mã SP500 lên:\n1import matplotlib.pyplot as plt 23plt.plot(prices_dataset.Open.values, color=\u0026#39;red\u0026#39;, label=\u0026#39;open\u0026#39;) 4plt.plot(prices_dataset.Close.values, color=\u0026#39;green\u0026#39;, label=\u0026#39;close\u0026#39;) 5plt.plot(prices_dataset.Low.values, color=\u0026#39;blue\u0026#39;, label=\u0026#39;low\u0026#39;) 6plt.plot(prices_dataset.High.values, color=\u0026#39;black\u0026#39;, label=\u0026#39;high\u0026#39;) 7plt.title(\u0026#39;stock price\u0026#39;) 8plt.xlabel(\u0026#39;time [days]\u0026#39;) 9plt.ylabel(\u0026#39;price\u0026#39;) 10plt.legend(loc=\u0026#39;best\u0026#39;) 11plt.show() Hình với số lượng hơi nhiều nên khó phân biệt được giá trị của dữ liệu, chúng ta thử show đồ thị của 50 ngày cuối cùng trong dữ liệu.\n1prices_dataset_tail_50 = prices_dataset.tail(50) 23plt.plot(prices_dataset_tail_50.Open.values, color=\u0026#39;red\u0026#39;, label=\u0026#39;open\u0026#39;) 4plt.plot(prices_dataset_tail_50.Close.values, color=\u0026#39;green\u0026#39;, label=\u0026#39;close\u0026#39;) 5plt.plot(prices_dataset_tail_50.Low.values, color=\u0026#39;blue\u0026#39;, label=\u0026#39;low\u0026#39;) 6plt.plot(prices_dataset_tail_50.High.values, color=\u0026#39;black\u0026#39;, label=\u0026#39;high\u0026#39;) 7plt.title(\u0026#39;stock price\u0026#39;) 8plt.xlabel(\u0026#39;time [days]\u0026#39;) 9plt.ylabel(\u0026#39;price\u0026#39;) 10plt.legend(loc=\u0026#39;best\u0026#39;) 11plt.show() Hình ảnh trông khá rõ ràng và trực quan hơn rất nhiều.\nChúng ta sẽ bỏ đi cột DATE,Adj Close,Volume đi. Các cột đó không cần thiết cho quá trình dự đoán.\n12prices_dataset_dropout = prices_dataset.drop([\u0026#39;Date\u0026#39;,\u0026#39;Adj Close\u0026#39;,\u0026#39;Volume\u0026#39;], 1) Scale dữ liệu Khi sử dụng ANN, chúng ta thông thường sẽ scale dữ liệu input về đoạn [-1,1]. Trong python, thư viện sklearn đã hỗ trợ cho chúng ta sẵn các hàm scale dữ liệu cần thiết.\n1# Scale data 2def normalize_data(df): 3min_max_scaler = MinMaxScaler() 4df[\u0026#39;Open\u0026#39;] = min_max_scaler.fit_transform(df.Open.values.reshape(-1,1)) 5df[\u0026#39;High\u0026#39;] = min_max_scaler.fit_transform(df.High.values.reshape(-1,1)) 6df[\u0026#39;Low\u0026#39;] = min_max_scaler.fit_transform(df.Low.values.reshape(-1,1)) 7df[\u0026#39;Close\u0026#39;] = min_max_scaler.fit_transform(df.Close.values.reshape(-1,1)) 8return df 910prices_dataset_norm = normalize_data(prices_dataset_dropout) Phân chia tập train và test. Chúng ta sẽ chia dữ liệu thành 2 phần với 80% là train và 20% còn lại là test. Chọn seq_len=20, các bạn có thể test với các seq len khác, và sau đó chuyển dữ liệu về dạng numpy array để dễ dàng thực hiện các phép chuyển đổi.\n12def generate_data(stock_ds, seq_len): 3data_raw = stock_ds.as_matrix() 4data = [] 56# create all possible sequences of length seq_len 7for index in range(len(data_raw) - seq_len): 8data.append(data_raw[index: index + seq_len]) 9return data 1011#data as numpy array 12def generate_train_test(data_ds,split_percent=0.8): 13print(len(data_ds)) 14data = np.asarray(data_ds) 1516data_size = len(data) 17train_end = int(np.floor(split_percent*data_size)) 1819x_train = data[:train_end,:-1,:] 20y_train = data[:train_end,-1,:] 21222324x_test = data[train_end:,:-1,:] 25y_test = data[train_end:,-1,:] 2627return [x_train, y_train, x_test, y_test] 28293031seq_len = 20 # choose sequence length 3233seq_prices_dataset = generate_data(prices_dataset_norm,seq_len) 3435x_train, y_train, x_test, y_test = generate_train_test(seq_prices_dataset, 0.8) 3637print(\u0026#39;x_train.shape = \u0026#39;,x_train.shape) 38print(\u0026#39;y_train.shape = \u0026#39;, y_train.shape) 39print(\u0026#39;x_test.shape = \u0026#39;, x_test.shape) 40print(\u0026#39;y_test.shape = \u0026#39;,y_test.shape) Kết quả:\n1x_train.shape = (13675, 19, 4) 2y_train.shape = (13675, 4) 3x_test.shape = (3419, 19, 4) 4y_test.shape = (3419, 4) Xây dựng mô hình sử dụng keras Ở đây mình sử dụng keras xây dựng mô hình ANN. Mô hình của mình xây dựng gồm:\n1model = Sequential() 23model.add(LSTM( 4input_dim=4, 5output_dim=50, 6return_sequences=True)) 7model.add(Dropout(0.2)) 89model.add(LSTM( 10100, 11return_sequences=False)) 12model.add(Dropout(0.2)) 1314model.add(Dense( 15output_dim=4)) 16model.add(Activation(\u0026#39;linear\u0026#39;)) 17181920model.compile(loss=\u0026#39;mean_squared_error\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) 21checkpoint = ModelCheckpoint(filepath=\u0026#39;sp500_stockperdict.h5\u0026#39;, verbose=1, save_best_only=True) 22hist = model.fit(x_train, y_train, epochs=300, batch_size=128, verbose=1, callbacks=[checkpoint], validation_split=0.2) Sau một thời gian chạy, mình cũng thu được model. Các bạn quan tâm có thể download model của mình huấn luyện được tại https://drive.google.com/open?id=1ImHQM9yWmOjpF5tjmSI9oqAi5BORa9Rs . Tiến hành plot dữ liệu tập test lên xem kết quả như thế nào.\n12model =load_model(\u0026#39;sp500_stockperdict.h5\u0026#39;) 345y_hat = model.predict(x_test) 67ft = 3 # 0 = open, 1 = highest, 2 =lowest , 3 = close 89plt.plot( y_test[:,ft], color=\u0026#39;blue\u0026#39;, label=\u0026#39;target\u0026#39;) 1011plt.plot( y_hat[:,ft], color=\u0026#39;red\u0026#39;, label=\u0026#39;prediction\u0026#39;) 1213plt.title(\u0026#39;future stock prices\u0026#39;) 14plt.xlabel(\u0026#39;time [days]\u0026#39;) 15plt.ylabel(\u0026#39;normalized price\u0026#39;) 16plt.legend(loc=\u0026#39;best\u0026#39;) 1718plt.show() 1920from sklearn.metrics import mean_squared_error 2122# 0 = open, 1 = highest, 2 =lowest , 3 = close 23print(\u0026#34;open error: \u0026#34;) 24print(mean_squared_error(y_test[:,0], y_hat[ :,0])) 2526print(\u0026#34;highest error: \u0026#34;) 27print(mean_squared_error(y_test[:,1], y_hat[ :,1])) 2829print(\u0026#34;lowest error: \u0026#34;) 30print(mean_squared_error(y_test[:,2], y_hat[ :,2])) 3132print(\u0026#34;close error: \u0026#34;) 33print(mean_squared_error(y_test[:,3], y_hat[ :,3])) 1open error: 20.0009739211460315127 3highest error: 40.0010539412808401607 5lowest error: 60.0010066509540756113 7close error: 80.0010840500965408758 Hiện đã có bản tensorflow 2 có tích hợp keras, mình update lại code\n12from re import T 3import numpy as np 4# linear algebra  5import pandas as pd 6from tensorflow.keras.models import Sequential 7from tensorflow.keras.layers import Dense 8from tensorflow.keras.layers import LSTM 9from sklearn.preprocessing import MinMaxScaler 10import tensorflow as tf 11import joblib 1213import matplotlib 14matplotlib.use(\u0026#39;TkAgg\u0026#39;) 15import matplotlib.pyplot as plt 161718file_name =\u0026#39;GSPC.csv\u0026#39; 192021prices_dataset = pd.read_csv(file_name, header=0) 222324# prices_dataset_dropout = prices_dataset.drop([\u0026#39;Date\u0026#39;,\u0026#39;Adj Close\u0026#39;,\u0026#39;Volume\u0026#39;], 1) 25prices_dataset_dropout=prices_dataset.reset_index()[\u0026#39;Close\u0026#39;] 262728scaler=MinMaxScaler(feature_range=(0,1)) 29prices_dataset_norm=scaler.fit_transform(np.array(prices_dataset_dropout).reshape(-1,1)) 30joblib.dump(scaler, \u0026#39;scaler.alex\u0026#39;) 313233print(prices_dataset_norm[:10]) 343536def generate_data(stock_ds, seq_len,predict_next_t): 37dataX, dataY = [], [] 38for i in range(len(stock_ds)-seq_len-1): 39dataX.append(stock_ds[i:(i+seq_len)]) 40dataY.append(stock_ds[i + seq_len+predict_next_t]) 41return np.array(dataX), np.array(dataY) 4243#data as numpy array 44def generate_train_test(data_x,data_y,split_percent=0.8): 4546train_end = int(np.floor(split_percent*data_x.shape[0])) 4748x_train,x_test=data_x[:train_end,:],data_x[train_end:,:] 49y_train,y_test = data_y[:train_end],data_y[train_end:] 50return x_train,y_train,x_test,y_test 51525354seq_len = 100 # choose sequence length 55predict_next_t = 1 # 0 is next date, 1 is 2 next date 5657data_x, data_y = generate_data(prices_dataset_norm,seq_len,predict_next_t) 5859x_train,y_train,x_test,y_test = generate_train_test(data_x,data_y, 0.8) 606162x_train =x_train.reshape(x_train.shape[0],x_train.shape[1] , 1) 63x_test = x_test.reshape(x_test.shape[0],x_test.shape[1] , 1) 64print(\u0026#39;x_train.shape = \u0026#39;,x_train.shape) 65print(\u0026#39;y_train.shape = \u0026#39;, y_train.shape) 66print(\u0026#39;x_test.shape = \u0026#39;, x_test.shape) 67print(\u0026#39;y_test.shape = \u0026#39;,y_test.shape) 68697071model = Sequential() 7273# input_dim=4, 74# output_dim=50, 75model.add(LSTM(units=100,input_shape=x_train.shape[1:], 76return_sequences=True)) 7778model.add(LSTM( 79100, 80return_sequences=False)) 81model.add(Dense(1)) 828384model.compile(loss=\u0026#39;mean_squared_error\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) 85checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=\u0026#39;my_model_stock.h5\u0026#39;, verbose=1, save_best_only=True) 86hist = model.fit(x_train, y_train, epochs=3, batch_size=64, verbose=1, callbacks=[checkpoint], validation_split=0.2) 8788from tensorflow.keras.models import load_model 89print(\u0026#39;load model\u0026#39;) 90model =load_model(\u0026#39;my_model_stock.h5\u0026#39;) 9192print(\u0026#39;predict\u0026#39;) 93y_test = y_test.reshape(y_test.shape[0]) 94# train_predict=model.predict(x_train) 95test_predict=model.predict(x_test) 96print(\u0026#39;invert\u0026#39;) 97print(y_test.shape) 98# train_predict=scaler.inverse_transform(train_predict) 99100# scaler = joblib.load(\u0026#39;scaler.alex\u0026#39;) 101102y_hat=scaler.inverse_transform(test_predict) 103y_test=scaler.inverse_transform(y_test.reshape(-1, 1)) 104print(y_hat.shape) 105# y_hat = model.predict(x_test) 106# import matplotlib 107# matplotlib.use(\u0026#39;GTKAgg\u0026#39;)  108# print(\u0026#39;plot\u0026#39;) 109110plt.plot( y_test, color=\u0026#39;blue\u0026#39;, label=\u0026#39;target\u0026#39;) 111112plt.plot( y_hat, color=\u0026#39;red\u0026#39;, label=\u0026#39;prediction\u0026#39;) 113print(\u0026#39;plot complete\u0026#39;) 114plt.title(\u0026#39;future stock prices\u0026#39;) 115plt.xlabel(\u0026#39;time [days]\u0026#39;) 116plt.ylabel(\u0026#39;normalized price\u0026#39;) 117plt.legend(loc=\u0026#39;best\u0026#39;) 118print(\u0026#39;plot show\u0026#39;) 119plt.savefig(\u0026#34;mygraph.png\u0026#34;) 120plt.show() Kết quả của mô hình trông khá tốt, về hình dạng thì khá tương đồng với kết quả. Chúng ta có thể cải tiến model bằng cách nâng số lượng layer/ hidden node.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Nov 10, 2018","img":"","permalink":"/blog/2018-11-10-stock-prediction_v1/","series":null,"tags":["Machine learning","Deeplearning","stock prediction","chứng khoán"],"title":"Dự Đoán Giá Chứng Khoán SP500 Sử Dụng LSTM"},{"categories":null,"content":"Lời mở đầu Ở bài viết này, mình sẽ xây dựng mô hình hơn giản để áp dụng vào tập dữ liệu giá chứng khoán. Mục tiêu của bài này là chúng ta sẽ dự đoán chỉ số S\u0026amp;P 500 dựa trên chỉ số của 500 mã chứng khoán. Các bạn có nhu cầu tìm hiểu thêm về chỉ số sp 500 có thể đọc thêm ở https://vi.wikipedia.org/wiki/S%26P_500. Đây là một ứng dụng nhỏ, không có ý nghĩa nhiều ở thực tế do khi phân tích chứng khoán, ta còn xét thêm rất nhiều yếu tố phụ nữa. Mô hình này thực chất chỉ là một trong những mô hình chơi chơi.\nDẫn nhập Phân tích dữ liệu Các bạn có thể download dữ liệu ở https://drive.google.com/open?id=1UTlj5Ced-yj6RBRVc6bBM6IWMjfQR3GR.\nĐầu tiên, chúng ta sẽ dùng pandas để load mô hình lên:\n1import pandas as pd 23# Import data 4data = pd.read_csv(\u0026#39;data_stocks.csv\u0026#39;) Xem kích thước của dữ liệu:\n1print(data.shape) 1(41266, 502) Kết quả là ta có hơn 40 ngàn dòng và 502 cột. Thử show 10 row đầu tiên của dữ liệu lên xem như thế nào.\n1print(data.head()) 1DATE SP500 NASDAQ.AAL NASDAQ.AAPL NASDAQ.ADBE NASDAQ.ADI \\ 20 1491226200 2363.6101 42.3300 143.6800 129.6300 82.040 31 1491226260 2364.1001 42.3600 143.7000 130.3200 82.080 42 1491226320 2362.6799 42.3100 143.6901 130.2250 82.030 53 1491226380 2364.3101 42.3700 143.6400 130.0729 82.000 64 1491226440 2364.8501 42.5378 143.6600 129.8800 82.035 78NASDAQ.ADP NASDAQ.ADSK NASDAQ.AKAM NASDAQ.ALXN ... NYSE.WYN \\ 90 102.2300 85.2200 59.760 121.52 ... 84.370 101 102.1400 85.6500 59.840 121.48 ... 84.370 112 102.2125 85.5100 59.795 121.93 ... 84.585 123 102.1400 85.4872 59.620 121.44 ... 84.460 134 102.0600 85.7001 59.620 121.60 ... 84.470 1415NYSE.XEC NYSE.XEL NYSE.XL NYSE.XOM NYSE.XRX NYSE.XYL NYSE.YUM \\ 160 119.035 44.40 39.88 82.03 7.36 50.22 63.86 171 119.035 44.11 39.88 82.03 7.38 50.22 63.74 182 119.260 44.09 39.98 82.02 7.36 50.12 63.75 193 119.260 44.25 39.99 82.02 7.35 50.16 63.88 204 119.610 44.11 39.96 82.03 7.36 50.20 63.91 2122NYSE.ZBH NYSE.ZTS 230 122.000 53.350 241 121.770 53.350 252 121.700 53.365 263 121.700 53.380 274 121.695 53.240 Cột đầu tiên là ngày, sau đó là mã chứng khoán. Chúng ta có tổng cộng 500 mã chứng khoán và 1 chỉ số. Để ý cột Date, ta thấy giá trị đầu tiên là 1491226200, giá trị thứ 2 là 1491226260, giá trị thứ 3 là 1491226320, mỗi giá trị cách nhau 60. Chuyển đổi số 1491226200 sang dạng datetime thì ra giá trị Monday, April 3, 2017 1:30:00 PM giờ GMT, tương tự số 1491226260 ra Monday, April 3, 2017 1:31:00 PM giờ GMT. Ta có thể suy luận ra là giá trị giao dịch lưu theo từng phút một (khoảng interval là 60 giây), và dữ liệu chúng ta có bắt đầu vào 3 tháng 4 năm 2017.\nPlot đồ thị của mã SP500 lên:\n1import matplotlib.pyplot as plt 23plt.plot(data[\u0026#39;SP500\u0026#39;]) 4plt.show() 1Notes: Ở đây có một lưu ý nhỏ nhưng rất quan trọng. Đó là tại thời điểm phút thứ t lưu trữ giá trị sp500 của thời điểm phút thứ t+1. Ví dụ với chỉ số sp500, dòng đầu tiên ta thấy là 1491226200 2363.6101, nghĩa là giá thực tế của thời điểm 1491226260 là 2363.6101. Do bài toán của chúng ta là dữ đoán giá tương lại, nên tại thời điểm hiện tại ta sẽ dự đoán giá 1 phút sau sẽ bằng bao nhiêu. Và tập dữ liệu đã tự động dịch chuyển giá trị lên 1 phút cho chúng ta đỡ mất công làm. Còn giá của 500 cỗ phiếu còn lại vẫn là giá tại thời điểm t Phân chia tập train và test. Chúng ta sẽ chia dữ liệu thành 2 phần với 80% là train và 20% còn lại là test. Do tích chất của dữ liệu là time serial nên chúng ta không thể làm thay đổi thứ tự dữ liệu.\nChúng ta sẽ bỏ đi cột DATE đầu tiên, và sau đó chuyển dữ liệu về dạng numpy array để dễ dàng thực hiện các phép chuyển đổi.\n1data_ = data_raw.drop([\u0026#39;DATE\u0026#39;], 1) 23data = data_.values 4# Training and test data 5train_start = 0 6train_end = int(np.floor(0.8*n)) 7test_start = train_end 8test_end = n 9data_train = data[ :train_end] 10data_test = data[train_end:] Scale dữ liệu Khi sử dụng ANN, chúng ta thông thường sẽ scale dữ liệu input về đoạn [-1,1]. Trong python, thư viện sklearn đã hỗ trợ cho chúng ta sẵn các hàm scale dữ liệu cần thiết.\n1# Scale data 2from sklearn.preprocessing import MinMaxScaler 3scaler = MinMaxScaler() 4data_train = scaler.fit_transform(data_train) 5data_test = scaler.transform(data_test) 6# Build X and y 7X_train = data_train[:, 1:] 8y_train = data_train[:, 0] 9X_test = data_test[:, 1:] 10y_test = data_test[:, 0] Mình cần dự đoán giá trị của chỉ số sp 500, nên giá trị của sp500 sẽ là cái mình cần dự đoán, chính là cột đầu tiên, còn 500 cái còn lại là input của mình.\nXây dựng mô hình sử dụng keras Ở đây mình sử dụng keras xây dựng mô hình ANN. Mô hình của mình xây dựng gồm\n1from keras.models import Sequential 2from keras.layers.core import Dense, Dropout, Activation 3from keras.callbacks import ModelCheckpoint 4from keras.optimizers import SGD 56import os 7os.environ[\u0026#34;CUDA_DEVICE_ORDER\u0026#34;]=\u0026#34;PCI_BUS_ID\u0026#34; 8# The GPU id to use, usually either \u0026#34;0\u0026#34; or \u0026#34;1\u0026#34; 9os.environ[\u0026#34;CUDA_VISIBLE_DEVICES\u0026#34;]=\u0026#34;0\u0026#34; 10# create model 11model = Sequential() 12model.add(Dense(2048, input_dim=input_dim,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 13model.add(Dense(1024,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 14model.add(Dense(512,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 15model.add(Dense(256,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 16model.add(Dense(128,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 17model.add(Dense(1,kernel_initializer=\u0026#39;normal\u0026#39;)) 18192021model.compile(loss=\u0026#39;mse\u0026#39;, optimizer=\u0026#39;rmsprop\u0026#39;) 22checkpoint = ModelCheckpoint(filepath=\u0026#39;my_model3.h5\u0026#39;, verbose=1, save_best_only=True) 23model.fit(X_train, y_train, epochs=100, batch_size=256, verbose=1, callbacks=[checkpoint], validation_split=0.2) Sau một thời gian chạy, mình cũng thu được model. Các bạn quan tâm có thể download model của mình huấn luyện được tại https://drive.google.com/open?id=1BLQZbcADfnLqzIHlkgpsqZBlhljBp1Eb . Tiến hành plot dữ liệu tập test lên xem kết quả như thế nào.\n12yhat = model.predict(X_test) 345x = np.arange(len(yhat)) 67plt.plot(x, y_test) 8plt.plot(x, yhat) 9plt.legend([\u0026#39;real\u0026#39;, \u0026#39;test\u0026#39;], loc=\u0026#39;upper right\u0026#39;) 10plt.show() 111213from sklearn.metrics import mean_squared_error 1415print(\u0026#34;mse: \u0026#34;+ str(mean_squared_error(y_test, yhat))) 1mse: 0.0014582120695331884 Kết quả của mô hình tạm chấp nhận được, về hình dạng thì khá tương đồng với kết quả. Chúng ta có thể cải tiến model bằng cách nâng số lượng layter/ hidden node, hoặc thêm dropout. Hoặc có thể thay thế mô hình bằng RNN. Chúng ta sẽ đề cập đến mô hình RNN trong bài viết sau.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Nov 3, 2018","img":"","permalink":"/blog/2018-11-03-stock-prediction/","series":null,"tags":["Machine learning","Deep learning","stock prediction"],"title":"Dự Đoán Chứng Khoán Sử Dụng Tensorflow"},{"categories":null,"content":"Lời mở đầu Sau khi thực hiện bài phân loại chó mèo bằng keras, mình phát hiện rằng keras có hỗ trợ rất nhiều thuật toán tối ưu hoá https://keras.io/optimizers/. Nhân dịp rãnh rỗi, mình sẽ tổng hợp lại một vài thuật toán mà keras hỗ trợ.\nDẫn nhập Tại thời điểm hiện tại, Gradient descent là một trong những thuật toán phổ biến được sử dụng để tối ưu hoá mạng neural networks. Các thư viện DNN sẽ implement kèm theo một vài biến thể của gradient descent giúp người dùng dễ dàng sử dụng công cụ hơn.\nBài viết này mình sẽ cập nhật dần đến khi hoàn thiện.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Oct 29, 2018","img":"","permalink":"/blog/2018-11-01-overview-of-gradient-descent-optimization-algorithm/","series":null,"tags":["Machine learning","Deeplearning"],"title":"Overview of Gradient Descent Optimization Algorithm"},{"categories":null,"content":"Lời mở đầu Bài toán phân loại chó mèo là bài toán khá cũ tại thời điểm hiện tại. Tuy nhiên, đối với các bạn mới bước chân vào con đường machine learning thì đây là một trong những bài toán cơ bản để các bạn thực hành sử dụng và tìm hiểu thư viện mà mình đang có. Ở đây, chúng ta sẽ sử dụng pretrain model có sẵn của kares áp dụng trên tập dữ liệu. Các bạn có thể download tập dữ liệu train và test ở địa chỉ https://www.kaggle.com/c/dogs-vs-cats/download/train.zip và https://www.kaggle.com/c/dogs-vs-cats/download/test1.zip để bắt đầu thực hiện.\nThực hiện Sau khi giải nén dữ liệu, ta thấy rằng thư mục train có cấu trúc đặt trên sẽ là label.số thứ tự.jpg. Trong đó label có thể là dog hoặc cat, số thứ tự tăng dần từ 0 đến \u0026hellip;. 12499. Để đảm bảo đúng với mô hình, ta phải cấu trúc lại dữ liệu thành dạng.\n1data_dir/classname1/*.* 2data_dir/classname2/*.* 3... Vì vậy, ta tạo ra thư mục cat và copy những file bắt đầu bằng cat.* vào thư mục cat. Làm tương tự với thư mục dog.\nĐầu tiên, các bạn download file pretrain model, giải nén ra và để ở đâu đó trong ổ cứng của máy bạn. Đường dẫn file pretrain model các bạn có thể download ở http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz. Các bạn có thể download các file pretrain khác nếu có hứng thú tìm hiểu.\nTiếp theo, chúng ta sẽ load dataset lên và tranform nó để đưa vào huấn luyện.\n1import sys 2import os 3from collections import defaultdict 4import numpy as np 5import scipy.misc 678def preprocess_input(x0): 9x = x0 / 255. 10x -= 0.5 11x *= 2. 12return x 131415def reverse_preprocess_input(x0): 16x = x0 / 2.0 17x += 0.5 18x *= 255. 19return x 202122def dataset(base_dir, n): 23print(\u0026#34;base dir: \u0026#34;+base_dir) 24print(\u0026#34;n: \u0026#34;+str(n)) 25n = int(n) 26d = defaultdict(list) 27for root, subdirs, files in os.walk(base_dir): 28for filename in files: 29file_path = os.path.join(root, filename) 30assert file_path.startswith(base_dir) 3132suffix = file_path[len(base_dir):] 3334suffix = suffix.lstrip(\u0026#34;/\u0026#34;) 35suffix = suffix.lstrip(\u0026#34;\\\\\u0026#34;) 36if(suffix.find(\u0026#39;/\u0026#39;)\u0026gt;-1): #linux 37label = suffix.split(\u0026#34;/\u0026#34;)[0] 38else: #window 39label = suffix.split(\u0026#34;\\\\\u0026#34;)[0] 40d[label].append(file_path) 41print(\u0026#34;walk directory complete\u0026#34;) 42tags = sorted(d.keys()) 4344processed_image_count = 0 45useful_image_count = 0 4647X = [] 48y = [] 4950for class_index, class_name in enumerate(tags): 51filenames = d[class_name] 52for filename in filenames: 53processed_image_count += 1 54if processed_image_count%100 ==0: 55print(class_name+\u0026#34;\\tprocess: \u0026#34;+str(processed_image_count)+\u0026#34;\\t\u0026#34;+str(len(d[class_name]))) 56img = scipy.misc.imread(filename) 57height, width, chan = img.shape 58assert chan == 3 59aspect_ratio = float(max((height, width))) / min((height, width)) 60if aspect_ratio \u0026gt; 2: 61continue 62# We pick the largest center square. 63centery = height // 2 64centerx = width // 2 65radius = min((centerx, centery)) 66img = img[centery-radius:centery+radius, centerx-radius:centerx+radius] 67img = scipy.misc.imresize(img, size=(n, n), interp=\u0026#39;bilinear\u0026#39;) 68X.append(img) 69y.append(class_index) 70useful_image_count += 1 71print(\u0026#34;processed %d, used %d\u0026#34; % (processed_image_count, useful_image_count)) 7273X = np.array(X).astype(np.float32) 74#X = X.transpose((0, 3, 1, 2)) 75X = preprocess_input(X) 76y = np.array(y) 7778perm = np.random.permutation(len(y)) 79X = X[perm] 80y = y[perm] 8182print(\u0026#34;classes:\u0026#34;,end=\u0026#34; \u0026#34;) 83for class_index, class_name in enumerate(tags): 84print(class_name, sum(y==class_index),end=\u0026#34; \u0026#34;) 85print(\u0026#34;X shape: \u0026#34;,X.shape) 8687return X, y, tags Đoạn code trên khá đơn giản và dễ hiểu. Lưu ý ở đây là với những bức ảnh có tỷ lệ width và height \u0026gt; 2 thì mình sẽ loại chúng ra khỏi tập dữ liệu.\nTiếp theo, chúng ta sẽ xây dựng mô hình dựa trên mô hình InceptionV3 có sẵn, thêm một lớp softmax ở cuối để phân lớp dữ liệu, chúng ta sẽ huấn luyện lớp softmax này. Các lớp trước lớp softmax này sẽ bị đóng băng (không cập nhật trọng số trong quá trình huấn luyện ).\n12# create the base pre-trained model 3def build_model(nb_classes): 4base_model = InceptionV3(weights=\u0026#39;imagenet\u0026#39;, include_top=False) 56# add a global spatial average pooling layer 7x = base_model.output 8x = GlobalAveragePooling2D()(x) 9# let\u0026#39;s add a fully-connected layer 10x = Dense(1024, activation=\u0026#39;relu\u0026#39;)(x) 11# and a logistic layer 12predictions = Dense(nb_classes, activation=\u0026#39;softmax\u0026#39;)(x) 1314# this is the model we will train 15model = Model(inputs=base_model.input, outputs=predictions) 1617# first: train only the top layers (which were randomly initialized) 18# i.e. freeze all convolutional InceptionV3 layers 19for layer in base_model.layers: 20layer.trainable = False 2122# compile the model (should be done *after* setting layers to non-trainable) 23print(\u0026#34;starting model compile\u0026#34;) 24compile(model) 25print(\u0026#34;model compile done\u0026#34;) 26return model 27Visualize một chút xíu về kiến trúc inceptionV3 mình đang dùng.\n1__________________________________________________________________________________________________ 2Layer (type) Output Shape Param # Connected to 3================================================================================================== 4input_1 (InputLayer) (None, None, None, 3 0 5__________________________________________________________________________________________________ 6conv2d_1 (Conv2D) (None, None, None, 3 864 input_1[0][0] 7__________________________________________________________________________________________________ 8batch_normalization_1 (BatchNor (None, None, None, 3 96 conv2d_1[0][0] 9__________________________________________________________________________________________________ 10activation_1 (Activation) (None, None, None, 3 0 batch_normalization_1[0][0] 11__________________________________________________________________________________________________ 12conv2d_2 (Conv2D) (None, None, None, 3 9216 activation_1[0][0] 13__________________________________________________________________________________________________ 14batch_normalization_2 (BatchNor (None, None, None, 3 96 conv2d_2[0][0] 15__________________________________________________________________________________________________ 16activation_2 (Activation) (None, None, None, 3 0 batch_normalization_2[0][0] 17__________________________________________________________________________________________________ 18conv2d_3 (Conv2D) (None, None, None, 6 18432 activation_2[0][0] 19__________________________________________________________________________________________________ 20batch_normalization_3 (BatchNor (None, None, None, 6 192 conv2d_3[0][0] 21__________________________________________________________________________________________________ 22activation_3 (Activation) (None, None, None, 6 0 batch_normalization_3[0][0] 23__________________________________________________________________________________________________ 24max_pooling2d_1 (MaxPooling2D) (None, None, None, 6 0 activation_3[0][0] 25__________________________________________________________________________________________________ 26conv2d_4 (Conv2D) (None, None, None, 8 5120 max_pooling2d_1[0][0] 27__________________________________________________________________________________________________ 28batch_normalization_4 (BatchNor (None, None, None, 8 240 conv2d_4[0][0] 29__________________________________________________________________________________________________ 30activation_4 (Activation) (None, None, None, 8 0 batch_normalization_4[0][0] 31__________________________________________________________________________________________________ 32conv2d_5 (Conv2D) (None, None, None, 1 138240 activation_4[0][0] 33__________________________________________________________________________________________________ 34batch_normalization_5 (BatchNor (None, None, None, 1 576 conv2d_5[0][0] 35__________________________________________________________________________________________________ 36activation_5 (Activation) (None, None, None, 1 0 batch_normalization_5[0][0] 37__________________________________________________________________________________________________ 38max_pooling2d_2 (MaxPooling2D) (None, None, None, 1 0 activation_5[0][0] 39__________________________________________________________________________________________________ 40conv2d_9 (Conv2D) (None, None, None, 6 12288 max_pooling2d_2[0][0] 41__________________________________________________________________________________________________ 42batch_normalization_9 (BatchNor (None, None, None, 6 192 conv2d_9[0][0] 43__________________________________________________________________________________________________ 44activation_9 (Activation) (None, None, None, 6 0 batch_normalization_9[0][0] 45__________________________________________________________________________________________________ 46conv2d_7 (Conv2D) (None, None, None, 4 9216 max_pooling2d_2[0][0] 47__________________________________________________________________________________________________ 48conv2d_10 (Conv2D) (None, None, None, 9 55296 activation_9[0][0] 49__________________________________________________________________________________________________ 50batch_normalization_7 (BatchNor (None, None, None, 4 144 conv2d_7[0][0] 51__________________________________________________________________________________________________ 52batch_normalization_10 (BatchNo (None, None, None, 9 288 conv2d_10[0][0] 53__________________________________________________________________________________________________ 54activation_7 (Activation) (None, None, None, 4 0 batch_normalization_7[0][0] 55__________________________________________________________________________________________________ 56activation_10 (Activation) (None, None, None, 9 0 batch_normalization_10[0][0] 57__________________________________________________________________________________________________ 58average_pooling2d_1 (AveragePoo (None, None, None, 1 0 max_pooling2d_2[0][0] 59__________________________________________________________________________________________________ 60conv2d_6 (Conv2D) (None, None, None, 6 12288 max_pooling2d_2[0][0] 61__________________________________________________________________________________________________ 62conv2d_8 (Conv2D) (None, None, None, 6 76800 activation_7[0][0] 63__________________________________________________________________________________________________ 64conv2d_11 (Conv2D) (None, None, None, 9 82944 activation_10[0][0] 65__________________________________________________________________________________________________ 66conv2d_12 (Conv2D) (None, None, None, 3 6144 average_pooling2d_1[0][0] 67__________________________________________________________________________________________________ 68batch_normalization_6 (BatchNor (None, None, None, 6 192 conv2d_6[0][0] 69__________________________________________________________________________________________________ 70batch_normalization_8 (BatchNor (None, None, None, 6 192 conv2d_8[0][0] 71__________________________________________________________________________________________________ 72batch_normalization_11 (BatchNo (None, None, None, 9 288 conv2d_11[0][0] 73__________________________________________________________________________________________________ 74batch_normalization_12 (BatchNo (None, None, None, 3 96 conv2d_12[0][0] 75__________________________________________________________________________________________________ 76activation_6 (Activation) (None, None, None, 6 0 batch_normalization_6[0][0] 77__________________________________________________________________________________________________ 78activation_8 (Activation) (None, None, None, 6 0 batch_normalization_8[0][0] 79__________________________________________________________________________________________________ 80activation_11 (Activation) (None, None, None, 9 0 batch_normalization_11[0][0] 81__________________________________________________________________________________________________ 82activation_12 (Activation) (None, None, None, 3 0 batch_normalization_12[0][0] 83__________________________________________________________________________________________________ 84mixed0 (Concatenate) (None, None, None, 2 0 activation_6[0][0] 85activation_8[0][0] 86activation_11[0][0] 87activation_12[0][0] 88__________________________________________________________________________________________________ 89conv2d_16 (Conv2D) (None, None, None, 6 16384 mixed0[0][0] 90__________________________________________________________________________________________________ 91batch_normalization_16 (BatchNo (None, None, None, 6 192 conv2d_16[0][0] 92__________________________________________________________________________________________________ 93activation_16 (Activation) (None, None, None, 6 0 batch_normalization_16[0][0] 94__________________________________________________________________________________________________ 95conv2d_14 (Conv2D) (None, None, None, 4 12288 mixed0[0][0] 96__________________________________________________________________________________________________ 97conv2d_17 (Conv2D) (None, None, None, 9 55296 activation_16[0][0] 98__________________________________________________________________________________________________ 99batch_normalization_14 (BatchNo (None, None, None, 4 144 conv2d_14[0][0] 100__________________________________________________________________________________________________ 101batch_normalization_17 (BatchNo (None, None, None, 9 288 conv2d_17[0][0] 102__________________________________________________________________________________________________ 103activation_14 (Activation) (None, None, None, 4 0 batch_normalization_14[0][0] 104__________________________________________________________________________________________________ 105activation_17 (Activation) (None, None, None, 9 0 batch_normalization_17[0][0] 106__________________________________________________________________________________________________ 107average_pooling2d_2 (AveragePoo (None, None, None, 2 0 mixed0[0][0] 108__________________________________________________________________________________________________ 109conv2d_13 (Conv2D) (None, None, None, 6 16384 mixed0[0][0] 110__________________________________________________________________________________________________ 111conv2d_15 (Conv2D) (None, None, None, 6 76800 activation_14[0][0] 112__________________________________________________________________________________________________ 113conv2d_18 (Conv2D) (None, None, None, 9 82944 activation_17[0][0] 114__________________________________________________________________________________________________ 115conv2d_19 (Conv2D) (None, None, None, 6 16384 average_pooling2d_2[0][0] 116__________________________________________________________________________________________________ 117batch_normalization_13 (BatchNo (None, None, None, 6 192 conv2d_13[0][0] 118__________________________________________________________________________________________________ 119batch_normalization_15 (BatchNo (None, None, None, 6 192 conv2d_15[0][0] 120__________________________________________________________________________________________________ 121batch_normalization_18 (BatchNo (None, None, None, 9 288 conv2d_18[0][0] 122__________________________________________________________________________________________________ 123batch_normalization_19 (BatchNo (None, None, None, 6 192 conv2d_19[0][0] 124__________________________________________________________________________________________________ 125activation_13 (Activation) (None, None, None, 6 0 batch_normalization_13[0][0] 126__________________________________________________________________________________________________ 127activation_15 (Activation) (None, None, None, 6 0 batch_normalization_15[0][0] 128__________________________________________________________________________________________________ 129activation_18 (Activation) (None, None, None, 9 0 batch_normalization_18[0][0] 130__________________________________________________________________________________________________ 131activation_19 (Activation) (None, None, None, 6 0 batch_normalization_19[0][0] 132__________________________________________________________________________________________________ 133mixed1 (Concatenate) (None, None, None, 2 0 activation_13[0][0] 134activation_15[0][0] 135activation_18[0][0] 136activation_19[0][0] 137__________________________________________________________________________________________________ 138conv2d_23 (Conv2D) (None, None, None, 6 18432 mixed1[0][0] 139__________________________________________________________________________________________________ 140batch_normalization_23 (BatchNo (None, None, None, 6 192 conv2d_23[0][0] 141__________________________________________________________________________________________________ 142activation_23 (Activation) (None, None, None, 6 0 batch_normalization_23[0][0] 143__________________________________________________________________________________________________ 144conv2d_21 (Conv2D) (None, None, None, 4 13824 mixed1[0][0] 145__________________________________________________________________________________________________ 146conv2d_24 (Conv2D) (None, None, None, 9 55296 activation_23[0][0] 147__________________________________________________________________________________________________ 148batch_normalization_21 (BatchNo (None, None, None, 4 144 conv2d_21[0][0] 149__________________________________________________________________________________________________ 150batch_normalization_24 (BatchNo (None, None, None, 9 288 conv2d_24[0][0] 151__________________________________________________________________________________________________ 152activation_21 (Activation) (None, None, None, 4 0 batch_normalization_21[0][0] 153__________________________________________________________________________________________________ 154activation_24 (Activation) (None, None, None, 9 0 batch_normalization_24[0][0] 155__________________________________________________________________________________________________ 156average_pooling2d_3 (AveragePoo (None, None, None, 2 0 mixed1[0][0] 157__________________________________________________________________________________________________ 158conv2d_20 (Conv2D) (None, None, None, 6 18432 mixed1[0][0] 159__________________________________________________________________________________________________ 160conv2d_22 (Conv2D) (None, None, None, 6 76800 activation_21[0][0] 161__________________________________________________________________________________________________ 162conv2d_25 (Conv2D) (None, None, None, 9 82944 activation_24[0][0] 163__________________________________________________________________________________________________ 164conv2d_26 (Conv2D) (None, None, None, 6 18432 average_pooling2d_3[0][0] 165__________________________________________________________________________________________________ 166batch_normalization_20 (BatchNo (None, None, None, 6 192 conv2d_20[0][0] 167__________________________________________________________________________________________________ 168batch_normalization_22 (BatchNo (None, None, None, 6 192 conv2d_22[0][0] 169__________________________________________________________________________________________________ 170batch_normalization_25 (BatchNo (None, None, None, 9 288 conv2d_25[0][0] 171__________________________________________________________________________________________________ 172batch_normalization_26 (BatchNo (None, None, None, 6 192 conv2d_26[0][0] 173__________________________________________________________________________________________________ 174activation_20 (Activation) (None, None, None, 6 0 batch_normalization_20[0][0] 175__________________________________________________________________________________________________ 176activation_22 (Activation) (None, None, None, 6 0 batch_normalization_22[0][0] 177__________________________________________________________________________________________________ 178activation_25 (Activation) (None, None, None, 9 0 batch_normalization_25[0][0] 179__________________________________________________________________________________________________ 180activation_26 (Activation) (None, None, None, 6 0 batch_normalization_26[0][0] 181__________________________________________________________________________________________________ 182mixed2 (Concatenate) (None, None, None, 2 0 activation_20[0][0] 183activation_22[0][0] 184activation_25[0][0] 185activation_26[0][0] 186__________________________________________________________________________________________________ 187conv2d_28 (Conv2D) (None, None, None, 6 18432 mixed2[0][0] 188__________________________________________________________________________________________________ 189batch_normalization_28 (BatchNo (None, None, None, 6 192 conv2d_28[0][0] 190__________________________________________________________________________________________________ 191activation_28 (Activation) (None, None, None, 6 0 batch_normalization_28[0][0] 192__________________________________________________________________________________________________ 193conv2d_29 (Conv2D) (None, None, None, 9 55296 activation_28[0][0] 194__________________________________________________________________________________________________ 195batch_normalization_29 (BatchNo (None, None, None, 9 288 conv2d_29[0][0] 196__________________________________________________________________________________________________ 197activation_29 (Activation) (None, None, None, 9 0 batch_normalization_29[0][0] 198__________________________________________________________________________________________________ 199conv2d_27 (Conv2D) (None, None, None, 3 995328 mixed2[0][0] 200__________________________________________________________________________________________________ 201conv2d_30 (Conv2D) (None, None, None, 9 82944 activation_29[0][0] 202__________________________________________________________________________________________________ 203batch_normalization_27 (BatchNo (None, None, None, 3 1152 conv2d_27[0][0] 204__________________________________________________________________________________________________ 205batch_normalization_30 (BatchNo (None, None, None, 9 288 conv2d_30[0][0] 206__________________________________________________________________________________________________ 207activation_27 (Activation) (None, None, None, 3 0 batch_normalization_27[0][0] 208__________________________________________________________________________________________________ 209activation_30 (Activation) (None, None, None, 9 0 batch_normalization_30[0][0] 210__________________________________________________________________________________________________ 211max_pooling2d_3 (MaxPooling2D) (None, None, None, 2 0 mixed2[0][0] 212__________________________________________________________________________________________________ 213mixed3 (Concatenate) (None, None, None, 7 0 activation_27[0][0] 214activation_30[0][0] 215max_pooling2d_3[0][0] 216__________________________________________________________________________________________________ 217conv2d_35 (Conv2D) (None, None, None, 1 98304 mixed3[0][0] 218__________________________________________________________________________________________________ 219batch_normalization_35 (BatchNo (None, None, None, 1 384 conv2d_35[0][0] 220__________________________________________________________________________________________________ 221activation_35 (Activation) (None, None, None, 1 0 batch_normalization_35[0][0] 222__________________________________________________________________________________________________ 223conv2d_36 (Conv2D) (None, None, None, 1 114688 activation_35[0][0] 224__________________________________________________________________________________________________ 225batch_normalization_36 (BatchNo (None, None, None, 1 384 conv2d_36[0][0] 226__________________________________________________________________________________________________ 227activation_36 (Activation) (None, None, None, 1 0 batch_normalization_36[0][0] 228__________________________________________________________________________________________________ 229conv2d_32 (Conv2D) (None, None, None, 1 98304 mixed3[0][0] 230__________________________________________________________________________________________________ 231conv2d_37 (Conv2D) (None, None, None, 1 114688 activation_36[0][0] 232__________________________________________________________________________________________________ 233batch_normalization_32 (BatchNo (None, None, None, 1 384 conv2d_32[0][0] 234__________________________________________________________________________________________________ 235batch_normalization_37 (BatchNo (None, None, None, 1 384 conv2d_37[0][0] 236__________________________________________________________________________________________________ 237activation_32 (Activation) (None, None, None, 1 0 batch_normalization_32[0][0] 238__________________________________________________________________________________________________ 239activation_37 (Activation) (None, None, None, 1 0 batch_normalization_37[0][0] 240__________________________________________________________________________________________________ 241conv2d_33 (Conv2D) (None, None, None, 1 114688 activation_32[0][0] 242__________________________________________________________________________________________________ 243conv2d_38 (Conv2D) (None, None, None, 1 114688 activation_37[0][0] 244__________________________________________________________________________________________________ 245batch_normalization_33 (BatchNo (None, None, None, 1 384 conv2d_33[0][0] 246__________________________________________________________________________________________________ 247batch_normalization_38 (BatchNo (None, None, None, 1 384 conv2d_38[0][0] 248__________________________________________________________________________________________________ 249activation_33 (Activation) (None, None, None, 1 0 batch_normalization_33[0][0] 250__________________________________________________________________________________________________ 251activation_38 (Activation) (None, None, None, 1 0 batch_normalization_38[0][0] 252__________________________________________________________________________________________________ 253average_pooling2d_4 (AveragePoo (None, None, None, 7 0 mixed3[0][0] 254__________________________________________________________________________________________________ 255conv2d_31 (Conv2D) (None, None, None, 1 147456 mixed3[0][0] 256__________________________________________________________________________________________________ 257conv2d_34 (Conv2D) (None, None, None, 1 172032 activation_33[0][0] 258__________________________________________________________________________________________________ 259conv2d_39 (Conv2D) (None, None, None, 1 172032 activation_38[0][0] 260__________________________________________________________________________________________________ 261conv2d_40 (Conv2D) (None, None, None, 1 147456 average_pooling2d_4[0][0] 262__________________________________________________________________________________________________ 263batch_normalization_31 (BatchNo (None, None, None, 1 576 conv2d_31[0][0] 264__________________________________________________________________________________________________ 265batch_normalization_34 (BatchNo (None, None, None, 1 576 conv2d_34[0][0] 266__________________________________________________________________________________________________ 267batch_normalization_39 (BatchNo (None, None, None, 1 576 conv2d_39[0][0] 268__________________________________________________________________________________________________ 269batch_normalization_40 (BatchNo (None, None, None, 1 576 conv2d_40[0][0] 270__________________________________________________________________________________________________ 271activation_31 (Activation) (None, None, None, 1 0 batch_normalization_31[0][0] 272__________________________________________________________________________________________________ 273activation_34 (Activation) (None, None, None, 1 0 batch_normalization_34[0][0] 274__________________________________________________________________________________________________ 275activation_39 (Activation) (None, None, None, 1 0 batch_normalization_39[0][0] 276__________________________________________________________________________________________________ 277activation_40 (Activation) (None, None, None, 1 0 batch_normalization_40[0][0] 278__________________________________________________________________________________________________ 279mixed4 (Concatenate) (None, None, None, 7 0 activation_31[0][0] 280activation_34[0][0] 281activation_39[0][0] 282activation_40[0][0] 283__________________________________________________________________________________________________ 284conv2d_45 (Conv2D) (None, None, None, 1 122880 mixed4[0][0] 285__________________________________________________________________________________________________ 286batch_normalization_45 (BatchNo (None, None, None, 1 480 conv2d_45[0][0] 287__________________________________________________________________________________________________ 288activation_45 (Activation) (None, None, None, 1 0 batch_normalization_45[0][0] 289__________________________________________________________________________________________________ 290conv2d_46 (Conv2D) (None, None, None, 1 179200 activation_45[0][0] 291__________________________________________________________________________________________________ 292batch_normalization_46 (BatchNo (None, None, None, 1 480 conv2d_46[0][0] 293__________________________________________________________________________________________________ 294activation_46 (Activation) (None, None, None, 1 0 batch_normalization_46[0][0] 295__________________________________________________________________________________________________ 296conv2d_42 (Conv2D) (None, None, None, 1 122880 mixed4[0][0] 297__________________________________________________________________________________________________ 298conv2d_47 (Conv2D) (None, None, None, 1 179200 activation_46[0][0] 299__________________________________________________________________________________________________ 300batch_normalization_42 (BatchNo (None, None, None, 1 480 conv2d_42[0][0] 301__________________________________________________________________________________________________ 302batch_normalization_47 (BatchNo (None, None, None, 1 480 conv2d_47[0][0] 303__________________________________________________________________________________________________ 304activation_42 (Activation) (None, None, None, 1 0 batch_normalization_42[0][0] 305__________________________________________________________________________________________________ 306activation_47 (Activation) (None, None, None, 1 0 batch_normalization_47[0][0] 307__________________________________________________________________________________________________ 308conv2d_43 (Conv2D) (None, None, None, 1 179200 activation_42[0][0] 309__________________________________________________________________________________________________ 310conv2d_48 (Conv2D) (None, None, None, 1 179200 activation_47[0][0] 311__________________________________________________________________________________________________ 312batch_normalization_43 (BatchNo (None, None, None, 1 480 conv2d_43[0][0] 313__________________________________________________________________________________________________ 314batch_normalization_48 (BatchNo (None, None, None, 1 480 conv2d_48[0][0] 315__________________________________________________________________________________________________ 316activation_43 (Activation) (None, None, None, 1 0 batch_normalization_43[0][0] 317__________________________________________________________________________________________________ 318activation_48 (Activation) (None, None, None, 1 0 batch_normalization_48[0][0] 319__________________________________________________________________________________________________ 320average_pooling2d_5 (AveragePoo (None, None, None, 7 0 mixed4[0][0] 321__________________________________________________________________________________________________ 322conv2d_41 (Conv2D) (None, None, None, 1 147456 mixed4[0][0] 323__________________________________________________________________________________________________ 324conv2d_44 (Conv2D) (None, None, None, 1 215040 activation_43[0][0] 325__________________________________________________________________________________________________ 326conv2d_49 (Conv2D) (None, None, None, 1 215040 activation_48[0][0] 327__________________________________________________________________________________________________ 328conv2d_50 (Conv2D) (None, None, None, 1 147456 average_pooling2d_5[0][0] 329__________________________________________________________________________________________________ 330batch_normalization_41 (BatchNo (None, None, None, 1 576 conv2d_41[0][0] 331__________________________________________________________________________________________________ 332batch_normalization_44 (BatchNo (None, None, None, 1 576 conv2d_44[0][0] 333__________________________________________________________________________________________________ 334batch_normalization_49 (BatchNo (None, None, None, 1 576 conv2d_49[0][0] 335__________________________________________________________________________________________________ 336batch_normalization_50 (BatchNo (None, None, None, 1 576 conv2d_50[0][0] 337__________________________________________________________________________________________________ 338activation_41 (Activation) (None, None, None, 1 0 batch_normalization_41[0][0] 339__________________________________________________________________________________________________ 340activation_44 (Activation) (None, None, None, 1 0 batch_normalization_44[0][0] 341__________________________________________________________________________________________________ 342activation_49 (Activation) (None, None, None, 1 0 batch_normalization_49[0][0] 343__________________________________________________________________________________________________ 344activation_50 (Activation) (None, None, None, 1 0 batch_normalization_50[0][0] 345__________________________________________________________________________________________________ 346mixed5 (Concatenate) (None, None, None, 7 0 activation_41[0][0] 347activation_44[0][0] 348activation_49[0][0] 349activation_50[0][0] 350__________________________________________________________________________________________________ 351conv2d_55 (Conv2D) (None, None, None, 1 122880 mixed5[0][0] 352__________________________________________________________________________________________________ 353batch_normalization_55 (BatchNo (None, None, None, 1 480 conv2d_55[0][0] 354__________________________________________________________________________________________________ 355activation_55 (Activation) (None, None, None, 1 0 batch_normalization_55[0][0] 356__________________________________________________________________________________________________ 357conv2d_56 (Conv2D) (None, None, None, 1 179200 activation_55[0][0] 358__________________________________________________________________________________________________ 359batch_normalization_56 (BatchNo (None, None, None, 1 480 conv2d_56[0][0] 360__________________________________________________________________________________________________ 361activation_56 (Activation) (None, None, None, 1 0 batch_normalization_56[0][0] 362__________________________________________________________________________________________________ 363conv2d_52 (Conv2D) (None, None, None, 1 122880 mixed5[0][0] 364__________________________________________________________________________________________________ 365conv2d_57 (Conv2D) (None, None, None, 1 179200 activation_56[0][0] 366__________________________________________________________________________________________________ 367batch_normalization_52 (BatchNo (None, None, None, 1 480 conv2d_52[0][0] 368__________________________________________________________________________________________________ 369batch_normalization_57 (BatchNo (None, None, None, 1 480 conv2d_57[0][0] 370__________________________________________________________________________________________________ 371activation_52 (Activation) (None, None, None, 1 0 batch_normalization_52[0][0] 372__________________________________________________________________________________________________ 373activation_57 (Activation) (None, None, None, 1 0 batch_normalization_57[0][0] 374__________________________________________________________________________________________________ 375conv2d_53 (Conv2D) (None, None, None, 1 179200 activation_52[0][0] 376__________________________________________________________________________________________________ 377conv2d_58 (Conv2D) (None, None, None, 1 179200 activation_57[0][0] 378__________________________________________________________________________________________________ 379batch_normalization_53 (BatchNo (None, None, None, 1 480 conv2d_53[0][0] 380__________________________________________________________________________________________________ 381batch_normalization_58 (BatchNo (None, None, None, 1 480 conv2d_58[0][0] 382__________________________________________________________________________________________________ 383activation_53 (Activation) (None, None, None, 1 0 batch_normalization_53[0][0] 384__________________________________________________________________________________________________ 385activation_58 (Activation) (None, None, None, 1 0 batch_normalization_58[0][0] 386__________________________________________________________________________________________________ 387average_pooling2d_6 (AveragePoo (None, None, None, 7 0 mixed5[0][0] 388__________________________________________________________________________________________________ 389conv2d_51 (Conv2D) (None, None, None, 1 147456 mixed5[0][0] 390__________________________________________________________________________________________________ 391conv2d_54 (Conv2D) (None, None, None, 1 215040 activation_53[0][0] 392__________________________________________________________________________________________________ 393conv2d_59 (Conv2D) (None, None, None, 1 215040 activation_58[0][0] 394__________________________________________________________________________________________________ 395conv2d_60 (Conv2D) (None, None, None, 1 147456 average_pooling2d_6[0][0] 396__________________________________________________________________________________________________ 397batch_normalization_51 (BatchNo (None, None, None, 1 576 conv2d_51[0][0] 398__________________________________________________________________________________________________ 399batch_normalization_54 (BatchNo (None, None, None, 1 576 conv2d_54[0][0] 400__________________________________________________________________________________________________ 401batch_normalization_59 (BatchNo (None, None, None, 1 576 conv2d_59[0][0] 402__________________________________________________________________________________________________ 403batch_normalization_60 (BatchNo (None, None, None, 1 576 conv2d_60[0][0] 404__________________________________________________________________________________________________ 405activation_51 (Activation) (None, None, None, 1 0 batch_normalization_51[0][0] 406__________________________________________________________________________________________________ 407activation_54 (Activation) (None, None, None, 1 0 batch_normalization_54[0][0] 408__________________________________________________________________________________________________ 409activation_59 (Activation) (None, None, None, 1 0 batch_normalization_59[0][0] 410__________________________________________________________________________________________________ 411activation_60 (Activation) (None, None, None, 1 0 batch_normalization_60[0][0] 412__________________________________________________________________________________________________ 413mixed6 (Concatenate) (None, None, None, 7 0 activation_51[0][0] 414activation_54[0][0] 415activation_59[0][0] 416activation_60[0][0] 417__________________________________________________________________________________________________ 418conv2d_65 (Conv2D) (None, None, None, 1 147456 mixed6[0][0] 419__________________________________________________________________________________________________ 420batch_normalization_65 (BatchNo (None, None, None, 1 576 conv2d_65[0][0] 421__________________________________________________________________________________________________ 422activation_65 (Activation) (None, None, None, 1 0 batch_normalization_65[0][0] 423__________________________________________________________________________________________________ 424conv2d_66 (Conv2D) (None, None, None, 1 258048 activation_65[0][0] 425__________________________________________________________________________________________________ 426batch_normalization_66 (BatchNo (None, None, None, 1 576 conv2d_66[0][0] 427__________________________________________________________________________________________________ 428activation_66 (Activation) (None, None, None, 1 0 batch_normalization_66[0][0] 429__________________________________________________________________________________________________ 430conv2d_62 (Conv2D) (None, None, None, 1 147456 mixed6[0][0] 431__________________________________________________________________________________________________ 432conv2d_67 (Conv2D) (None, None, None, 1 258048 activation_66[0][0] 433__________________________________________________________________________________________________ 434batch_normalization_62 (BatchNo (None, None, None, 1 576 conv2d_62[0][0] 435__________________________________________________________________________________________________ 436batch_normalization_67 (BatchNo (None, None, None, 1 576 conv2d_67[0][0] 437__________________________________________________________________________________________________ 438activation_62 (Activation) (None, None, None, 1 0 batch_normalization_62[0][0] 439__________________________________________________________________________________________________ 440activation_67 (Activation) (None, None, None, 1 0 batch_normalization_67[0][0] 441__________________________________________________________________________________________________ 442conv2d_63 (Conv2D) (None, None, None, 1 258048 activation_62[0][0] 443__________________________________________________________________________________________________ 444conv2d_68 (Conv2D) (None, None, None, 1 258048 activation_67[0][0] 445__________________________________________________________________________________________________ 446batch_normalization_63 (BatchNo (None, None, None, 1 576 conv2d_63[0][0] 447__________________________________________________________________________________________________ 448batch_normalization_68 (BatchNo (None, None, None, 1 576 conv2d_68[0][0] 449__________________________________________________________________________________________________ 450activation_63 (Activation) (None, None, None, 1 0 batch_normalization_63[0][0] 451__________________________________________________________________________________________________ 452activation_68 (Activation) (None, None, None, 1 0 batch_normalization_68[0][0] 453__________________________________________________________________________________________________ 454average_pooling2d_7 (AveragePoo (None, None, None, 7 0 mixed6[0][0] 455__________________________________________________________________________________________________ 456conv2d_61 (Conv2D) (None, None, None, 1 147456 mixed6[0][0] 457__________________________________________________________________________________________________ 458conv2d_64 (Conv2D) (None, None, None, 1 258048 activation_63[0][0] 459__________________________________________________________________________________________________ 460conv2d_69 (Conv2D) (None, None, None, 1 258048 activation_68[0][0] 461__________________________________________________________________________________________________ 462conv2d_70 (Conv2D) (None, None, None, 1 147456 average_pooling2d_7[0][0] 463__________________________________________________________________________________________________ 464batch_normalization_61 (BatchNo (None, None, None, 1 576 conv2d_61[0][0] 465__________________________________________________________________________________________________ 466batch_normalization_64 (BatchNo (None, None, None, 1 576 conv2d_64[0][0] 467__________________________________________________________________________________________________ 468batch_normalization_69 (BatchNo (None, None, None, 1 576 conv2d_69[0][0] 469__________________________________________________________________________________________________ 470batch_normalization_70 (BatchNo (None, None, None, 1 576 conv2d_70[0][0] 471__________________________________________________________________________________________________ 472activation_61 (Activation) (None, None, None, 1 0 batch_normalization_61[0][0] 473__________________________________________________________________________________________________ 474activation_64 (Activation) (None, None, None, 1 0 batch_normalization_64[0][0] 475__________________________________________________________________________________________________ 476activation_69 (Activation) (None, None, None, 1 0 batch_normalization_69[0][0] 477__________________________________________________________________________________________________ 478activation_70 (Activation) (None, None, None, 1 0 batch_normalization_70[0][0] 479__________________________________________________________________________________________________ 480mixed7 (Concatenate) (None, None, None, 7 0 activation_61[0][0] 481activation_64[0][0] 482activation_69[0][0] 483activation_70[0][0] 484__________________________________________________________________________________________________ 485conv2d_73 (Conv2D) (None, None, None, 1 147456 mixed7[0][0] 486__________________________________________________________________________________________________ 487batch_normalization_73 (BatchNo (None, None, None, 1 576 conv2d_73[0][0] 488__________________________________________________________________________________________________ 489activation_73 (Activation) (None, None, None, 1 0 batch_normalization_73[0][0] 490__________________________________________________________________________________________________ 491conv2d_74 (Conv2D) (None, None, None, 1 258048 activation_73[0][0] 492__________________________________________________________________________________________________ 493batch_normalization_74 (BatchNo (None, None, None, 1 576 conv2d_74[0][0] 494__________________________________________________________________________________________________ 495activation_74 (Activation) (None, None, None, 1 0 batch_normalization_74[0][0] 496__________________________________________________________________________________________________ 497conv2d_71 (Conv2D) (None, None, None, 1 147456 mixed7[0][0] 498__________________________________________________________________________________________________ 499conv2d_75 (Conv2D) (None, None, None, 1 258048 activation_74[0][0] 500__________________________________________________________________________________________________ 501batch_normalization_71 (BatchNo (None, None, None, 1 576 conv2d_71[0][0] 502__________________________________________________________________________________________________ 503batch_normalization_75 (BatchNo (None, None, None, 1 576 conv2d_75[0][0] 504__________________________________________________________________________________________________ 505activation_71 (Activation) (None, None, None, 1 0 batch_normalization_71[0][0] 506__________________________________________________________________________________________________ 507activation_75 (Activation) (None, None, None, 1 0 batch_normalization_75[0][0] 508__________________________________________________________________________________________________ 509conv2d_72 (Conv2D) (None, None, None, 3 552960 activation_71[0][0] 510__________________________________________________________________________________________________ 511conv2d_76 (Conv2D) (None, None, None, 1 331776 activation_75[0][0] 512__________________________________________________________________________________________________ 513batch_normalization_72 (BatchNo (None, None, None, 3 960 conv2d_72[0][0] 514__________________________________________________________________________________________________ 515batch_normalization_76 (BatchNo (None, None, None, 1 576 conv2d_76[0][0] 516__________________________________________________________________________________________________ 517activation_72 (Activation) (None, None, None, 3 0 batch_normalization_72[0][0] 518__________________________________________________________________________________________________ 519activation_76 (Activation) (None, None, None, 1 0 batch_normalization_76[0][0] 520__________________________________________________________________________________________________ 521max_pooling2d_4 (MaxPooling2D) (None, None, None, 7 0 mixed7[0][0] 522__________________________________________________________________________________________________ 523mixed8 (Concatenate) (None, None, None, 1 0 activation_72[0][0] 524activation_76[0][0] 525max_pooling2d_4[0][0] 526__________________________________________________________________________________________________ 527conv2d_81 (Conv2D) (None, None, None, 4 573440 mixed8[0][0] 528__________________________________________________________________________________________________ 529batch_normalization_81 (BatchNo (None, None, None, 4 1344 conv2d_81[0][0] 530__________________________________________________________________________________________________ 531activation_81 (Activation) (None, None, None, 4 0 batch_normalization_81[0][0] 532__________________________________________________________________________________________________ 533conv2d_78 (Conv2D) (None, None, None, 3 491520 mixed8[0][0] 534__________________________________________________________________________________________________ 535conv2d_82 (Conv2D) (None, None, None, 3 1548288 activation_81[0][0] 536__________________________________________________________________________________________________ 537batch_normalization_78 (BatchNo (None, None, None, 3 1152 conv2d_78[0][0] 538__________________________________________________________________________________________________ 539batch_normalization_82 (BatchNo (None, None, None, 3 1152 conv2d_82[0][0] 540__________________________________________________________________________________________________ 541activation_78 (Activation) (None, None, None, 3 0 batch_normalization_78[0][0] 542__________________________________________________________________________________________________ 543activation_82 (Activation) (None, None, None, 3 0 batch_normalization_82[0][0] 544__________________________________________________________________________________________________ 545conv2d_79 (Conv2D) (None, None, None, 3 442368 activation_78[0][0] 546__________________________________________________________________________________________________ 547conv2d_80 (Conv2D) (None, None, None, 3 442368 activation_78[0][0] 548__________________________________________________________________________________________________ 549conv2d_83 (Conv2D) (None, None, None, 3 442368 activation_82[0][0] 550__________________________________________________________________________________________________ 551conv2d_84 (Conv2D) (None, None, None, 3 442368 activation_82[0][0] 552__________________________________________________________________________________________________ 553average_pooling2d_8 (AveragePoo (None, None, None, 1 0 mixed8[0][0] 554__________________________________________________________________________________________________ 555conv2d_77 (Conv2D) (None, None, None, 3 409600 mixed8[0][0] 556__________________________________________________________________________________________________ 557batch_normalization_79 (BatchNo (None, None, None, 3 1152 conv2d_79[0][0] 558__________________________________________________________________________________________________ 559batch_normalization_80 (BatchNo (None, None, None, 3 1152 conv2d_80[0][0] 560__________________________________________________________________________________________________ 561batch_normalization_83 (BatchNo (None, None, None, 3 1152 conv2d_83[0][0] 562__________________________________________________________________________________________________ 563batch_normalization_84 (BatchNo (None, None, None, 3 1152 conv2d_84[0][0] 564__________________________________________________________________________________________________ 565conv2d_85 (Conv2D) (None, None, None, 1 245760 average_pooling2d_8[0][0] 566__________________________________________________________________________________________________ 567batch_normalization_77 (BatchNo (None, None, None, 3 960 conv2d_77[0][0] 568__________________________________________________________________________________________________ 569activation_79 (Activation) (None, None, None, 3 0 batch_normalization_79[0][0] 570__________________________________________________________________________________________________ 571activation_80 (Activation) (None, None, None, 3 0 batch_normalization_80[0][0] 572__________________________________________________________________________________________________ 573activation_83 (Activation) (None, None, None, 3 0 batch_normalization_83[0][0] 574__________________________________________________________________________________________________ 575activation_84 (Activation) (None, None, None, 3 0 batch_normalization_84[0][0] 576__________________________________________________________________________________________________ 577batch_normalization_85 (BatchNo (None, None, None, 1 576 conv2d_85[0][0] 578__________________________________________________________________________________________________ 579activation_77 (Activation) (None, None, None, 3 0 batch_normalization_77[0][0] 580__________________________________________________________________________________________________ 581mixed9_0 (Concatenate) (None, None, None, 7 0 activation_79[0][0] 582activation_80[0][0] 583__________________________________________________________________________________________________ 584concatenate_1 (Concatenate) (None, None, None, 7 0 activation_83[0][0] 585activation_84[0][0] 586__________________________________________________________________________________________________ 587activation_85 (Activation) (None, None, None, 1 0 batch_normalization_85[0][0] 588__________________________________________________________________________________________________ 589mixed9 (Concatenate) (None, None, None, 2 0 activation_77[0][0] 590mixed9_0[0][0] 591concatenate_1[0][0] 592activation_85[0][0] 593__________________________________________________________________________________________________ 594conv2d_90 (Conv2D) (None, None, None, 4 917504 mixed9[0][0] 595__________________________________________________________________________________________________ 596batch_normalization_90 (BatchNo (None, None, None, 4 1344 conv2d_90[0][0] 597__________________________________________________________________________________________________ 598activation_90 (Activation) (None, None, None, 4 0 batch_normalization_90[0][0] 599__________________________________________________________________________________________________ 600conv2d_87 (Conv2D) (None, None, None, 3 786432 mixed9[0][0] 601__________________________________________________________________________________________________ 602conv2d_91 (Conv2D) (None, None, None, 3 1548288 activation_90[0][0] 603__________________________________________________________________________________________________ 604batch_normalization_87 (BatchNo (None, None, None, 3 1152 conv2d_87[0][0] 605__________________________________________________________________________________________________ 606batch_normalization_91 (BatchNo (None, None, None, 3 1152 conv2d_91[0][0] 607__________________________________________________________________________________________________ 608activation_87 (Activation) (None, None, None, 3 0 batch_normalization_87[0][0] 609__________________________________________________________________________________________________ 610activation_91 (Activation) (None, None, None, 3 0 batch_normalization_91[0][0] 611__________________________________________________________________________________________________ 612conv2d_88 (Conv2D) (None, None, None, 3 442368 activation_87[0][0] 613__________________________________________________________________________________________________ 614conv2d_89 (Conv2D) (None, None, None, 3 442368 activation_87[0][0] 615__________________________________________________________________________________________________ 616conv2d_92 (Conv2D) (None, None, None, 3 442368 activation_91[0][0] 617__________________________________________________________________________________________________ 618conv2d_93 (Conv2D) (None, None, None, 3 442368 activation_91[0][0] 619__________________________________________________________________________________________________ 620average_pooling2d_9 (AveragePoo (None, None, None, 2 0 mixed9[0][0] 621__________________________________________________________________________________________________ 622conv2d_86 (Conv2D) (None, None, None, 3 655360 mixed9[0][0] 623__________________________________________________________________________________________________ 624batch_normalization_88 (BatchNo (None, None, None, 3 1152 conv2d_88[0][0] 625__________________________________________________________________________________________________ 626batch_normalization_89 (BatchNo (None, None, None, 3 1152 conv2d_89[0][0] 627__________________________________________________________________________________________________ 628batch_normalization_92 (BatchNo (None, None, None, 3 1152 conv2d_92[0][0] 629__________________________________________________________________________________________________ 630batch_normalization_93 (BatchNo (None, None, None, 3 1152 conv2d_93[0][0] 631__________________________________________________________________________________________________ 632conv2d_94 (Conv2D) (None, None, None, 1 393216 average_pooling2d_9[0][0] 633__________________________________________________________________________________________________ 634batch_normalization_86 (BatchNo (None, None, None, 3 960 conv2d_86[0][0] 635__________________________________________________________________________________________________ 636activation_88 (Activation) (None, None, None, 3 0 batch_normalization_88[0][0] 637__________________________________________________________________________________________________ 638activation_89 (Activation) (None, None, None, 3 0 batch_normalization_89[0][0] 639__________________________________________________________________________________________________ 640activation_92 (Activation) (None, None, None, 3 0 batch_normalization_92[0][0] 641__________________________________________________________________________________________________ 642activation_93 (Activation) (None, None, None, 3 0 batch_normalization_93[0][0] 643__________________________________________________________________________________________________ 644batch_normalization_94 (BatchNo (None, None, None, 1 576 conv2d_94[0][0] 645__________________________________________________________________________________________________ 646activation_86 (Activation) (None, None, None, 3 0 batch_normalization_86[0][0] 647__________________________________________________________________________________________________ 648mixed9_1 (Concatenate) (None, None, None, 7 0 activation_88[0][0] 649activation_89[0][0] 650__________________________________________________________________________________________________ 651concatenate_2 (Concatenate) (None, None, None, 7 0 activation_92[0][0] 652activation_93[0][0] 653__________________________________________________________________________________________________ 654activation_94 (Activation) (None, None, None, 1 0 batch_normalization_94[0][0] 655__________________________________________________________________________________________________ 656mixed10 (Concatenate) (None, None, None, 2 0 activation_86[0][0] 657mixed9_1[0][0] 658concatenate_2[0][0] 659activation_94[0][0] 660__________________________________________________________________________________________________ 661global_average_pooling2d_1 (Glo (None, 2048) 0 mixed10[0][0] 662__________________________________________________________________________________________________ 663dense_1 (Dense) (None, 1024) 2098176 global_average_pooling2d_1[0][0] 664__________________________________________________________________________________________________ 665dense_2 (Dense) (None, 2) 2050 dense_1[0][0] 666================================================================================================== 667Total params: 23,903,010 668Trainable params: 2,100,226 669Non-trainable params: 21,802,784 670__________________________________________________________________________________________________ Phần train lại sẽ có khoảng hơn 2 triệu tham số, phần layter ở trước đó không train là khoảng 21 triệu tham số.\nĐồ hình của model (các bạn có thể download về rồi zoom bự lên để xem rõ hơn).\nChia tập dữ liệu ra thành 5 phần, 4 phần làm tập train, 1 phần làm tập validation.\n1X, y, tags = dataset.dataset(data_directory, n) 2nb_classes = len(tags) 345sample_count = len(y) 6train_size = sample_count * 4 // 5 7X_train = X[:train_size] 8y_train = y[:train_size] 9Y_train = np_utils.to_categorical(y_train, nb_classes) 10X_test = X[train_size:] 11y_test = y[train_size:] 12Y_test = np_utils.to_categorical(y_test, nb_classes) Để chống overfit, chúng ta sẽ thêm một số yếu tố như thực hiện các phép biến đổi affine trên ảnh gốc.\n1datagen = ImageDataGenerator( 2featurewise_center=False, 3samplewise_center=False, 4featurewise_std_normalization=False, 5samplewise_std_normalization=False, 6zca_whitening=False, 7rotation_range=45, 8width_shift_range=0.25, 9height_shift_range=0.25, 10horizontal_flip=True, 11vertical_flip=False, 12zoom_range=0.5, 13channel_shift_range=0.5, 14fill_mode=\u0026#39;nearest\u0026#39;) 1516datagen.fit(X_train) Cuối cùng, chúng ta sẽ xây dựng mô hình và tiến hành huấn luyện, lưu mô hình. Quá trình này tốn hơi nhiều thời gian.\n12model = net.build_model(nb_classes) 3model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;, metrics=[\u0026#34;accuracy\u0026#34;]) 45# train the model on the new data for a few epochs 67print(\u0026#34;training the newly added dense layers\u0026#34;) 89samples_per_epoch = X_train.shape[0]//batch_size*batch_size 10steps_per_epoch = samples_per_epoch//batch_size 11validation_steps = X_test.shape[0]//batch_size*batch_size 1213model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True), 14samples_per_epoch=samples_per_epoch, 15epochs=nb_epoch, 16steps_per_epoch = steps_per_epoch, 17validation_data=datagen.flow(X_test, Y_test, batch_size=batch_size), 18validation_steps=validation_steps, 19) 202122net.save(model, tags, model_file_prefix) Độ chính xác trên tập train.\n1Y_pred = model.predict(X_test, batch_size=batch_size) 2y_pred = np.argmax(Y_pred, axis=1) 34accuracy = float(np.sum(y_test==y_pred)) / len(y_test) 5print(\u0026#34;accuracy: \u0026#34;, accuracy) 67confusion = np.zeros((nb_classes, nb_classes), dtype=np.int32) 8for (predicted_index, actual_index, image) in zip(y_pred, y_test, X_test): 9confusion[predicted_index, actual_index] += 1 1011print(\u0026#34;rows are predicted classes, columns are actual classes\u0026#34;) 12for predicted_index, predicted_tag in enumerate(tags): 13print(predicted_tag[:7], end=\u0026#39;\u0026#39;, flush=True) 14for actual_index, actual_tag in enumerate(tags): 15print(\u0026#34;\\t%d\u0026#34; % confusion[predicted_index, actual_index], end=\u0026#39;\u0026#39;) 16print(\u0026#34;\u0026#34;, flush=True) 1accuracy: 0.9907213167661771 2rows are predicted classes, columns are actual classes 3cat 12238 106 4dog 124 12320 Kết quả đạt 0.99 trên tập train, khá tốt phải không các bạn.\nCác bạn có thể download mô hình mình đã huấn luyện ở https://drive.google.com/open?id=1qQo8gj3KA6c1rPmJMVS_FZkVDcDmRgSf.\nThử show ra kết quả trên tập test xem như thế nào.\n1Y_pred = model.predict(X_test, batch_size=batch_size) 2y_pred = np.argmax(Y_pred, axis=1) 34lst_img = [] 56columns = 5 7rows = 5 8# fig,= plt.figure(rows) 9for idx, val in enumerate(X_test): 10pred =y_pred[idx] 11label = \u0026#34;{}: {:.2f}%\u0026#34;.format(tags[pred], Y_pred[idx][pred] * 100) 12image = dataset.reverse_preprocess_input(val) 13image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) 14cv2.putText(image,label , (10, 25), cv2.FONT_HERSHEY_SIMPLEX,0.7, (255, 000, 0), 2) 1516plt.subplot(rows,rows,idx+1) 17plt.imshow(image) 18plt.title(label) 19plt.axis(\u0026#39;off\u0026#39;) 2021plt.show() Kết quả có một số hình mèo bị nhận nhầm là chó, và một số hình không phải mèo, không phải chó. Nhìn chung kết quả cũng không đến nỗi nào quá tệ.\nQuậy phá mô hình Mô hình InceptionV3 chúng ta đang xài có tổng cộng 311 lớp, chúng ta sẽ tiến hành một số pha quậy phá mô hình xem kết quả như trả ra như thế nào\nQuậy phá 1: Mở đóng băng một số lớp cuối và train trên chúng. Nếu các bạn để ý kỹ, trong đoạn mã nguồn của mình có đoạn\n1# first: train only the top layers (which were randomly initialized) 2# i.e. freeze all convolutional InceptionV3 layers 3for layer in base_model.layers: 4layer.trainable = False Nghĩa là mình đóng băng toàn bộ 311 lớp, không cho nó train mà chỉ lấy kết quả của nó train lớp softmax cuối cùng. Bây giờ mình sẽ thử nghiệm với việc là để 299 lớp ban đầu vẫn đóng băng, và train lại toàn bộ các lớp còn lại (Các bạn đừng thắc mắc vì sao lại là 299 nha, do mình thích thôi).\n1for layer in model.layers[:299]: 2layer.trainable = False 3for layer in model.layers[299:]: 4layer.trainable = True Đồ hình của mô đồ khá giống ở trên, mình chỉ post lại kết quả của số param.\n1================================================================================================== 2Total params: 23,903,010 3Trainable params: 2,493,954 4Non-trainable params: 21,409,056 5__________________________________________________________________________________________________ Như vậy là có khoảng 2 triệu 5 tham số được huấn luyện lại\nModel của mình huấn luyện được các bạn có thể download ở https://drive.google.com/open?id=1Ts18LICUAh6gcOnXcmuVr7PUG5IxpCdt.\nKết quả đạt được:\n1accuracy: 0.9834610730133119 2rows are predicted classes, columns are actual classes 3cat 2429 69 4dog 13 2447 Kết quả 25 hình ngẫu nhiên cũng khá giống kết quả ở trước đó. Một số hình không có con vật bị nhận nhầm như hình còn mèo ở góc phải trên bị nhận nhầm là chó. Tuy nhiên, với chất lượng hình ảnh như thế này thì mình thấy kết quả như vậy là khá tuyệt vời.\nQuậy phá 2: Chỉ sử dụng 72 lớp đầu tiên của inception. Ở lần thí nghiệm này, mình sẽ chỉ sử dụng 72 lớp đầu tiên của inception để huấn luyện. Mình sẽ sửa lại một xíu ở hàm build model như sau:\n1x = base_model.layers[72].output Một lưu ý nhỏ là do inception không có tính tuần tự giữa các lớp (các bạn có thể nhìn hình ở trên sẽ thấy rõ), nên index sẽ không phải là 72 như thông thường.\nTiếp theo, chúng ta sẽ thực hiện việc huấn luyện lại mô hình và kết quả là:\n1accuracy: 0.5494150867285196 2rows are predicted classes, columns are actual classes 3cat 339 131 4dog 2103 2385 Kết quả khá tệ, lý do là mô hình các layer không theo sequence, mình lấy ngẫu nhiêu 72 lớp làm thông tin feature của các hình bị mất mát nhiều (ví dụ trường hợp layey 80 là tổng hợp thông tin của layter 79 + layter 4 + layer 48, mà mình chỉ lấy 72 layter đầu, nên sẽ mất đi phần đóng góp cực kỳ quan trọng của layter 4 và 48 ở lớp cao hơn).\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Oct 29, 2018","img":"","permalink":"/blog/2018-10-29-phan-loai-cho-meo/","series":null,"tags":["Machine learning","Deeplearning","dog cat"],"title":"Phân Loại Chó Mèo Sử Dụng Pretrain Model"},{"categories":null,"content":"Lời mở đầu Phân vùng đối tượng là một bài toán khá phổ biến trong lĩnh vực computer vision. Trong open cv có hỗ trợ cho chúng ta một số hàm để phân vùng đối tượng rất dễ sử dụng. Đặc điểm chung của các hàm này là độ chính xác không được cao cho lắm. Ở bài viết này, chúng ta sẽ tìm hiểu cách sử dụng mô hình pretrain của DNN để phân vùng các đối tượng trong ảnh.\nSử dụng pretrain model Đầu tiên, các bạn download file pretrain model, giải nén ra và để ở đâu đó trong ổ cứng của máy bạn. Đường dẫn file pretrain model các bạn có thể download ở http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz. Các bạn có thể download các file pretrain khác nếu có hứng thú tìm hiểu.\nTiếp theo, chúng ta sẽ load mô hình lên:\n1import numpy as np 2import os 3import sys 4import tarfile 5import tensorflow as tf 67from collections import defaultdict 8from io import StringIO 9from matplotlib import pyplot as plt 10from PIL import Image 11import PIL.ImageDraw as ImageDraw 12import PIL.ImageFont as ImageFont 13import cv2 1415import pprint 1617import PIL.Image as Image 18import PIL.ImageColor as ImageColor 1920# Model preparation 212223# Path to frozen detection graph. This is the actual model that is used for the object detection. 24PATH_TO_CKPT = \u0026#39;mask_rcnn_inception_v2_coco_2018_01_28\u0026#39; + \u0026#39;/frozen_inference_graph.pb\u0026#39; 2526# List of the strings that is used to add correct label for each box. 27#PATH_TO_LABELS = \u0026#39;mscoco_label_map.pbtxt\u0026#39; 2829NUM_CLASSES = 1 303132# categories 3334category_index = {1: {\u0026#39;id\u0026#39;: 1, \u0026#39;name\u0026#39;: \u0026#39;person\u0026#39;}, 35# 3: {\u0026#39;id\u0026#39;: 3, \u0026#39;name\u0026#39;: \u0026#39;car\u0026#39;}, 36} 3738detection_graph = tf.Graph() 39with detection_graph.as_default(): 40od_graph_def = tf.GraphDef() 41with tf.gfile.GFile(PATH_TO_CKPT, \u0026#39;rb\u0026#39;) as fid: 42serialized_graph = fid.read() 43od_graph_def.ParseFromString(serialized_graph) 44tf.import_graph_def(od_graph_def, name=\u0026#39;\u0026#39;) Ở đây, mình chỉ demo detect người trong hình, nên mình chỉ để category_index chỉ là \u0026ldquo;person\u0026rdquo;. Thực tế, mô hình COCO hỗ trợ cho chúng ta nhận dạng 90 loại đối tượng khác nhau, các bạn có nhu cầu tìm hiểu thì thay bằng đoạn mã sau:\n1category_index = {1: {\u0026#39;id\u0026#39;: 1, \u0026#39;name\u0026#39;: \u0026#39;person\u0026#39;}, 22: {\u0026#39;id\u0026#39;: 2, \u0026#39;name\u0026#39;: \u0026#39;bicycle\u0026#39;}, 33: {\u0026#39;id\u0026#39;: 3, \u0026#39;name\u0026#39;: \u0026#39;car\u0026#39;}, 44: {\u0026#39;id\u0026#39;: 4, \u0026#39;name\u0026#39;: \u0026#39;motorcycle\u0026#39;}, 55: {\u0026#39;id\u0026#39;: 5, \u0026#39;name\u0026#39;: \u0026#39;airplane\u0026#39;}, 66: {\u0026#39;id\u0026#39;: 6, \u0026#39;name\u0026#39;: \u0026#39;bus\u0026#39;}, 77: {\u0026#39;id\u0026#39;: 7, \u0026#39;name\u0026#39;: \u0026#39;train\u0026#39;}, 88: {\u0026#39;id\u0026#39;: 8, \u0026#39;name\u0026#39;: \u0026#39;truck\u0026#39;}, 99: {\u0026#39;id\u0026#39;: 9, \u0026#39;name\u0026#39;: \u0026#39;boat\u0026#39;}, 1010: {\u0026#39;id\u0026#39;: 10, \u0026#39;name\u0026#39;: \u0026#39;traffic light\u0026#39;}, 1111: {\u0026#39;id\u0026#39;: 11, \u0026#39;name\u0026#39;: \u0026#39;fire hydrant\u0026#39;}, 1213: {\u0026#39;id\u0026#39;: 13, \u0026#39;name\u0026#39;: \u0026#39;stop sign\u0026#39;}, 1314: {\u0026#39;id\u0026#39;: 14, \u0026#39;name\u0026#39;: \u0026#39;parking meter\u0026#39;}, 1415: {\u0026#39;id\u0026#39;: 15, \u0026#39;name\u0026#39;: \u0026#39;bench\u0026#39;}, 1516: {\u0026#39;id\u0026#39;: 16, \u0026#39;name\u0026#39;: \u0026#39;bird\u0026#39;}, 1617: {\u0026#39;id\u0026#39;: 17, \u0026#39;name\u0026#39;: \u0026#39;cat\u0026#39;}, 1718: {\u0026#39;id\u0026#39;: 18, \u0026#39;name\u0026#39;: \u0026#39;dog\u0026#39;}, 1819: {\u0026#39;id\u0026#39;: 19, \u0026#39;name\u0026#39;: \u0026#39;horse\u0026#39;}, 1920: {\u0026#39;id\u0026#39;: 20, \u0026#39;name\u0026#39;: \u0026#39;sheep\u0026#39;}, 2021: {\u0026#39;id\u0026#39;: 21, \u0026#39;name\u0026#39;: \u0026#39;cow\u0026#39;}, 2122: {\u0026#39;id\u0026#39;: 22, \u0026#39;name\u0026#39;: \u0026#39;elephant\u0026#39;}, 2223: {\u0026#39;id\u0026#39;: 23, \u0026#39;name\u0026#39;: \u0026#39;bear\u0026#39;}, 2324: {\u0026#39;id\u0026#39;: 24, \u0026#39;name\u0026#39;: \u0026#39;zebra\u0026#39;}, 2425: {\u0026#39;id\u0026#39;: 25, \u0026#39;name\u0026#39;: \u0026#39;giraffe\u0026#39;}, 2527: {\u0026#39;id\u0026#39;: 27, \u0026#39;name\u0026#39;: \u0026#39;backpack\u0026#39;}, 2628: {\u0026#39;id\u0026#39;: 28, \u0026#39;name\u0026#39;: \u0026#39;umbrella\u0026#39;}, 2731: {\u0026#39;id\u0026#39;: 31, \u0026#39;name\u0026#39;: \u0026#39;handbag\u0026#39;}, 2832: {\u0026#39;id\u0026#39;: 32, \u0026#39;name\u0026#39;: \u0026#39;tie\u0026#39;}, 2933: {\u0026#39;id\u0026#39;: 33, \u0026#39;name\u0026#39;: \u0026#39;suitcase\u0026#39;}, 3034: {\u0026#39;id\u0026#39;: 34, \u0026#39;name\u0026#39;: \u0026#39;frisbee\u0026#39;}, 3135: {\u0026#39;id\u0026#39;: 35, \u0026#39;name\u0026#39;: \u0026#39;skis\u0026#39;}, 3236: {\u0026#39;id\u0026#39;: 36, \u0026#39;name\u0026#39;: \u0026#39;snowboard\u0026#39;}, 3337: {\u0026#39;id\u0026#39;: 37, \u0026#39;name\u0026#39;: \u0026#39;sports ball\u0026#39;}, 3438: {\u0026#39;id\u0026#39;: 38, \u0026#39;name\u0026#39;: \u0026#39;kite\u0026#39;}, 3539: {\u0026#39;id\u0026#39;: 39, \u0026#39;name\u0026#39;: \u0026#39;baseball bat\u0026#39;}, 3640: {\u0026#39;id\u0026#39;: 40, \u0026#39;name\u0026#39;: \u0026#39;baseball glove\u0026#39;}, 3741: {\u0026#39;id\u0026#39;: 41, \u0026#39;name\u0026#39;: \u0026#39;skateboard\u0026#39;}, 3842: {\u0026#39;id\u0026#39;: 42, \u0026#39;name\u0026#39;: \u0026#39;surfboard\u0026#39;}, 3943: {\u0026#39;id\u0026#39;: 43, \u0026#39;name\u0026#39;: \u0026#39;tennis racket\u0026#39;}, 4044: {\u0026#39;id\u0026#39;: 44, \u0026#39;name\u0026#39;: \u0026#39;bottle\u0026#39;}, 4146: {\u0026#39;id\u0026#39;: 46, \u0026#39;name\u0026#39;: \u0026#39;wine glass\u0026#39;}, 4247: {\u0026#39;id\u0026#39;: 47, \u0026#39;name\u0026#39;: \u0026#39;cup\u0026#39;}, 4348: {\u0026#39;id\u0026#39;: 48, \u0026#39;name\u0026#39;: \u0026#39;fork\u0026#39;}, 4449: {\u0026#39;id\u0026#39;: 49, \u0026#39;name\u0026#39;: \u0026#39;knife\u0026#39;}, 4550: {\u0026#39;id\u0026#39;: 50, \u0026#39;name\u0026#39;: \u0026#39;spoon\u0026#39;}, 4651: {\u0026#39;id\u0026#39;: 51, \u0026#39;name\u0026#39;: \u0026#39;bowl\u0026#39;}, 4752: {\u0026#39;id\u0026#39;: 52, \u0026#39;name\u0026#39;: \u0026#39;banana\u0026#39;}, 4853: {\u0026#39;id\u0026#39;: 53, \u0026#39;name\u0026#39;: \u0026#39;apple\u0026#39;}, 4954: {\u0026#39;id\u0026#39;: 54, \u0026#39;name\u0026#39;: \u0026#39;sandwich\u0026#39;}, 5055: {\u0026#39;id\u0026#39;: 55, \u0026#39;name\u0026#39;: \u0026#39;orange\u0026#39;}, 5156: {\u0026#39;id\u0026#39;: 56, \u0026#39;name\u0026#39;: \u0026#39;broccoli\u0026#39;}, 5257: {\u0026#39;id\u0026#39;: 57, \u0026#39;name\u0026#39;: \u0026#39;carrot\u0026#39;}, 5358: {\u0026#39;id\u0026#39;: 58, \u0026#39;name\u0026#39;: \u0026#39;hot dog\u0026#39;}, 5459: {\u0026#39;id\u0026#39;: 59, \u0026#39;name\u0026#39;: \u0026#39;pizza\u0026#39;}, 5560: {\u0026#39;id\u0026#39;: 60, \u0026#39;name\u0026#39;: \u0026#39;donut\u0026#39;}, 5661: {\u0026#39;id\u0026#39;: 61, \u0026#39;name\u0026#39;: \u0026#39;cake\u0026#39;}, 5762: {\u0026#39;id\u0026#39;: 62, \u0026#39;name\u0026#39;: \u0026#39;chair\u0026#39;}, 5863: {\u0026#39;id\u0026#39;: 63, \u0026#39;name\u0026#39;: \u0026#39;couch\u0026#39;}, 5964: {\u0026#39;id\u0026#39;: 64, \u0026#39;name\u0026#39;: \u0026#39;potted plant\u0026#39;}, 6065: {\u0026#39;id\u0026#39;: 65, \u0026#39;name\u0026#39;: \u0026#39;bed\u0026#39;}, 6167: {\u0026#39;id\u0026#39;: 67, \u0026#39;name\u0026#39;: \u0026#39;dining table\u0026#39;}, 6270: {\u0026#39;id\u0026#39;: 70, \u0026#39;name\u0026#39;: \u0026#39;toilet\u0026#39;}, 6372: {\u0026#39;id\u0026#39;: 72, \u0026#39;name\u0026#39;: \u0026#39;tv\u0026#39;}, 6473: {\u0026#39;id\u0026#39;: 73, \u0026#39;name\u0026#39;: \u0026#39;laptop\u0026#39;}, 6574: {\u0026#39;id\u0026#39;: 74, \u0026#39;name\u0026#39;: \u0026#39;mouse\u0026#39;}, 6675: {\u0026#39;id\u0026#39;: 75, \u0026#39;name\u0026#39;: \u0026#39;remote\u0026#39;}, 6776: {\u0026#39;id\u0026#39;: 76, \u0026#39;name\u0026#39;: \u0026#39;keyboard\u0026#39;}, 6877: {\u0026#39;id\u0026#39;: 77, \u0026#39;name\u0026#39;: \u0026#39;cell phone\u0026#39;}, 6978: {\u0026#39;id\u0026#39;: 78, \u0026#39;name\u0026#39;: \u0026#39;microwave\u0026#39;}, 7079: {\u0026#39;id\u0026#39;: 79, \u0026#39;name\u0026#39;: \u0026#39;oven\u0026#39;}, 7180: {\u0026#39;id\u0026#39;: 80, \u0026#39;name\u0026#39;: \u0026#39;toaster\u0026#39;}, 7281: {\u0026#39;id\u0026#39;: 81, \u0026#39;name\u0026#39;: \u0026#39;sink\u0026#39;}, 7382: {\u0026#39;id\u0026#39;: 82, \u0026#39;name\u0026#39;: \u0026#39;refrigerator\u0026#39;}, 7484: {\u0026#39;id\u0026#39;: 84, \u0026#39;name\u0026#39;: \u0026#39;book\u0026#39;}, 7585: {\u0026#39;id\u0026#39;: 85, \u0026#39;name\u0026#39;: \u0026#39;clock\u0026#39;}, 7686: {\u0026#39;id\u0026#39;: 86, \u0026#39;name\u0026#39;: \u0026#39;vase\u0026#39;}, 7787: {\u0026#39;id\u0026#39;: 87, \u0026#39;name\u0026#39;: \u0026#39;scissors\u0026#39;}, 7888: {\u0026#39;id\u0026#39;: 88, \u0026#39;name\u0026#39;: \u0026#39;teddy bear\u0026#39;}, 7989: {\u0026#39;id\u0026#39;: 89, \u0026#39;name\u0026#39;: \u0026#39;hair drier\u0026#39;}, 8090: {\u0026#39;id\u0026#39;: 90, \u0026#39;name\u0026#39;: \u0026#39;toothbrush\u0026#39;}} Tiếp theo, chúng ta sẽ load một số hàm giúp hỗ trợ việc hậu xử lý ảnh để vẽ các mask cho chúng ta xem trực quan hơn.\n12draw = ImageDraw.Draw(image) 3im_width, im_height = image.size 4if use_normalized_coordinates: 5(left, right, top, bottom) = (xmin * im_width, xmax * im_width, 6ymin * im_height, ymax * im_height) 7else: 8(left, right, top, bottom) = (xmin, xmax, ymin, ymax) 9draw.line([(left, top), (left, bottom), (right, bottom), 10(right, top), (left, top)], width=thickness, fill=color) 11try: 12font = ImageFont.truetype(\u0026#39;arial.ttf\u0026#39;, 24) 13except IOError: 14font = ImageFont.load_default() 1516# If the total height of the display strings added to the top of the bounding 17# box exceeds the top of the image, stack the strings below the bounding box 18# instead of above. 19display_str_heights = [font.getsize(ds)[1] for ds in display_str_list] 20# Each display_str has a top and bottom margin of 0.05x. 21total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights) 2223if top \u0026gt; total_display_str_height: 24text_bottom = top 25else: 26text_bottom = bottom + total_display_str_height 27# Reverse list and print from bottom to top. 28for display_str in display_str_list[::-1]: 29text_width, text_height = font.getsize(display_str) 30margin = np.ceil(0.05 * text_height) 31draw.rectangle( 32[(left, text_bottom - text_height - 2 * margin), (left + text_width, 33text_bottom)], 34fill=color) 35draw.text( 36(left + margin, text_bottom - text_height - margin), 37display_str, 38fill=\u0026#39;black\u0026#39;, 39font=font) 40text_bottom -= text_height - 2 * margin 41424344def visualize_boxes_and_labels_on_image_array( 45image, 46boxes, 47classes, 48scores, 49category_index, 50instance_masks=None, 51instance_boundaries=None, 52keypoints=None, 53use_normalized_coordinates=False, 54max_boxes_to_draw=20, 55min_score_thresh=.5, 56agnostic_mode=False, 57line_thickness=4, 58groundtruth_box_visualization_color=\u0026#39;black\u0026#39;, 59skip_scores=False, 60skip_labels=False): 6162box_to_display_str_map = collections.defaultdict(list) 63box_to_color_map = collections.defaultdict(str) 64box_to_instance_masks_map = {} 65box_to_instance_boundaries_map = {} 66box_to_keypoints_map = collections.defaultdict(list) 67if not max_boxes_to_draw: 68max_boxes_to_draw = boxes.shape[0] 69#print(boxes) 70for i in range(min(max_boxes_to_draw, boxes.shape[0])): 71if scores is None or scores[i] \u0026gt; min_score_thresh: 72box = tuple(boxes[i].tolist()) 73if instance_masks is not None: 74box_to_instance_masks_map[box] = instance_masks[i] 75if instance_boundaries is not None: 76box_to_instance_boundaries_map[box] = instance_boundaries[i] 77if keypoints is not None: 78box_to_keypoints_map[box].extend(keypoints[i]) 79if scores is None: 80box_to_color_map[box] = groundtruth_box_visualization_color 81else: 82display_str = \u0026#39;\u0026#39; 83if not skip_labels: 84if not agnostic_mode: 85if classes[i] in category_index.keys(): 86class_name = category_index[classes[i]][\u0026#39;name\u0026#39;] 87else: 88class_name = \u0026#39;N/A\u0026#39; 89display_str = str(class_name) 90if not skip_scores: 91if not display_str: 92display_str = \u0026#39;{}%\u0026#39;.format(int(100 * scores[i])) 93else: 94display_str = \u0026#39;{}: {}%\u0026#39;.format( 95display_str, int(100 * scores[i])) 96box_to_display_str_map[box].append(display_str) 97if agnostic_mode: 98box_to_color_map[box] = \u0026#39;DarkOrange\u0026#39; 99else: 100box_to_color_map[box] = STANDARD_COLORS[classes[i] % 101len(STANDARD_COLORS)] 102103# Draw all boxes onto image. 104for box, color in box_to_color_map.items(): 105ymin, xmin, ymax, xmax = box 106if instance_masks is not None: 107draw_mask_on_image_array(image, box_to_instance_masks_map[box], color=color) 108109draw_bounding_box_on_image_array( 110image, 111ymin, 112xmin, 113ymax, 114xmax, 115color=color, 116thickness=line_thickness, 117display_str_list=box_to_display_str_map[box], 118use_normalized_coordinates=use_normalized_coordinates) 119120return image 121122123def reframe_box_masks_to_image_masks(box_masks, boxes, image_height, 124image_width): 125\u0026#34;\u0026#34;\u0026#34;Transforms the box masks back to full image masks. 126127Embeds masks in bounding boxes of larger masks whose shapes correspond to 128image shape. 129130Args: 131box_masks: A tf.float32 tensor of size [num_masks, mask_height, mask_width]. 132boxes: A tf.float32 tensor of size [num_masks, 4] containing the box 133corners. Row i contains [ymin, xmin, ymax, xmax] of the box 134corresponding to mask i. Note that the box corners are in 135normalized coordinates. 136image_height: Image height. The output mask will have the same height as 137the image height. 138image_width: Image width. The output mask will have the same width as the 139image width. 140141Returns: 142A tf.float32 tensor of size [num_masks, image_height, image_width]. 143\u0026#34;\u0026#34;\u0026#34; 144# TODO(rathodv): Make this a public function. 145def reframe_box_masks_to_image_masks_default(): 146\u0026#34;\u0026#34;\u0026#34;The default function when there are more than 0 box masks.\u0026#34;\u0026#34;\u0026#34; 147def transform_boxes_relative_to_boxes(boxes, reference_boxes): 148boxes = tf.reshape(boxes, [-1, 2, 2]) 149min_corner = tf.expand_dims(reference_boxes[:, 0:2], 1) 150max_corner = tf.expand_dims(reference_boxes[:, 2:4], 1) 151transformed_boxes = (boxes - min_corner) / \\ 152(max_corner - min_corner) 153return tf.reshape(transformed_boxes, [-1, 4]) 154155box_masks_expanded = tf.expand_dims(box_masks, axis=3) 156num_boxes = tf.shape(box_masks_expanded)[0] 157unit_boxes = tf.concat( 158[tf.zeros([num_boxes, 2]), tf.ones([num_boxes, 2])], axis=1) 159reverse_boxes = transform_boxes_relative_to_boxes(unit_boxes, boxes) 160return tf.image.crop_and_resize( 161image=box_masks_expanded, 162boxes=reverse_boxes, 163box_ind=tf.range(num_boxes), 164crop_size=[image_height, image_width], 165extrapolation_value=0.0) 166image_masks = tf.cond( 167tf.shape(box_masks)[0] \u0026gt; 0, 168reframe_box_masks_to_image_masks_default, 169lambda: tf.zeros([0, image_height, image_width, 1], dtype=tf.float32)) 170return tf.squeeze(image_masks, axis=3) Cho hình ảnh vào và rút ra kết quả.\n12def detect_frame(image_np, sess, detection_graph): 34with detection_graph.as_default(): 56ops = tf.get_default_graph().get_operations() 7all_tensor_names = {output.name for op in ops for output in op.outputs} 8tensor_dict = {} 9for key in [ 10\u0026#39;num_detections\u0026#39;, \u0026#39;detection_boxes\u0026#39;, \u0026#39;detection_scores\u0026#39;, 11\u0026#39;detection_classes\u0026#39;, \u0026#39;detection_masks\u0026#39; 12]: 13tensor_name = key + \u0026#39;:0\u0026#39; 14if tensor_name in all_tensor_names: 15tensor_dict[key] = tf.get_default_graph( 16).get_tensor_by_name(tensor_name) 17if \u0026#39;detection_masks\u0026#39; in tensor_dict: 18# The following processing is only for single image 19detection_boxes = tf.squeeze(tensor_dict[\u0026#39;detection_boxes\u0026#39;], [0]) 20detection_masks = tf.squeeze(tensor_dict[\u0026#39;detection_masks\u0026#39;], [0]) 21# Reframe is required to translate mask from box coordinates to image coordinates and fit the image size. 22real_num_detection = tf.cast( 23tensor_dict[\u0026#39;num_detections\u0026#39;][0], tf.int32) 2425detection_boxes = tf.slice(detection_boxes, [0, 0], [ 26real_num_detection, -1]) 27detection_masks = tf.slice(detection_masks, [0, 0, 0], [ 28real_num_detection, -1, -1]) 29detection_masks_reframed = reframe_box_masks_to_image_masks( 30detection_masks, detection_boxes, image_np.shape[0], image_np.shape[1]) 31detection_masks_reframed = tf.cast( 32tf.greater(detection_masks_reframed, 0.5), tf.uint8) 33# Follow the convention by adding back the batch dimension 34tensor_dict[\u0026#39;detection_masks\u0026#39;] = tf.expand_dims( 35detection_masks_reframed, 0) 36image_tensor = tf.get_default_graph().get_tensor_by_name(\u0026#39;image_tensor:0\u0026#39;) 3738# Run inference 39output_dict = sess.run(tensor_dict, 40feed_dict={image_tensor: np.expand_dims(image_np, 0)}) 4142# all outputs are float32 numpy arrays, so convert types as appropriate 43output_dict[\u0026#39;num_detections\u0026#39;] = int(output_dict[\u0026#39;num_detections\u0026#39;][0]) 44#print(\u0026#34;num detect \u0026#34;+str(output_dict[\u0026#39;num_detections\u0026#39;])) 45output_dict[\u0026#39;detection_classes\u0026#39;] = output_dict[\u0026#39;detection_classes\u0026#39;][0].astype( 46np.uint8) 47output_dict[\u0026#39;detection_boxes\u0026#39;] = output_dict[\u0026#39;detection_boxes\u0026#39;][0] 48output_dict[\u0026#39;detection_scores\u0026#39;] = output_dict[\u0026#39;detection_scores\u0026#39;][0] 49if \u0026#39;detection_masks\u0026#39; in output_dict: 50output_dict[\u0026#39;detection_masks\u0026#39;] = output_dict[\u0026#39;detection_masks\u0026#39;][0] 5152visualize_boxes_and_labels_on_image_array( 53image_np, 54output_dict[\u0026#39;detection_boxes\u0026#39;], 55output_dict[\u0026#39;detection_classes\u0026#39;], 56output_dict[\u0026#39;detection_scores\u0026#39;], 57category_index, 58instance_masks=output_dict.get(\u0026#39;detection_masks\u0026#39;), 59use_normalized_coordinates=True, 60line_thickness=1, 61max_boxes_to_draw=min(output_dict[\u0026#39;num_detections\u0026#39;],20) 62) 6364return image_np 1image = cv2.imread(\u0026#39;img2.jpg\u0026#39;) 2with detection_graph.as_default(): 3with tf.Session(graph=detection_graph) as sess: 4image_np = detect_frame(image, sess, detection_graph) 56cv2.imwrite(\u0026#39;output.jpg\u0026#39;, image) Kết quả file output.jpg của chúng ta là:\nThử với bức ảnh người và xe hơi.\nCảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.\n","date":"Oct 8, 2018","img":"","permalink":"/blog/2018-10-08-mask-rnn/","series":null,"tags":["Machine learning","Deeplearning","Spark"],"title":"Mask R-CNN Trong Bài Toán Nhận Dạng Và Phân Vùng Đối Tượng"},{"categories":null,"content":"Lời mở đầu Lưu ý: Để sử dụng được các mô hình trong bài viết này, bạn phải sử dụng phiên bản opencv \u0026gt; 3.4.1.\nỞ bài viết trước, chúng ta đã tìm hiểu cách thức rút trích khung xương sử dụng DNN và đã áp dụng thành công trên ảnh có chứa 1 đối tượng người. Trong bài viết này, chúng ta sẽ thực hiện áp dụng mô hình cho bài toán có nhiều người trong cùng 1 bức ảnh.\nSử dụng pretrain model trong bài toán multiple Pose Estimation Trong bài viết này, chúng ta tiếp tục sử dụng mô hình MPI để dò tìm các điểm đặc trưng của con người và rút ra mô hình khung xương. Kết quả trả về của thuật toán gồm 15 đặc trưng như bên dưới.\n1Head – 0, Neck – 1, Right Shoulder – 2, Right Elbow – 3, Right Wrist – 4, 2Left Shoulder – 5, Left Elbow – 6, Left Wrist – 7, Right Hip – 8, 3Right Knee – 9, Right Ankle – 10, Left Hip – 11, Left Knee – 12, 4Left Ankle – 13, Chest – 14, Background – 15 Áp dụng mô hình với ảnh của nhóm T-ARA.\n1import cv2 23nPoints = 15 4POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ] 56protoFile = \u0026#34;pose/mpi/pose_deploy_linevec.prototxt\u0026#34; 7weightsFile = \u0026#34;pose/mpi/pose_iter_160000.caffemodel\u0026#34; 89net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile) 1011frame = cv2.imread(\u0026#34;tara1.jpg\u0026#34;) 1213inWidth = 368 14inHeight = 368 1516# Prepare the frame to be fed to the network 17inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False) 1819# Set the prepared object as the input blob of the network 20net.setInput(inpBlob) 2122output = net.forward() Thử show lên vị trí vùng cổ trong hình.\n12i = 0 3probMap = output[0, i, :, :] 4probMap = cv2.resize(probMap, (frameWidth, frameHeight)) 56import matplotlib.pyplot as plt 78plt.imshow(cv2.cvtColor(frameCopy, cv2.COLOR_BGR2RGB)) 9plt.imshow(probMap, alpha=0.5) 10plt.show() Thử show lên hình điểm đặc trưng vùng cổ\n1i = 1 2probMap = output[0, i, :, :] 3probMap = cv2.resize(probMap, (frameWidth, frameHeight)) 45import matplotlib.pyplot as plt 67plt.imshow(cv2.cvtColor(frameCopy, cv2.COLOR_BGR2RGB)) 8plt.imshow(probMap, alpha=0.5) 9plt.show() Bằng một số phép biến đổi quen thuộc có sẵn trong opencv, chúng ta hoàn toàn có thể lấy được toạ độ của các điểm keypoint một cách dễ dàng.\n12# Find the Keypoints using Non Maximum Suppression on the Confidence Map 3def getKeypoints(probMap, threshold=0.1): 45mapSmooth = cv2.GaussianBlur(probMap,(3,3),0,0) 67mapMask = np.uint8(mapSmooth\u0026gt;threshold) 8keypoints = [] 910#find the blobs 11_, contours, _ = cv2.findContours(mapMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) 1213#for each blob find the maxima 14for cnt in contours: 15blobMask = np.zeros(mapMask.shape) 16blobMask = cv2.fillConvexPoly(blobMask, cnt, 1) 17maskedProbMap = mapSmooth * blobMask 18_, maxVal, _, maxLoc = cv2.minMaxLoc(maskedProbMap) 19keypoints.append(maxLoc + (probMap[maxLoc[1], maxLoc[0]],)) 2021return keypoints 222324detected_keypoints = [] 25keypoints_list = np.zeros((0,3)) 26keypoint_id = 0 27threshold = 0.1 28for i in range(nPoints): 29probMap = output[0, i, :, :] 30probMap = cv2.resize(probMap, (frameWidth, frameHeight)) 3132keypoints = getKeypoints(probMap, threshold) 33keypoints_with_id = [] 34for j in range(len(keypoints)): 35keypoints_with_id.append(keypoints[j] + (keypoint_id,)) 36keypoints_list = np.vstack([keypoints_list, keypoints[j]]) 37keypoint_id += 1 3839detected_keypoints.append(keypoints_with_id) 40414243frameClone = cv2.cvtColor(frameCopy,cv2.COLOR_BGR2RGB) 44for i in range(nPoints): 45for j in range(len(detected_keypoints[i])): 46cv2.circle(frameClone, detected_keypoints[i][j][0:2], 3, [0,0,255], -1, cv2.LINE_AA) 4748plt.imshow(frameClone) 49plt.show() Cuối cùng, chúng ta sẽ nối các điểm đặc trưng của các nhân vật thông qua thuật toán Part Affinity Heatmaps. Thuật toán này được đề xuất bởi nhóm tác giả Zhe Cao, Tomas Simon,Shih-En Wei, Yaser Sheikh thuộc phòng thí nghiệm The Robotics Institute trường đại học Carnegie Mellon. Các bạn có nhu cầu có thể tìm hiểu ở https://arxiv.org/pdf/1611.08050.pdf.\n12mapIdx = [[16,17], [18,19], [20,21], [22,23], [24,25], [26,27], [28,29], [30,31], [32,33], [34,35], [36,37], [38,39], [40,41], [42,43]] 3456colors = [ [0,100,255], [0,100,255], [0,255,255], [0,100,255], [0,255,255], [0,100,255], 7[0,255,0], [255,200,100], [255,0,255], [0,255,0], [255,200,100], [255,0,255], 8[0,0,255], [255,0,0], [200,200,0], [255,0,0], [200,200,0], [0,0,0]] 9# Find valid connections between the different joints of a all persons present 10def getValidPairs(output): 11valid_pairs = [] 12invalid_pairs = [] 13n_interp_samples = 10 14paf_score_th = 0.1 15conf_th = 0.5 16# loop for every POSE_PAIR 17for k in range(len(mapIdx)): 18# A-\u0026gt;B constitute a limb 19pafA = output[0, mapIdx[k][0], :, :] 20pafB = output[0, mapIdx[k][1], :, :] 21pafA = cv2.resize(pafA, (frameWidth, frameHeight)) 22pafB = cv2.resize(pafB, (frameWidth, frameHeight)) 232425# Find the keypoints for the first and second limb 26candA = detected_keypoints[POSE_PAIRS[k][0]] 27candB = detected_keypoints[POSE_PAIRS[k][1]] 28nA = len(candA) 29nB = len(candB) 3031# fig=plt.figure(figsize=(8, 8)) 3233# interp_coord = list(zip(np.linspace(candA[0][0], candB[0][0], num=n_interp_samples), 34# np.linspace(candA[0][1], candB[0][1], num=n_interp_samples))) 3536# frameClone1 = frameClone.copy()  37# fig.add_subplot(1, 2, 1) 3839# for xx in interp_coord: 40# cv2.circle(frameClone1,(int(xx[0]),int(xx[1])), 3, [0,0,255], -1, cv2.LINE_AA) 414243# plt.imshow(cv2.cvtColor(frameClone1, cv2.COLOR_BGR2RGB)) 44# plt.imshow(pafA, alpha=0.5) 4546# frameClone1 = frameClone.copy()  47# fig.add_subplot(1, 2, 2) 4849505152# for xx in interp_coord: 53# cv2.circle(frameClone1,(int(xx[0]),int(xx[1])), 3, [0,0,255], -1, cv2.LINE_AA) 5455# plt.imshow(cv2.cvtColor(frameClone1, cv2.COLOR_BGR2RGB)) 56# plt.imshow(pafB, alpha=0.5) 57# plt.show() 585960616263# If keypoints for the joint-pair is detected 64# check every joint in candA with every joint in candB  65# Calculate the distance vector between the two joints 66# Find the PAF values at a set of interpolated points between the joints 67# Use the above formula to compute a score to mark the connection valid 6869if( nA != 0 and nB != 0): 70valid_pair = np.zeros((0,3)) 71for i in range(nA): 72max_j=-1 73maxScore = -1 74found = 0 75for j in range(nB): 76# Find d_ij 77d_ij = np.subtract(candB[j][:2], candA[i][:2]) 78norm = np.linalg.norm(d_ij) 79if norm: 80d_ij = d_ij / norm 81else: 82continue 83# Find p(u) 84interp_coord = list(zip(np.linspace(candA[i][0], candB[j][0], num=n_interp_samples), 85np.linspace(candA[i][1], candB[j][1], num=n_interp_samples))) 86# Find L(p(u)) 87paf_interp = [] 88for k in range(len(interp_coord)): 89paf_interp.append([pafA[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))], 90pafB[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))] ]) 91# Find E 92paf_scores = np.dot(paf_interp, d_ij) 93avg_paf_score = sum(paf_scores)/len(paf_scores) 9495# Check if the connection is valid 96# If the fraction of interpolated vectors aligned with PAF is higher then threshold -\u0026gt; Valid Pair  97if ( len(np.where(paf_scores \u0026gt; paf_score_th)[0]) / n_interp_samples ) \u0026gt; conf_th : 98if avg_paf_score \u0026gt; maxScore: 99max_j = j 100maxScore = avg_paf_score 101found = 1 102# Append the connection to the list 103if found: 104valid_pair = np.append(valid_pair, [[candA[i][3], candB[max_j][3], maxScore]], axis=0) 105106# Append the detected connections to the global list 107valid_pairs.append(valid_pair) 108109pprint(valid_pair) 110else: # If no keypoints are detected 111print(\u0026#34;No Connection : k = {}\u0026#34;.format(k)) 112invalid_pairs.append(k) 113valid_pairs.append([]) 114pprint(valid_pairs) 115return valid_pairs, invalid_pairs 116117# This function creates a list of keypoints belonging to each person 118# For each detected valid pair, it assigns the joint(s) to a person 119# It finds the person and index at which the joint should be added. This can be done since we have an id for each joint 120def getPersonwiseKeypoints(valid_pairs, invalid_pairs): 121# the last number in each row is the overall score  122personwiseKeypoints = -1 * np.ones((0, 19)) 123124for k in range(len(mapIdx)): 125if k not in invalid_pairs: 126partAs = valid_pairs[k][:,0] 127partBs = valid_pairs[k][:,1] 128indexA, indexB = np.array(POSE_PAIRS[k]) 129130for i in range(len(valid_pairs[k])): 131found = 0 132person_idx = -1 133for j in range(len(personwiseKeypoints)): 134if personwiseKeypoints[j][indexA] == partAs[i]: 135person_idx = j 136found = 1 137break 138139if found: 140personwiseKeypoints[person_idx][indexB] = partBs[i] 141personwiseKeypoints[person_idx][-1] += keypoints_list[partBs[i].astype(int), 2] + valid_pairs[k][i][2] 142143# if find no partA in the subset, create a new subset 144elif not found and k \u0026lt; 17: 145row = -1 * np.ones(19) 146row[indexA] = partAs[i] 147row[indexB] = partBs[i] 148# add the keypoint_scores for the two keypoints and the paf_score  149row[-1] = sum(keypoints_list[valid_pairs[k][i,:2].astype(int), 2]) + valid_pairs[k][i][2] 150personwiseKeypoints = np.vstack([personwiseKeypoints, row]) 151return personwiseKeypoints 152153valid_pairs, invalid_pairs = getValidPairs(output) 154155personwiseKeypoints = getPersonwiseKeypoints(valid_pairs, invalid_pairs) 156157158for i in range(nPoints-1): 159for n in range(len(personwiseKeypoints)): 160161index = personwiseKeypoints[n][np.array(POSE_PAIRS[i])] 162if -1 in index: 163continue 164B = np.int32(keypoints_list[index.astype(int), 0]) 165A = np.int32(keypoints_list[index.astype(int), 1]) 166cv2.line(frameClone, (B[0], A[0]), (B[1], A[1]), colors[i], 3, cv2.LINE_AA) 167168169170plt.imshow(frameClone) 171# plt.imshow(mapMask, alpha=0.5) 172plt.show() Hẹn gặp lại các bạn ở những bài viết tiếp theo.\nBài viết này được viết dựa vào nguồn https://www.learnopencv.com/multi-person-pose-estimation-in-opencv-using-openpose/ của tác giả VIKAS GUPTA. Tôi sử dụng tập model và hình ảnh khác với bài viết nguyên gốc của tác giả.\n","date":"Oct 5, 2018","img":"","permalink":"/blog/2018-10-05-deep-learning-base-multiple-human-pose-estimation/","series":null,"tags":["Machine learning","Deeplearning","multiple pose estimation"],"title":"Deep Learning Based Multiple Human Pose Estimation Using OpenCV"},{"categories":null,"content":"Lời mở đầu Để sử dụng được các mô hình trong bài viết này, bạn phải sử dụng phiên bản opencv \u0026gt; 3.4.1.\nPose Estimation là gì? \nPost Estimation ( đôi khi được dùng với thuật ngữ Keypoint Detection) là một vấn đề khá phổ biến trong lĩnh vực xử lý ảnh khi chúng ta cần xác định vị trí và hướng của một đối tượng. Mức ý nghĩa ở đây là chúng ta phải rút ra được những đặc điểm chính, những đặc điểm đó là những đặc trưng của đối tượng ( có thể mô tả được đối tượng).\nVí dụ, trong bài toán face pose estimation ( có tên khác là facial landmark detection), chúng ta cần xác định được đâu là vị trí của những điểm landmark trên khuôn mặt người.\nMột bài toán có liên quan đến bài toán trên là head pose estimation. Chúng ta cần xác định những điểm landmark để mô hình hoá lại được mô hình 3D của đầu người.\nỞ trong bài viết này, chúng ta đề cập đến bài toán human pose estimation, công việc chính là xác định và chỉ ra được một phần/ toàn bộ các phần chính của cơ thể con người (vd vai, khuỷu tay, cổ tay, đầu gối v.v).\nTrong bài viết này, chúng ta sẽ sử dụng mô hình được huấn luyện sẵn để chỉ ra các phần chính của cơ thể con người. Kết quả cơ bản của phần nhận diện này sẽ gần giống như hình bên dưới.\nSử dụng pretrain model trong bài toán Pose Estimation Vào nằm 2016, 2017, Phòng thí nghiệm Perceptual Computing của trường đại học Carnegie Mellon University đã công bố một bài báo có liên quan đến chủ đề Multi-Person Pose Estimation. Và đến nay, họ đã công bố mô hình huấn luyện cho chúng ta sử dụng. Các bạn có nhu cầu tìm hiểu sâu hơn có thể đọc kỹ nguồn dữ liệu của họ công bố ở link https://github.com/CMU-Perceptual-Computing-Lab/openpose.\nTrong bài post này, mình sẽ không đề cập kỹ đến phần kiến trúc mạng neural net họ sử dụng bên dưới, thay vào đó, mình sẽ tập trung hơn vào cách thức sử dụng mô hình để thu được kết quả cần thiết.\nTrước khi bắt đầu vào thực hành, mình sẽ mô tả một chút về mô hình pretrain có sẵn. Ở đây, họ cung cấp cho chúng ta 2 mô hình là MPII model và COCO model. Đó chính là tên của hai bộ database mà họ sử dụng để đào tạo mô hình. Kết quả trả về của mỗ bộ database là khác nhau hoàn toàn.\nVới bộ COCO dataset, kết quả trả về là 18 đặc trưng gồm các thông tin:\n1Nose – 0, Neck – 1, Right Shoulder – 2, Right Elbow – 3, Right Wrist – 4, 2Left Shoulder – 5, Left Elbow – 6, Left Wrist – 7, Right Hip – 8, 3Right Knee – 9, Right Ankle – 10, Left Hip – 11, Left Knee – 12, 4LAnkle – 13, Right Eye – 14, Left Eye – 15, Right Ear – 16, 5Left Ear – 17, Background – 18 Với bộ MPII, kết quả trả về là 15 đặc trưng gồm các thông tin:\n1Head – 0, Neck – 1, Right Shoulder – 2, Right Elbow – 3, Right Wrist – 4, 2Left Shoulder – 5, Left Elbow – 6, Left Wrist – 7, Right Hip – 8, 3Right Knee – 9, Right Ankle – 10, Left Hip – 11, Left Knee – 12, 4Left Ankle – 13, Chest – 14, Background – 15 Trong phần này, chúng ta sẽ tập trung vào mô hình MPII, mô hình COCO sử dụng tương tự, chỉ việc thay lại đường dẫn file mô hình là được.\nBắt đầu code. Bước 1: Download mô hình.\nNhóm tác giả sử dụng caffe để huấn luyện mô hình, do đó, để sử dụng được, chúng ta cần download file mô hình ở đường dẫn http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_iter_160000.caffemodel và file cấu hình ở đường dẫn http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_deploy_linevec.prototxt. Các bạn có thể để đâu đó tuỳ thích, ở đây tôi để trong thư mục pose/mpi để dễ dàng nhận biết với các mô hình khác.\nBước 2: Load mô hình.\nĐể load mô hình lên bộ nhớ chính, đơn giản là chúng ta thực hiện câu lệnh sau trong python\n1import cv2 2# Specify the paths for the 2 files 3protoFile = \u0026#34;pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\u0026#34; 4weightsFile = \u0026#34;pose/mpi/pose_iter_160000.caffemodel\u0026#34; 56# Read the network into Memory 7net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile) Đơn giản quá phải không các bạn :).\nBước 3: Đọc ảnh và đưa ảnh vào trong mô hình.\n12# Read image 3frame = cv2.imread(\u0026#34;img2.jpg\u0026#34;) 45frameCopy = np.copy(frame) 6frameWidth = frame.shape[1] 7frameHeight = frame.shape[0] 8t = time.time() 9# Specify the input image dimensions 10inWidth = 368 11inHeight = 368 1213# Prepare the frame to be fed to the network 14inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False) 1516# Set the prepared object as the input blob of the network 17net.setInput(inpBlob) Chắc không cần phải nói gì thêm, phần comment chú thích đã mô tả khá đầy đủ chức năng của từng phần trong này rồi.\nBước 4: Thu thập kết quả và trích xuất điểm đặc trưng\n12frameCopy = frame.copy() 34output = net.forward() 5print(\u0026#34;time taken by network : {:.3f}\u0026#34;.format(time.time() - t)) 6H = output.shape[2] 7W = output.shape[3] 89nPoints = 15 10POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ] 111213threshold = 0.01 14# Empty list to store the detected keypoints 15points = [] 16for i in range(nPoints): 17# confidence map of corresponding body\u0026#39;s part. 18probMap = output[0, i, :, :] 1920# Find global maxima of the probMap. 21minVal, prob, minLoc, point = cv2.minMaxLoc(probMap) 2223# Scale the point to fit on the original image 24x = (frameWidth * point[0]) / W 25y = (frameHeight * point[1]) / H 2627print(prob) 2829if prob \u0026gt; threshold : 30cv2.circle(frame, (int(x), int(y)), 15, (0, 255, 255), thickness=-1, lineType=cv2.FILLED) 31cv2.putText(frame, \u0026#34;{}\u0026#34;.format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 2, lineType=cv2.LINE_AA) 3233# Add the point to the list if the probability is greater than the threshold 34points.append((int(x), int(y))) 35else : 36points.append(None) 3738# cv2.imshow(\u0026#34;Output-Keypoints\u0026#34;,frame) 39# cv2.waitKey(0) 40# cv2.destroyAllWindows() 4142cv2.imwrite(\u0026#34;dot_keypoint.png\u0026#34;,frame) 4344# Draw Skeleton 45for pair in POSE_PAIRS: 46partA = pair[0] 47partB = pair[1] 4849if points[partA] and points[partB]: 50cv2.line(frameCopy, points[partA], points[partB], (0, 255, 255), 2) 51cv2.circle(frameCopy, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED) 52cv2.circle(frameCopy, points[partB], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED) 535455cv2.imwrite(\u0026#34;line_keypoint.png\u0026#34;,frameCopy) Kết quả của giá trị output là một ma trận 4D, với ý nghĩa của mỗi chiều như sau:\n Chiều đầu tiên là image ID (định danh ảnh trong trường hợp bạn truyền nhiều ảnh vào mạng) Chiều thứ 2 là chỉ số của các điểm đặc trưng. Tập MPI trả về tập gồm 44 điểm dữ liệu, ta chỉ sử dụng một vài điểm dữ liệu tương ứng với vị trí các điểm đặc trưng mà chúng ta quan tâm. Chiều thứ 3 là height của output map. Chiều thứ 4 là width của output map. Một lưu ý ở đây là tôi có sử dụng đặt giá trị chặn dưới threshold để giảm thiểu sự sai sót do nhận diện sai. Và kết quả đạt được là hai hình bên dưới:  Hẹn gặp lại các bạn ở những bài viết tiếp theo.\n","date":"Oct 4, 2018","img":"","permalink":"/blog/2018-10-04-deep-learning-base-human-pose-estimation/","series":null,"tags":["Machine learning","Deeplearning","pose estimation"],"title":"Deep Learning Based Human Pose Estimation Using OpenCV"},{"categories":null,"content":"Lời mở đầu Khi mới bắt đầu bước vào thế giới của ML/DL chúng ta sẽ bắt gặp các thuật ngữ Epoch - Batch size và Iterations. Và sẽ cảm thấy bối rối vì chúng khá giống nhau, nhưng thực tế là chúng khác xa nhau.\nĐể cho dễ hình dung, mình lấy ví dụ về việc ăn cơm. Chúng ta không thể ăn một lần hết một chén cơm được, mà phải mỗi lần ăn phải xúc từng muỗn ăn. Xúc lần lượt khi hết bát thứ nhất, chúng ta lại ăn tiếp bát thứ 2, bát thứ 3 \u0026hellip; đến khi no, kết thúc bữa ăn.\nLiên tưởng giữa việt ăn cơm và các thuật ngữ epoch, batch size, iteration như sau:\n  batch size: Số hạt cơm trong 1 lần xúc.\n  Iteration : Số lần xúc cơm hết 1 bát.\n  epoch : Số bát cơm bạn ăn trong 1 bữa ăn.\n  Hết phần diễn giải bằng ví dụ. Đến phần viết hàn lâm bên dưới, nếu bạn nào đã hiểu rồi thì có thể bỏ qua, bạn nào muốn đào sâu thêm lý do thì xem mình diễn giải bên dưới.\nĐể hiểu rõ sự khác biệt giữa chúng, các bạn cần tìm hiểu một khái niệm vô cùng quan trọng trong machine learning - Gradient Descent.\nĐịnh nghĩa ngắn gọn của Gradient Descent:\nGradient Descent là thuật toán lặp tối ưu (iteractive optimization algorithm) được sử dụng trong machine learning để tìm kết quả tốt nhất (minima of a curve).\nTrong đó:\n..* Gradient có nghĩa là tỷ lệ của độ nghiêng của đường dốc.\n..* Descent là từ viết tắt của decending - nghĩa là giảm.\nThuật toán sẽ lặp đi lặp lại nhiều lần để tìm ra được cực tiểu.\nhttps://medium.com/onfido-tech/machine-learning-101-be2e0a86c96a Nguồn ảnh\nCác bạn quan sát hình phía trên bên trái, ban đầu, bước nhảy khá lớn, nghĩa là giá trị cost lớn, và sau một vài lần lặp, điểm chấm đen đi xuống dần, và giá trị cost nhỏ dần theo. Mô hình hội tụ dần dần đến khi cost \u0026lt;= epselon\nChúng ta sử dụng thuật ngữ epochs, batch size, iterations khi chúng ta cần phải trainning mô hình machine learning, mà tập trainset của chúng ta quá (rất) lớn (vd 10 triệu mẫu, ví dụ train mô hình nhận dạng khuôn mặt với tập ms-celeb-1m). Lúc này các khái niệm trên mới trở nên rõ ràng, còn với trường hợp dữ liệu nhỏ thì chúng khá tương tự nhau.\nKhái niện Epoch Một Epoch được tính là khi chúng ta đưa tất cả dữ liệu trong tập train vào mạng neural network 1 lần. Ví dụ, bạn có 10 triệu bức hình trong tập train, bạn cho toàn bộ số hình đó là input của mô hình 3 lần, suy ra bạn đã train được 3 epoch.\nKhi dữ liệu quá lớn, chúng ta không thể đưa hết mỗi lần tất cả tập dữ liệu vào để huấn luyện được, vì bạn cần một siêu máy tính có lượng RAM và GPU RAM cực lớn để lưu trữ toàn bộ hình ảnh trên, điều này là bất khả thi đối với người dùng bình thường, phòng lab nhỏ. Buộc lòng chúng ta phải chia nhỏ tập dữ liệu ra, và khái niệm batch hình thành.\nBatch Size Batch size là số lượng mẫu dữ liệu trong một lần huấn luyện. Ví dụ, trong bài toán phân loại chó mèo, chọn batch size =32, nghĩa là 1 lần lặp ta sẽ cho ngẫu nhiên 32 bức nhìn chó hoặc mèo chạy lan truyền tiến trong mạng neural network. tiếp theo bạn quăng tiếp 32 hình ngẫu nhiên, không lặp với các hình trước đó, vào mạng, quăng đến khi nào không còn hình nào có thể quăng vào nữa -\u0026gt; bạn hoàn thành 1 epoch.\nIterations Iterations là số lượng batchs cần để hoàn thành 1 epoch.\nVí dụ chúng ta có tập dữ liệu có 20,000 mẫu, batch size là 500, vậy chúng ta cần 40 lần lặp (iteration) để hoàn thành 1 epoch.\nTại sao phải dùng hơn 1 Epoch. Câu trả lời ở đây là tại vì chúng ta đang dùng thuật toán tối ưu là Gradient Descent. Thuật toán này đòi hỏi chúng ta phải đem toàn bộ dữ liệu qua mạng một vài lần để tìm được kết quả tối ưu. Vì vậy, dùng 1 epoch thật sự không đủ để tìm được kết quả tốt nhất.\nVới việc chỉ sử dụng 1 lần lặp, xác suất rất cao là dữ liệu sẽ bị underfitting(như hình mô tả bên dưới).\nKhi số lần lặp tăng dần, trạng thái của mô hình sẽ chuyển dần từ underfitting sang optimal và sau đó là overfitting (thông thường là vậy, trừ khi mô hình huấn luyện của bạn đang sử dụng quá đơn giản, quá ít trọng số thì chúng không thể nào overfitting nổi).\nChúng ta có thể dùng 1 epoch để huấn luyện mô hình, với điều kiện là ta sử dụng thuật toán tối ưu không phải là gradient descent.\nSố lần lặp tối ưu là bao nhiêu? Tiếc rằng không có câu trả lời cho câu hỏi này. Phụ thuộc hoàn toàn vào nhiều yếu tố. Mục tiêu chung là ta sẽ lặp đến khi nào hội tụ. Có một số phương pháp giúp chúng ta xác định mô hình đã đứng ở ngưỡng cực tiểu cục bộ rồi, không thể xuống hơn được nữa.\nCác bạn có thể tìm hiểu với từ khóa early stopping.\nCảm ơn các bạn đã theo dõi bài viết.\nNguồn: https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9\n","date":"Oct 2, 2018","img":"","permalink":"/blog/2018-10-02-understanding-epoch-batchsize-iterations/","series":null,"tags":["Machine learning","Deeplearning","Epoch","Batch Size","Iteration"],"title":"Phân Biệt Epoch - Batch Size Và Iterations"},{"categories":null,"content":"Lời mở đầu MovieLens là một tập dữ liệu được sử dụng rộng rãi cách đây nhiều năm. Hôm nay, mình sẽ sử dụng tập dữ liệu này và mô hình ALS của spark để xây dựng chương trình dự đoán phim cho người dùng.\nChuẩn bị dữ liệu Các bạn có thể download tập dữ liệu MovieLens ở link https://grouplens.org/datasets/movielens/. Các bạn có thể download trực tiếp 2 file nén ở link http://files.grouplens.org/datasets/movielens/ml-latest-small.zip và link http://files.grouplens.org/datasets/movielens/ml-latest.zip.\nỞ trên bao gồm 2 tập dữ liệu. chúng ta tạo thư mục datasets và download rồi bỏ chúng vào trong thư mục đấy.\n1complete_dataset_url = \u0026#39;http://files.grouplens.org/datasets/movielens/ml-latest.zip\u0026#39; 2small_dataset_url = \u0026#39;http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\u0026#39; 34import os 56datasets_path = \u0026#39;datasets\u0026#39; 7if not os.path.exists(datasets_path): 8os.makedirs(datasets_path)) 910complete_dataset_path = os.path.join(datasets_path, \u0026#39;ml-latest.zip\u0026#39;) 11small_dataset_path = os.path.join(datasets_path, \u0026#39;ml-latest-small.zip\u0026#39;) 1213import urllib 14import zipfile 1516if not os.path.exists(small_dataset_url): 17small_f = urllib.urlretrieve (small_dataset_url, small_dataset_path)#Download 18with zipfile.ZipFile(small_dataset_path, \u0026#34;r\u0026#34;) as z:#Giải nén 19z.extractall(datasets_path) 20if not os.path.exists(small_dataset_url): 21complete_f = urllib.urlretrieve (complete_dataset_url, complete_dataset_path)#Download 22with zipfile.ZipFile(complete_dataset_path, \u0026#34;r\u0026#34;) as z:#Giải nén 23z.extractall(datasets_path) Trong thư mục giải nén, chúng ta sẽ có các file ratings.csv, movies.csv, tags.csv, links.csv, README.txt.\nLoading và parsing dữ liệu. Mỗi dòng trong tập ratings.csv có định dạng \u0026quot;userId,movieId,rating,timestamp\u0026quot;.\nMỗi dòng trong tập movies.csv có định dạng \u0026quot;movieId,title,genres\u0026quot;.\nMỗi dòng trong tập tags.csv có định dạng \u0026quot;userId,movieId,tag,timestamp\u0026quot;.\nMỗi dòng trong tập links.csv có định dạng \u0026quot;movieId,imdbId,tmdbId\u0026quot;.\nTóm lại, các trường dữ liệu trong các file csv đều ngăn cách nhau bởi dấu phẩy (,). Trong python, ta có thể dùng hàm split để cắt chúng ra. Sau đó sẽ load toàn bộ dữ liệu lên RDDs.\nLưu ý nhỏ:\n Ở tập dữ liệu ratings, chúng ta chỉ giữ lại các trường (UserID, MovieID, Rating) bỏ đi trường timestamp vì không cần thiết. Ở tập dữ liệu movies chúng ta giữ lại trường (MovieID, Title) và bỏ đi trường genres vì lý do tương tự.  1small_ratings_file = os.path.join(datasets_path, \u0026#39;ml-latest-small\u0026#39;, \u0026#39;ratings.csv\u0026#39;) 2small_ratings_raw_data = sc.textFile(small_ratings_file) 3small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0] 4small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header).map(lambda line: line.split(\u0026#34;,\u0026#34;)).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache() 5print(small_ratings_data.take(3)) #Hiện thị top 3 ratting đầu tiên 67small_movies_file = os.path.join(datasets_path, \u0026#39;ml-latest-small\u0026#39;, \u0026#39;movies.csv\u0026#39;) 89small_movies_raw_data = sc.textFile(small_movies_file) 10small_movies_raw_data_header = small_movies_raw_data.take(1)[0] 1112small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\ 13.map(lambda line: line.split(\u0026#34;,\u0026#34;)).map(lambda tokens: (tokens[0],tokens[1])).cache() 1415small_movies_data.take(3) #Hiện thị top 3 movie đầu tiên Phần tiếp theo, chúng ta sẽ tìm hiểu lọc cộng tác (Collaborative Filtering) và cách sử dụng Spark MLlib để xây dựng mô hình dự báo.\nCollaborative Filtering Ở đây, tôi sẽ không đề cập đến lọc cộng tác là gì, các bạn có nhu cầu tìm hiểu có thể xem ở bài post khác hoặc tham khảo trên wiki. Chúng ta sẽ tập trung vào tìm hiểu cách sử dụng ALS trong thư viện MLlib của Spark. Các tham số của thuật toán này bao gồm:\n  numBlocks: số lượng block được sử dụng trong tính toán song song (-1 với ý nghĩa là auto configure).\n  rank: số lượng nhân tố ẩn (latent factor) trong mô hình.\n  iterations: số lần lặp.\n  lambda: tham số của chuẩn hoá(regularization ) trong ALS.\n  implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.\n  alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations.\n  Chọn các tham số cho ALS Để chọn được các tham số tốt nhất cho mô hình ALS, chúng ta sẽ sử dụng tập small để grid search. Đầu tiên, chúng ta chia tập dữ liệu thành 3 phần là tập train, tập vali và tập test. Sau đó tiến hành huấn luyện trên tập train và predict trên tập valid để tìm được tham số tốt nhất. Cuối cùng đánh giá kết quả đạt được trên tập test.\n1training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0) 2validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1])) 3test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1])) 45from pyspark.mllib.recommendation import ALS 6import math 78seed = 5L 9iterations = 10 10regularization_parameter = 0.1 11ranks = [4, 8, 12] 12errors = [0, 0, 0] 13err = 0 14tolerance = 0.02 1516min_error = float(\u0026#39;inf\u0026#39;) 17best_rank = -1 18best_iteration = -1 19for rank in ranks: 20model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations, 21lambda_=regularization_parameter) 22predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2])) 23rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions) 24error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()) 25errors[err] = error 26err += 1 27print(\u0026#39;For rank %sthe RMSE is %s\u0026#39; % (rank, error)) 28if error \u0026lt; min_error: 29min_error = error 30best_rank = rank 3132print(\u0026#39;The best model was trained with rank %s\u0026#39; % best_rank) Kết quả sau khi thực hiện đoạn code trên là:\n1For rank 4 the RMSE is 0.963681878574 2For rank 8 the RMSE is 0.96250475933 3For rank 12 the RMSE is 0.971647563632 4The best model was trained with rank 8 Tiến hành thực hiện test.\n1model_test = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations, 2lambda_=regularization_parameter) 3predictions = model_test.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2])) 4rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions) 5error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()) 67print(\u0026#39;For testing data the RMSE is %s\u0026#39; % (error)) 1For testing data the RMSE is 0.972342381898 Xem kỹ hơn một chút về dữ liệu mà spark trả về cho chúng ta. Với predictions và rates_and_preds, ta có:\n1print(predictions.take(3)) 1[((32, 4018), 3.280114696166238), 2((375, 4018), 2.7365714977314086), 3((674, 4018), 2.510684514310653)] Tập dữ liệu trả về bao gồm cặp (UserID, MovieID) và Rating (tương ứng với colum 0, column 1 và column 2 ở trên),được hiểu ở đây là với người dùng UserID và phim MovieID thì mô hình sẽ dự đoán người dùng sẽ rating kết quả Rating.\nSau đó chúng ta sẽ nối(join) chúng với tập valid tương ứng theo cặp (UserID, MovieID), kết quả đạt được là:\n1rates_and_preds.take(3) 1[((558, 788), (3.0, 3.0419325487471403)), 2((176, 3550), (4.5, 3.3214065001580986)), 3((302, 3908), (1.0, 2.4728711204440765))] Việc còn lại là chúng ta sẽ tính trung bình độ lỗi bằng hàm mean() và sqlt().\nXây dựng mô hình với tập dữ liệu large Tiếp theo, chúng ta sẽ sử dụng tập dự liệu bự hơn để xây dựng mô hình. Cách thực hiện y chang như tập dữ liệu nhỏ đã được trình bày ở trên, nên tôi sẽ bỏ qua một số giải thích không cần thiết để tránh lặp lại.\n1# Load the complete dataset file 2complete_ratings_file = os.path.join(datasets_path, \u0026#39;ml-latest\u0026#39;, \u0026#39;ratings.csv\u0026#39;) 3complete_ratings_raw_data = sc.textFile(complete_ratings_file) 4complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0] 56# Parse 7complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header)\\ 8.map(lambda line: line.split(\u0026#34;,\u0026#34;)).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache() 910print(\u0026#34;There are %srecommendations in the complete dataset\u0026#34; % (complete_ratings_data.count())) 1There are 21063128 recommendations in the complete dataset Tiến hành train và test.\n1training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=0) 23complete_model = ALS.train(training_RDD, best_rank, seed=seed,iterations=iterations, lambda_=regularization_parameter) 45test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1])) 67predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2])) 8rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions) 9error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()) 1011print(\u0026#39;For testing data the RMSE is %s\u0026#39; % (error)) 1For testing data the RMSE is 0.82183583368 Xây dựng mô hình dự đoán phim 1complete_movies_file = os.path.join(datasets_path, \u0026#39;ml-latest\u0026#39;, \u0026#39;movies.csv\u0026#39;) 2complete_movies_raw_data = sc.textFile(complete_movies_file) 3complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0] 45# Parse 6complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\ 7.map(lambda line: line.split(\u0026#34;,\u0026#34;)).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache() 89complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1])) 1011print(\u0026#34;There are %smovies in the complete dataset\u0026#34; % (complete_movies_titles.count())) 1There are 27303 movies in the complete dataset 1def get_counts_and_averages(ID_and_ratings_tuple): 2nratings = len(ID_and_ratings_tuple[1]) 3return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings) 45movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey()) 6movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages) 7movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0])) Giả sử chúng ta có 1 người dùng mới, với các ratting như sau:\n1new_user_ID = 0 23# The format of each line is (userID, movieID, rating) 4new_user_ratings = [ 5(0,260,4), # Star Wars (1977) 6(0,1,3), # Toy Story (1995) 7(0,16,3), # Casino (1995) 8(0,25,4), # Leaving Las Vegas (1995) 9(0,32,4), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995) 10(0,335,1), # Flintstones, The (1994) 11(0,379,1), # Timecop (1994) 12(0,296,3), # Pulp Fiction (1994) 13(0,858,5) , # Godfather, The (1972) 14(0,50,4) # Usual Suspects, The (1995) 15] 16new_user_ratings_RDD = sc.parallelize(new_user_ratings) 17print(\u0026#39;New user ratings: %s\u0026#39; % new_user_ratings_RDD.take(10)) 1New user ratings: [(0, 260, 9), (0, 1, 8), (0, 16, 7), (0, 25, 8), (0, 32, 9), (0, 335, 4), (0, 379, 3), (0, 296, 7), (0, 858, 10), (0, 50, 8)] Chúng ta tiến hành huấn luyện lại mô hình khi có thêm người mới:\n1complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD) 23from time import time 45t0 = time() 6new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, 7iterations=iterations, lambda_=regularization_parameter) 8tt = time() - t0 910print(\u0026#34;New model trained in %sseconds\u0026#34; % round(tt,3)) 1New model trained in 56.61 seconds Tiến hành dự đoán ratting của người dùng mới cho toàn bộ các phim người dùng đó chưa xem.\n1new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs 2# keep just those not on the ID list (thanks Lei Li for spotting the error!) 3new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0]))) 45# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies 6new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD) Và show ra top 3 kết quả :\n1# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating) 2new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating)) 3new_user_recommendations_rating_title_and_count_RDD = \\ 4new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD) 5new_user_recommendations_rating_title_and_count_RDD.take(3) Hiển thị top recommend (Ở đây sẽ flat dữ liệu hiển thị thành dàng ((Title, Rating, Ratings Count)) ra cho dễ nhìn).\n1new_user_recommendations_rating_title_and_count_RDD = new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1])) 23top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]\u0026gt;=25).takeOrdered(25, key=lambda x: -x[1]) 45print (\u0026#39;TOP recommended movies (with more than 25 reviews):\\n%s\u0026#39; % 6\u0026#39;\\n\u0026#39;.join(map(str, top_movies))) 1TOP recommended movies (with more than 25 reviews): 2(u\u0026#39;\u0026#34;Godfather: Part II\u0026#39;, 8.503749129186701, 29198) 3(u\u0026#39;\u0026#34;Civil War\u0026#39;, 8.386497469089297, 257) 4(u\u0026#39;Frozen Planet (2011)\u0026#39;, 8.372705479107108, 31) 5(u\u0026#39;\u0026#34;Shawshank Redemption\u0026#39;, 8.258510064442426, 67741) 6(u\u0026#39;Cosmos (1980)\u0026#39;, 8.252254825768972, 948) 7(u\u0026#39;Band of Brothers (2001)\u0026#39;, 8.225114960311624, 4450) 8(u\u0026#39;Generation Kill (2008)\u0026#39;, 8.206487040524653, 52) 9(u\u0026#34;Schindler\u0026#39;s List (1993)\u0026#34;, 8.172761674773625, 53609) 10(u\u0026#39;Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\u0026#39;, 8.166229786764168, 23915) 11(u\u0026#34;One Flew Over the Cuckoo\u0026#39;s Nest (1975)\u0026#34;, 8.15617022970577, 32948) 12(u\u0026#39;Casablanca (1942)\u0026#39;, 8.141303207981174, 26114) 13(u\u0026#39;Seven Samurai (Shichinin no samurai) (1954)\u0026#39;, 8.139633165142612, 11796) 14(u\u0026#39;Goodfellas (1990)\u0026#39;, 8.12931139039048, 27123) 15(u\u0026#39;Star Wars: Episode V - The Empire Strikes Back (1980)\u0026#39;, 8.124225700242096, 47710) 16(u\u0026#39;Jazz (2001)\u0026#39;, 8.078538221315313, 25) 17(u\u0026#34;Long Night\u0026#39;s Journey Into Day (2000)\u0026#34;, 8.050176820606127, 34) 18(u\u0026#39;Lawrence of Arabia (1962)\u0026#39;, 8.041331489948814, 13452) 19(u\u0026#39;Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\u0026#39;, 8.0399424815528, 45908) 20(u\u0026#39;12 Angry Men (1957)\u0026#39;, 8.011389274280754, 13235) 21(u\u0026#34;It\u0026#39;s Such a Beautiful Day (2012)\u0026#34;, 8.007734839026181, 35) 22(u\u0026#39;Apocalypse Now (1979)\u0026#39;, 8.005094327199552, 23905) 23(u\u0026#39;Paths of Glory (1957)\u0026#39;, 7.999379786394267, 3598) 24(u\u0026#39;Rear Window (1954)\u0026#39;, 7.9860865203540214, 17996) 25(u\u0026#39;State of Play (2003)\u0026#39;, 7.981582126801772, 27) 26(u\u0026#39;Chinatown (1974)\u0026#39;, 7.978673289692703, 16195) Dự đoán rating của 1 cá nhân Một trường hợp khác là chúng ta cần dự đoán giá trị ratting của 1 người dùng với 1 bộ phim cụ thể nào đó.\n1my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994) 2individual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD) 3individual_movie_rating_RDD.take(1) 1[Rating(user=0, product=122880, rating=4.955831875971526)] Lưu trữ mô hình Sau khi có được mô hình. Chúng ta cần phải lưu trữ chúng lại để sau này dùng.\n1from pyspark.mllib.recommendation import MatrixFactorizationModel 23model_path = os.path.join(\u0026#39;models\u0026#39;, \u0026#39;movie_lens_als\u0026#39;) 45# Save and load model 6model.save(sc, model_path) 7same_model = MatrixFactorizationModel.load(sc, model_path) ","date":"Oct 1, 2018","img":"","permalink":"/blog/2018-10-01-buiding-a-movie-model/","series":null,"tags":["Machine learning","Deeplearning","Spark"],"title":"Xây Dựng Chương Trình Gợi Ý Phim Dựa Vào Tập Dữ Liệu Movie Len"},{"categories":null,"content":"Lời mở đầu Tỷ phú Peter Thiel đã từng đưa ra câu hỏi tréo ngoe như thế này: \u0026ldquo;What important truth do very few people agree with you on?\u0026rdquo;\nNếu bạn đem câu này hỏi giáo sư Geoffrey Hinton vào năm 2010, ông ấy sẽ trả lời rằng mạng Convolutional Neural Networks (CNN) sẽ có bước đột phá lớn và giúp chúng ta giải quyết hoàn toàn bài toán phân loại ảnh. Tại thời điểm năm 2010, các nhà nghiên cứu trong lĩnh vực phân loại ảnh đều không nghĩ như giáo sư Geoffrey Hinton. Và Deep Learning tại thời điểm đó chưa thật sự giải quyết được bài toán này.\nNăm 2010 cũng là năm ra đời của cuộc thi ImageNet Large Scale Visual Recognition Challenge. Tập dữ liệu ảnh trong cuộc thi bao gồm khoảng 1.2 triệu ảnh thuộc 1000 lớp khác nhau, người thắng cuộc là người tạo ra mô hình làm cho độ lỗi trên tập dữ liệu trên là nhỏ nhất.\nHai năm sau, trong bài báo \u0026ldquo;ImageNet Classification with Deep Convolutional Neural Networks\u0026rdquo; của nhóm tác giả Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton, Geoffrey và các cộng sự của mình đã chứng minh điều ông ấy nói hai năm trước là hoàn toàn chính xác. Ở bài báo này, nhóm tác giả đã huấn luyện mạng CNN và và đạt độ lỗi top-5 error rate là 15.3% (nhóm tác giả đã giành hạng nhất), cách biệt khá xa so với kết quả của nhóm đứng thứ hai(độ lỗi 26.2%). Trong các năm tiếp theo, rất nhiều nhóm đã nghiên cứu, cải tiến kiến trúc của mô hình CNN để đạt được kết quả tốt hơn, thậm chí hơn luôn khả năng nhận biết của con người.\nKiến trúc mạng CNN được sử dụng vào năm 2012 được cộng đồng nghiên cứu gọi với tên gọi thân thương là AlexNet do tác giả chính của nhóm nghiên cứu là Alex Krizhevsky. Ở trong bài viết này, chúng ta sẽ đi sâu vào tìm hiểu kiến trúc AlexNet và đóng góp chính của nó trong CNN.\nĐầu vào Như đã đề cập ở phần trên, mạng AlexNet đã thắng hạng nhất trong cuộc thi ILSVRC năm 2012. Mô hình giải quyết bài toán phân lớp một bức ảnh vào 1 lớp trong 1000 lớp khác nhau (vd gà, chó, mèo \u0026hellip; ). Đầu ra của mô hình là một vector có 1000 phần tử. Phần tử thứ i của vector đại diện cho xác suất bức ảnh thuộc về lớp thứ i. Do đó, tổng của các phần tử trong vector là 1.\nĐầu vào của mạng AlexNet là một bức ảnh RGB có kích thước 256x256 pixel. Toàn bộ các bức ảnh của tập train và tập test đều có cùng kích thước là 256x256. Nếu một bức ảnh nào đó không có kích thước 256x256, bức ảnh đó sẽ được chuyển về kích thước đúng 256x256. Những bức hình có kích thước nhỏ hơn 256 thì sẽ được phóng bự lên đến kích thước 256, những bức hình nào có kích thước lớn hơn 256 thì sẽ được cắt loại phần thừa để nhận được bức hình có kích thước 256x256. Hình ảnh ở dưới là một ví dụ về việc điều chỉnh bức ảnh về kích thước 256x256.\nNếu ảnh đầu vào là ảnh xám (grayscale), bức ảnh trên sẽ được chuyển đổi thành định dạng RGB bằng cách tạo ra 3 layer kênh màu giống nhau từ ảnh xám.\nSau khi chuẩn hoá hết tất cả các ảnh về dạng 256x256x3, nhóm tác giả chỉ sử dụng một phần của bức ảnh có kích thước 227x227x3 của một bức ảnh làm đầu vào cho mạng neural network. Trong bài báo nhóm tác giả ghi là 224x224, nhưng đây là một lỗi nhỏ của nhóm tác giả, và kích thước thực tế đầu vào của bức ảnh là 227x227.\nKiến trúc AlexNet Kiến trúc AlexNet lớn hơn nhiều so với các kiến trúc CNNs được sử dụng trong thị giác máy tính trước kia (trước năm 2010), vd kiến trúc LeNet của Yann LeCun năm 1998. Nó có 60 triệu tham số và 650000 neural và tốn khoảng từ năm đến sáu ngày huấn luyện trên hai GPU GTX 580 3GB. Ngày nay, với sự tiến bộ vượt bật của GPU, chúng ta có nhiều kiến trúc CNN có cấu trúc phức tạp hơn, và hoạt động rất hiệu quả trên những tập dữ liệu phức tạp. Nhưng tại thời điểm năm 2012 thì việc huấn luyện mô hình với lượng tham số và neural lớn như vậy là một vấn đề cực kỳ khó khăn. Nhìn kỹ vào hình bên dưới để hiểu rõ hơn về kiến trúc AlexNet. AlexNet bao gồm 5 convolution Layer và 3 Fully connected Layers.\nNhững convolution layer ( hay còn gọi với tên khác là các filter) rút trích các thông tin hữu ích trong các bức ảnh. Trong một convolution layer bất kỳ thường bao gồm nhiều kernel có cùng kích thước. Ví dụ như convolution layer đầu tiên của AlexNet chứa 96 kernel có kích thước 11x11x3. Thông thường thì width và height của một kernel bằng nhau, và độ sâu (depth) thường bằng số lượng kênh màu.\nConvolutional 1 và convolution 2 kết nối với nhau qua một Overlapping Max Pooling ở giữa. Tương tự như vậy giữa convolution 2 và convolution 3. Convolutional 3, convolution 4, convolution 5 kết nối trực tiếp với nhau, không thông qua trung gian. Convolutional 5 kết nối fully connected layter 1 thông qua một Overlapping Max pooling, tiếp theo mà một fully connected layter nữa. Và cuối cùng là một bộ phân lớp softmax với 1000 lớp nhãn (các bạn có thể xem hình kiến trúc mạng AlexNet ở trên để có cái nhìn tổng quát hơn).\nReLU nonlinerity được sử dụng sau tất các các convolution và fully connected layer. Trước đây, ReLU nonlinerity của lớp convolution 1 và 2 thường theo sau bởi một bước chuẩn hoá cục bộ (local normalization) rồi mới thực hiện pooling. Tuy nhiên, các nghiên cứu sau đó nhận thấy rằng việc sử dụng normalization không thật sự hữu ích. Do vậy chúng ta sẽ không đi chi tiết về vấn đề đó.\nOverlapping Max Pooling Max Pooling layer thường được sử dụng để giảm chiều rộng và chiều dài của một tensor nhưng vẫn giữ nguyên chiều sâu. Overlapping Max Pool layter cũng tương tự như Max Pool layter, ngoại trừ việc là một window của bước này sẽ có một phần chồng lên window của bước tiếp theo. Tác giả sử dụng pooling có kích thước 3x3 và bước nhảy là 2 giữa các pooling. Nghĩa là giữa pooling này và pooling khác sẽ overlapping với nhau 1 pixel. Các thí nghiệm thực tế đã chứng minh rằng việc sử dụng overlapping giữa các pooling giúp giảm độ lỗi top-1 error 0.4% và top-5 error là 0.3% khi so với việc sử dụng pooling có kích thước 2x2 và bước nhảy 2 (vector output của cả hai đều có số chiều bằng nhau).\nReLu Nonlinearity Một cải tiến quan trọng khác của AlexNet là việc sử dụng hàm phi tuyến ReLU. Trước đây, các nhóm nghiên cứu khác thường sử dụng hàm kích hoạt là hàm Tanh hoặc hàm Sigmoid để huấn luyên mô hình neural network. AlexNet chỉ ra rằng, khi sử dụng ReLU, mô hình deep CNN sẽ huấn luyện nhanh hơn so với viêc sử dụng tanh hoặc sigmoid. Hình bên dưới được rút ra từ bài báo chỉ ra rằng với việc sử dụng ReLU (đường nét liền trong hình), AlexNet đạt độ lỗi 25% trên tập huấn luyện và nhanh hơn gấp 6 lần so với mô hình tương tự nhưng sử dụng Tanh (đường nét đứt trong hình). Thí nghiệm trên sử dụng tập dữ liệu CIFAR-10 để huấn luyện.\nĐể hiểu rõ hơn lý do vì sao ReLU lại nhanh hơn so với các hàm khác, chúng ta hãy đối sánh hình dạng giá trị output của các hàm trên.\nCông thức của ReLU là: f(X) = max(0,x)\nNhìn kỹ vào hình trên, ta có nhận xét rằng: hàm tanh đạt giá trị bão hoà khi giá trị z \u0026gt;2.5 và z \u0026lt; -2.5 (số 2.5 là số cảm tính của mình). Và tại vùng |z|\u0026gt;2.5, thì độ dốc của hàm hầu như gần như bằng 0, |z| càng lớn thì độ dốc càng gần 0 hơn. Vì lý do này nên gradient descent sẽ hội tụ chậm. Còn đối với hàm ReLU, với giá trị z dương thì độ dốc của hàm không gần bằng 0 như hàm tanh. Điều này giúp cho việc hội tụ xảy ra nhanh hơn. Với giá trị z âm, độ dốc bằng 0, tuy nhiên, hầu hết các giá trị của các neural trong mạng thường có giá trị dương, nên trường hợp âm ít (hiếm) khi xảy ra. ReLU huấn luyện nhanh hơn so với sigmoid cũng bởi lý do tương tự.\nReducing overfitting Overfitting là gì? Khi bạn dạy một đứa trẻ từ 2-5 tuổi về việc cộng hai số, chúng sẽ học rất nhanh và trả lời đúng hầu hết các câu hỏi mà chúng ta đã dạy chúng. Tuy nhiên, chúng sẽ trả lời sai đối với những câu hỏi hơi lắc léo một chút (câu hỏi tương tự câu chúng ta đã dạy, nhưng thêm một xíu thông tin đòi hỏi trẻ phải suy nghĩ), hoặc các câu hỏi chưa được dạy. Lý do chúng trả lời sai những câu hỏi đó là khi trả lời những câu hỏi được dạy, chúng thường nhớ lại câu trả lời, chứ không thực sự hiểu câu hỏi. Cái này ở Việt Nam ta gọi là học vẹt.\nTương tự vậy, Neural network chính bản thân nó có khả năng học được những gì được dạy, tuy nhiên, nếu quá trình huấn luyện của bạn không tốt, mô hình có khả năng sẽ giống như những đứa trẻ trên kia, hồi tưởng lại những gì đã dạy cho chúng mà không hiểu bản chất. Và kết quả Neural Network sẽ hoạt động tốt trên tập huấn luyện ( nhưng chúng không rút ra được bản chất chính của vấn đề), và kết quả trên tập test tệ. Người ta gọi trường hợp trên là overfitting.\nNhóm nghiên cứu AlexNet sử dụng nhiều phương pháp khác nhau để giảm overfitting.\nData Augmentation Việc sử dụng nhiều biến thể khác nhau của một bức hình có thể giúp ngăn mô hình không bị overfitting. Với việc sử dụng nhiều biến thể của 1 bức hình, bạn bắt ép mô hình không học vẹt dữ liệu. Có nhiều cách khác nhau để sinh ra dữ liệu mới dựa vào dữ liệu có sẵn. Một vài các mà nhóm AlexNet đã sử dụng là.\nData Augmentation by Mirroring Ý tưởng của việc này là lấy ảnh trong gương của một bức hình (ảnh ảo). Nhìn vào ảnh bên dưới, bên trái là hình gốc của con mèo trong tập huấn luyện, bên phải là ảnh của con mèo khi thêm hiệu ứng hình qua gương (đơn giản là xoay qua trục y là được ) Data Augmentation by Random Crops Việc lựa chọn vị trí ảnh gốc một cách ngẫu nhiên cũng giúp chúng ta có thêm một ảnh khác so với ảnh gốc ban đầu.\nNhóm tác giả của AlexNet rút trích ngẫu nhiên bức ảnh có kích thước 227x227 từ bức ảnh 256x256 ban đầu làm input dầu vào cho mô hình. Bằng cách này, chúng ta có thể tăng số lượng dữ liệu lên gấp 2048 lần bằng việc sử dụng cách này.\nBốn bức ảnh được crop ngẫu nhiên ở trên thoạt nhìn có vẻ giống nhau, nhưng thực chất không phải như vậy.\nVới việc sử dụng Data Augmentation, chúng ta đang bố gắng dạy cho mô hình rằng với việc nhìn hình con mèo qua gương, nó vẫn là con mèo, hoặc hình hình con mèo ở bất kỳ góc độ nào thì nó vẫn là nó.\nDropout Với gần 60 triệu tham số trong tập huấn luyện, việc overfitting xảy ra là điều dễ hiểu. Các tác giả của AlexNet đã thực nghiệm nhiều cách nữa để giảm overfitting. Họ sử dụng một kỹ thuật gọi là dropout - kỹ thuật này được giới thiệu ở bài báo khác của G.E. Hintol vào năm 2012. Kỹ thuật này khá đơn giản, một neural sẽ có xác suất bị loại khỏi mô hình là 0.5. Khi một neural bị loại khỏi mô hình, nó sẽ không được tham qia vào quá trình lan truyền tiến hoặc lan truyền ngược. Cho nên, mỗi giá trị input sẽ đi qua một kiến trúc mạng khác nhau. Như mô tả ở hình động ở dưới, kết quả là giá trị của tham số trọng số sẽ tốt hơn và khó bị overfitting hơn. Trong quá trình test, toàn bộ network được sử dụng, không có dropout, tuy nhiên, giá trị output sẽ scaled bởi tham số 0.5 tương ứng với những neural không sử dụng trong quá trình trainning. Với việc sử dụng dropout, chúng ta sẽ tăng gấp đôi lần lặp cần thiết để đạt được độ hội tụ, nhưng khi không sử dụng dropout, mạng AlexNet rất dễ bị overfitting.\nNgày nay, chuẩn hoá dropout là một yếu tố không thể thiếu và các mô hình sử dụng nó thường có kết quả tốt hơn so với mô hình tương tự không sử dụng dropout. Chúng ta sẽ bàn sâu hơn về dropout ở một bài khác trong tương lai.\nTham khảo\nImageNet Classification with Deep Convolutional Neural Networks by Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton, 2012\nhttps://www.learnopencv.com/understanding-alexnet/\n","date":"Jun 15, 2018","img":"","permalink":"/blog/2018-06-15-understanding-alexnet/","series":null,"tags":["Machine learning","Deeplearning","AlexNet"],"title":"Tìm Hiểu Về Mạng Neural Network AlexNet"},{"categories":null,"content":"Chapter 9: References Introduction to References Declaring and using references Comparing pointers and references References and const\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/10_references/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 10: Character Manipulation and Strings Introduction to Strings Character Manipulation C-string manipulation C-String concatenation and copy Introducing std::string Declaring and using std::string\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/11_string/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 11: Functions The One Definition Rule First Hand on C++ Functions Function Declaration and Function Definitions Multiple Files - Compilation Model Revisited Pass by value Pass by pointer Pass by reference\nChapter 12: Getting Things out of functions Introduction to getting things out of functions Input and output parameters Returning from functions by value\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/12_function/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 13: Function Overloading Function Overloading Introduction Overloading with different parameters\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/13_function_overloading/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 14: Lambda functions Introduction to Lambda Functions Declaring and using lambda functions Capture lists Capture all in context Summary\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/14_lambda_function/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 15: Function Templates Introduction to function templates Trying out function templates Template type deduction and explicit arguments Template parameters by reference Template specialization\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/15_function_template/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 16: C++20 Concepts Crash course Introduction to C++20 Concepts Using C++20 Concepts Building your own C++20 Concepts Zooming in on the requires clause Combining C++20 Concepts C++20 Concepts and auto\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/16_concept/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 17: Classes Introduction to classes Your First Class C++ Constructors Defaulted constructors Setters and Getters Class Across Multiple Files Arrow pointer call notation Destructors Order of Constructor Destructor Calls The this Pointer struct Size of objects\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/17_class/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 18: Inheritance Introduction to Inheritance First try on Inheritance Protected members Base class access specifiers : Zooming in Base class access specifiers - A demo Closing in on Private Inheritance Resurrecting Members Back in Context Default Constructors with Inheritance Custom Constructors With Inheritance Copy Constructors with Inheritance Inheriting Base Constructors Inheritance and Destructors Reused Symbols in Inheritance\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/18_inheritance/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 19: Polymorphism Introduction to Polymorphism Static Binding with Inheritance Dynamic binding with virtual functions Size of polymorphic objects and slicing Polymorphic objects stored in collections (array) Override Overloading, overriding and function hiding Inheritance and Polymorphism at different levels Inheritance and polymorphism with static members Final Virtual functions with default arguments Virtual Destructors Dynamic casts Polymorphic Functions and Destructors Pure virtual functions and abstract classes Abstract Classes as Interfaces\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/19_polymorphism/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 3: Variables and data types Variables and data types Introduction Number Systems Integer types : Decimals and Integers Integer Modifiers Fractional Numbers Booleans Characters And Text Auto Assignments Variables and data types summary\nBài 3: Xây dựng chương trình C++ đầu tiên với Visual Studio 2015\nMột số kiến thức cần lưu ý Cách tạo và biên dịch chương trình C++ đầu tiên trên Visual Studio Một số vấn đề thường gặp đối với lập trình viên mới Bài 4: Cấu trúc một chương trình C++ (Structure of a program)\nCấu trúc của một chương trình C++ Cú pháp và lỗi cú pháp trong C++ (Syntax and syntax errors) Bài 5: Ghi chú trong C++ (Comments in C++)\nCú pháp comment trong C++ Một số kinh nghiệm khi comment trong lập trình Bài 6: Biến trong C++ (Variables in C++)\nBiến trong C++ Khởi tạo biến trong C++ (Defining a variable) Định nghĩa biến ở đâu (Where to define variables) Bài 7: Số tự nhiên và Số chấm động trong C++ (Integer, Floating point)\nTổng quan về kiểu dữ liệu cơ bản trong C++ Kiểu số nguyên (Integer) Số chấm động (Floating point numbers) Bài 8: Kiểu ký tự trong C++ (Character)\nTổng quan về kiểu ký tự (Character) Khai báo, khởi tạo và gán giá trị một biến ký tự In ký tự ra màn hình In ký tự từ số nguyên và ngược lại (Casting) Escape sequences Newline ‘\\n’ và std::endl Dấu nháy đơn ‘K’ và dấu nháy kép “Kteam” Bài 9: Kiểu luận lý và cơ bản về Câu điều kiện If (Boolean and If statements)\nTổng quan về kiểu luận lý (Boolean) Cơ bản về câu điều kiện If và Boolean Bài 10: Nhập, Xuất và Định dạng dữ liệu trong C++ (Input and Output)\nXuất dữ liệu với std::cout trong C++ Nhập dữ liệu với std::cin trong C++ Định dạng dữ liệu nhập xuất trong C++ Bài 11: Hằng số trong C++ (Constants)\nTổng quan hằng số (Constants) Hằng số với từ khóa const Hằng số với chỉ thị tiền xử lý #define Nên định nghĩa hằng số ở đâu Bài 12: Toán tử số học, toán tử tăng giảm, toán tử gán số học trong C++ (Operators)\nTổng quan về toán tử Toán tử số học trong C++ (Arithmetic operators) Toán tử gán số học trong C++ (Arithmetic assignment operators) Bài 13: Toán tử quan hệ, logic, bitwise, misc và độ ưu tiên toán tử trong C++\nToán tử quan hệ trong C++ (Relational operators) Toán tử logic trong C++ (Logical operators) Toán tử trên bit trong C++ (Bitwise operators) Các toán tử hỗn hợp trong C++ (Misc Operators) Độ ưu tiên và quy tắc kết hợp toán tử trong C++ Bài 14: Cơ bản về chuỗi ký tự trong C++ (An introduction to std::string)\nTổng quan về chuỗi ký tự (std::string) Khai báo, khởi tạo và gán giá trị một chuỗi ký tự Xuất một chuỗi ký tự (string output): Nhập một chuỗi ký tự (string input) Một số thao tác cơ bản với chuỗi ký tự Bài 15: Biến cục bộ trong C++ (Local variables in C++)\nTổng quan về tầm vực của biến Biến cục bộ (Local variables) Bài 16: Biến toàn cục trong C++ (Global variables in C++)\nTổng quan về tầm vực của biến Biến toàn cục (Global variables) Sử dụng biến toàn cục là nguy hiểm Khi nào cần sử dụng biến toàn cục (non-const) Bài 17: Biến tĩnh trong C++ (Static variables in C++)\nTổng quan về biến tĩnh (static variables) Khi nào nên sử dụng biến tĩnh Bài 18: Ép kiểu ngầm định trong C++ (Implicit type conversion in C++)\nTổng quan về ép kiểu dữ liệu Ép kiểu ngầm định trong C++ (Implicit type conversion) Bài 19: Ép kiểu tường minh trong C++ (Explicit type conversion in C++)\nÉp kiểu tường minh trong C++ (Explicit type conversion) Bài 20: Cơ bản về Hàm và Giá trị trả về (Basic of functions and return values)\nTổng quan về hàm (functions overview) Giá trị trả về (return values) Giá trị trả về của kiểu void (return values of type void) Bài 21: Truyền Giá Trị cho Hàm (Passing Arguments by Value)\nTham số và đối số của hàm (Function parameters and arguments) Truyền giá trị cho hàm (Passing arguments by value) Tổng kết về phương pháp truyền giá trị cho hàm (Passing argument by value) Bài 22: Truyền Tham Chiếu cho Hàm (Passing Arguments by Reference)\nTruyền tham chiếu cho hàm (Passing arguments by reference) Truyền tham chiếu hằng (Pass by const reference) Tổng kết về phương pháp truyền tham chiếu cho hàm (Passing arguments by reference) Bài 23: Tiền khai báo và Định nghĩa Hàm (Forward declarations and Definitions of Functions)\nLỗi “identifier not found” Tiền khai báo và nguyên mẫu hàm (Forward declaration and function prototypes) Khai báo và định nghĩa trong C++ (Declarations and definitions in C++) Bài 24: Giới thiệu về cấu trúc điều khiển (Control flow introduction)\nTổng quan về cấu trúc điều khiển trong C++ Câu lệnh dừng (halt) Câu lệnh nhảy (Jumps) Cấu trúc rẽ nhánh có điều kiện (Conditional branches) Cấu trúc vòng lặp (Loops) Xử lý ngoại lệ (Exceptions handling) Bài 25: Câu điều kiện If và Toán tử điều kiện (If statements and Conditional operator)\nCâu điều kiện If Toán tử điều kiện (Conditional operator) Bài 26: Câu điều kiện Switch trong C++ (Switch statements)\nCâu điều kiện Switch (Switch statements) Khai báo và khởi tạo biến bên trong case statement Bài 27: Câu lệnh Goto trong C++ (Goto statements)\nTổng quan về câu lệnh Goto trong C++ Một số vấn đề của câu lệnh Goto Bài 28: Vòng lặp While trong C++ (While statements)\nTổng quan về cấu trúc vòng lặp Vòng lặp while (while statements) Bài 29: Vòng lặp Do while trong C++ (Do while statements)\nVòng lặp do while (do while statements) Bài 30: Vòng lặp For trong C++ (For statements)\nVòng lặp for (for statements) Bài 31: Từ khóa Break and continue trong C++\nTừ khóa break Từ khóa continue Bài 32: Phát sinh số ngẫu nhiên trong C++ (Random number generation)\nTổng quan về phát sinh số ngẫu nhiên Phát sinh số ngẫu nhiên trong C++ Phát sinh số ngẫu nhiên trong C++ 11 Bài 33: Mảng 1 chiều trong C++ (Arrays)\nTại sao lại sử dụng mảng? Tổng quan về mảng 1 chiều Khai báo và khởi tạo mảng 1 chiều Xuất các phần tử mảng 1 chiều Nhập dữ liệu cho mảng 1 chiều Phát sinh dữ liệu ngẫu nhiên cho mảng 1 chiều Bài 34: Các thao tác trên Mảng một chiều\nTruyền mảng vào hàm (passing arrays to functions) Nhập và xuất mảng 1 chiều Sao chép mảng 1 chiều Tìm kiếm phần tử trong mảng Sắp xếp mảng 1 chiều Thêm và xóa một phần tử trong mảng Bài 35: Mảng 2 chiều trong C++ (Two-dimensional arrays)\nMảng 2 chiều là gì? Khai báo và khởi tạo mảng 2 chiều Xuất các phần tử mảng 2 chiều Nhập các phần tử mảng 2 chiều Bài 36: Các thao tác trên Mảng 2 chiều\nTruyền mảng vào hàm (passing arrays to functions) Nhập và xuất mảng 2 chiều Tính tổng các phần tử trong mảng Tìm giá trị lớn nhất của mảng 2 chiều Bài 37: Mảng ký tự trong C++ (C-style strings)\nMảng ký tự (C-style strings) là gì? Khai báo và khởi tạo mảng ký tự (C-style strings) Xuất mảng ký tự (C-style strings) với std::cout Nhập mảng ký tự (C-style strings) với std::cin Bài 38: Các thao tác trên Mảng ký tự (C-style strings)\nMột số thao tác với mảng ký tự (C-style strings)\nhttps://www.freecodecamp.org/news/learn-c-with-free-31-hour-course/\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/4_variable_and_datatype/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 4: Operations on Data Introduction on Data operations Basic Operations Precedence and Associativity Prefix/Postfix Increment \u0026amp; Decrement Compound Assignment Operators Relational Operators Logical Operators Output formatting Numeric Limits Math Functions Weird Integral Types Data Operations Summary\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/5_operator_on_data/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 5: Flow Control Flow Control Introduction If Statements Else If Switch Ternary Operators Flow Control Summary\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/6_flow_control/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 6: Loops Loops Introduction For Loop While Loop Do While Loop\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/7_loop/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 7: Arrays Introduction to Arrays Declaring and using arrays Size of an array Arrays of characters Array Bounds\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/8_array/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 8: Pointers Introduction to Pointers Declaring and using pointers Pointer to char Program Memory Map Revisited Dynamic Memory Allocation Dangling Pointers When new Fails Null Pointer Safety Memory Leaks Dynamically allocated arrays\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/9_array/","series":null,"tags":null,"title":""},{"categories":null,"content":"⌨️ (0:00:00) Introduction to data structures ⌨️ (0:06:33) Data Structures: List as abstract data type ⌨️ (0:19:40) Introduction to linked list ⌨️ (0:36:50) Arrays vs Linked Lists ⌨️ (0:49:05) Linked List - Implementation in C/C++ ⌨️ (1:03:02) Linked List in C/C++ - Inserting a node at beginning ⌨️ (1:15:50) Linked List in C/C++ - Insert a node at nth position ⌨️ (1:31:04) Linked List in C/C++ - Delete a node at nth position ⌨️ (1:43:32) Reverse a linked list - Iterative method ⌨️ (1:57:21) Print elements of a linked list in forward and reverse order using recursion ⌨️ (2:11:43) Reverse a linked list using recursion ⌨️ (2:20:38) Introduction to Doubly Linked List ⌨️ (2:27:50) Doubly Linked List - Implementation in C/C++ ⌨️ (2:43:09) Introduction to stack ⌨️ (2:51:34) Array implementation of stacks ⌨️ (3:04:42) Linked List implementation of stacks ⌨️ (3:15:39) Reverse a string or linked list using stack. ⌨️ (3:32:03) Check for balanced parentheses using stack ⌨️ (3:46:14) Infix, Prefix and Postfix ⌨️ (3:59:14) Evaluation of Prefix and Postfix expressions using stack ⌨️ (4:14:00) Infix to Postfix using stack ⌨️ (4:32:17) Introduction to Queues ⌨️ (4:41:35) Array implementation of Queue ⌨️ (4:56:33) Linked List implementation of Queue ⌨️ (5:10:48) Introduction to Trees ⌨️ (5:26:37) Binary Tree ⌨️ (5:42:51) Binary Search Tree ⌨️ (6:02:17) Binary search tree - Implementation in C/C++ ⌨️ (6:20:52) BST implementation - memory allocation in stack and heap ⌨️ (6:33:55) Find min and max element in a binary search tree ⌨️ (6:39:41) Find height of a binary tree ⌨️ (6:46:50) Binary tree traversal - breadth-first and depth-first strategies ⌨️ (6:58:43) Binary tree: Level Order Traversal ⌨️ (7:10:05) Binary tree traversal: Preorder, Inorder, Postorder ⌨️ (7:24:33) Check if a binary tree is binary search tree or not ⌨️ (7:41:01) Delete a node from Binary Search Tree ⌨️ (7:59:27) Inorder Successor in a binary search tree ⌨️ (8:17:23) Introduction to graphs ⌨️ (8:34:05) Properties of Graphs ⌨️ (8:49:19) Graph Representation part 01 - Edge List ⌨️ (9:03:03) Graph Representation part 02 - Adjacency Matrix ⌨️ (9:17:46) Graph Representation part 03 - Adjacency List\n","date":"Jan 1, 0001","img":"","permalink":"/courses/data_structures/","series":null,"tags":null,"title":""},{"categories":null,"content":"Thông thường, chúng ta đọc nội dung của file sau khi mở file.\nGiả sử chúng ta có file \u0026ldquo;test.txt\u0026rdquo; có nội dung như bên dưới:\n1This file is testing. 2Good Luck! Hàm mở file ra được viết như thế này:\nf = open(\u0026ldquo;test.txt\u0026rdquo;,\u0026lsquo;r\u0026rsquo;,encoding = \u0026lsquo;utf-8\u0026rsquo;)\nĐể đọc nội dung file, python hỗ trợ các hàm là read, readline, readlines, mỗi hàm sẽ có tác dụng khác nhau\n hàm read sẽ trả về toàn bộ nội dung của file  f.read()\n'This file is testing.\\nGood Luck!\\n'\n hàm readline, mỗi lần đọc sẽ trả về 1 dòng trong file  f.readline()\n\u0026lsquo;This file is testing.\\n\u0026rsquo;\nKhi gọi readline một lần nữa, chương trình sẽ trả về dòng tiếp theo\nf.readline()\n\u0026lsquo;Good Luck!\\n\u0026rsquo;\n hàm readlines sẽ trả về một mảng các chuỗi, mỗi chuỗi tương ứng một dòng trong file  f.readlines()\n[\u0026lsquo;This file is testing.\\n\u0026rsquo;, \u0026lsquo;Good Luck!\\n\u0026rsquo;]\n","date":"Jan 1, 0001","img":"","permalink":"/courses/python/io/","series":null,"tags":null,"title":""},{"categories":null,"content":"","date":"Jan 1, 0001","img":"","permalink":"/contact/","series":null,"tags":null,"title":"Contact Us"},{"categories":null,"content":"","date":"Jan 1, 0001","img":"","permalink":"/faq/","series":null,"tags":null,"title":"FAQs"},{"categories":null,"content":"","date":"Jan 1, 0001","img":"","permalink":"/offline/","series":null,"tags":null,"title":"Offline"},{"categories":null,"content":"Tools sinh password\nTools sinh số ngẫu nhiên\n","date":"Jan 1, 0001","img":"","permalink":"/tools/","series":null,"tags":null,"title":"Tools"}]