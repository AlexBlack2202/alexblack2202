<!DOCTYPE HTML>

<html>

    <head>

	<script defer="defer" async="async" src="https://www.googleoptimize.com/optimize.js?id=OPT-52RT2BV"></script>
        <script type="application/ld+json">
    {
        "@context" : "http://schema.org",
        "@type" : "BlogPosting",
        "mainEntityOfPage": {
             "@type": "WebPage",
             "@id": "/"
        },
        "articleSection" : "blog",
        "name" : "Mask R-CNN trong bài toán nhận dạng và phân vùng đối tượng",
        "headline" : "Mask R-CNN trong bài toán nhận dạng và phân vùng đối tượng",
        "description" : "Ở bài viết này, chúng ta đề cập đến vấn đề sử dụng Mask R-CNN để nhận dạng và phân vùng đối tượng.",
        "inLanguage" : "en",
        "author" : "",
        "creator" : "",
        "publisher": "",
        "accountablePerson" : "",
        "copyrightHolder" : "",
        "copyrightYear" : "2018",
        "datePublished": "2018-10-08 00:19:00 &#43;0300 &#43;0300",
        "dateModified" : "2018-10-08 00:19:00 &#43;0300 &#43;0300",
        "url" : "/blog/2018-10-08-mask-rnn/",
        "wordCount" : "1598",
        "keywords" : [ "Machine learning","Deeplearning","Spark","Blog" ]
    }
    </script>
        
            
                <title>Mask R-CNN trong bài toán nhận dạng và phân vùng đối tượng</title>
            
        

        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        
		<meta name="generator" content="Phạm Duy Tùng" />
        <meta property="fb:pages" content="1244186728962161" />

        
  
    
  

  

  
  
  
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content='/favicon/mstile.png'>
  <meta name="application-name" content="Phạm Duy Tùng Machine Learning Blog">
  <meta name="msapplication-tooltip" content="Blog ML của Phạm Duy Tùng và Đặng Thị Hằng">
   
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">



        
            <meta name="author" content="Phạm Duy Tùng">
        
        
            <meta name="description" content="Ở bài viết này, chúng ta đề cập đến vấn đề sử dụng Mask R-CNN để nhận dạng và phân vùng đối tượng.">
        

        <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Mask R-CNN trong bài toán nhận dạng và phân vùng đối tượng"/>
<meta name="twitter:description" content="Ở bài viết này, chúng ta đề cập đến vấn đề sử dụng Mask R-CNN để nhận dạng và phân vùng đối tượng."/>
<meta name="twitter:site" content="@example"/>

        <meta property="og:title" content="Mask R-CNN trong bài toán nhận dạng và phân vùng đối tượng" />
<meta property="og:description" content="Ở bài viết này, chúng ta đề cập đến vấn đề sử dụng Mask R-CNN để nhận dạng và phân vùng đối tượng." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/2018-10-08-mask-rnn/" /><meta property="article:published_time" content="2018-10-08T00:19:00&#43;03:00"/>
<meta property="article:modified_time" content="2018-10-08T00:19:00&#43;03:00"/>

        <meta property="og:image" content="//images/logo.png">
        <meta property="og:image:type" content="image/png">
        <meta property="og:image:width" content="512">
        <meta property="og:image:height" content="512">
        
<meta itemprop="name" content="Mask R-CNN trong bài toán nhận dạng và phân vùng đối tượng">
<meta itemprop="description" content="Ở bài viết này, chúng ta đề cập đến vấn đề sử dụng Mask R-CNN để nhận dạng và phân vùng đối tượng.">


<meta itemprop="datePublished" content="2018-10-08T00:19:00&#43;03:00" />
<meta itemprop="dateModified" content="2018-10-08T00:19:00&#43;03:00" />
<meta itemprop="wordCount" content="1598">



<meta itemprop="keywords" content="Machine learning,Deeplearning,Spark," />

        

        
            
        

        
        
          
			 <link rel="stylesheet" type="text/css" href="/css/bootstrap.min.css">


          
            
        

        
            
                
            
        


  
    
    <link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/styles/xcode.min.css' rel='stylesheet' type='text/css' />
  


      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-114911596-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

	  <style>
	  
	  body{
font-family: Helvetica,Arial,sans-serif;
}

.card{
	margin-bottom: 10px;
}

#disqus_thread{
padding: 0 5px;
}

.item-header{
padding: 0;
}

.single-content-img{
width: 100%;
    max-height: 450px !important;
    background-size: cover;
    display: block;
    background-position: center;
}

.thumbnail {
    position: relative;
}

.caption {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
	background: rgba(0, 0, 0, 0.25);
	text-align:left;
}

.caption .title{
	font-size: 1.6em;
    line-height: 1.4em;
    top: 0;
	margin-left:20px;
	margin-top:20px;
	
}

.caption .title-caption{
margin-left:10px;
}

#content p{
text-align: justify;
    font-size: 16px;
    <!-- color: #333;-->	
    line-height: 28px;
}

#content img{
	display: block;
    margin-left: auto;
margin-right: auto;
max-width:98%;
}

img + strong {
    font-style: normal;
    display: inherit;
    text-align: center;
}
.img-news{
max-height:150px;
width:100%;
}

.news-tittle{
	padding-top:15px;
	text-align:justify;
}

.author{
	color: orange;
}
.author-inline{
	color: orange;
}

.adv{
height:18px;
}


.hljs{
    white-space: pre-wrap;
    white-space: -moz-pre-wrap;
    white-space: -pre-wrap;
    white-space: -o-pre-wrap;
    word-wrap: break-word;}
.titledetail {
    display: block;
    overflow: hidden;
    line-height: 53px;
    font-size: 45px;
    font-family: 'Roboto Condensed',sans-serif;
    font-weight: 600;

    margin: auto;
	padding: 0 ;
}

.newsrelate {
    display: block;
    overflow: hidden;
	 list-style:none;
}
a ,a:hover{
    text-decoration: none;
}
.newsrelate li {
    float: left;
    overflow: hidden;
    width: 30%;
    margin-left: 2.5%;
    margin-bottom: 15px;
}

.newsrelate li a {
    display: block;
    overflow: hidden;
}

.userdetail {
    display: block;
    overflow: hidden;
    margin: 0 10px 0 0;
    padding: 15px 0;
}
.newsrelate li h3 {
    display: block;
    overflow: hidden;
    line-height: 1.3em;
    font-size: 16pt;
    line-height: 22px;
    font-weight: 300;
    font-family: Arial,Helvetica,sans-serif;
    width: auto;
    margin: 5px auto;
}

.titlerelate {
    overflow: hidden;
    font-size: 18px;
    font-weight: 600;
    font-family: 'Roboto Condensed',sans-serif;
    line-height: 32px;
    text-transform: uppercase;
}
article .captionnews {
    color: #999;
    font-size: 14px;
    font-style: italic;
    padding: 10px;
    text-align: center;
    margin-bottom: 15px;
}

.bgtrans h1 {
    display: block;
    overflow: hidden;
    font-size: 45px;
    line-height: 55px;
    margin: auto;
    left: 0;
    right: 0;
    bottom: 50px;
    font-family: 'Roboto Condensed',sans-serif;
    font-weight: 600;
}

.bgcover {
    display: block;
    overflow: hidden;
    height: 450px;
    background: no-repeat center center;
    -webkit-background-size: cover;
    -moz-background-size: cover;
    -o-background-size: cover;
    background-size: cover;
    position: relative;
    margin-bottom: -65px;
}
.bgcover .bgtrans .userdetail {
    width: 800px;
    margin: auto;
    position: absolute;
    left: 0;
    right: 0;
    bottom: 10px;
}
.userdetail {
    display: block;
    overflow: hidden;
    margin: 0 10px 0 0;
    padding: 15px 0;
}

.amlich{border-collapse:collapse;font-size:14px;font-family:Roboto,sans-serif}.calendar{font-size:12px}.calendar td{background-color:#e9eff3}.calendar-month{background-color:#1e8cbe!important;color:#fff;text-shadow:0 0 3px #000;padding:6px;font-weight:700;text-transform:uppercase;font-size:14px!important}.amlich-tennam{text-align:center;font-weight:700;color:#000;background-color:#ccc;font-size:14px;font-family:Roboto,sans-serif}.amlich .calendar-month,.amlich .calendar-b-left,.amlich .calendar-b-right{text-align:center;padding:4px 0;font-size:11px}.amlich .calendar-day{text-align:center;font-weight:700}.amlich .calendar-day .day-num{font-size:80px;font-family:Roboto,sans-serif;line-height:100%;color:#31708f}.amlich .lunar-day-num{font-size:44px;line-height:100%;font-weight:700;color:#3c763d}.amlich .calendar-holiday,.amlich .calendar-hoangdao{padding:0 4px 4px;font-size:11px;text-align:center}.amlich .calendar-holiday{color:#a94442;font-weight:700}.amlich a{text-decoration:none;color:#fff}.amlich a:hover{color:red}.amlich .tenthang,.amlich .navi-l,.amlich .navi-r{text-align:center;padding:6px;background-color:#1e8cbe;color:#fff;font-weight:700}.amlich .tenthang{text-shadow:0 0 3px #000}.amlich .navi-l{font-size:12px}.amlich .navi-r{font-size:12px}.amlich .ngaytuan{text-align:center;color:#303;background-color:#ddd;padding:3px;width:14.286%;font-size:10px;font-weight:700}.amlich .ngaythang,.amlich .homnay,.amlich .tet,.amlich .leam,.amlich .leduong{cursor:pointer;border-bottom:solid 1px #eee;padding:3px;width:14.286%}.amlich .ngaythang div,.amlich .homnay div,.amlich .tet div,.amlich .leam div,.amlich .leduong div{line-height:110%}.amlich .ngaythang{color:#5a5c5b}.amlich tr:nth-child(odd) td.ngaythang:nth-child(odd){background-color:#f9f9f9}.amlich tr:nth-child(odd) td.ngaythang:nth-child(even){background-color:#fff}.amlich tr:nth-child(even) td.ngaythang:nth-child(odd){background-color:#fff}.amlich tr:nth-child(even) td.ngaythang:nth-child(even){background-color:#f9f9f9}.amlich tr td.ngaythang:hover{background-color:#f5f5f5!important}.amlich .homnay{background-color:#fcf8e3;color:#fff}.amlich .homnay:hover{background-color:#faf2cc}.amlich .tet{background-color:#f2dede}.amlich .tet:hover{background-color:#ebcccc}.amlich .leam{background-color:#d9edf7}.amlich .leam:hover{background-color:#c4e3f3}.amlich .leduong{background-color:#dff0d8}.amlich .leduong:hover{background-color:#d0e9c6}.amlich .am{text-align:right;font-size:75%;color:#554c00}.amlich .am2{text-align:right;font-size:75%;color:#337ab7;font-weight:700}.amlich .t2t6{text-align:left;color:#5a5c5b;font-weight:700}.amlich .t7{font-weight:700;text-align:left;color:blue}.amlich .cn{font-weight:700;text-align:left;color:red}
	  </style>

    </head>
    <body class="text-dark bg-light">
<script  async defer>
  window.fbAsyncInit = function() {
    FB.init({
      appId      : '1546237302193677',
      xfbml      : true,
      version    : 'v5.0'
    });
    FB.AppEvents.logPageView();
  };

  (function(d, s, id){
     var js, fjs = d.getElementsByTagName(s)[0];
     if (d.getElementById(id)) {return;}
     js = d.createElement(s); js.id = id;
     js.src = "https://connect.facebook.net/en_US/sdk.js";
     fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
</script>
<div id="fb-root"></div>
<script async defer crossorigin="anonymous" src="https://connect.facebook.net/vi_VN/sdk.js#xfbml=1&version=v5.0&appId=1853483258232756&autoLogAppEvents=1"></script>
      
      

    
    
<header id="header"  style="background: #790014; color: hsla(0,0%,100%,1);">
<div class="container">
    <nav class="navbar navbar-expand-md navbar-dark">
	
	<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
        <ul class="navbar-nav mr-auto">
            
                <li class="nav-item">
                    <a class='nav-link' href="/blog">
                            <i class="fa fa-home active">&nbsp;</i>Home
                    </a>
                </li>
            
                <li class="nav-item">
                    <a class='nav-link' href="/xem-truyen/">
                            <i class="fa fa-id-card-o">&nbsp;</i>Truyện
                    </a>
                </li>
            
        </ul>
    </nav>
    </div></div>
</header>


   
    
	<div class="container">
	<div class="adv"></div>
	<div class="row">
    <main role="main"  class="col-md-9 border-right" >
	
        
        
          


        
		 <div class="header">
           
		<div class="bgtrans">
		 <h1 class="titledetail">Mask R-CNN trong bài toán nhận dạng và phân vùng đối tượng</h1>
		<div class="userdetail">
			 
			  <time class="published" 
            datetime='2018-10-08'>
            08/10/2018</time>
		 - 
			   <span class="author">Phạm Duy Tùng</span>
			   
			</div>	
		
			</div>
			</div>
  <div class="fb-like" data-share="true"  data-width="800"  data-show-faces="true">
</div>
			
		
		
			 
            
        
       



  

  
 
  <div style="    margin: 0;
    border-bottom: 1px dotted #d9d9d9;
    padding-bottom: 20px;"></div>
  <div id="content">
    

<h2 id="lời-mở-đầu">Lời mở đầu</h2>

<p>Phân vùng đối tượng là một bài toán khá phổ biến trong lĩnh vực computer vision. Trong open cv có hỗ trợ cho chúng ta một số hàm để phân vùng đối tượng rất dễ sử dụng. Đặc điểm chung của các hàm này là độ chính xác không được cao cho lắm. Ở bài viết này, chúng ta sẽ tìm hiểu cách sử dụng mô hình pretrain của DNN để phân vùng các đối tượng trong ảnh.</p>

<h2 id="sử-dụng-pretrain-model">Sử dụng pretrain model</h2>

<p>Đầu tiên, các bạn download file pretrain model, giải nén ra và để ở đâu đó trong ổ cứng của máy bạn. Đường dẫn file pretrain model các bạn có thể download ở <a href="http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz">http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz</a>. Các bạn có thể download các file pretrain khác nếu có hứng thú tìm hiểu.</p>

<p>Tiếp theo, chúng ta sẽ load mô hình lên:</p>

<pre><code class="language-python">import numpy as np
import os
import sys
import tarfile
import tensorflow as tf

from collections import defaultdict
from io import StringIO
from matplotlib import pyplot as plt
from PIL import Image
import PIL.ImageDraw as ImageDraw
import PIL.ImageFont as ImageFont
import cv2

import pprint

import PIL.Image as Image
import PIL.ImageColor as ImageColor

# Model preparation


# Path to frozen detection graph. This is the actual model that is used for the object detection.
PATH_TO_CKPT = 'mask_rcnn_inception_v2_coco_2018_01_28' + '/frozen_inference_graph.pb'

# List of the strings that is used to add correct label for each box.
#PATH_TO_LABELS = 'mscoco_label_map.pbtxt'

NUM_CLASSES = 1


# categories

category_index = {1: {'id': 1, 'name': 'person'},
# 3: {'id': 3, 'name': 'car'},
 }

detection_graph = tf.Graph()
with detection_graph.as_default():
    od_graph_def = tf.GraphDef()
    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
        serialized_graph = fid.read()
        od_graph_def.ParseFromString(serialized_graph)
        tf.import_graph_def(od_graph_def, name='')
</code></pre>

<p>Ở đây, mình chỉ demo detect người trong hình, nên mình chỉ để category_index chỉ là &ldquo;person&rdquo;. Thực tế, mô hình COCO hỗ trợ cho chúng ta nhận dạng 90 loại đối tượng khác nhau, các bạn có nhu cầu tìm hiểu thì thay bằng đoạn mã sau:</p>

<pre><code class="language-python">category_index = {1: {'id': 1, 'name': 'person'},
 2: {'id': 2, 'name': 'bicycle'},
 3: {'id': 3, 'name': 'car'},
 4: {'id': 4, 'name': 'motorcycle'},
 5: {'id': 5, 'name': 'airplane'},
 6: {'id': 6, 'name': 'bus'},
 7: {'id': 7, 'name': 'train'},
 8: {'id': 8, 'name': 'truck'},
 9: {'id': 9, 'name': 'boat'},
 10: {'id': 10, 'name': 'traffic light'},
 11: {'id': 11, 'name': 'fire hydrant'},
 13: {'id': 13, 'name': 'stop sign'},
 14: {'id': 14, 'name': 'parking meter'},
 15: {'id': 15, 'name': 'bench'},
 16: {'id': 16, 'name': 'bird'},
 17: {'id': 17, 'name': 'cat'},
 18: {'id': 18, 'name': 'dog'},
 19: {'id': 19, 'name': 'horse'},
 20: {'id': 20, 'name': 'sheep'},
 21: {'id': 21, 'name': 'cow'},
 22: {'id': 22, 'name': 'elephant'},
 23: {'id': 23, 'name': 'bear'},
 24: {'id': 24, 'name': 'zebra'},
 25: {'id': 25, 'name': 'giraffe'},
 27: {'id': 27, 'name': 'backpack'},
 28: {'id': 28, 'name': 'umbrella'},
 31: {'id': 31, 'name': 'handbag'},
 32: {'id': 32, 'name': 'tie'},
 33: {'id': 33, 'name': 'suitcase'},
 34: {'id': 34, 'name': 'frisbee'},
 35: {'id': 35, 'name': 'skis'},
 36: {'id': 36, 'name': 'snowboard'},
 37: {'id': 37, 'name': 'sports ball'},
 38: {'id': 38, 'name': 'kite'},
 39: {'id': 39, 'name': 'baseball bat'},
 40: {'id': 40, 'name': 'baseball glove'},
 41: {'id': 41, 'name': 'skateboard'},
 42: {'id': 42, 'name': 'surfboard'},
 43: {'id': 43, 'name': 'tennis racket'},
 44: {'id': 44, 'name': 'bottle'},
 46: {'id': 46, 'name': 'wine glass'},
 47: {'id': 47, 'name': 'cup'},
 48: {'id': 48, 'name': 'fork'},
 49: {'id': 49, 'name': 'knife'},
 50: {'id': 50, 'name': 'spoon'},
 51: {'id': 51, 'name': 'bowl'},
 52: {'id': 52, 'name': 'banana'},
 53: {'id': 53, 'name': 'apple'},
 54: {'id': 54, 'name': 'sandwich'},
 55: {'id': 55, 'name': 'orange'},
 56: {'id': 56, 'name': 'broccoli'},
 57: {'id': 57, 'name': 'carrot'},
 58: {'id': 58, 'name': 'hot dog'},
 59: {'id': 59, 'name': 'pizza'},
 60: {'id': 60, 'name': 'donut'},
 61: {'id': 61, 'name': 'cake'},
 62: {'id': 62, 'name': 'chair'},
 63: {'id': 63, 'name': 'couch'},
 64: {'id': 64, 'name': 'potted plant'},
 65: {'id': 65, 'name': 'bed'},
 67: {'id': 67, 'name': 'dining table'},
 70: {'id': 70, 'name': 'toilet'},
 72: {'id': 72, 'name': 'tv'},
 73: {'id': 73, 'name': 'laptop'},
 74: {'id': 74, 'name': 'mouse'},
 75: {'id': 75, 'name': 'remote'},
 76: {'id': 76, 'name': 'keyboard'},
 77: {'id': 77, 'name': 'cell phone'},
 78: {'id': 78, 'name': 'microwave'},
 79: {'id': 79, 'name': 'oven'},
 80: {'id': 80, 'name': 'toaster'},
 81: {'id': 81, 'name': 'sink'},
 82: {'id': 82, 'name': 'refrigerator'},
 84: {'id': 84, 'name': 'book'},
 85: {'id': 85, 'name': 'clock'},
 86: {'id': 86, 'name': 'vase'},
 87: {'id': 87, 'name': 'scissors'},
 88: {'id': 88, 'name': 'teddy bear'},
 89: {'id': 89, 'name': 'hair drier'},
 90: {'id': 90, 'name': 'toothbrush'}} 
</code></pre>

<p>Tiếp theo, chúng ta sẽ load một số hàm giúp hỗ trợ việc hậu xử lý ảnh để vẽ các mask cho chúng ta xem trực quan hơn.</p>

<pre><code class="language-python">
    draw  =  ImageDraw.Draw(image)
    im_width,  im_height  =  image.size
    if  use_normalized_coordinates:
        (left,  right,  top,  bottom)  =  (xmin  *  im_width,  xmax  *  im_width,
                                                                    ymin  *  im_height,  ymax  *  im_height)
    else:
        (left,  right,  top,  bottom)  =  (xmin,  xmax,  ymin,  ymax)
    draw.line([(left,  top),  (left,  bottom),  (right,  bottom),
                          (right,  top),  (left,  top)],  width=thickness,  fill=color)
    try:
        font  =  ImageFont.truetype('arial.ttf',  24)
    except  IOError:
        font  =  ImageFont.load_default()

    #  If  the  total  height  of  the  display  strings  added  to  the  top  of  the  bounding
    #  box  exceeds  the  top  of  the  image,  stack  the  strings  below  the  bounding  box
    #  instead  of  above.
    display_str_heights  =  [font.getsize(ds)[1]  for  ds  in  display_str_list]
    #  Each  display_str  has  a  top  and  bottom  margin  of  0.05x.
    total_display_str_height  =  (1  +  2  *  0.05)  *  sum(display_str_heights)

    if  top  &gt;  total_display_str_height:
        text_bottom  =  top
    else:
        text_bottom  =  bottom  +  total_display_str_height
    #  Reverse  list  and  print  from  bottom  to  top.
    for  display_str  in  display_str_list[::-1]:
        text_width,  text_height  =  font.getsize(display_str)
        margin  =  np.ceil(0.05  *  text_height)
        draw.rectangle(
                [(left,  text_bottom  -  text_height  -  2  *  margin),  (left  +  text_width,
                                                                                                                    text_bottom)],
                fill=color)
        draw.text(
                (left  +  margin,  text_bottom  -  text_height  -  margin),
                display_str,
                fill='black',
                font=font)
        text_bottom  -=  text_height  -  2  *  margin



def visualize_boxes_and_labels_on_image_array(
        image,
        boxes,
        classes,
        scores,
        category_index,
        instance_masks=None,
        instance_boundaries=None,
        keypoints=None,
        use_normalized_coordinates=False,
        max_boxes_to_draw=20,
        min_score_thresh=.5,
        agnostic_mode=False,
        line_thickness=4,
        groundtruth_box_visualization_color='black',
        skip_scores=False,
        skip_labels=False):

    box_to_display_str_map = collections.defaultdict(list)
    box_to_color_map = collections.defaultdict(str)
    box_to_instance_masks_map = {}
    box_to_instance_boundaries_map = {}
    box_to_keypoints_map = collections.defaultdict(list)
    if not max_boxes_to_draw:
        max_boxes_to_draw = boxes.shape[0]
    #print(boxes)
    for i in range(min(max_boxes_to_draw, boxes.shape[0])):
        if scores is None or scores[i] &gt; min_score_thresh:
            box = tuple(boxes[i].tolist())
        if instance_masks is not None:
            box_to_instance_masks_map[box] = instance_masks[i]
        if instance_boundaries is not None:
            box_to_instance_boundaries_map[box] = instance_boundaries[i]
        if keypoints is not None:
            box_to_keypoints_map[box].extend(keypoints[i])
        if scores is None:
            box_to_color_map[box] = groundtruth_box_visualization_color
        else:
            display_str = ''
            if not skip_labels:
                if not agnostic_mode:
                    if classes[i] in category_index.keys():
                        class_name = category_index[classes[i]]['name']
                    else:
                        class_name = 'N/A'
                    display_str = str(class_name)
            if not skip_scores:
                if not display_str:
                    display_str = '{}%'.format(int(100 * scores[i]))
                else:
                    display_str = '{}: {}%'.format(
                        display_str, int(100 * scores[i]))
            box_to_display_str_map[box].append(display_str)
            if agnostic_mode:
                box_to_color_map[box] = 'DarkOrange'
            else:
                box_to_color_map[box] = STANDARD_COLORS[classes[i] %
                                                        len(STANDARD_COLORS)]

    # Draw all boxes onto image.
    for box, color in box_to_color_map.items():
        ymin, xmin, ymax, xmax = box
        if instance_masks is not None:
            draw_mask_on_image_array(image, box_to_instance_masks_map[box], color=color)

        draw_bounding_box_on_image_array(
        image,
        ymin,
        xmin,
        ymax,
        xmax,
        color=color,
        thickness=line_thickness,
        display_str_list=box_to_display_str_map[box],
        use_normalized_coordinates=use_normalized_coordinates)

    return image


def reframe_box_masks_to_image_masks(box_masks,  boxes,  image_height,
                                     image_width):
    &quot;&quot;&quot;Transforms  the  box  masks  back  to  full  image  masks.

    Embeds  masks  in  bounding  boxes  of  larger  masks  whose  shapes  correspond  to
    image  shape.

    Args:
        box_masks:  A  tf.float32  tensor  of  size  [num_masks,  mask_height,  mask_width].
        boxes:  A  tf.float32  tensor  of  size  [num_masks,  4]  containing  the  box
                      corners.  Row  i  contains  [ymin,  xmin,  ymax,  xmax]  of  the  box
                      corresponding  to  mask  i.  Note  that  the  box  corners  are  in
                      normalized  coordinates.
        image_height:  Image  height.  The  output  mask  will  have  the  same  height  as
                                    the  image  height.
        image_width:  Image  width.  The  output  mask  will  have  the  same  width  as  the
                                  image  width.

    Returns:
        A  tf.float32  tensor  of  size  [num_masks,  image_height,  image_width].
    &quot;&quot;&quot;
    #  TODO(rathodv):  Make  this  a  public  function.
    def reframe_box_masks_to_image_masks_default():
        &quot;&quot;&quot;The  default  function  when  there  are  more  than  0  box  masks.&quot;&quot;&quot;
        def transform_boxes_relative_to_boxes(boxes,  reference_boxes):
            boxes = tf.reshape(boxes,  [-1,  2,  2])
            min_corner = tf.expand_dims(reference_boxes[:,  0:2],  1)
            max_corner = tf.expand_dims(reference_boxes[:,  2:4],  1)
            transformed_boxes = (boxes - min_corner) / \
                (max_corner - min_corner)
            return tf.reshape(transformed_boxes,  [-1,  4])

        box_masks_expanded = tf.expand_dims(box_masks,  axis=3)
        num_boxes = tf.shape(box_masks_expanded)[0]
        unit_boxes = tf.concat(
            [tf.zeros([num_boxes,  2]),  tf.ones([num_boxes,  2])],  axis=1)
        reverse_boxes = transform_boxes_relative_to_boxes(unit_boxes,  boxes)
        return tf.image.crop_and_resize(
            image=box_masks_expanded,
            boxes=reverse_boxes,
            box_ind=tf.range(num_boxes),
            crop_size=[image_height,  image_width],
            extrapolation_value=0.0)
    image_masks = tf.cond(
        tf.shape(box_masks)[0] &gt; 0,
        reframe_box_masks_to_image_masks_default,
        lambda:  tf.zeros([0,  image_height,  image_width,  1],  dtype=tf.float32))
    return tf.squeeze(image_masks,  axis=3)
</code></pre>

<p>Cho hình ảnh vào và rút ra kết quả.</p>

<pre><code class="language-python">
def detect_frame(image_np, sess, detection_graph):

    with detection_graph.as_default():

        ops = tf.get_default_graph().get_operations()
        all_tensor_names = {output.name for op in ops for output in op.outputs}
        tensor_dict = {}
        for key in [
            'num_detections', 'detection_boxes', 'detection_scores',
            'detection_classes', 'detection_masks'
        ]:
            tensor_name = key + ':0'
            if tensor_name in all_tensor_names:
                tensor_dict[key] = tf.get_default_graph(
                ).get_tensor_by_name(tensor_name)
        if 'detection_masks' in tensor_dict:
            # The following processing is only for single image
            detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])
            detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])
            # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.
            real_num_detection = tf.cast(
                tensor_dict['num_detections'][0], tf.int32)
           
            detection_boxes = tf.slice(detection_boxes, [0, 0], [
                                       real_num_detection, -1])
            detection_masks = tf.slice(detection_masks, [0, 0, 0], [
                                       real_num_detection, -1, -1])
            detection_masks_reframed = reframe_box_masks_to_image_masks(
                detection_masks, detection_boxes, image_np.shape[0], image_np.shape[1])
            detection_masks_reframed = tf.cast(
                tf.greater(detection_masks_reframed, 0.5), tf.uint8)
            # Follow the convention by adding back the batch dimension
            tensor_dict['detection_masks'] = tf.expand_dims(
                detection_masks_reframed, 0)
        image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')

      # Run inference
        output_dict = sess.run(tensor_dict,
                               feed_dict={image_tensor: np.expand_dims(image_np, 0)})

      # all outputs are float32 numpy arrays, so convert types as appropriate
        output_dict['num_detections'] = int(output_dict['num_detections'][0])
        #print(&quot;num detect &quot;+str(output_dict['num_detections']))
        output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(
            np.uint8)
        output_dict['detection_boxes'] = output_dict['detection_boxes'][0]
        output_dict['detection_scores'] = output_dict['detection_scores'][0]
        if 'detection_masks' in output_dict:
            output_dict['detection_masks'] = output_dict['detection_masks'][0]

        visualize_boxes_and_labels_on_image_array(
            image_np,
            output_dict['detection_boxes'],
            output_dict['detection_classes'],
            output_dict['detection_scores'],
            category_index,
            instance_masks=output_dict.get('detection_masks'),
            use_normalized_coordinates=True,
            line_thickness=1,
            max_boxes_to_draw=min(output_dict['num_detections'],20)
            )

    return image_np
</code></pre>

<pre><code class="language-python">image = cv2.imread('img2.jpg')
with detection_graph.as_default():
    with tf.Session(graph=detection_graph) as sess:
        image_np = detect_frame(image, sess, detection_graph)

cv2.imwrite('output.jpg', image)
</code></pre>

<p>Kết quả file output.jpg của chúng ta là:</p>

<p><img src="/post_image/mask_rnn_output_mieule.jpg" alt="Phân vùng của mark ca sĩ midu" /></p>

<p>Thử với bức ảnh người và xe hơi.</p>

<p><img src="/post_image/mask_rnn_output_nguoidep_xehoi.jpg" alt="Phân vùng của người và xe hơi" /></p>

<p>Cảm ơn các bạn đã theo dõi. Hẹn gặp bạn ở các bài viết tiếp theo.</p>

  </div>
  
		
  <footer class="col-md-10  mx-auto">
  <ul class="stats list-unstyled">
 
    
  <li class="tags">
    <ul class="list-inline">
       
            
            
                <i class="fa fa-tags"></i>
                
                
                <li class="list-inline-item"><a class="article-category-link" href="/tags/machine-learning">Machine learning</a></li>
                
                
                <li class="list-inline-item"><a class="article-category-link" href="/tags/deeplearning">Deeplearning</a></li>
                
                
                <li class="list-inline-item"><a class="article-category-link" href="/tags/spark">Spark</a></li>
                
            
        
    </ul>
  </li>
  
</ul>

  <div class="fb-like" data-share="true"  data-width="800"  data-show-faces="true">
</div>
    
  </footer>
  <hr/>
<div class="infinite-container featured-task col-md-8 mx-auto">
<div class="titlerelate">Bài viết khác</div>

<div class="card-deck card-break infinite-item">



    
        <div class="card  col-md-6" style="padding-top:15px;">
		<a href="/blog/2018-10-05-deep-learning-base-multiple-human-pose-estimation/"
                class="button big previous">
		
		<img class="card-img-top lazy" src="/thumbnails/post_estimator_shark.gif" width="100" />
		<div class="card-body">
		<h5 class="card-title">
		Deep Learning based Multiple Human Pose Estimation using OpenCV
				</h5>
				</div>
				</a>
				</div>
    

    
        <div class="card  col-md-6"  style="padding-top:15px;">
		<a href="/blog/2018-10-29-phan-loai-cho-meo/"
                class="button big previous">
		
		<img class="card-img-top lazy" src="/thumbnails/dot_cat_classification.jpg" width="100" />
		
		<div class="card-body">
		<h5 class="card-title">
		Phân loại chó mèo sử dụng pretrain model
				</h5>
				</div>
				</a>
				</div>
    

</div>
</div>



<div class="fb-comments" data-href="" data-width="" data-numposts="5"></div>

    <article class="post">
        
        <div class="disqus-comments">                  
            <button id="show-comments" class="btn btn-warning" type="button">Show <span class="disqus-comment-count" data-disqus-url="blog/2018-10-08-mask-rnn">comments</span></button>
            <div id="disqus_thread"></div>
          </div>
    </article>





		
    </main>
    
<section id="sidebar" class="col-md-3">
<br/>
<div>
		<ul class="list-group" id="news-contents"></ul>
    <div id="calander">
	</div>
    </div>

  
   
  
  
  
  
  
  
  
  
 

</section>

</div>
	</div>
    
	<hr>
  <footer class="footer">
  <div class="container text-center">
    
    <p class="copyright">
      
        &copy; 2021
        
          Phạm Duy Tùng Machine Learning Blog
        
      
     
    </p>
	</div>
	

      <div id="fb-root"></div>
      <script>
        window.fbAsyncInit = function() {
          FB.init({
            xfbml            : true,
            version          : 'v10.0'
          });
        };

        (function(d, s, id) {
        var js, fjs = d.getElementsByTagName(s)[0];
        if (d.getElementById(id)) return;
        js = d.createElement(s); js.id = id;
        js.src = 'https://connect.facebook.net/vi_VN/sdk/xfbml.customerchat.js';
        fjs.parentNode.insertBefore(js, fjs);
      }(document, 'script', 'facebook-jssdk'));</script>

      
      <div class="fb-customerchat"
        attribution="setup_tool"
        page_id="1244186728962161">
      </div>
  </footer>
    
    

    
      
    

    
      
      
      
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/highlight.min.js"></script>
        
        
        
        <script  src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/languages/python.min.js"></script>
        <script defer="defer" async="async">hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>
      
    
    
    
    <script defer="defer" src="https://cdnjs.cloudflare.com/ajax/libs/skel/3.0.1/skel.min.js"></script>
     

   <script  src="/js/jquery-2.2.4.min.js" data-cfasync="false"></script>
   
    <script defer="defer" async="async" src="/js/bootstrap.min.js"></script>
      <script defer="defer" async="async" src="/js/util.js"></script>
	  
      <script defer="defer"  src="/js/main.js"></script>
     
    

    
      
        
      
    
	
    
    
      

<script defer="defer" async="async" src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script  defer="defer" async="async" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


	  
	  
	   

<script id="dsq-count-scr" src="//phamduytung.disqus.com/count.js" async></script>

 <script defer="defer"   src="/js/jquery.amlich.js" data-cfasync="false" ></script>
	   <script defer="defer"   type="text/javascript"  data-cfasync="false">

  function getcontent(){
 

   

           
                }
            
			
			$(document).ready(function(){
      getcontent();
      $('#calander').amLich({
  type: 'calendar', 
  tableWidth: '100%' 
});
  

			}); 
			
			
			$(function(){
  $('#show-comments').on('click', function(){
    var disqus_shortname = 'phamduytung';

    (function() {
      var disqus = document.createElement('script'); 
      disqus.type = 'text/javascript'; 
      disqus.async = true;
      disqus.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(disqus);
    })();

    $(this).hide(); 
  });
});

var disqus_config = function () {
  this.page.url = 'blog\/2018-10-08-mask-rnn';
};
</script>


 


  </body>
</html>

